<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Yuan - 记录学习中的点点滴滴</title><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:type" content="website"><meta property="og:title" content="Yuan"><meta property="og:url" content="https://qiyuan-z.github.io/index.html"><meta property="og:site_name" content="Yuan"><meta property="og:description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><meta property="article:author" content="Qiyuan-Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:200,languages:{author:"作者: Qiyuan-Z",link:"链接: ",source:"来源: Yuan",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-right"},source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={isPost:!1,isHome:!0,isHighlightShrink:!1,isToc:!1,postUpdate:"2022-01-02 15:01:24"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));const n=saveToLocal.get("global-font-size");void 0!==n&&document.documentElement.style.setProperty("--global-font-size",n+"px")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/02/29/SSD/" title="SSD"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="SSD"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/29/SSD/" title="SSD">SSD</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-29T02:47:42.375Z" title="发表于 2020-02-29 10:47:42">2020-02-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">摘要本文提出了仅需要单个卷积神经网络就能完成目标检测的算法，并命名为SSD(Single Shot Detector)。SSD算法将目标框的输出空间离散化为一组在每个特征图位置不同大小和形状的默认框。预测时，网络对位于每个默认框类的物体类别进行打分，并修正默认框位置来更好的匹配物体的位置。此外，SSD网络在不同分辨率的特征图上预测，这样就可以处理大小不同的物体。SSD比那些需要搜索物体候选框的算法简单，因为它完全去除了proposal生成和随后的特征再筛选的过程，把所有的计算封装在一个网络里面。这使得SSD训练起来很容易，可以直接加入到检测系统里面。在PASCAL VOC，COCO,和ILSVRC数据集上的实验也证明，与那些需要object proposal的算法相比，SSD在保证准确性的同时，速度更快。SSD只需一个完整的框架来训练和测试。在NVIDIA Titan X对于一个大小是300 x 300的输入图像，SSD在VOC2007测试上的MAP是74.3%，速度是59FPS。对于512 x 512的输入，SSD的MAP是76.9%，比Faster RCNN更准。和其他单阶段的 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/02/26/Faster-RCNN/" title="Faster-RCNN"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Faster-RCNN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/26/Faster-RCNN/" title="Faster-RCNN">Faster-RCNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-26T05:41:21.531Z" title="发表于 2020-02-26 13:41:21">2020-02-26</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言我们知道RCNN和Fast-RCNN都是双阶段的算法，依赖于候选框搜索算法。而搜索算法是很慢的，这就导致这两个算法不能实时。基于这个重大缺点，Faster-RCNN算法问世。 贡献Fast-RCNN仍依赖于搜索候选框方法，其中以Selective Search为主。在Fast-RCNN给出的时间测试结果中，一张图片需要2.3s的前向推理时间，其中2s用于生成2000个ROI。可以看到整个算法的时间消耗几乎都在区域候选框搜索这个步骤了，如果我们能去掉候选框搜索这个过程是不是实时有希望了？Faster-RCNN就干了这件事，论文提出在内部使用深层网络代替候选区域。新的候选区域网络(RPN)在生成ROI的效率大大提升，一张图片只需要10毫秒！！！ 网络结构Faster-RCNN的网络结构如下图表示： 我们可以发现除了添加一个RPN网络之外，其他地方和Fast-RCNN是完全一致的。引用知乎上看到的一张更详细的网络结构如下： RPN网络RPN网络将第一个卷积网络(backbone，如VGG16,ResNet)的输出特征图作为输入。它在特征图上滑动一个$3 \times 3$的卷积核， ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/02/24/Fast-RCNN/" title="Fast RCNN"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Fast RCNN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/24/Fast-RCNN/" title="Fast RCNN">Fast RCNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-24T06:14:47.692Z" title="发表于 2020-02-24 14:14:47">2020-02-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言我们知道RCNN需要把每一个可能有目标的候选框搜索出来，然后把每个候选框传入CNN提取特征，每一张图片要产生大约2K个候选框，而每个框对应的图像都要传入CNN，这个时间开销肯定是很难承受的。基于RCNN这个致命问题，Fast-RCNN出现了。 算法介绍Fast-RCNN是在SPPNet和RCNN的基础上进行改进的。SPPNet的主要贡献是在整张图像上计算全局特征图，然后对于特定的proposal，只需要在全局特征图上取出对应坐标的特征图就可以了。但SPPNet仍然需要将特征保存在磁盘中，速度还是很慢。结合RCNN的思想，论文提出直接将候选框区域应用于特征图，并使用ROI Pooling将其转化为固定大小的特征图，最后再连接两个并行的分类头和回归头完成检测任务。整个算法可以用下面的图来表示： 贡献&amp;创新点 Fast-RCNN 只对整个图像进行一次特征提取，避免R-CNN的上千次特征提取。 使用ROI Pooling层替换最后一层的Max Pooling层，巧妙避免RCNN中的将每个候选框Resize到固定大小的操作。 Fast RCNN在网络的尾部采用并行的全连接层，可同时 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/02/24/RCNN/" title="RCNN"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="RCNN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/24/RCNN/" title="RCNN">RCNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-24T05:50:04.413Z" title="发表于 2020-02-24 13:50:04">2020-02-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">背景介绍什么是目标检测所谓目标检测就是在一张图像中找到我们关注的目标，并确定它的类别和位置，这是计算机视觉领域最核心的问题之一。由于各类目标不同的外观，颜色，大小以及在成像时光照，遮挡等具有挑战性的问题，目标检测一直处于不断的优化和研究中。 目标检测算法分类 这张甘特图已经说明了目标检测算法主要分为两类，即： Two Stage目标检测算法。这类算法都是先进行区域候选框生成，就是找到一个可能包含物体的预选框，再通过卷积神经网络进行分类和回归修正，常见算法有R-CNN，SPP-Net，Fast-RCNN，Faster-RCNN和R-FCN等。 One Stage目标检测算法。这类算法不使用候选框生成，直接在网络中提取特征来预测物体的分类和位置。常见的One-Stage算法有：YOLO系列，SSD，RetinaNet。 RCNN算法贡献RCNN是第一个使用卷积神经网络来对目标候选框提取特征的目标检测算法。同时，RCNN使用了微调(finetune)的技术，使用大数据集上训练好的分类模型的前几层做backbone，进行更有效的特征提取。 RCNN总览看下图： 首先，R-CNN是将传统图像 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/" title="ECCV 2018 Convolutional Block Attention Module"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="ECCV 2018 Convolutional Block Attention Module"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/" title="ECCV 2018 Convolutional Block Attention Module">ECCV 2018 Convolutional Block Attention Module</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-19T03:10:17.114Z" title="发表于 2020-02-19 11:10:17">2020-02-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言目前cv领域借鉴了nlp领域的attention机制以后生产出了很多有用的基于attention机制的论文，attention机制也是在2019年论文中非常火。这篇cbam虽然是在2018年提出的，但是其影响力比较深远，在很多领域都用到了该模块，所以一起来看一下这个模块有什么独到之处，并学着实现它。 什么是注意力机制？注意力机制（Attention Mechanism）是机器学习中的一种数据处理方法，广泛应用在自然语言处理、图像识别及语音识别等各种不同类型的机器学习任务中。 通俗来讲：注意力机制就是希望网络能够自动学出来图片或者文字序列中的需要注意的地方。比如人眼在看一幅画的时候，不会将注意力平等地分配给画中的所有像素，而是将更多注意力分配给人们关注的地方。 从实现的角度来讲：注意力机制通过神经网络的操作生成一个掩码mask,，mask上的值一个打分，评价当前需要关注的点的评分。 注意力机制可以分为： 通道注意力机制：对通道生成掩码mask，进行打分，代表是SENet, Channel Attention Module 空间注意力机制：对空间进行掩码的生成，进行打分，代表是Spa ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/02/19/%E6%9C%80%E7%AE%80%E5%8D%95%E6%9C%80%E6%98%93%E5%AE%9E%E7%8E%B0%E7%9A%84SE%E6%A8%A1%E5%9D%97/" title="最简单最易实现的SE模块"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="最简单最易实现的SE模块"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/19/%E6%9C%80%E7%AE%80%E5%8D%95%E6%9C%80%E6%98%93%E5%AE%9E%E7%8E%B0%E7%9A%84SE%E6%A8%A1%E5%9D%97/" title="最简单最易实现的SE模块">最简单最易实现的SE模块</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-19T02:51:28.774Z" title="发表于 2020-02-19 10:51:28">2020-02-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">Squeeze-and-Excitation NetworksSENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果比较好。 通过上图可以理解他的实现过程，通过对卷积的到的feature map进行处理，得到一个和通道数一样的一维向量作为每个通道的评价分数，然后将修改的分数分别施加到对应的通道上，得到其结果，就在原有的基础上只添加了一个模块，下边我们用pytorch实现这个很简单的模块。 12345678910111213141516class SELayer(nn.Module): def __init__(self, channel, reduction=16): super(SELayer, self).__init__() self.avg_pool = nn.Ad ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/03/02/FPN/" title="FPN"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="FPN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/02/FPN/" title="FPN">FPN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-02T03:16:50.715Z" title="发表于 2020-03-02 11:16:50">2020-03-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">背景Faster-RCNN选取一个特征提取网络如VGG16做backbone，然后在高层特征（如VGG16后面的conv4）接RPN和检测头进行网络。正是由于Faster-RCNN基于图像的高级特征，这就导致对小目标的检测效果很差。而CV领域常用的处理尺度问题的办法就是特征金字塔，将原图以不同的比例采样，然后得到不同分辨率的图像进行训练和测试，在多数情况下确实是有效的。但是特征金字塔的时间开销非常大，导致在工程中应用是及其困难。FPN从新的角度出发提出了一个独特的特征金字塔网络来避免图像金字塔产生的超高计算量，同时可以较好的处理目标检测中的尺度变化问题，对小目标检测更鲁棒，同时在VOC和COCO数据集上MAP值均超过了Faster-RCNN。 简介使用下图来阐释是如何处理尺度变化大的物体检测的。 上图(a)是处理这类问题最常用的方法，即特征金字塔，这种方法在传统的手动设计特征的方法中非常常用，例如DPM方法使用了接近10种不同的尺度获得了不错的效果。 上图(b)是在CNN提出之后出现的，因为神经网络模型对物体尺度本身有一定的鲁棒性，所以也取得了不错的性能，但最近的研究表明将特征金字 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/03/05/NIPS-2016-R-FCN%EF%BC%88%E6%9D%A5%E8%87%AA%E5%BE%AE%E8%BD%AF%E4%BD%95%E5%87%AF%E6%98%8E%E5%9B%A2%E9%98%9F%EF%BC%89/" title="NIPS 2016 R-FCN（来自微软何凯明团队）"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="NIPS 2016 R-FCN（来自微软何凯明团队）"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/05/NIPS-2016-R-FCN%EF%BC%88%E6%9D%A5%E8%87%AA%E5%BE%AE%E8%BD%AF%E4%BD%95%E5%87%AF%E6%98%8E%E5%9B%A2%E9%98%9F%EF%BC%89/" title="NIPS 2016 R-FCN（来自微软何凯明团队）">NIPS 2016 R-FCN（来自微软何凯明团队）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-05T02:56:07.488Z" title="发表于 2020-03-05 10:56:07">2020-03-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言R-FCN全称为Region-based Fully Convolutional Networks，是由微软的何凯明团队在NIPS 2016上提出来的，仍然是双阶段的目标检检测算法。论文地址和官方开源代码见文后。 背景R-FCN论文的发表时间比YOLO,SSD出来的都晚一些，并且这个算法更像是针对Faster-RCNN的一种改进，并且扔属于two-stage算法。那个R-FCN具体要解决什么问题呢？我们不妨先来看看R-FCN之前的典型的two-stage算法分别是在解决什么？ rcnn证明cnn具有良好的特征提取能力，也是第一个将cnn用来做目标检测任务的算法。 fast-rcnn提出ROI-Pooling将需要应用到多个候选框的骨干CNN网络进行共享，加快速度的同时也提升了准确率。 faster-rcnn解决了候选框搜索耗时过多的问题，提出RPN全卷积网络用于学习提取候选框，速度更快且精度更高。 而Faster-RCNN的一个缺点在于在ROI Pooling之后全是全连接层，从而将ROI Pooling之后的特征图映射为分类和回归两个任务。而越来越多的基础CNN架构如Goo ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/03/06/RetinaNet%EF%BC%88%E5%BC%95%E5%85%A5Focal-Loss%EF%BC%89/" title="RetinaNet（引入Focal Loss）"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="RetinaNet（引入Focal Loss）"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/06/RetinaNet%EF%BC%88%E5%BC%95%E5%85%A5Focal-Loss%EF%BC%89/" title="RetinaNet（引入Focal Loss）">RetinaNet（引入Focal Loss）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-06T02:46:14.942Z" title="发表于 2020-03-06 10:46:14">2020-03-06</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言今天来介绍一下目标检测算法中RetinaNet，这篇论文是CVPR2018的作品，Kaiming He大神也是作者之一，同时这篇论文提出的Focal Loss也对工程上训练更好的目标检测模型做出了很大贡献，论文地址为：https://arxiv.org/pdf/1708.02002.pdf 研究背景前面介绍了一些One-Stage目标检测算法和Two-Stage目标检测算法，这些算法在精度和速度上都各有特点，现在画个图总结一下之前介绍的各种算法的速度和精度： 可以看到One-Stage算法的精度相对于Two_Stage偏低，然后作者把这种问题的原因归结于正负类别不平衡（简单难分类别不平衡）。因此论文通过重新设计标准的交叉熵损失来解决这种难易样本不平衡的问题，即文章的核心Focal Loss。结合了Focal Loss的One-Stage的目标检测器被称为RetinaNet，该检测器在COCO数据集上MAP值可以和FPN（特征金字塔目标检测器）和MaskRCNN接近。 一些问题什么是hard/esay postive/negtive example网上找到一张图解释在目标检测任 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/03/07/ECCV-2018-RFBNet%EF%BC%8C%E5%9C%A8%E6%A3%80%E6%B5%8B%E4%B8%AD%E8%B0%83%E6%84%9F%E5%8F%97%E9%87%8E/" title="ECCV 2018 RFBNet，在检测中调感受野"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="ECCV 2018 RFBNet，在检测中调感受野"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/07/ECCV-2018-RFBNet%EF%BC%8C%E5%9C%A8%E6%A3%80%E6%B5%8B%E4%B8%AD%E8%B0%83%E6%84%9F%E5%8F%97%E9%87%8E/" title="ECCV 2018 RFBNet，在检测中调感受野">ECCV 2018 RFBNet，在检测中调感受野</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-07T03:13:19.856Z" title="发表于 2020-03-07 11:13:19">2020-03-07</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言看了不少的目标检测论文了，个人认为多数论文的出发点就两个，一是感受野，二是特征融合。此外，解决数据不平衡和轻量化也是另外两个重要的方向。今天为大家科普一篇ECCV 2018的一篇目标检测网络RFBNet就是从感受野角度来改善了SSD检测器，论文全名为：Receptive Field Block Net for Accurate and Fast Object Detection 。这篇论文主要的贡献点主要是在SSD网络中提出了一个Receptive Field Block (RFB) 模块，RFB模块主要是在Inception的基础上加入了空洞卷积层从而有效的增大了感受野。另外，RFB模块是嵌在SSD上的，所以检测的速度比较快，精度比SSD更高。 RFB模块RFB模块的效果示意图如图所示，其中虚线部分就是指RFB模块。 RFB模块主要有两个特点： RFB模块有多个分支，每个分支的第一层都由特定大小卷积核的卷积核构成，例如图上的1 x 1， 3 x 3，5 x 5。 RFB模块引入了空洞卷积，主要作用是为了增加感受野，空洞卷积之前是应用在分割网络DeepLab中，这里将其应用 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"><div class="author-info__name">Qiyuan-Z</div><div class="author-info__description">偉大な魂は目的を持ち、そうでないものは願望を持つ</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Qiyuan-Z" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zhengqiyuan@stu.jiangnan.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-pixiv"><div class="card-content"><div class="item-headline"><i class="fa fa-image" aria-hidden="true"></i><span>Pixiv日榜Top50</span><iframe src="https://fun.hujingnb.com/pixiv/i" frameborder="0" style="width:99%;height:380px;margin:0"></iframe></div></div></div><div class="sticky_layout"><div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height:100px;overflow:hidden"><div class="history_swiper-container" id="history-container" style="width:100%;height:100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/06/%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87Latex%E6%A8%A1%E6%9D%BF/" title="江南大学学位论文LaTeX模板">江南大学学位论文LaTeX模板</a><time datetime="2021-12-06T06:47:38.303Z" title="发表于 2021-12-06 14:47:38">2021-12-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/25/keras%E8%BD%AConnx/" title="keras/tensorflow转onnx">keras/tensorflow转onnx</a><time datetime="2021-09-25T08:25:42.672Z" title="发表于 2021-09-25 16:25:42">2021-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/03/09/Leetcode%E5%88%B7%E9%A2%98/" title="Leetcode刷题(Python3及Java实现)">Leetcode刷题(Python3及Java实现)</a><time datetime="2021-03-09T10:57:57.768Z" title="发表于 2021-03-09 18:57:57">2021-03-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/12/11/EndNote%E6%A0%B7%E5%BC%8F%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="EndNote样式使用教程">EndNote样式使用教程</a><time datetime="2020-12-11T12:36:41.848Z" title="发表于 2020-12-11 20:36:41">2020-12-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/12/11/%E5%8E%86%E5%B1%8ACCF%E9%A1%B6%E4%BC%9A%E5%9C%B0%E7%82%B9%E6%9F%A5%E8%AF%A2/" title="历届CCF顶会地点查询">历届CCF顶会地点查询</a><time datetime="2020-12-11T04:04:06.233Z" title="发表于 2020-12-11 12:04:06">2020-12-11</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size:1.5em;color:#75c625">目标检测</a><a href="/tags/YOLOv3/" style="font-size:1.39em;color:#4c9208">YOLOv3</a><a href="/tags/Ubuntu/" style="font-size:1.44em;color:#5ab075">Ubuntu</a><a href="/tags/Attention%E6%9C%BA%E5%88%B6/" style="font-size:1.16em;color:#c79026">Attention机制</a><a href="/tags/Fast-RCNN/" style="font-size:1.1em;color:#5d9a44">Fast RCNN</a><a href="/tags/Latex/" style="font-size:1.16em;color:#b31272">Latex</a><a href="/tags/potplayer/" style="font-size:1.1em;color:#3daf5e">potplayer</a><a href="/tags/Python/" style="font-size:1.33em;color:#906daa">Python</a><a href="/tags/Opencv/" style="font-size:1.16em;color:#29229d">Opencv</a><a href="/tags/PyQt5/" style="font-size:1.1em;color:#aba1ad">PyQt5</a><a href="/tags/Pycharm/" style="font-size:1.16em;color:#9e108e">Pycharm</a><a href="/tags/SSH/" style="font-size:1.16em;color:#13c8bc">SSH</a><a href="/tags/Pytorch/" style="font-size:1.21em;color:#954b59">Pytorch</a><a href="/tags/RCNN/" style="font-size:1.1em;color:#a21d7d">RCNN</a><a href="/tags/CUDA/" style="font-size:1.1em;color:#26a654">CUDA</a><a href="/tags/cuDNN/" style="font-size:1.1em;color:#781e69">cuDNN</a><a href="/tags/Proxy/" style="font-size:1.27em;color:#355650">Proxy</a><a href="/tags/Tensorflow/" style="font-size:1.16em;color:#bb1031">Tensorflow</a><a href="/tags/virtualenv/" style="font-size:1.1em;color:#13ac49">virtualenv</a><a href="/tags/C/" style="font-size:1.16em;color:#b98e6d">C++</a><a href="/tags/VSCode/" style="font-size:1.21em;color:#ba5b77">VSCode</a><a href="/tags/Xshell/" style="font-size:1.1em;color:#615337">Xshell</a><a href="/tags/Windows10/" style="font-size:1.1em;color:#af59b2">Windows10</a><a href="/tags/VNC/" style="font-size:1.1em;color:#af8556">VNC</a><a href="/tags/arxiv/" style="font-size:1.1em;color:#9f1639">arxiv</a><a href="/tags/Keras/" style="font-size:1.1em;color:#808ba7">Keras</a><a href="/tags/onnx/" style="font-size:1.1em;color:#b693b7">onnx</a><a href="/tags/Teamviewer/" style="font-size:1.1em;color:#6d342b">Teamviewer</a><a href="/tags/Onedrive/" style="font-size:1.16em;color:#1b3a0a">Onedrive</a><a href="/tags/frp/" style="font-size:1.1em;color:#900a6c">frp</a><a href="/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/" style="font-size:1.1em;color:#5cc780">路由器</a><a href="/tags/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/" style="font-size:1.1em;color:#7f9635">百度网盘</a><a href="/tags/leetcode/" style="font-size:1.1em;color:#2d59ae">leetcode</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多"><i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/09/"><span class="card-archive-list-date">九月 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">八月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/07/"><span class="card-archive-list-date">七月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/06/"><span class="card-archive-list-date">六月 2020</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">115</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">292.5k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2022-01-02T07:01:21.891Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022<i id="heartbeat" class="fa fas fa-heartbeat"></i> Qiyuan-Z</div><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为 Hexo" alt="HEXO"></a><a style="margin-inline:5px" target="_blank" href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用 Butterfly" alt="Butterfly"></a><a style="margin-inline:5px" target="_blank" href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用 Jsdelivr 为静态资源提供CDN加速" alt="Jsdelivr"></a><a style="margin-inline:5px" target="_blank" href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由 GitHub 托管" alt="GitHub"></a><a style="margin-inline:5px" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" alt="img" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a><br>昨日までの私は、もうどこにもいない<br></p></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",preloader.endLoading())</script><div class="js-pjax"></div><script defer src="https://cdn.jsdelivr.net/gh/Qiyuan-Z/live2d-widget/autoload.js"></script><script src="https://unpkg.com/swiper/swiper-bundle.min.js"></script><script src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>