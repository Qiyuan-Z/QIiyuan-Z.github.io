<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Yuan - 记录学习中的点点滴滴</title><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:type" content="website"><meta property="og:title" content="Yuan"><meta property="og:url" content="https://qiyuan-z.github.io/page/2/index.html"><meta property="og:site_name" content="Yuan"><meta property="og:description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><meta property="article:author" content="Qiyuan-Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:200,languages:{author:"作者: Qiyuan-Z",link:"链接: ",source:"来源: Yuan",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-right"},source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={isPost:!1,isHome:!0,isHighlightShrink:!1,isToc:!1,postUpdate:"2022-01-02 20:09:29"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));const n=saveToLocal.get("global-font-size");void 0!==n&&document.documentElement.style.setProperty("--global-font-size",n+"px")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/03/03/NMS%E5%90%8E%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3/" title="NMS后处理相关"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="NMS后处理相关"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/03/NMS%E5%90%8E%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3/" title="NMS后处理相关">NMS后处理相关</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-03T03:16:05.447Z" title="发表于 2020-03-03 11:16:05">2020-03-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">介绍非极大值抑制(Non-Maximum Suppression，NMS)，顾名思义就是抑制不是极大值的元素。在目标检测任务，例如行人检测中，滑动窗口经过特征提取和分类器识别后，每个窗口都会得到一个分数。但滑动窗口会导致很多窗口和其它窗口存在包含大部分交叉的情况。这个时候就需要用到NMS来选取那些邻域里分数最高，同时抑制那些分数低的窗口。 原理在目标检测任务中，定义最后的候选框集合为$B$，每个候选框对应的置信度是$S$，IOU阈值设为$T$，然后NMS的算法过程可以表示如下： 选择具有最大score的候选框$M$ 将$M$从集合$B$中移除并加入到最终的检测结果$D$中 将$B$中剩余检测框中和$M$的交并比(IOU)大于阈值$T$的框从$B$中移除 重复上面的步骤，直到$B$为空 代码实现rgb大神实现Faster-RCNN中的单类别物体nms代码解释如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 -------------------------- ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/05/08/%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AL1-loss,-L2-loss%E4%BB%A5%E5%8F%8ASmooth-L1-Loss%E7%9A%84%E5%AF%B9%E6%AF%94/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/08/%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AL1-loss,-L2-loss%E4%BB%A5%E5%8F%8ASmooth-L1-Loss%E7%9A%84%E5%AF%B9%E6%AF%94/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比">回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-08T03:58:11.819Z" title="发表于 2020-05-08 11:58:11">2020-05-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言总结对比下$L_{1}$损失函数，$L_{2}$损失函数以及损$SmoothL_{1}$失函数的优缺点。 均方误差MSE ($L_{2}$ Loss)均方误差（Mean Square Error,MSE）是模型预测值$f(x)$与真实样本值$y$之间差值平方的平均值，其公式如下 M S E=\frac{\sum_{i=1}^{n}\left(f_{x_{i}}-y_{i}\right)^{2}}{n}其中，$\boldsymbol{y}_{i}$和$f\left(x_{i}\right)$分别表示第$i$个样本的真实值及其对应的预测值，$n$为样本的个数。 忽略下标$i$ ，设$n=1$，以$f(x)−y$为横轴，MSE的值为纵轴，得到函数的图形如下： MSE的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。 而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。 当$y$和$f(x)$也就是真实值和预测值的差值大于1时，会放大误差；而当差值小于1时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差（& ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/" title="CNN结构无痛涨点技巧：ACNet"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="CNN结构无痛涨点技巧：ACNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/" title="CNN结构无痛涨点技巧：ACNet">CNN结构无痛涨点技巧：ACNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-17T02:54:37.109Z" title="发表于 2020-04-17 10:54:37">2020-04-17</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言CNN的结构创新在这两年已经变得相对很少了，同时要做出有影响力并且Solid的工作也变得越来越难，最近CNN结构方面的创新主要包含两个方面： 网络结构搜索，以Google Brain的EfficientNet为代表作。 获取更好的特征表达，主要是将特征复用，特征细化做得更加极致，以HRNet，Res2Net等为代表作。 本文要介绍的是ICCV 2019的一个新CNN架构ACNet（全称为Asymmetric Convolution Net），因此这篇文章的目的是讲清楚ACNet的原理并总结它的核心思想，另外借助作者开源的Pytorch代码端来加深理解。 介绍ACNet的切入点为获取更好的特征表达，但和其它方法最大的区别在于它没有带来额外的超参数，而且在推理阶段没有增加计算量，这是十分具有吸引力的。 在正式介绍ACNet之前，首先来明确一下关于卷积计算的一个等式，这个等式表达的意思就是「对于输入特征图$I$，先进行$K^{(1)}$和$I$卷积，$K^{(2)}$和$I$卷积后再对结果进行相加，与先进行$K^{(1)}$和$K^{(2)}$的逐点相加后再和$I$进行卷积得到的结 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Perceptual Generative Adversarial Networks for Small Object Detection"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection">Perceptual Generative Adversarial Networks for Small Object Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-09T06:25:22.859Z" title="发表于 2020-05-09 14:25:22">2020-05-09</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">详解 小目标检测的一个常用思路是提升图片输入分辨率，来增强小目标的分辨率和生成高分辨率的特征图，但这会导致训练和验证极度费时。 本文提出的PGAN方法对小目标生成高分辨率特征表示，使小目标的特征表示与大目标特征表示类似。 生成器网络通过较前层提取细粒度特征将小目标分辨率较低的特征转换为分辨率较高的特征。 判别器网络不仅用于生成小目标高分辨表示，同时证明带感知损失的生成高分辨率特征对检测准确率是有帮助的。 生成器网络被训练欺骗辨别器通过产生最像大目标表征的小目标，同时提升检测准确率。 辨别器被训练用于提升正确从实际大目标中分辨出生成的高分辨率表征，同时将定位准确率反馈给生成器。 小目标检测典型应用领域：交通标志检测、行人检测 perception branch（感知分支）首先利用仅包含大目标的图片进行训练，然后利用仅包含小目标的图片进行训练，generator network 被训练用于对小目标生成高分辨率的类似大目标的表征。adversarial branch被训练用于区分生成的小目标高分辨率表征与实际大目标的原始表征。 generator 从底层提取细粒度特征，放入深度残差网络 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-%E2%80%93-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="An Analysis of Scale Invariance in Object Detection – SNIP"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-%E2%80%93-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP">An Analysis of Scale Invariance in Object Detection – SNIP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-08T05:50:38.647Z" title="发表于 2020-05-08 13:50:38">2020-05-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">动机概括而言，这篇文章从COCO数据集开始分析，认为目前目标检测算法的难点在于数据集中object的尺寸分布较大，尤其对于小目标的检测效果也有待提高，因此提出Scale Normalization for Image Pyramids (SNIP)算法来解决这个问题。 作者将数据集按照图像中目标的尺寸/图像尺寸进行排序，在ImageNet数据集中，这个倍数的中位数差不多0.554，而在COCO数据集中，这个数是0.106。如Figure1中两条线标出的Median点所示。Figure1是关于ImageNet和COCO数据集中object尺寸和图像尺寸的倍数关系曲线，横坐标表示object的尺寸/图像尺寸的值，纵坐标表示占比。也就是说在COCO数据集中，大部分的object面积只有图像面积的1%以下，这说明在COCO数据集中小目标占比要比ImageNet数据集大。另外，从Figure1中的COCO曲线可以看出，第90%的倍数（0.472）差不多是第10%的倍数（0.106）的20倍！这说明在COCO数据集中的object尺寸变化范围非常大。 那么这种差异会带来什么影响呢？因为在目标检测 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/" title="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/" title="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）">ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-18T02:06:17.892Z" title="发表于 2020-04-18 10:06:17">2020-04-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言这是一篇图森科技在ICCV 2019的目标检测论文《Scale-Aware Trident Networks for Object Detection》，简称TridentNet，中文翻译为三叉戟网络。 背景我们知道在目标检测任务中，尺度变化一直是很关键的问题。针对尺度变化问题，也有很多的方案被提出，如Figure 1所示： 其中 (a)图表示多尺度图像金字塔网络，直接对图像进行不同尺度的缩放。 (b)是FPN网络，借鉴了金字塔结构将分辨率信息和语义信息相结合，克服不同层，不同尺度带来的问题。 这两种方法的目的都是让模型对尺寸不同的目标具有不同的感受野。除此之外还有SNIP，SNIP主要包含了两个改进点： 1、为了减少domain-shift，在梯度回传的时候只将和预训练模型所基于的训练数据尺寸相应的ROI的梯度进行回传。 2、借鉴了多尺度训练思想，引入图像金字塔来处理数据集中不同尺寸的数据。虽然图像金字塔的效率比较低，但通过对原图不同比例的缩放，充分利用了模型的表征能力。相比之下，FPN产生多层次的特征，但也牺牲了不同尺度下的特征一致性。 总结一下就是，图像金字塔虽然慢但是精度 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/" title="两阶段实时检测网络ThunderNet"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="两阶段实时检测网络ThunderNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/" title="两阶段实时检测网络ThunderNet">两阶段实时检测网络ThunderNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-30T01:33:48.689Z" title="发表于 2020-04-30 09:33:48">2020-04-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言ThunderNet是旷视和国防科技大学合作提出的目标检测模型，目标是在计算力受限的平台进行实时目标检测。需要关注的地方主要就是提出的两个特征增强模块CEM和SAM,其设计理念和应用的方法都非常值得借鉴。 介绍在移动端的实时目标检测是一个极为重要并且有挑战性的视觉问题。很多基于CNN的检测器都有巨大的计算量，所以在计算受限的场景下难以进行实时推理。论文提出了一个轻量级的两阶段的检测方法-ThunderNet。 在backbone部分，分析了以往的轻量级backbone的不足并提出了一个专门用于目标检测的轻量级基础网络-SNet。 在detection部分，提出一个有效的RPN和检测头。其中涉及到两个特征增强模块： Context Enhancement Module(CEM) 用于整合局部和全局特征。 Spatial Attention Module(SAM)引入RPN前后背景信息用以优化特征分布。 对目标输入分辨率、Backbone、检测头三个部分进行了平衡。 最终ThunderNet可以在ARM设备上达到24.1fps的速度，精度和速度上超过了很多一阶段检测器。 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/" title="自适应空间特征融合 (ASFF)"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="自适应空间特征融合 (ASFF)"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/" title="自适应空间特征融合 (ASFF)">自适应空间特征融合 (ASFF)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-20T03:35:51.667Z" title="发表于 2020-04-20 11:35:51">2020-04-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言这是2019年的一篇论文 《Learning Spatial Fusion for Single-Shot Object Detection》，这篇论文主要是因为其提出的 自适应空间特征融合 (ASFF)被大家所熟知。金字塔特征表示法(FPN)是解决目标检测尺度变化挑战的常用方法。但是，对于基于FPN的单级检测器来说，不同特征尺度之间的不一致是其主要限制。因此这篇论文提出了一种新的数据驱动的金字塔特征融合方式，称之为自适应空间特征融合（ASFF）。它学习了在空间上过滤冲突信息以抑制梯度反传的时候不一致的方法，从而改善了特征的比例不变性，并且推理开销降低。借助ASFF策略和可靠的YOLOV3 BaseLine，在COCO数据集上实现了45FPS/42.4%AP以及29FPS/43.9%AP。下面先放一张论文的结果图。 一个更强的YOLOV3基准这篇文章之所以取得这么好的效果不仅仅是因为它提出的ASFF这种特征自适应融合方式，论文在YOLOV3的基础上集百家之长，构建了一个非常强的YOLOV3 BaseLine，这个BaseLine在MSCOCO上的mAP就达到了38.8%。相比 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/02/19/%E6%9C%80%E7%AE%80%E5%8D%95%E6%9C%80%E6%98%93%E5%AE%9E%E7%8E%B0%E7%9A%84SE%E6%A8%A1%E5%9D%97/" title="最简单最易实现的SE模块"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="最简单最易实现的SE模块"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/19/%E6%9C%80%E7%AE%80%E5%8D%95%E6%9C%80%E6%98%93%E5%AE%9E%E7%8E%B0%E7%9A%84SE%E6%A8%A1%E5%9D%97/" title="最简单最易实现的SE模块">最简单最易实现的SE模块</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-19T02:51:28.774Z" title="发表于 2020-02-19 10:51:28">2020-02-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">Squeeze-and-Excitation NetworksSENet是Squeeze-and-Excitation Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果比较好。 通过上图可以理解他的实现过程，通过对卷积的到的feature map进行处理，得到一个和通道数一样的一维向量作为每个通道的评价分数，然后将修改的分数分别施加到对应的通道上，得到其结果，就在原有的基础上只添加了一个模块，下边我们用pytorch实现这个很简单的模块。 12345678910111213141516class SELayer(nn.Module): def __init__(self, channel, reduction=16): super(SELayer, self).__init__() self.avg_pool = nn.Ada ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/" title="ECCV 2018 Convolutional Block Attention Module"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="ECCV 2018 Convolutional Block Attention Module"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/" title="ECCV 2018 Convolutional Block Attention Module">ECCV 2018 Convolutional Block Attention Module</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-19T03:10:17.114Z" title="发表于 2020-02-19 11:10:17">2020-02-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言目前cv领域借鉴了nlp领域的attention机制以后生产出了很多有用的基于attention机制的论文，attention机制也是在2019年论文中非常火。这篇cbam虽然是在2018年提出的，但是其影响力比较深远，在很多领域都用到了该模块，所以一起来看一下这个模块有什么独到之处，并学着实现它。 什么是注意力机制？注意力机制（Attention Mechanism）是机器学习中的一种数据处理方法，广泛应用在自然语言处理、图像识别及语音识别等各种不同类型的机器学习任务中。 通俗来讲：注意力机制就是希望网络能够自动学出来图片或者文字序列中的需要注意的地方。比如人眼在看一幅画的时候，不会将注意力平等地分配给画中的所有像素，而是将更多注意力分配给人们关注的地方。 从实现的角度来讲：注意力机制通过神经网络的操作生成一个掩码mask,，mask上的值一个打分，评价当前需要关注的点的评分。 注意力机制可以分为： 通道注意力机制：对通道生成掩码mask，进行打分，代表是SENet, Channel Attention Module 空间注意力机制：对空间进行掩码的生成，进行打分，代表是Spa ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" href="/page/3/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"><div class="author-info__name">Qiyuan-Z</div><div class="author-info__description">偉大な魂は目的を持ち、そうでないものは願望を持つ</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">115</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">33</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Qiyuan-Z" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zhengqiyuan@stu.jiangnan.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-pixiv"><div class="card-content"><div class="item-headline"><i class="fa fa-image" aria-hidden="true"></i><span>Pixiv日榜Top50</span><iframe src="https://fun.hujingnb.com/pixiv/i" frameborder="0" style="width:99%;height:380px;margin:0"></iframe></div></div></div><div class="sticky_layout"><div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height:100px;overflow:hidden"><div class="history_swiper-container" id="history-container" style="width:100%;height:100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/06/%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87Latex%E6%A8%A1%E6%9D%BF/" title="江南大学学位论文LaTeX模板">江南大学学位论文LaTeX模板</a><time datetime="2021-12-06T06:47:38.303Z" title="发表于 2021-12-06 14:47:38">2021-12-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/25/keras%E8%BD%AConnx/" title="keras/tensorflow转onnx">keras/tensorflow转onnx</a><time datetime="2021-09-25T08:25:42.672Z" title="发表于 2021-09-25 16:25:42">2021-09-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/03/09/Leetcode%E5%88%B7%E9%A2%98/" title="Leetcode刷题(Python3及Java实现)">Leetcode刷题(Python3及Java实现)</a><time datetime="2021-03-09T10:57:57.768Z" title="发表于 2021-03-09 18:57:57">2021-03-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/12/11/EndNote%E6%A0%B7%E5%BC%8F%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/" title="EndNote样式使用教程">EndNote样式使用教程</a><time datetime="2020-12-11T12:36:41.848Z" title="发表于 2020-12-11 20:36:41">2020-12-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2020/12/11/%E5%8E%86%E5%B1%8ACCF%E9%A1%B6%E4%BC%9A%E5%9C%B0%E7%82%B9%E6%9F%A5%E8%AF%A2/" title="历届CCF顶会地点查询">历届CCF顶会地点查询</a><time datetime="2020-12-11T04:04:06.233Z" title="发表于 2020-12-11 12:04:06">2020-12-11</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size:1.5em;color:#88b79d">目标检测</a><a href="/tags/YOLOv3/" style="font-size:1.39em;color:#481aa7">YOLOv3</a><a href="/tags/Ubuntu/" style="font-size:1.44em;color:#275ca3">Ubuntu</a><a href="/tags/Attention%E6%9C%BA%E5%88%B6/" style="font-size:1.16em;color:#168fb8">Attention机制</a><a href="/tags/Fast-RCNN/" style="font-size:1.1em;color:#965a91">Fast RCNN</a><a href="/tags/Latex/" style="font-size:1.16em;color:#649da2">Latex</a><a href="/tags/potplayer/" style="font-size:1.1em;color:#7dbf0d">potplayer</a><a href="/tags/Python/" style="font-size:1.33em;color:#b50a4e">Python</a><a href="/tags/Opencv/" style="font-size:1.16em;color:#623414">Opencv</a><a href="/tags/PyQt5/" style="font-size:1.1em;color:#195b78">PyQt5</a><a href="/tags/Pycharm/" style="font-size:1.16em;color:#22363e">Pycharm</a><a href="/tags/SSH/" style="font-size:1.16em;color:#2db47c">SSH</a><a href="/tags/Pytorch/" style="font-size:1.21em;color:#b91888">Pytorch</a><a href="/tags/RCNN/" style="font-size:1.1em;color:#c52b38">RCNN</a><a href="/tags/CUDA/" style="font-size:1.1em;color:#136332">CUDA</a><a href="/tags/cuDNN/" style="font-size:1.1em;color:#0a2a0b">cuDNN</a><a href="/tags/Proxy/" style="font-size:1.27em;color:#379f7e">Proxy</a><a href="/tags/Tensorflow/" style="font-size:1.16em;color:#b64a84">Tensorflow</a><a href="/tags/virtualenv/" style="font-size:1.1em;color:#3165a5">virtualenv</a><a href="/tags/C/" style="font-size:1.16em;color:#91265e">C++</a><a href="/tags/VSCode/" style="font-size:1.21em;color:#5a2108">VSCode</a><a href="/tags/Xshell/" style="font-size:1.1em;color:#2a0685">Xshell</a><a href="/tags/Windows10/" style="font-size:1.1em;color:#6f625c">Windows10</a><a href="/tags/VNC/" style="font-size:1.1em;color:#3cc56f">VNC</a><a href="/tags/arxiv/" style="font-size:1.1em;color:#c8964a">arxiv</a><a href="/tags/Keras/" style="font-size:1.1em;color:#b80127">Keras</a><a href="/tags/onnx/" style="font-size:1.1em;color:#05900f">onnx</a><a href="/tags/Teamviewer/" style="font-size:1.1em;color:#503328">Teamviewer</a><a href="/tags/Onedrive/" style="font-size:1.16em;color:#54607a">Onedrive</a><a href="/tags/frp/" style="font-size:1.1em;color:#3b121f">frp</a><a href="/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/" style="font-size:1.1em;color:#0d5266">路由器</a><a href="/tags/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/" style="font-size:1.1em;color:#8b2233">百度网盘</a><a href="/tags/leetcode/" style="font-size:1.1em;color:#7a5d11">leetcode</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多"><i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/09/"><span class="card-archive-list-date">九月 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">八月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/07/"><span class="card-archive-list-date">七月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/06/"><span class="card-archive-list-date">六月 2020</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">115</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">292.5k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2022-01-02T12:09:27.516Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022<i id="heartbeat" class="fa fas fa-heartbeat"></i> Qiyuan-Z</div><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为 Hexo" alt="HEXO"></a><a style="margin-inline:5px" target="_blank" href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用 Butterfly" alt="Butterfly"></a><a style="margin-inline:5px" target="_blank" href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用 Jsdelivr 为静态资源提供CDN加速" alt="Jsdelivr"></a><a style="margin-inline:5px" target="_blank" href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由 GitHub 托管" alt="GitHub"></a><a style="margin-inline:5px" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" alt="img" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a><br>昨日までの私は、もうどこにもいない<br></p></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",preloader.endLoading())</script><div class="js-pjax"></div><script defer src="https://cdn.jsdelivr.net/gh/Qiyuan-Z/live2d-widget/autoload.js"></script><script src="https://unpkg.com/swiper/swiper-bundle.min.js"></script><script src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>