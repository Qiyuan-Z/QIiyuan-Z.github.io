<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Yuan - 记录学习中的点点滴滴</title><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:type" content="website"><meta property="og:title" content="Yuan"><meta property="og:url" content="https://qiyuan-z.github.io/page/8/index.html"><meta property="og:site_name" content="Yuan"><meta property="og:description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><meta property="article:author" content="Qiyuan-Z"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://qiyuan-z.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/page/8/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:200,languages:{author:"作者: Qiyuan-Z",link:"链接: ",source:"来源: Yuan",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#121212",position:"bottom-right"},source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={isPost:!1,isHome:!0,isHighlightShrink:!1,isToc:!1,postUpdate:"2022-01-12 15:05:00"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){if(0===o)return;const n=864e5*o,a={value:t,expiry:(new Date).getTime()+n};localStorage.setItem(e,JSON.stringify(a))},get:function(e){const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!((new Date).getTime()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=e=>new Promise((t,o)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=o,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,t())},document.head.appendChild(n)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme");"dark"===t?activateDarkMode():"light"===t&&activateLightMode();const o=saveToLocal.get("aside-status");void 0!==o&&("hide"===o?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));const n=saveToLocal.get("global-font-size");void 0!==n&&document.documentElement.style.setProperty("--global-font-size",n+"px")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.com/swiper/swiper-bundle.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">121</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/"><i class="fa-fw fas fa-video"></i> <span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7/" title="目标检测算法优化技巧"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="目标检测算法优化技巧"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7/" title="目标检测算法优化技巧">目标检测算法优化技巧</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-08T03:08:33.892Z" title="发表于 2020-04-08 11:08:33">2020-04-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">简介目标检测模型相比于分类模型的研究相比，更缺少普遍性，并且网络结构和优化目标更加复杂。 本文主要是基于Faster R-CNN和YOLOv3来探索目标检测网络的调整策略。这些策略不会改变模型的结构，也不会引入额外的计算代价。通过使用这些trick，可以比SOTA提高最多5个百分点。 19年由亚马逊团队发表的《Bag of Freebies for Training Object Detection Neural Networks》。在使用了trick后，Faster R-CNN能提高1-2个百分点，而YOLOv3则提高了5个百分点。 Trickmixupmixup也是图片分类中的一个非常有效的trick, 具体流程如下图所示： 简单来讲就是将两张图片通过不同的比例进行融合，同时图片对应的one-hot编码也以相同的比例相乘，从而构造出新的数据集。本质上，mixup在成对样本及其标签的凸组合（convex combinations）上训练神经网络，可以规范神经网络，增强训练样本之间的线性表达。其优点是： 改善了网络模型的泛化能力 减少对错误标签的记忆 增加对抗样本的鲁棒性 稳定 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/02/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86%E5%92%8C%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E9%9B%86/" title="目标检测算法的评价标准和常见数据集"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="目标检测算法的评价标准和常见数据集"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/02/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86%E5%92%8C%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E9%9B%86/" title="目标检测算法的评价标准和常见数据集">目标检测算法的评价标准和常见数据集</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-02-14T03:50:54.723Z" title="发表于 2020-02-14 11:50:54">2020-02-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">评价指标1.准确率(Accuracy)检测时分对的样本数除以所有的样本数。准确率一般被用来评估检测模型的全局准确程度，包含的信息有限，不能完全评价一个模型性能。 2.混淆矩阵(Confusion Matrix)混淆矩阵是以模型预测的类别数量统计信息为横轴，真实标签的数量统计信息为纵轴画出的矩阵。对角线代表了模型预测和数据标签一致的数目，所以准确率也可以用混淆矩阵对角线之和除以测试集图片数量来计算。对角线上的数字越大越好，在混淆矩阵可视化结果中颜色越深，代表模型在该类的预测结果更好。其他地方自然是预测错误的地方，自然值越小，颜色越浅说明模型预测的更好。 3.精确率(Precision)和召回率(Recall)和PR曲线一个经典例子是存在一个测试集合，测试集合只有大雁和飞机两种图片组成，假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片。然后就可以定义： True positives: 简称为TP，即正样本被正确识别为正样本，飞机的图片被正确的识别成了飞机。 True negatives: 简称为TN，即负样本被正确识别为负样本，大雁的图片没有被识别出来，系统正 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/03/03/NMS%E5%90%8E%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3/" title="NMS后处理相关"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="NMS后处理相关"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/03/03/NMS%E5%90%8E%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3/" title="NMS后处理相关">NMS后处理相关</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-03-03T03:16:05.447Z" title="发表于 2020-03-03 11:16:05">2020-03-03</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">介绍非极大值抑制(Non-Maximum Suppression，NMS)，顾名思义就是抑制不是极大值的元素。在目标检测任务，例如行人检测中，滑动窗口经过特征提取和分类器识别后，每个窗口都会得到一个分数。但滑动窗口会导致很多窗口和其它窗口存在包含大部分交叉的情况。这个时候就需要用到NMS来选取那些邻域里分数最高，同时抑制那些分数低的窗口。 原理在目标检测任务中，定义最后的候选框集合为$B$，每个候选框对应的置信度是$S$，IOU阈值设为$T$，然后NMS的算法过程可以表示如下： 选择具有最大score的候选框$M$ 将$M$从集合$B$中移除并加入到最终的检测结果$D$中 将$B$中剩余检测框中和$M$的交并比(IOU)大于阈值$T$的框从$B$中移除 重复上面的步骤，直到$B$为空 代码实现rgb大神实现Faster-RCNN中的单类别物体nms代码解释如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 -------------------------- ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/05/08/%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AL1-loss,-L2-loss%E4%BB%A5%E5%8F%8ASmooth-L1-Loss%E7%9A%84%E5%AF%B9%E6%AF%94/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/08/%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AL1-loss,-L2-loss%E4%BB%A5%E5%8F%8ASmooth-L1-Loss%E7%9A%84%E5%AF%B9%E6%AF%94/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比">回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-08T03:58:11.819Z" title="发表于 2020-05-08 11:58:11">2020-05-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言总结对比下$L_{1}$损失函数，$L_{2}$损失函数以及损$SmoothL_{1}$失函数的优缺点。 均方误差MSE ($L_{2}$ Loss)均方误差（Mean Square Error,MSE）是模型预测值$f(x)$与真实样本值$y$之间差值平方的平均值，其公式如下 M S E=\frac{\sum_{i=1}^{n}\left(f_{x_{i}}-y_{i}\right)^{2}}{n}其中，$\boldsymbol{y}_{i}$和$f\left(x_{i}\right)$分别表示第$i$个样本的真实值及其对应的预测值，$n$为样本的个数。 忽略下标$i$ ，设$n=1$，以$f(x)−y$为横轴，MSE的值为纵轴，得到函数的图形如下： MSE的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。 而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。 当$y$和$f(x)$也就是真实值和预测值的差值大于1时，会放大误差；而当差值小于1时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差（& ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/" title="CNN结构无痛涨点技巧：ACNet"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="CNN结构无痛涨点技巧：ACNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/" title="CNN结构无痛涨点技巧：ACNet">CNN结构无痛涨点技巧：ACNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-17T02:54:37.109Z" title="发表于 2020-04-17 10:54:37">2020-04-17</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言CNN的结构创新在这两年已经变得相对很少了，同时要做出有影响力并且Solid的工作也变得越来越难，最近CNN结构方面的创新主要包含两个方面： 网络结构搜索，以Google Brain的EfficientNet为代表作。 获取更好的特征表达，主要是将特征复用，特征细化做得更加极致，以HRNet，Res2Net等为代表作。 本文要介绍的是ICCV 2019的一个新CNN架构ACNet（全称为Asymmetric Convolution Net），因此这篇文章的目的是讲清楚ACNet的原理并总结它的核心思想，另外借助作者开源的Pytorch代码端来加深理解。 介绍ACNet的切入点为获取更好的特征表达，但和其它方法最大的区别在于它没有带来额外的超参数，而且在推理阶段没有增加计算量，这是十分具有吸引力的。 在正式介绍ACNet之前，首先来明确一下关于卷积计算的一个等式，这个等式表达的意思就是「对于输入特征图$I$，先进行$K^{(1)}$和$I$卷积，$K^{(2)}$和$I$卷积后再对结果进行相加，与先进行$K^{(1)}$和$K^{(2)}$的逐点相加后再和$I$进行卷积得到的结 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Perceptual Generative Adversarial Networks for Small Object Detection"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection">Perceptual Generative Adversarial Networks for Small Object Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-09T06:25:22.859Z" title="发表于 2020-05-09 14:25:22">2020-05-09</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">详解 小目标检测的一个常用思路是提升图片输入分辨率，来增强小目标的分辨率和生成高分辨率的特征图，但这会导致训练和验证极度费时。 本文提出的PGAN方法对小目标生成高分辨率特征表示，使小目标的特征表示与大目标特征表示类似。 生成器网络通过较前层提取细粒度特征将小目标分辨率较低的特征转换为分辨率较高的特征。 判别器网络不仅用于生成小目标高分辨表示，同时证明带感知损失的生成高分辨率特征对检测准确率是有帮助的。 生成器网络被训练欺骗辨别器通过产生最像大目标表征的小目标，同时提升检测准确率。 辨别器被训练用于提升正确从实际大目标中分辨出生成的高分辨率表征，同时将定位准确率反馈给生成器。 小目标检测典型应用领域：交通标志检测、行人检测 perception branch（感知分支）首先利用仅包含大目标的图片进行训练，然后利用仅包含小目标的图片进行训练，generator network 被训练用于对小目标生成高分辨率的类似大目标的表征。adversarial branch被训练用于区分生成的小目标高分辨率表征与实际大目标的原始表征。 generator 从底层提取细粒度特征，放入深度残差网络 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-%E2%80%93-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="An Analysis of Scale Invariance in Object Detection – SNIP"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-%E2%80%93-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP">An Analysis of Scale Invariance in Object Detection – SNIP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-05-08T05:50:38.647Z" title="发表于 2020-05-08 13:50:38">2020-05-08</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">动机概括而言，这篇文章从COCO数据集开始分析，认为目前目标检测算法的难点在于数据集中object的尺寸分布较大，尤其对于小目标的检测效果也有待提高，因此提出Scale Normalization for Image Pyramids (SNIP)算法来解决这个问题。 作者将数据集按照图像中目标的尺寸/图像尺寸进行排序，在ImageNet数据集中，这个倍数的中位数差不多0.554，而在COCO数据集中，这个数是0.106。如Figure1中两条线标出的Median点所示。Figure1是关于ImageNet和COCO数据集中object尺寸和图像尺寸的倍数关系曲线，横坐标表示object的尺寸/图像尺寸的值，纵坐标表示占比。也就是说在COCO数据集中，大部分的object面积只有图像面积的1%以下，这说明在COCO数据集中小目标占比要比ImageNet数据集大。另外，从Figure1中的COCO曲线可以看出，第90%的倍数（0.472）差不多是第10%的倍数（0.106）的20倍！这说明在COCO数据集中的object尺寸变化范围非常大。 那么这种差异会带来什么影响呢？因为在目标检测 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/" title="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/" title="ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）">ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-18T02:06:17.892Z" title="发表于 2020-04-18 10:06:17">2020-04-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言这是一篇图森科技在ICCV 2019的目标检测论文《Scale-Aware Trident Networks for Object Detection》，简称TridentNet，中文翻译为三叉戟网络。 背景我们知道在目标检测任务中，尺度变化一直是很关键的问题。针对尺度变化问题，也有很多的方案被提出，如Figure 1所示： 其中 (a)图表示多尺度图像金字塔网络，直接对图像进行不同尺度的缩放。 (b)是FPN网络，借鉴了金字塔结构将分辨率信息和语义信息相结合，克服不同层，不同尺度带来的问题。 这两种方法的目的都是让模型对尺寸不同的目标具有不同的感受野。除此之外还有SNIP，SNIP主要包含了两个改进点： 1、为了减少domain-shift，在梯度回传的时候只将和预训练模型所基于的训练数据尺寸相应的ROI的梯度进行回传。 2、借鉴了多尺度训练思想，引入图像金字塔来处理数据集中不同尺寸的数据。虽然图像金字塔的效率比较低，但通过对原图不同比例的缩放，充分利用了模型的表征能力。相比之下，FPN产生多层次的特征，但也牺牲了不同尺度下的特征一致性。 总结一下就是，图像金字塔虽然慢但是精度 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/" title="两阶段实时检测网络ThunderNet"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="两阶段实时检测网络ThunderNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/" title="两阶段实时检测网络ThunderNet">两阶段实时检测网络ThunderNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-30T01:33:48.689Z" title="发表于 2020-04-30 09:33:48">2020-04-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言ThunderNet是旷视和国防科技大学合作提出的目标检测模型，目标是在计算力受限的平台进行实时目标检测。需要关注的地方主要就是提出的两个特征增强模块CEM和SAM,其设计理念和应用的方法都非常值得借鉴。 介绍在移动端的实时目标检测是一个极为重要并且有挑战性的视觉问题。很多基于CNN的检测器都有巨大的计算量，所以在计算受限的场景下难以进行实时推理。论文提出了一个轻量级的两阶段的检测方法-ThunderNet。 在backbone部分，分析了以往的轻量级backbone的不足并提出了一个专门用于目标检测的轻量级基础网络-SNet。 在detection部分，提出一个有效的RPN和检测头。其中涉及到两个特征增强模块： Context Enhancement Module(CEM) 用于整合局部和全局特征。 Spatial Attention Module(SAM)引入RPN前后背景信息用以优化特征分布。 对目标输入分辨率、Backbone、检测头三个部分进行了平衡。 最终ThunderNet可以在ARM设备上达到24.1fps的速度，精度和速度上超过了很多一阶段检测器。 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/" title="自适应空间特征融合 (ASFF)"><img class="post_bg" src="https://gitee.com/qiyuan-z/yuan-blog-image/raw/master/img/paper.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="自适应空间特征融合 (ASFF)"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/" title="自适应空间特征融合 (ASFF)">自适应空间特征融合 (ASFF)</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-04-20T03:35:51.667Z" title="发表于 2020-04-20 11:35:51">2020-04-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="content">前言这是2019年的一篇论文 《Learning Spatial Fusion for Single-Shot Object Detection》，这篇论文主要是因为其提出的 自适应空间特征融合 (ASFF)被大家所熟知。金字塔特征表示法(FPN)是解决目标检测尺度变化挑战的常用方法。但是，对于基于FPN的单级检测器来说，不同特征尺度之间的不一致是其主要限制。因此这篇论文提出了一种新的数据驱动的金字塔特征融合方式，称之为自适应空间特征融合（ASFF）。它学习了在空间上过滤冲突信息以抑制梯度反传的时候不一致的方法，从而改善了特征的比例不变性，并且推理开销降低。借助ASFF策略和可靠的YOLOV3 BaseLine，在COCO数据集上实现了45FPS/42.4%AP以及29FPS/43.9%AP。下面先放一张论文的结果图。 一个更强的YOLOV3基准这篇文章之所以取得这么好的效果不仅仅是因为它提出的ASFF这种特征自适应融合方式，论文在YOLOV3的基础上集百家之长，构建了一个非常强的YOLOV3 BaseLine，这个BaseLine在MSCOCO上的mAP就达到了38.8%。相比 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/7/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/9/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"><div class="author-info__name">Qiyuan-Z</div><div class="author-info__description">偉大な魂は目的を持ち、そうでないものは願望を持つ</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">121</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">36</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Qiyuan-Z" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:zhengqiyuan@stu.jiangnan.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-pixiv"><div class="card-content"><div class="item-headline"><i class="fa fa-image" aria-hidden="true"></i><span>Pixiv日榜Top50</span><iframe src="https://fun.hujingnb.com/pixiv/i" frameborder="0" style="width:99%;height:380px;margin:0"></iframe></div></div></div><div class="sticky_layout"><div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height:100px;overflow:hidden"><div class="history_swiper-container" id="history-container" style="width:100%;height:100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/12/BitComet%E9%85%8D%E7%BD%AE/" title="BitComet配置">BitComet配置</a><time datetime="2022-01-12T06:56:56.861Z" title="发表于 2022-01-12 14:56:56">2022-01-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/11/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Pytorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/" title="如何使用PyTorch分布式训练">如何使用PyTorch分布式训练</a><time datetime="2022-01-11T02:01:07.163Z" title="发表于 2022-01-11 10:01:07">2022-01-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/10/Grad-CAM%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/" title="Grad-CAM原理和实现">Grad-CAM原理和实现</a><time datetime="2022-01-10T01:58:38.768Z" title="发表于 2022-01-10 09:58:38">2022-01-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/07/TensorRT%E5%AE%89%E8%A3%85/" title="TensorRT安装">TensorRT安装</a><time datetime="2022-01-07T05:08:13.073Z" title="发表于 2022-01-07 13:08:13">2022-01-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/01/06/%E8%A7%A3%E5%86%B3nvidia-smi%E5%92%8Cnvcc%E6%98%BE%E7%A4%BA%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%89%80%E5%AE%89%E8%A3%85CUDA%E7%89%88%E6%9C%AC%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/" title="解决nvidia-smi和nvcc显示信息与所安装CUDA版本不一致问题">解决nvidia-smi和nvcc显示信息与所安装CUDA版本不一致问题</a><time datetime="2022-01-06T02:09:53.081Z" title="发表于 2022-01-06 10:09:53">2022-01-06</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size:1.5em;color:#2c5bc8">目标检测</a><a href="/tags/YOLOv3/" style="font-size:1.4em;color:#36bf0f">YOLOv3</a><a href="/tags/BitComet/" style="font-size:1.1em;color:#2c9848">BitComet</a><a href="/tags/Ubuntu/" style="font-size:1.45em;color:#0b754a">Ubuntu</a><a href="/tags/Attention%E6%9C%BA%E5%88%B6/" style="font-size:1.15em;color:#7f0725">Attention机制</a><a href="/tags/Fast-RCNN/" style="font-size:1.1em;color:#be9fb4">Fast RCNN</a><a href="/tags/Pytorch/" style="font-size:1.3em;color:#c803aa">Pytorch</a><a href="/tags/Latex/" style="font-size:1.15em;color:#c76475">Latex</a><a href="/tags/potplayer/" style="font-size:1.1em;color:#147172">potplayer</a><a href="/tags/Python/" style="font-size:1.35em;color:#7e173d">Python</a><a href="/tags/Opencv/" style="font-size:1.15em;color:#c026bc">Opencv</a><a href="/tags/PyQt5/" style="font-size:1.1em;color:#95263c">PyQt5</a><a href="/tags/Pycharm/" style="font-size:1.15em;color:#483943">Pycharm</a><a href="/tags/SSH/" style="font-size:1.15em;color:#2bc011">SSH</a><a href="/tags/RCNN/" style="font-size:1.1em;color:#4f158b">RCNN</a><a href="/tags/TensorRT/" style="font-size:1.1em;color:#314548">TensorRT</a><a href="/tags/CUDA/" style="font-size:1.2em;color:#603479">CUDA</a><a href="/tags/cuDNN/" style="font-size:1.2em;color:#63c2a5">cuDNN</a><a href="/tags/Proxy/" style="font-size:1.25em;color:#584587">Proxy</a><a href="/tags/Tensorflow/" style="font-size:1.15em;color:#9db70e">Tensorflow</a><a href="/tags/virtualenv/" style="font-size:1.1em;color:#0837ab">virtualenv</a><a href="/tags/C/" style="font-size:1.15em;color:#34064b">C++</a><a href="/tags/VSCode/" style="font-size:1.2em;color:#2a537b">VSCode</a><a href="/tags/Xshell/" style="font-size:1.1em;color:#8e5c48">Xshell</a><a href="/tags/Windows10/" style="font-size:1.1em;color:#685293">Windows10</a><a href="/tags/VNC/" style="font-size:1.1em;color:#86bab9">VNC</a><a href="/tags/arxiv/" style="font-size:1.1em;color:#07a1a6">arxiv</a><a href="/tags/Keras/" style="font-size:1.1em;color:#2c1096">Keras</a><a href="/tags/onnx/" style="font-size:1.1em;color:#1c852e">onnx</a><a href="/tags/Teamviewer/" style="font-size:1.1em;color:#025cc5">Teamviewer</a><a href="/tags/%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98/" style="font-size:1.1em;color:#854e3c">百度网盘</a><a href="/tags/Onedrive/" style="font-size:1.1em;color:#593134">Onedrive</a><a href="/tags/frp/" style="font-size:1.1em;color:#3850a9">frp</a><a href="/tags/%E8%B7%AF%E7%94%B1%E5%99%A8/" style="font-size:1.1em;color:#912405">路由器</a><a href="/tags/Docker/" style="font-size:1.1em;color:#7e1b88">Docker</a><a href="/tags/leetcode/" style="font-size:1.1em;color:#770bb9">leetcode</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多"><i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/09/"><span class="card-archive-list-date">九月 2020</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">八月 2020</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/07/"><span class="card-archive-list-date">七月 2020</span><span class="card-archive-list-count">2</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">121</div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">286.7k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastpushdate="2022-01-12T07:04:57.730Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2022<i id="heartbeat" class="fa fas fa-heartbeat"></i> Qiyuan-Z</div><div class="footer_custom_text"><p><a style="margin-inline:5px" target="_blank" href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为 Hexo" alt="HEXO"></a><a style="margin-inline:5px" target="_blank" href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用 Butterfly" alt="Butterfly"></a><a style="margin-inline:5px" target="_blank" href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用 Jsdelivr 为静态资源提供CDN加速" alt="Jsdelivr"></a><a style="margin-inline:5px" target="_blank" href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由 GitHub 托管" alt="GitHub"></a><a style="margin-inline:5px" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" alt="img" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a><br>昨日までの私は、もうどこにもいない<br></p></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader={endLoading:()=>{document.body.style.overflow="auto",document.getElementById("loading-box").classList.add("loaded")},initLoading:()=>{document.body.style.overflow="",document.getElementById("loading-box").classList.remove("loaded")}};window.addEventListener("load",preloader.endLoading())</script><div class="js-pjax"></div><script defer src="https://cdn.jsdelivr.net/gh/Qiyuan-Z/live2d-widget/autoload.js"></script><script src="https://unpkg.com/swiper/swiper-bundle.min.js"></script><script src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>