<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AlexeyAB DarkNet Dropout层代码详解</title>
    <url>/2020/04/17/AlexeyAB-DarkNet-Dropout%E5%B1%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本次解析<code>src/dropout.h</code>和<code>src/dropout.c</code>两个文件，也即是Dropout层。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>在CNN中使用Dropout分成训练和测试两个阶段，在训练阶段，Dropout以一定的概率$p$随机丢弃一部分神经元节点，即这部分神经元节点不参与计算，如下图所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/669.webp" alt></p>
<p>在训练时，每个神经元有概率$p$的可能性被保留下来，即Dropout的丢弃概率为$1-p$。在测试阶段，每个神经元都是存在的，权重参数$w$要乘以$p$成为$pw$。为什么测试阶段要乘以$p$呢？</p>
<p>考虑第一个隐藏层的一个神经元在Dropout之前的输出是$x$，那么Dropout之后的期望值为$E=px+(1-p)0$，在测试时该神经元总是激活的，为了保持同样的输出期望值并使得下一层也得到同样的结果，需要调整$x-&gt;px$。其中$p$是<strong>Bernoulli分布</strong>（0-1分布）中值为1的概率。示意图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/670.png" alt></p>
<h2 id="Inverted-Dropout"><a href="#Inverted-Dropout" class="headerlink" title="Inverted Dropout"></a>Inverted Dropout</h2><p>在训练的时候由于舍弃一些神经元，因此在测试的时候需要在激活的结果中乘上因子$p$进行缩放，但是这样需要对测试的代码进行修改并增加了测试时的运算量，十分影响测试时的性能。通常为了提高测试的性能，可以将缩放的工作转移到训练阶段，而测试阶段和不使用Dropout一致，这一操作就被叫作<strong>Inverted Dropout</strong>。具体实现的时候只需要将前向传播Dropout时保留下来的神经元的权重乘上$\frac{1}{p}$即可。</p>
<h2 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h2><h3 id="dropout-layer-h代码解析"><a href="#dropout-layer-h代码解析" class="headerlink" title="dropout_layer.h代码解析"></a>dropout_layer.h代码解析</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;layer.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;network.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> layer dropout_layer;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="comment">// 构建一个dropout层</span></span><br><span class="line"><span class="function">dropout_layer <span class="title">make_dropout_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> inputs, <span class="keyword">float</span> probability, <span class="keyword">int</span> dropblock, <span class="keyword">float</span> dropblock_size_rel, <span class="keyword">int</span> dropblock_size_abs, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> c)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// dropout前向传播</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_dropout_layer</span><span class="params">(dropout_layer l, network_state state)</span></span>;</span><br><span class="line"><span class="comment">// dropout反向传播</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_dropout_layer</span><span class="params">(dropout_layer l, network_state state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize_dropout_layer</span><span class="params">(dropout_layer *l, <span class="keyword">int</span> inputs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_dropout_layer_gpu</span><span class="params">(dropout_layer l, network_state state)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_dropout_layer_gpu</span><span class="params">(dropout_layer l, network_state state)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<h3 id="dropout-layer-cpp代码解析"><a href="#dropout-layer-cpp代码解析" class="headerlink" title="dropout_layer.cpp代码解析"></a>dropout_layer.cpp代码解析</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 构建dropout层</span></span><br><span class="line"><span class="comment"> * batch 一个batch中图片张数</span></span><br><span class="line"><span class="comment"> * inputs  dropout层每张输入图片的元素个数</span></span><br><span class="line"><span class="comment"> * probability dropout概率,即某个输入神经元被丢弃的概率,由配置文件指定;如果配置文件中未指定,则默认值为0.5(参见parse_dropout_layer()函数)</span></span><br><span class="line"><span class="comment"> * 返回dropout_layer</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 说明: dropout层的构建函数需要的输入参数比较少,网络输入数据尺寸h,w,c也不需要;</span></span><br><span class="line"><span class="comment"> * 注意: dropout层有l.inputs = l.outputs; 另外此处实现使用了inverted dropout, 不是标准的dropout</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">dropout_layer <span class="title">make_dropout_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> inputs, <span class="keyword">float</span> probability, <span class="keyword">int</span> dropblock, <span class="keyword">float</span> dropblock_size_rel, <span class="keyword">int</span> dropblock_size_abs, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    dropout_layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    l.type = DROPOUT;</span><br><span class="line">    l.probability = probability; <span class="comment">//丢弃概率 (1-probability 为保留概率)</span></span><br><span class="line">    l.dropblock = dropblock; </span><br><span class="line">    l.dropblock_size_rel = dropblock_size_rel;</span><br><span class="line">    l.dropblock_size_abs = dropblock_size_abs;</span><br><span class="line">    <span class="keyword">if</span> (l.dropblock) &#123;</span><br><span class="line">        l.out_w = l.w = w;</span><br><span class="line">        l.out_h = l.h = h;</span><br><span class="line">        l.out_c = l.c = c;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (l.w &lt;= <span class="number">0</span> || l.h &lt;= <span class="number">0</span> || l.c &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot; Error: DropBlock - there must be positive values for: l.w=%d, l.h=%d, l.c=%d \n&quot;</span>, l.w, l.h, l.c);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    l.inputs = inputs; <span class="comment">// dropout层不会改变输入输出的个数,因此有 l.inputs == l.outputs</span></span><br><span class="line">    l.outputs = inputs; <span class="comment">// 虽然dropout会丢弃一些输入神经元, 但这丢弃只是置该输入元素值为0, 并没有删除</span></span><br><span class="line">    l.batch = batch; <span class="comment">// 一个batch中图片数量</span></span><br><span class="line">    l.rand = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(inputs * batch, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//动态分配内存,</span></span><br><span class="line">    l.scale = <span class="number">1.</span>/(<span class="number">1.0</span> - probability); <span class="comment">//使用inverted dropout, scale取保留概率的倒数</span></span><br><span class="line">    l.forward = forward_dropout_layer; <span class="comment">//前向传播</span></span><br><span class="line">    l.backward = backward_dropout_layer; <span class="comment">// 反向传播</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    l.forward_gpu = forward_dropout_layer_gpu;</span><br><span class="line">    l.backward_gpu = backward_dropout_layer_gpu;</span><br><span class="line">    l.rand_gpu = <span class="built_in">cuda_make_array</span>(l.rand, inputs*batch);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">if</span> (l.dropblock) &#123;</span><br><span class="line">        <span class="keyword">if</span>(l.dropblock_size_abs) <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;dropblock       p = %.2f   l.dropblock_size_abs = %d         %4d  -&gt;   %4d\n&quot;</span>, probability, l.dropblock_size_abs, inputs, inputs);</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;dropblock       p = %.2f   l.dropblock_size_rel = %.2f         %4d  -&gt;   %4d\n&quot;</span>, probability, l.dropblock_size_rel, inputs, inputs);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;dropout       p = %.2f                  %4d  -&gt;   %4d\n&quot;</span>, probability, inputs, inputs);</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize_dropout_layer</span><span class="params">(dropout_layer *l, <span class="keyword">int</span> inputs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    l-&gt;inputs = l-&gt;outputs = inputs;</span><br><span class="line">    l-&gt;rand = (<span class="keyword">float</span>*)<span class="built_in">xrealloc</span>(l-&gt;rand, l-&gt;inputs * l-&gt;batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="built_in">cuda_free</span>(l-&gt;rand_gpu);</span><br><span class="line"></span><br><span class="line">    l-&gt;rand_gpu = <span class="built_in">cuda_make_array</span>(l-&gt;rand, l-&gt;inputs*l-&gt;batch);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * dropout层前向传播函数</span></span><br><span class="line"><span class="comment"> * @l 当前dropout层函数</span></span><br><span class="line"><span class="comment"> * @state 整个网络</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 说明:dropout层没有训练参数,因此前向传播函数比较简单,只需要完成一件事: 按指定概率 l.probability</span></span><br><span class="line"><span class="comment"> * 丢弃输入元素,并将保留下来的输入元素乘以比例因子scale(采用inverted dropout, 这种凡是实现更为方便,</span></span><br><span class="line"><span class="comment"> * 且代码接口比较统一;如果采用标准的dropout, 则测试阶段需要进入 forward_dropout_layer(),</span></span><br><span class="line"><span class="comment"> * 使每个输入乘以保留概率,而使用inverted dropout, 测试阶段就不需要进入到forward_dropout_layer())</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 说明: dropout层有l.inputs = l.outputs;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_dropout_layer</span><span class="params">(dropout_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 因为使用inverted dropout,所以测试阶段不需要进入forward_dropout_layer()</span></span><br><span class="line">    <span class="keyword">if</span> (!state.train) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.batch * l.inputs; ++i)&#123;</span><br><span class="line">		<span class="comment">// 采样一个0-1之间均匀分布的随机数</span></span><br><span class="line">        <span class="keyword">float</span> r = <span class="built_in">rand_uniform</span>(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">        l.rand[i] = r; <span class="comment">// 每一个随机数都要保存到l.rand,之后反向传播时候会用到</span></span><br><span class="line">        <span class="keyword">if</span>(r &lt; l.probability) state.input[i] = <span class="number">0</span>; <span class="comment">// 舍弃该元素,将其值置为0, 所以这里元素的总个数并没有发生变化;</span></span><br><span class="line">        <span class="keyword">else</span> state.input[i] *= l.scale; <span class="comment">//保留该输入元素,并乘以比例因子scale</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * dropout层反向传播函数</span></span><br><span class="line"><span class="comment"> * l 当前dropout层网络</span></span><br><span class="line"><span class="comment"> * state 整个网络</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 说明: dropout层的反向传播相对简单,因为其本身没有训练参数,也没有激活函数,或者说激活函数为f(x) =x,</span></span><br><span class="line"><span class="comment"> * 也就是激活函数关于加权输入的导数值为1, 因此其自身的误差项值以后由下一层网络反向传播时计算完了,</span></span><br><span class="line"><span class="comment"> * 没有必要再曾以激活函数关于加权输入的导数了.剩下要做的就是计算上一层的误差项net.delta, 这个计算也很简单;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_dropout_layer</span><span class="params">(dropout_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 如果state.delta为空,则返回(state.delta为空则说明已经反向传播到第一层了,此处所指定的第一层,是state.layers[0]</span></span><br><span class="line">    <span class="comment">// 也就是与输入层直接相连的第一层隐含层, 详细见 network.c 中的 forward_network()函数)</span></span><br><span class="line">    <span class="keyword">if</span>(!state.delta) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.batch * l.inputs; ++i)&#123;</span><br><span class="line">		<span class="comment">// 与前向过程 forward_dropout_layer 照应,根据l.rand指示,</span></span><br><span class="line">        <span class="keyword">float</span> r = l.rand[i];</span><br><span class="line">		<span class="comment">// 如果r &lt;　probability,说明舍丢弃的输入，其误差项值为0</span></span><br><span class="line">        <span class="keyword">if</span>(r &lt; l.probability) state.delta[i] = <span class="number">0</span>;</span><br><span class="line">		<span class="comment">// 保留下的输入元素,其误差项值为当前层对应输出的误差项值乘以l.scale</span></span><br><span class="line">        <span class="keyword">else</span> state.delta[i] *= l.scale;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet数据结构解析</title>
    <url>/2020/02/21/AlexeyAB-DarkNet%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="基础数据结构"><a href="#基础数据结构" class="headerlink" title="基础数据结构"></a>基础数据结构</h2><p>为了解析网络配置参数，DarkNet 中定义了三个关键的数据结构类型。<code>list</code>类型变量保存所有的网络参数, <code>section</code>类型变量保存的是网络中每一层的网络类型和参数, 其中的参数又是使用list类型来表示。<code>kvp</code>键值对类型用来保存解析后的参数变量和参数值。</p>
<ul>
<li>list类型定义在<code>src/list.h</code>中，代码如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 链表上的节点</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">void</span> *val;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">prev</span>;</span></span><br><span class="line">&#125; node;</span><br><span class="line"></span><br><span class="line"><span class="comment">//双向链表</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> size; <span class="comment">//list的所有节点个数</span></span><br><span class="line">    node *front; <span class="comment">//list的首节点</span></span><br><span class="line">    node *back; <span class="comment">//list的普通节点</span></span><br><span class="line">&#125; list;</span><br></pre></td></tr></table></figure>
<ul>
<li>section 类型定义在<code>src/parser.c</code>文件中，代码如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义section</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="keyword">char</span> *type;</span><br><span class="line">    list *options;</span><br><span class="line">&#125;section;</span><br></pre></td></tr></table></figure>
<ul>
<li>kvp 键值对类型定义在<code>src/option_list.h</code>文件中，具体定义如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// kvp 键值对</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="keyword">char</span> *key;</span><br><span class="line">    <span class="keyword">char</span> *val;</span><br><span class="line">    <span class="keyword">int</span> used;</span><br><span class="line">&#125; kvp;</span><br></pre></td></tr></table></figure>
<p>在Darknet的网络配置文件(<code>.cfg</code>结尾)中，以<code>[</code>开头的行被称为一个段(<code>section</code>)。所有的网络配置参数保存在<code>list</code>类型变量中，<code>list</code>中有很多的<code>section</code>节点，每个<code>section</code>中又有一个保存层参数的小<code>list</code>，整体上出现了一种大链挂小链的结构。大链的每个节点为<code>section</code>，每个<code>section</code>中包含的参数保存在小链中，小链的节点值的数据类型为kvp键值对，这里有个图片可以解释这种结构。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/648.webp" alt></p>
<p>我们来大概解释下该参数网，首先创建一个<code>list</code>，取名<code>sections</code>，记录一共有多少个<code>section</code>（一个<code>section</code>存储了某一网络层所需参数）；然后创建一个<code>node</code>，该<code>node</code>的<code>void</code>类型的指针指向一个新创建的<code>section</code>；该<code>section</code>的<code>char</code>类型指针指向<code>.cfg</code>文件中的某一行（<code>line</code>），然后将该<code>section</code>的<code>list</code>指针指向一个新创建的<code>node</code>，该<code>node</code>的<code>void</code>指针指向一个<code>kvp</code>结构体，<code>kvp</code>结构体中的<code>key</code>就是<code>.cfg</code>文件中的关键字（如：<code>batch，subdivisions</code>等），<code>val</code>就是对应的值；如此循环就形成了上述的参数网络图。</p>
<h2 id="解析并保存网络参数到链表中"><a href="#解析并保存网络参数到链表中" class="headerlink" title="解析并保存网络参数到链表中"></a>解析并保存网络参数到链表中</h2><p>读取配置文件由<code>src/parser.c</code>中的<code>read_cfg()</code>函数实现：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 读取神经网络结构配置文件（.cfg文件）中的配置数据， 将每个神经网络层参数读取到每个</span></span><br><span class="line"><span class="comment"> * section 结构体 (每个 section 是 sections 的一个节点) 中， 而后全部插入到</span></span><br><span class="line"><span class="comment"> * list 结构体 sections 中并返回</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * \param: filename    C 风格字符数组， 神经网络结构配置文件路径</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * \return: list 结构体指针，包含从神经网络结构配置文件中读入的所有神经网络层的参数</span></span><br><span class="line"><span class="comment"> * 每个 section 的所在行的开头是 ‘[’ , ‘\0’ , ‘#’ 和 ‘;’ 符号开头的行为无效行, 除此</span></span><br><span class="line"><span class="comment"> *之外的行为 section 对应的参数行. 每一行都是一个等式, 类似键值对的形式.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> *可以看到, 如果某一行开头是符号 ‘[’ , 说明读到了一个新的 section: current, 然后第1508行</span></span><br><span class="line"><span class="comment"> *list_insert(options, current);` 将该新的 section 保存起来.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> *在读取到下一个开头符号为 ‘[’ 的行之前的所有行都是该 section 的参数, 在第 1518 行</span></span><br><span class="line"><span class="comment"> *read_option(line, current-&gt;options) 将读取到的参数保存在 current 变量的 options 中.</span></span><br><span class="line"><span class="comment"> *注意, 这里保存在 options 节点中的数据为 kvp 键值对类型.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> *当然对于 kvp 类型的参数, 需要先将每一行中对应的键和值(用 ‘=’ 分割) 分离出来, 然后再</span></span><br><span class="line"><span class="comment"> *构造一个 kvp 类型的变量作为节点元素的数据.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">list *<span class="title">read_cfg</span><span class="params">(<span class="keyword">char</span> *filename)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FILE *file = <span class="built_in">fopen</span>(filename, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">	<span class="comment">//一个section表示配置文件中的一个字段，也就是网络结构中的一层</span></span><br><span class="line">    <span class="comment">//因此，一个section将读取并存储某一层的参数以及该层的type</span></span><br><span class="line">    <span class="keyword">if</span>(file == <span class="number">0</span>) <span class="built_in">file_error</span>(filename);</span><br><span class="line">    <span class="keyword">char</span> *line;</span><br><span class="line">    <span class="keyword">int</span> nu = <span class="number">0</span>; <span class="comment">//当前读取行号</span></span><br><span class="line">    list *sections = <span class="built_in">make_list</span>(); <span class="comment">//sections包含所有的神经网络层参数</span></span><br><span class="line">    section *current = <span class="number">0</span>;<span class="comment">//当前读取到某一层</span></span><br><span class="line">    <span class="keyword">while</span>((line=<span class="built_in">fgetl</span>(file)) != <span class="number">0</span>)&#123;</span><br><span class="line">        ++ nu;</span><br><span class="line">        <span class="built_in">strip</span>(line); <span class="comment">//去除读入行中含有的空格符</span></span><br><span class="line">        <span class="built_in"><span class="keyword">switch</span></span>(line[<span class="number">0</span>])&#123;</span><br><span class="line">			 <span class="comment">// 以 &#x27;[&#x27; 开头的行是一个新的 section , 其内容是层的 type</span></span><br><span class="line">            <span class="comment">// 比如 [net], [maxpool], [convolutional] ...</span></span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;[&#x27;</span>:</span><br><span class="line">                current = (section*)<span class="built_in">xmalloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(section));</span><br><span class="line">                <span class="built_in">list_insert</span>(sections, current);</span><br><span class="line">                current-&gt;options = <span class="built_in">make_list</span>();</span><br><span class="line">                current-&gt;type = line;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;\0&#x27;</span>: <span class="comment">//空行</span></span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;#&#x27;</span>: <span class="comment">//注释</span></span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;;&#x27;</span>: <span class="comment">//空行</span></span><br><span class="line">                <span class="built_in">free</span>(line); <span class="comment">// 对于上述三种情况直接释放内存即可</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">			    <span class="comment">// 剩下的才真正是网络结构的数据，调用 read_option() 函数读取</span></span><br><span class="line">                <span class="comment">// 返回 0 说明文件中的数据格式有问题，将会提示错误</span></span><br><span class="line">                <span class="keyword">if</span>(!<span class="built_in">read_option</span>(line, current-&gt;options))&#123;</span><br><span class="line">                    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Config file error line %d, could parse: %s\n&quot;</span>, nu, line);</span><br><span class="line">                    <span class="built_in">free</span>(line);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//关闭文件</span></span><br><span class="line">    <span class="built_in">fclose</span>(file);</span><br><span class="line">    <span class="keyword">return</span> sections;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="链表的插入操作"><a href="#链表的插入操作" class="headerlink" title="链表的插入操作"></a>链表的插入操作</h2><p>保存<code>section</code>和每个参数组成的键值对时使用的是<code>list_insert()</code>函数, 前面提到了参数保存的结构其实是大链(节点为<code>section</code>)上边挂着很多小链(每个<code>section</code>节点的各个参数)。<code>list_insert()</code>函数实现了链表插入操作，该函数定义在<code>src/list.c</code>文件中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 简介: 将 val 指针插入 list 结构体 l 中，这里相当于是用 C 实现了 C++ 中的</span></span><br><span class="line"><span class="comment"> *         list 的元素插入功能</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 参数: l    链表指针</span></span><br><span class="line"><span class="comment"> *         val  链表节点的元素值</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 流程：list 中保存的是 node 指针. 因此，需要用 node 结构体将 val 包裹起来后才可以</span></span><br><span class="line"><span class="comment"> *       插入 list 指针 l 中</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 注意: 此函数类似 C++ 的 insert() 插入方式；</span></span><br><span class="line"><span class="comment"> *      而 opion_insert() 函数类似 C++ map 的按值插入方式，比如 map[key]= value</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *      两个函数操作对象都是 list 变量， 只是操作方式略有不同。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">list_insert</span><span class="params">(list *l, <span class="keyword">void</span> *val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    node* newnode = (node*)<span class="built_in">xmalloc</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(node));</span><br><span class="line">    newnode-&gt;val = val;</span><br><span class="line">    newnode-&gt;next = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 如果 list 的 back 成员为空(初始化为 0), 说明 l 到目前为止，还没有存入数据</span></span><br><span class="line">    <span class="comment">// 另外, 令 l 的 front 为 new （此后 front 将不会再变，除非删除）</span></span><br><span class="line">    <span class="keyword">if</span>(!l-&gt;back)&#123;</span><br><span class="line">        l-&gt;front = newnode;</span><br><span class="line">        newnode-&gt;prev = <span class="number">0</span>;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        l-&gt;back-&gt;next = newnode;</span><br><span class="line">        newnode-&gt;prev = l-&gt;back;</span><br><span class="line">    &#125;</span><br><span class="line">    l-&gt;back = newnode;</span><br><span class="line">    ++l-&gt;size;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到, 插入的数据都会被重新包装在一个新的<code>node</code> : 变量<code>new</code>中，然后再将这个节点插入到链表中。网络结构解析到链表中后还不能直接使用, 因为想使用任意一个参数都不得不每次去遍历整个链表, 这样就会导致程序效率变低, 所以最好的办法是将其保存到一个结构体变量中, 使用的时候按照成员进行访问。复杂度从$O(n)-&gt;O(1)$。</p>
<h2 id="将链表中的网络结构保存到network结构体"><a href="#将链表中的网络结构保存到network结构体" class="headerlink" title="将链表中的网络结构保存到network结构体"></a>将链表中的网络结构保存到network结构体</h2><ul>
<li>首先来看看<code>network</code>结构体的定义，在<code>include/darknet.h</code>中：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义network结构体</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">network</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> n; <span class="comment">//网络的层数，调用make_network(int n)时赋值</span></span><br><span class="line">    <span class="keyword">int</span> batch; <span class="comment">//一批训练中的图片参数，和subdivsions参数相关</span></span><br><span class="line">    <span class="keyword">uint64_t</span> *seen; <span class="comment">//目前已经读入的图片张数(网络已经处理的图片张数)</span></span><br><span class="line">    <span class="keyword">int</span> *t;</span><br><span class="line">    <span class="keyword">float</span> epoch; <span class="comment">//到目前为止训练了整个数据集的次数</span></span><br><span class="line">    <span class="keyword">int</span> subdivisions;</span><br><span class="line">    layer *layers; <span class="comment">//存储网络中的所有层</span></span><br><span class="line">    <span class="keyword">float</span> *output;</span><br><span class="line">    learning_rate_policy policy; <span class="comment">// 学习率下降策略</span></span><br><span class="line">    <span class="keyword">int</span> benchmark_layers;</span><br><span class="line">    <span class="comment">// 梯度下降法相关参数</span></span><br><span class="line">    <span class="keyword">float</span> learning_rate; <span class="comment">//学习率</span></span><br><span class="line">    <span class="keyword">float</span> learning_rate_min; <span class="comment">//学习率最小值</span></span><br><span class="line">    <span class="keyword">float</span> learning_rate_max;  <span class="comment">//学习率最大值</span></span><br><span class="line">    <span class="keyword">int</span> batches_per_cycle; <span class="comment">//</span></span><br><span class="line">    <span class="keyword">int</span> batches_cycle_mult;</span><br><span class="line">    <span class="keyword">float</span> momentum;</span><br><span class="line">    <span class="keyword">float</span> decay;</span><br><span class="line">    <span class="keyword">float</span> gamma;</span><br><span class="line">    <span class="keyword">float</span> scale;</span><br><span class="line">    <span class="keyword">float</span> power;</span><br><span class="line">    <span class="keyword">int</span> time_steps;</span><br><span class="line">    <span class="keyword">int</span> step;</span><br><span class="line">    <span class="keyword">int</span> max_batches;</span><br><span class="line">    <span class="keyword">int</span> num_boxes;</span><br><span class="line">    <span class="keyword">int</span> train_images_num;</span><br><span class="line">    <span class="keyword">float</span> *seq_scales;</span><br><span class="line">    <span class="keyword">float</span> *scales;</span><br><span class="line">    <span class="keyword">int</span>   *steps;</span><br><span class="line">    <span class="keyword">int</span> num_steps;</span><br><span class="line">    <span class="keyword">int</span> burn_in;</span><br><span class="line">    <span class="keyword">int</span> cudnn_half;</span><br><span class="line">    <span class="comment">// ADAM优化方法相关策略</span></span><br><span class="line">    <span class="keyword">int</span> adam;</span><br><span class="line">    <span class="keyword">float</span> B1;</span><br><span class="line">    <span class="keyword">float</span> B2;</span><br><span class="line">    <span class="keyword">float</span> eps;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> inputs;</span><br><span class="line">    <span class="keyword">int</span> outputs;</span><br><span class="line">    <span class="keyword">int</span> truths;</span><br><span class="line">    <span class="keyword">int</span> notruth;</span><br><span class="line">    <span class="keyword">int</span> h, w, c;</span><br><span class="line">    <span class="keyword">int</span> max_crop;</span><br><span class="line">    <span class="keyword">int</span> min_crop;</span><br><span class="line">    <span class="keyword">float</span> max_ratio;</span><br><span class="line">    <span class="keyword">float</span> min_ratio;</span><br><span class="line">    <span class="keyword">int</span> center;</span><br><span class="line">    <span class="keyword">int</span> flip; <span class="comment">// horizontal flip 50% probability augmentaiont for classifier training (default = 1)</span></span><br><span class="line">    <span class="keyword">int</span> blur;</span><br><span class="line">    <span class="keyword">int</span> mixup;</span><br><span class="line">    <span class="keyword">float</span> label_smooth_eps;</span><br><span class="line">    <span class="keyword">int</span> resize_step;</span><br><span class="line">    <span class="keyword">int</span> letter_box;</span><br><span class="line">    <span class="keyword">float</span> angle;</span><br><span class="line">    <span class="keyword">float</span> aspect;</span><br><span class="line">    <span class="keyword">float</span> exposure;</span><br><span class="line">    <span class="keyword">float</span> saturation;</span><br><span class="line">    <span class="keyword">float</span> hue;</span><br><span class="line">    <span class="keyword">int</span> random;</span><br><span class="line">    <span class="keyword">int</span> track;</span><br><span class="line">    <span class="keyword">int</span> augment_speed;</span><br><span class="line">    <span class="keyword">int</span> sequential_subdivisions;</span><br><span class="line">    <span class="keyword">int</span> init_sequential_subdivisions;</span><br><span class="line">    <span class="keyword">int</span> current_subdivision;</span><br><span class="line">    <span class="keyword">int</span> try_fix_nan;</span><br><span class="line">    <span class="comment">//darknet 为每个 GPU 维护一个相同的 network, 每个 network 以 gpu_index 区分</span></span><br><span class="line">    <span class="keyword">int</span> gpu_index;</span><br><span class="line">    tree *hierarchy;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//中间变量，用来暂存某层网络的输入（包含一个 batch 的输入，比如某层网络完成前向，</span></span><br><span class="line">    <span class="comment">//将其输出赋给该变量，作为下一层的输入，可以参看 network.c 中的forward_network()</span></span><br><span class="line">    <span class="keyword">float</span> *input;</span><br><span class="line">	<span class="comment">// 中间变量，与上面的 input 对应，用来暂存 input 数据对应的标签数据（真实数据）</span></span><br><span class="line">    <span class="keyword">float</span> *truth;</span><br><span class="line">	 <span class="comment">// 中间变量，用来暂存某层网络的敏感度图（反向传播处理当前层时，用来存储上一层的敏</span></span><br><span class="line">    <span class="comment">//感度图，因为当前层会计算部分上一层的敏感度图，可以参看 network.c 中的 backward_network() 函数）</span></span><br><span class="line">    <span class="keyword">float</span> *delta;</span><br><span class="line">	<span class="comment">// 网络的工作空间, 指的是所有层中占用运算空间最大的那个层的 workspace_size,</span></span><br><span class="line">    <span class="comment">// 因为实际上在 GPU 或 CPU 中某个时刻只有一个层在做前向或反向运算</span></span><br><span class="line">    <span class="keyword">float</span> *workspace;</span><br><span class="line">	<span class="comment">// 网络是否处于训练阶段的标志参数，如果是则值为1. 这个参数一般用于训练与测试阶段有不</span></span><br><span class="line">    <span class="comment">// 同操作的情况，比如 dropout 层，在训练阶段才需要进行 forward_dropout_layer()</span></span><br><span class="line">    <span class="comment">// 函数， 测试阶段则不需要进入到该函数</span></span><br><span class="line">    <span class="keyword">int</span> train;</span><br><span class="line">	<span class="comment">// 标志参数，当前网络的活跃层</span></span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line">	<span class="comment">//每一层的损失，只有[yolo]层有值</span></span><br><span class="line">    <span class="keyword">float</span> *cost;</span><br><span class="line">    <span class="keyword">float</span> clip;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="comment">//float *input_gpu;</span></span><br><span class="line">    <span class="comment">//float *truth_gpu;</span></span><br><span class="line">    <span class="keyword">float</span> *delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> *output_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *input_state_gpu;</span><br><span class="line">    <span class="keyword">float</span> *input_pinned_cpu;</span><br><span class="line">    <span class="keyword">int</span> input_pinned_cpu_flag;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> **input_gpu;</span><br><span class="line">    <span class="keyword">float</span> **truth_gpu;</span><br><span class="line">    <span class="keyword">float</span> **input16_gpu;</span><br><span class="line">    <span class="keyword">float</span> **output16_gpu;</span><br><span class="line">    <span class="keyword">size_t</span> *max_input16_size;</span><br><span class="line">    <span class="keyword">size_t</span> *max_output16_size;</span><br><span class="line">    <span class="keyword">int</span> wait_stream;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *global_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> *state_delta_gpu;</span><br><span class="line">    <span class="keyword">size_t</span> max_delta_gpu_size;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">int</span> optimized_memory;</span><br><span class="line">    <span class="keyword">size_t</span> workspace_size_limit;</span><br><span class="line">&#125; network;</span><br></pre></td></tr></table></figure>
<ul>
<li>为<code>network</code>结构体分配内存空间，函数定义在<code>src/network.c</code>文件中，代码如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//为network结构体分配内存空间</span></span><br><span class="line"><span class="function">network <span class="title">make_network</span><span class="params">(<span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    network net = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    net.n = n;</span><br><span class="line">    net.layers = (layer*)<span class="built_in">xcalloc</span>(net.n, <span class="built_in"><span class="keyword">sizeof</span></span>(layer));</span><br><span class="line">    net.seen = (<span class="keyword">uint64_t</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">uint64_t</span>));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    net.input_gpu = (<span class="keyword">float</span>**)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>*));</span><br><span class="line">    net.truth_gpu = (<span class="keyword">float</span>**)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>*));</span><br><span class="line"></span><br><span class="line">    net.input16_gpu = (<span class="keyword">float</span>**)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>*));</span><br><span class="line">    net.output16_gpu = (<span class="keyword">float</span>**)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>*));</span><br><span class="line">    net.max_input16_size = (<span class="keyword">size_t</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">size_t</span>));</span><br><span class="line">    net.max_output16_size = (<span class="keyword">size_t</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">size_t</span>));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">return</span> net;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>src/parser.c</code>中的<code>parse_network_cfg()</code>函数中，从<code>net</code>变量开始，依次为其中的指针变量分配内存。由于第一个段<code>[net]</code>中存放的是和网络并不直接相关的配置参数, 因此网络层的数目为<code>sections-&gt;size - 1</code>，即：<code>network *net = make_network(sections-&gt;size - 1);</code></p>
<ul>
<li><p>将链表中的网络参数解析后保存到<code>network</code>结构体，配置文件的第一个段一定是<code>[net]</code>段，该段的参数解析由<code>parse_net_options()</code>函数完成，函数定义在<code>src/parser.c</code>中。之后的各段都是网络中的层。比如完成特定特征提取的卷积层，用来降低训练误差的<code>shortcur</code>层和防止过拟合的<code>dropout</code>层等。这些层都有特定的解析函数：比如<code>parse_convolutional()</code>, <code>parse_shortcut()</code>和<code>parse_dropout()</code>。每个解析函数返回一个填充好的层<code>l</code>，将这些层全部添加到<code>network</code>结构体的<code>layers</code>数组中。即是：<code>net-&gt;layers[count] = l</code>;另外需要注意的是这行代码：<code>if (l.workspace_size &gt; workspace_size) workspace_size = l.workspace_size</code>;，其中<code>workspace</code>代表网络的工作空间，指的是所有层中占用运算空间最大那个层的<code>workspace</code>。因为在CPU或GPU中某个时刻只有一个层在做前向或反向传播。输出层只能在网络搭建完毕之后才可以确定，输入层需要考虑<code>batch_size</code>的因素，<code>truth</code>是输入标签，同样需要考虑<code>batch_size</code>的因素。具体层的参数解析后面专门写一篇推文来帮助理解。</p>
</li>
<li><p>到这里，网络的宏观解析结束。<code>parse_network_cfg()</code>(<code>src/parser.c</code>中)函数返回解析好的<code>network</code>类型的指针变量。</p>
</li>
</ul>
<h2 id="为啥需要中间数据结构缓存？"><a href="#为啥需要中间数据结构缓存？" class="headerlink" title="为啥需要中间数据结构缓存？"></a>为啥需要中间数据结构缓存？</h2><p>这里可能有个疑问，为什么不将配置文件读取并解析到<code>network</code>结构体变量中, 而要使用一个中间数据结构来缓存读取到的文件呢？因为，如果不使用中间数据结构来缓存. 将读取和解析流程串行进行的话, 如果配置文件较为复杂,  就会长时间使文件处于打开状态。如果此时用户更改了配置文件中的一些条目,  就会导致读取和解析过程出现问题。分开两步进行可以先快速读取文件信息到内存中组织好的结构中, 这时就可以关闭文件.  然后再慢慢的解析参数。这种机制类似于操作系统中断的底半部机制, 先处理重要的中断信号, 然后在系统负荷较小时再处理中断信号中携带的任务。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet框架总览</title>
    <url>/2020/02/21/AlexeyAB-DarkNet%E6%A1%86%E6%9E%B6%E6%80%BB%E8%A7%88/</url>
    <content><![CDATA[<h2 id="Darknet框架分析主线"><a href="#Darknet框架分析主线" class="headerlink" title="Darknet框架分析主线"></a>Darknet框架分析主线</h2><h3 id="分析主线的确定"><a href="#分析主线的确定" class="headerlink" title="分析主线的确定"></a>分析主线的确定</h3><p>Darknet相比当前训练的C/C++主流框架（如Caffe）来讲，具有编译速度快，依赖少，易部署等众多优点，我们先定位到<code>src/darknet.c</code>里面的<code>main</code>函数，这是这个框架实现分类，定位，回归，分割等功能的初始入口。这一节的核心代码如下，注意一下就是<code>run_yolo</code>只提供了<code>yolo</code>目标检测算法的原始实现。而<code>run_detector</code>函数提供了AlexeyAB添加了各种新特性的目标检测算法，所以之后我们会从这个函数跟进去来解析Darknet框架。Darknet提供的其他功能如<code>run_super</code>（高分辨率重建），<code>run_classifier</code>（图像分类），<code>run_char_rnn</code>（RNN文本识别）有兴趣可以自己去读（这个框架用来做目标检测比较好，其他算法建议还是去其它框架实现吧），本系列只讲目标检测。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;average&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">average</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;yolo&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_yolo</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;voxel&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_voxel</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;super&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_super</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;detector&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_detector</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;detect&quot;</span>))&#123;</span><br><span class="line">       <span class="keyword">float</span> thresh = <span class="built_in">find_float_arg</span>(argc, argv, <span class="string">&quot;-thresh&quot;</span>, <span class="number">.24</span>);</span><br><span class="line">	<span class="keyword">int</span> ext_output = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-ext_output&quot;</span>);</span><br><span class="line">       <span class="keyword">char</span> *filename = (argc &gt; <span class="number">4</span>) ? argv[<span class="number">4</span>]: <span class="number">0</span>;</span><br><span class="line">       <span class="built_in">test_detector</span>(<span class="string">&quot;cfg/coco.data&quot;</span>, argv[<span class="number">2</span>], argv[<span class="number">3</span>], filename, thresh, <span class="number">0.5</span>, <span class="number">0</span>, ext_output, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;cifar&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_cifar</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;go&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_go</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;rnn&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_char_rnn</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;vid&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_vid_rnn</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;coco&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_coco</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;classify&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">predict_classifier</span>(<span class="string">&quot;cfg/imagenet1k.data&quot;</span>, argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>], <span class="number">5</span>);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;classifier&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_classifier</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;art&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_art</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;tag&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_tag</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;compare&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_compare</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;dice&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_dice</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;writing&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_writing</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;3d&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">composite_3d</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>], (argc &gt; <span class="number">5</span>) ? <span class="built_in">atof</span>(argv[<span class="number">5</span>]) : <span class="number">0</span>);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;test&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">test_resize</span>(argv[<span class="number">2</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;captcha&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_captcha</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;nightmare&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">run_nightmare</span>(argc, argv);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;rgbgr&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">rgbgr_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;reset&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">reset_normalize_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;denormalize&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">denormalize_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;statistics&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">statistics_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;normalize&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">normalize_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;rescale&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">rescale_net</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;ops&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">operations</span>(argv[<span class="number">2</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;speed&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">speed</span>(argv[<span class="number">2</span>], (argc &gt; <span class="number">3</span> &amp;&amp; argv[<span class="number">3</span>]) ? <span class="built_in">atoi</span>(argv[<span class="number">3</span>]) : <span class="number">0</span>);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;oneoff&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">oneoff</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;partial&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">partial</span>(argv[<span class="number">2</span>], argv[<span class="number">3</span>], argv[<span class="number">4</span>], <span class="built_in">atoi</span>(argv[<span class="number">5</span>]));</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;visualize&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">visualize</span>(argv[<span class="number">2</span>], (argc &gt; <span class="number">3</span>) ? argv[<span class="number">3</span>] : <span class="number">0</span>);</span><br><span class="line">   &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">1</span>], <span class="string">&quot;imtest&quot;</span>))&#123;</span><br><span class="line">       <span class="built_in">test_resize</span>(argv[<span class="number">2</span>]);</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">       <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Not an option: %s\n&quot;</span>, argv[<span class="number">1</span>]);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h3 id="跟进run-detector"><a href="#跟进run-detector" class="headerlink" title="跟进run_detector"></a>跟进run_detector</h3><p><code>run_detector</code>函数在<code>src/detector.c</code>里面，这个函数首先有很多超参数可以设置，然后我们可以看到这个函数包含了训练验证，测试，计算Anchors，demo展示，计算map值和recall值等功能。由于训练，测试，验证阶段差不多，我们跟进去一个看看就好，至于后面那几个功能是AlexeyAB添加的，之后再逐一解释。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run_detector</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> dont_show = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-dont_show&quot;</span>);<span class="comment">//展示图像界面</span></span><br><span class="line">    <span class="keyword">int</span> benchmark = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-benchmark&quot;</span>);<span class="comment">//评估模型的表现</span></span><br><span class="line">    <span class="keyword">int</span> benchmark_layers = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-benchmark_layers&quot;</span>);</span><br><span class="line">    <span class="comment">//if (benchmark_layers) benchmark = 1;</span></span><br><span class="line">    <span class="keyword">if</span> (benchmark) dont_show = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> show = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-show&quot;</span>);</span><br><span class="line">    <span class="keyword">int</span> letter_box = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-letter_box&quot;</span>);<span class="comment">//是否对图像做letter-box变换</span></span><br><span class="line">    <span class="keyword">int</span> calc_map = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-map&quot;</span>);<span class="comment">//是否计算map值</span></span><br><span class="line">    <span class="keyword">int</span> map_points = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-points&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    check_mistakes = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-check_mistakes&quot;</span>);<span class="comment">//检查数据是否有误</span></span><br><span class="line">    <span class="keyword">int</span> show_imgs = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-show_imgs&quot;</span>);<span class="comment">//显示图片</span></span><br><span class="line">    <span class="keyword">int</span> mjpeg_port = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-mjpeg_port&quot;</span>, <span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">int</span> json_port = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-json_port&quot;</span>, <span class="number">-1</span>);</span><br><span class="line">    <span class="keyword">char</span> *http_post_host = <span class="built_in">find_char_arg</span>(argc, argv, <span class="string">&quot;-http_post_host&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">int</span> time_limit_sec = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-time_limit_sec&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">char</span> *out_filename = <span class="built_in">find_char_arg</span>(argc, argv, <span class="string">&quot;-out_filename&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">char</span> *outfile = <span class="built_in">find_char_arg</span>(argc, argv, <span class="string">&quot;-out&quot;</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">char</span> *prefix = <span class="built_in">find_char_arg</span>(argc, argv, <span class="string">&quot;-prefix&quot;</span>, <span class="number">0</span>);<span class="comment">//模型保存的前缀</span></span><br><span class="line">    <span class="keyword">float</span> thresh = <span class="built_in">find_float_arg</span>(argc, argv, <span class="string">&quot;-thresh&quot;</span>, <span class="number">.25</span>);    <span class="comment">// 置信度</span></span><br><span class="line">    <span class="keyword">float</span> iou_thresh = <span class="built_in">find_float_arg</span>(argc, argv, <span class="string">&quot;-iou_thresh&quot;</span>, <span class="number">.5</span>);    <span class="comment">// 0.5 for mAP</span></span><br><span class="line">    <span class="keyword">float</span> hier_thresh = <span class="built_in">find_float_arg</span>(argc, argv, <span class="string">&quot;-hier&quot;</span>, <span class="number">.5</span>);</span><br><span class="line">    <span class="keyword">int</span> cam_index = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-c&quot;</span>, <span class="number">0</span>);<span class="comment">//摄像头编号</span></span><br><span class="line">    <span class="keyword">int</span> frame_skip = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-s&quot;</span>, <span class="number">0</span>);<span class="comment">//跳帧检测间隔</span></span><br><span class="line">    <span class="keyword">int</span> num_of_clusters = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-num_of_clusters&quot;</span>, <span class="number">5</span>);</span><br><span class="line">    <span class="keyword">int</span> width = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-width&quot;</span>, <span class="number">-1</span>);<span class="comment">// 输入网络的图像宽度</span></span><br><span class="line">    <span class="keyword">int</span> height = <span class="built_in">find_int_arg</span>(argc, argv, <span class="string">&quot;-height&quot;</span>, <span class="number">-1</span>);<span class="comment">// 输入网络的图像高度</span></span><br><span class="line">    <span class="comment">// extended output in test mode (output of rect bound coords)</span></span><br><span class="line">    <span class="comment">// and for recall mode (extended output table-like format with results for best_class fit)</span></span><br><span class="line">    <span class="keyword">int</span> ext_output = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-ext_output&quot;</span>);</span><br><span class="line">    <span class="keyword">int</span> save_labels = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-save_labels&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (argc &lt; <span class="number">4</span>) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;usage: %s %s [train/test/valid/demo/map] [data] [cfg] [weights (optional)]\n&quot;</span>, argv[<span class="number">0</span>], argv[<span class="number">1</span>]);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">char</span> *gpu_list = <span class="built_in">find_char_arg</span>(argc, argv, <span class="string">&quot;-gpus&quot;</span>, <span class="number">0</span>);<span class="comment">// 多个gpu训练</span></span><br><span class="line">    <span class="keyword">int</span> *gpus = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> gpu = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> ngpus = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (gpu_list) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, gpu_list);</span><br><span class="line">        <span class="keyword">int</span> len = (<span class="keyword">int</span>)<span class="built_in">strlen</span>(gpu_list);</span><br><span class="line">        ngpus = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> i;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; len; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (gpu_list[i] == <span class="string">&#x27;,&#x27;</span>) ++ngpus;</span><br><span class="line">        &#125;</span><br><span class="line">        gpus = (<span class="keyword">int</span>*)<span class="built_in">xcalloc</span>(ngpus, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; ngpus; ++i) &#123;</span><br><span class="line">            gpus[i] = <span class="built_in">atoi</span>(gpu_list);</span><br><span class="line">            gpu_list = <span class="built_in">strchr</span>(gpu_list, <span class="string">&#x27;,&#x27;</span>) + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        gpu = gpu_index;</span><br><span class="line">        gpus = &amp;gpu;</span><br><span class="line">        ngpus = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> clear = <span class="built_in">find_arg</span>(argc, argv, <span class="string">&quot;-clear&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *datacfg = argv[<span class="number">3</span>];<span class="comment">//存储训练集，验证集，以及类别对应名字等信息的cfg文件</span></span><br><span class="line">    <span class="keyword">char</span> *cfg = argv[<span class="number">4</span>];<span class="comment">//要训练的网络cfg文件</span></span><br><span class="line">    <span class="keyword">char</span> *weights = (argc &gt; <span class="number">5</span>) ? argv[<span class="number">5</span>] : <span class="number">0</span>;<span class="comment">//是否有预训练模型</span></span><br><span class="line">    <span class="keyword">if</span> (weights)</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">strlen</span>(weights) &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">if</span> (weights[<span class="built_in">strlen</span>(weights) - <span class="number">1</span>] == <span class="number">0x0d</span>) weights[<span class="built_in">strlen</span>(weights) - <span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">char</span> *filename = (argc &gt; <span class="number">6</span>) ? argv[<span class="number">6</span>] : <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;test&quot;</span>)) <span class="built_in">test_detector</span>(datacfg, cfg, weights, filename, thresh, hier_thresh, dont_show, ext_output, save_labels, outfile, letter_box, benchmark_layers);<span class="comment">//执行目标检测模型测试</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;train&quot;</span>)) <span class="built_in">train_detector</span>(datacfg, cfg, weights, gpus, ngpus, clear, dont_show, calc_map, mjpeg_port, show_imgs, benchmark_layers);<span class="comment">//目标检测模型训练</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;valid&quot;</span>)) <span class="built_in">validate_detector</span>(datacfg, cfg, weights, outfile);<span class="comment">//目标检测模型验证</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;recall&quot;</span>)) <span class="built_in">validate_detector_recall</span>(datacfg, cfg, weights);<span class="comment">///计算验证集的召回率</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;map&quot;</span>)) <span class="built_in">validate_detector_map</span>(datacfg, cfg, weights, thresh, iou_thresh, map_points, letter_box, <span class="literal">NULL</span>);<span class="comment">//计算验证集的map值</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;calc_anchors&quot;</span>)) <span class="built_in">calc_anchors</span>(datacfg, num_of_clusters, width, height, show);<span class="comment">//计算验证集的anchors</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span>(argv[<span class="number">2</span>], <span class="string">&quot;demo&quot;</span>)) &#123;<span class="comment">//demo展示</span></span><br><span class="line">        list *options = <span class="built_in">read_data_cfg</span>(datacfg);</span><br><span class="line">        <span class="keyword">int</span> classes = <span class="built_in">option_find_int</span>(options, <span class="string">&quot;classes&quot;</span>, <span class="number">20</span>);</span><br><span class="line">        <span class="keyword">char</span> *name_list = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;names&quot;</span>, <span class="string">&quot;data/names.list&quot;</span>);</span><br><span class="line">        <span class="keyword">char</span> **names = <span class="built_in">get_labels</span>(name_list);</span><br><span class="line">        <span class="keyword">if</span> (filename)</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">strlen</span>(filename) &gt; <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">if</span> (filename[<span class="built_in">strlen</span>(filename) - <span class="number">1</span>] == <span class="number">0x0d</span>) filename[<span class="built_in">strlen</span>(filename) - <span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">demo</span>(cfg, weights, thresh, hier_thresh, cam_index, filename, names, classes, frame_skip, prefix, out_filename,</span><br><span class="line">            mjpeg_port, json_port, dont_show, ext_output, letter_box, time_limit_sec, http_post_host, benchmark, benchmark_layers);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">free_list_contents_kvp</span>(options);</span><br><span class="line">        <span class="built_in">free_list</span>(options);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot; There isn&#x27;t such command: %s&quot;</span>, argv[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (gpus &amp;&amp; gpu_list &amp;&amp; ngpus &gt; <span class="number">1</span>) <span class="built_in">free</span>(gpus);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="跟进train-detector"><a href="#跟进train-detector" class="headerlink" title="跟进train_detector"></a>跟进train_detector</h3><p>由于训练，验证和测试阶段代码几乎是差不多的，只不过训练多了一个反向传播的过程。所以我们主要分析一下训练过程，训练过程是一个比较复杂的过程，不过宏观上大致分为解析网络配置文件，加载训练样本图像和标签，开启训练，结束训练保存模型这样一个过程，部分代码如下（我省略了很多代码，因为这一节是框架总览，后面会详细解释的）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">train_detector</span><span class="params">(<span class="keyword">char</span> *datacfg, <span class="keyword">char</span> *cfgfile, <span class="keyword">char</span> *weightfile, <span class="keyword">int</span> *gpus, <span class="keyword">int</span> ngpus, <span class="keyword">int</span> clear, <span class="keyword">int</span> dont_show, <span class="keyword">int</span> calc_map, <span class="keyword">int</span> mjpeg_port, <span class="keyword">int</span> show_imgs, <span class="keyword">int</span> benchmark_layers)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 从options找出训练图片路径信息，如果没找到，默认使用&quot;data/train.list&quot;路径下的图片信息（train.list含有标准的信息格式：&lt;object-class&gt; &lt;x&gt; &lt;y&gt; &lt;width&gt; &lt;height&gt;），</span></span><br><span class="line">    <span class="comment">// 该文件可以由darknet提供的scripts/voc_label.py根据自行在网上下载的voc数据集生成，所以说是默认路径，其实也需要使用者自行调整，也可以任意命名，不一定要为train.list，</span></span><br><span class="line">    <span class="comment">// 甚至可以不用voc_label.py生成，可以自己不厌其烦的制作一个（当然规模应该是很小的，不然太累了。。。）</span></span><br><span class="line">    <span class="comment">// 读入后，train_images将含有训练图片中所有图片的标签以及定位信息</span></span><br><span class="line">    list *options = <span class="built_in">read_data_cfg</span>(datacfg);</span><br><span class="line">    <span class="keyword">char</span> *train_images = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;train&quot;</span>, <span class="string">&quot;data/train.txt&quot;</span>);</span><br><span class="line">    <span class="keyword">char</span> *valid_images = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;valid&quot;</span>, train_images);</span><br><span class="line">    <span class="keyword">char</span> *backup_directory = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;backup&quot;</span>, <span class="string">&quot;/backup/&quot;</span>);</span><br><span class="line"></span><br><span class="line">    network net_map;</span><br><span class="line">    <span class="comment">//如果要计算map</span></span><br><span class="line">    <span class="keyword">if</span> (calc_map) &#123;</span><br><span class="line">        FILE* valid_file = <span class="built_in">fopen</span>(valid_images, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (!valid_file) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n Error: There is no %s file for mAP calculation!\n Don&#x27;t use -map flag.\n Or set valid=%s in your %s file. \n&quot;</span>, valid_images, train_images, datacfg);</span><br><span class="line">            <span class="built_in">getchar</span>();</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">fclose</span>(valid_file);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">cuda_set_device</span>(gpus[<span class="number">0</span>]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot; Prepare additional network for mAP calculation...\n&quot;</span>);</span><br><span class="line">        net_map = <span class="built_in">parse_network_cfg_custom</span>(cfgfile, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//分类数</span></span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">int</span> net_classes = net_map.layers[net_map.n - <span class="number">1</span>].classes;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> k;  <span class="comment">// free memory unnecessary arrays</span></span><br><span class="line">        <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; net_map.n - <span class="number">1</span>; ++k) <span class="built_in">free_layer_custom</span>(net_map.layers[k], <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">char</span> *name_list = <span class="built_in">option_find_str</span>(options, <span class="string">&quot;names&quot;</span>, <span class="string">&quot;data/names.list&quot;</span>);</span><br><span class="line">        <span class="keyword">int</span> names_size = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//获取类别对应的名字</span></span><br><span class="line">        <span class="keyword">char</span> **names = <span class="built_in">get_labels_custom</span>(name_list, &amp;names_size);</span><br><span class="line">        <span class="keyword">if</span> (net_classes != names_size) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot; Error: in the file %s number of names %d that isn&#x27;t equal to classes=%d in the file %s \n&quot;</span>,</span><br><span class="line">                name_list, names_size, net_classes, cfgfile);</span><br><span class="line">            <span class="keyword">if</span> (net_classes &gt; names_size) <span class="built_in">getchar</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">free_ptrs</span>((<span class="keyword">void</span>**)names, net_map.layers[net_map.n - <span class="number">1</span>].classes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line">     <span class="comment">// 提取配置文件名称中的主要信息，用于输出打印（并无实质作用），比如提取cfg/yolo.cfg中的yolo，用于下面的输出打印</span></span><br><span class="line">    <span class="keyword">char</span> *base = <span class="built_in">basecfg</span>(cfgfile);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, base);</span><br><span class="line">    <span class="keyword">float</span> avg_loss = <span class="number">-1</span>;</span><br><span class="line">    <span class="comment">// 构建网络：用多少块GPU，就会构建多少个相同的网络（不使用GPU时，ngpus=1）</span></span><br><span class="line">    network* nets = (network*)<span class="built_in">xcalloc</span>(ngpus, <span class="built_in"><span class="keyword">sizeof</span></span>(network));</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//设定随机数种子</span></span><br><span class="line">    <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">int</span> seed = <span class="built_in">rand</span>();</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">      <span class="comment">// for循环次数为ngpus，使用多少块GPU，就循环多少次（不使用GPU时，ngpus=1，也会循环一次）</span></span><br><span class="line">    <span class="comment">// 这里每一次循环都会构建一个相同的神经网络，如果提供了初始训练参数，也会为每个网络导入相同的初始训练参数</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; ngpus; ++i) &#123;</span><br><span class="line">        <span class="built_in">srand</span>(seed);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">        <span class="built_in">cuda_set_device</span>(gpus[i]);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">		<span class="comment">//解析网络配置文件</span></span><br><span class="line">        nets[i] = <span class="built_in">parse_network_cfg</span>(cfgfile);</span><br><span class="line">        <span class="comment">//测试某一个网络层的相关指标如运行时间</span></span><br><span class="line">        nets[i].benchmark_layers = benchmark_layers;</span><br><span class="line">        <span class="comment">//如果有预训练模型则加载</span></span><br><span class="line">        <span class="keyword">if</span> (weightfile) &#123;</span><br><span class="line">            <span class="built_in">load_weights</span>(&amp;nets[i], weightfile);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="keyword">if</span> (clear) *nets[i].seen = <span class="number">0</span>;</span><br><span class="line">        nets[i].learning_rate *= ngpus;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="解析配置文件"><a href="#解析配置文件" class="headerlink" title="解析配置文件"></a>解析配置文件</h3><p>截图部分<code>yolov3.cfg</code>网络配置文件如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/647.webp" alt></p>
<p>可以看到配置参数大概分为2类：</p>
<ul>
<li>与训练相关的项，以 [net] 行开头的段. 其中包含的参数有: <code>batch_size, width,height,channel,momentum,decay,angle,saturation,  exposure,hue,learning_rate,burn_in,max_batches,policy,steps,scales</code>。</li>
<li>不同类型的层的配置参数. 如<code>[convolutional], [short_cut], [yolo], [route], [upsample]</code>层等。</li>
</ul>
<p>在src/parse.c中我们会看到一行代码，<code>net-&gt;batch /= net-&gt;subdivisions;</code>，也就是说<code>batch_size</code> 在 darknet 内部又被均分为 <code>net-&gt;subdivisions</code>份, 成为更小的<code>batch_size</code>。 但是这些小的 <code>batch_size</code> 最终又被汇总, 因此 darknet 中的<code>batch_size = net-&gt;batch / net-&gt;subdivisions * net-&gt;subdivisions</code>。此外，和这个参数相关的计算训练图片数目的时候是这样，<code>int imgs = net-&gt;batch * net-&gt;subdivisions * ngpus;</code>，这样可以保证<code>imgs</code>可以被<code>subdivisions</code>整除，因此，通常将这个参数设为8的倍数。从这里也可以看出每个gpu或者cpu都会训练<code>batch</code>个样本。</p>
<p>我们知道了参数是什么样子，那么darknet是如何保存这些参数的呢？这就要看下基本数据结构了。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>An Analysis of Scale Invariance in Object Detection – SNIP</title>
    <url>/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-%E2%80%93-SNIP/</url>
    <content><![CDATA[<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>概括而言，这篇文章从COCO数据集开始分析，认为目前目标检测算法的难点在于数据集中object的尺寸分布较大，尤其对于小目标的检测效果也有待提高，因此提出Scale Normalization for Image Pyramids (SNIP)算法来解决这个问题。</p>
<p>作者将数据集按照图像中目标的尺寸/图像尺寸进行排序，在ImageNet数据集中，这个倍数的中位数差不多0.554，而在COCO数据集中，这个数是0.106。如Figure1中两条线标出的Median点所示。Figure1是关于ImageNet和COCO数据集中object尺寸和图像尺寸的倍数关系曲线，横坐标表示object的尺寸/图像尺寸的值，纵坐标表示占比。<strong>也就是说在COCO数据集中，大部分的object面积只有图像面积的1%以下，这说明在COCO数据集中小目标占比要比ImageNet数据集大</strong>。另外，从Figure1中的COCO曲线可以看出，第90%的倍数（0.472）差不多是第10%的倍数（0.106）的20倍！<strong>这说明在COCO数据集中的object尺寸变化范围非常大</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/v2-61cd98f989aba662764ae4930f6a3c82_hd.jpg" alt></p>
<p><strong>那么这种差异会带来什么影响呢？</strong>因为在目标检测算法中常用基于ImageNet数据集预训练的模型来提取特征，也就是常说的迁移学习，但是<strong>从Figure1的两条曲线可以看出ImageNet和COCO数据集在object的尺寸分布上差异比较大</strong>，这样在做迁移学习时可能会存在一些问题，文章中将这个问题概括为<strong>domain-shift</strong>，可以简单理解为训练集和测试集分布存在较大差异，后面会有实验来证明这种差异对效果的影响。其实YOLO v2也研究了类似的问题，YOLO v2考虑到在ImageNet数据集上预训练模型时输入图像大小是224x224，和检测网络用的尺寸差别较大（YOLO v2中常用416x416），所以就将预训练模型在416x416的ImageNet数据集上继续预训练，然后再用到检测模型提特征，这样就实现了预训练模型和检测模型的良好过渡。（<strong>所以，我们在Imagnet上做预训练，然后进行迁移学习时可能会存在一些问题，简单理解为训练集和测试集分布存在较大差异。</strong>）</p>
<p>其实之前就有不少算法针对数据集中不同尺寸的object检测进行改进，比如以Feature Pyramid Network(FPN)为例的通过融合高低层特征并基于多层融合特征单独预测的算法；以Dilated/Deformable Convolution为例的通过改变卷积核的感受野来提升检测效果；以multi-scale training/inference为例的通过引入图像金字塔来训练或验证图像。<strong>这篇文章基于对数据集的分析，提出一种新的训练模型的方式：Scale Normalization for Image Pyramids (SNIP)，该算法主要包含两个改进点：</strong></p>
<p><strong>1、为了减少前面所提到的domain-shift，在梯度回传时只将和预训练模型所基于的训练数据尺寸相对应的ROI的梯度进行回传。</strong></p>
<p><strong>2、借鉴了multi-scale training的思想，引入图像金字塔来处理数据集中不同尺寸的数据。</strong></p>
<h2 id="几组实验"><a href="#几组实验" class="headerlink" title="几组实验"></a>几组实验</h2><p><strong>①ImageNet数据集实验验证尺寸变化对网络产生的影响</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/v2-62f2ddd1572194258dfb44896f96a61e_hd.jpg" alt></p>
<p><strong>CNN-B：</strong>预训练：ImageNet数据集常规的224x224大小来训练<br>                验证集：首先将ImageNet的验证数据缩小到48x48、64x64、80x80、96x96和128x128，然后再将这些尺寸放大到224x224作为模型的输入，可以看出放大后的图像分辨率较低。<strong>因此这个实验模拟的就是你训练数据的分辨率（resolution）和验证数据的分辨率不一致（甚至是差别很大）的时候对效果的影响，该实验的结果可以看Figure4(a)。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/v2-2ee48ab51574f5b084232195fcf2220d_hd.jpg" alt></p>
<p><strong>CNN-S：</strong>训练数据的分辨率和验证数据的分辨率保持一致，这里主要针对48x48和96x96分辨率，同时对网络结构的第一层做了修改。比如基于48x48的数据进行训练，将卷积核大小为7x7的卷积层换成卷积核为3x3，stride为1的卷积层（因为如果不修改stride的话很容易就卷没了）。基于96x96的数据进行训练时，将卷积核大小为7x7的卷积层换成卷积核尺寸为5x5，stride为2的卷积层。<strong>显然，该实验模拟的是训练数据分辨率和验证数据分辨率一致时的效果，实验结果可以看Figure4(b)(c)。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/v2-342b6b8c14dd6086af6864f7609ee0a6_hd.jpg" alt></p>
<p><strong>CNN-B-FT：</strong>是CNN-B在放大的低分辨率图像上微调后的模型，同时输入图像也采用放大的低分辨率图像。<strong>可以看出该实验主要验证基于高分辨率图像训练的模型是否能有效提取低分辨率图像的特征，实验结果可以看Figure4(b)(c)。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/v2-342b6b8c14dd6086af6864f7609ee0a6_hd.jpg" alt></p>
<p><strong>从（a）可以看出如果验证数据的分辨率和训练数据的分辨率差别越大，则实验结果越差。这说明其实CNN网络对尺寸变化的输入图像的鲁棒性（robust）还不够好。</strong>从（b）和（c）中CNN-B和CNN-S的对比可以看出当训练数据的分辨率和验证数据的分辨率相同时，效果要好很多。从（b）和（c）中CNN-B和CNN-B-FT的对比可以看出后者的效果要更好，二者的差别仅仅在于模型是否在放大的低分辨率图像上做fine tune，因此可以得出结论：<strong>基于高分辨率图像训练的模型同样能有效提取放大的低分辨率图像的特征。</strong></p>
<p><strong>②COCO数据集上关于多尺度和不同尺寸的训练对于实验结果的影响</strong></p>
<p><strong>Table1是关于在小目标验证集上的检测效果对比，所用的验证图像尺寸都是1400x2000。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/18194124-b67e299cac5ef81d.png" alt></p>
<p><strong>800all和1400all：</strong>分别表示检测网络基于800x1400和1400x2000大小的图像进行训练，从二者的mAP结果对比可以看出1400all的效果要更好一些，主要原因就在于训练图像的分辨率和验证图像的分辨率一致，这和前面基于ImageNet数据集的实验结果也吻合，但这个提升非常小，<strong>猜测原因在于虽然基于放大图像（原始图像大概640x480，放大成1400x2000）训练的模型在训练过程中可以提高对小目标物体的检测</strong>，但是由于训练数据中尺寸中等或较大的目标的尺寸太大所以难以训练，这就影响了模型最终的效果。检测结果可以参考Figure5(1)。 </p>
<p><strong>1400&lt;80px：</strong>表示训练数据尺寸是1400x2000，但是训练过程中忽略中等尺寸和大尺寸的目标（中等和大尺寸目标的标准是在原始图像中目标宽高的像素点大于80），也就是基于单一尺寸范围(<strong>scale-specific detector</strong>)的输入进行训练，目的是减少迁移误差。<strong>因此做这个实验的目的是基于前面那个实验中的猜想：基于1400x2000大小的图像训练时由于训练数据中尺寸中等及较大的目标对模型训练有负作用，因此这里直接在训练过程中忽略这样的数据。但是从Table1可以看出这个模型的效果非常差，猜想原因是忽略这些训练数据（占比大约30%）所带来的数据损失对模型效果的影响更大。</strong>具体的检测结果可以参考Figure5(2)。 </p>
<p><strong>Multi-Scale Training(MST)：</strong>表示训练一个检测器时采用不同尺度的图像进行训练（包括480x800），也就是前面所说的<strong>scale invariant detector</strong>。照理来说这个实验的效果应该会比较好的，因为每个object都会有多种尺寸来训检测模型，但是从Table1可以看出该模型的效果和800all差不多，这是为什么呢？<strong>主要原因在于训练数据中那些尺寸非常大或非常小的object会影响训练效果。</strong></p>
<p>Scale Normalization for Image Pyramids(SNIP)是这篇文章提出的算法，在引入MST思想的同时限定了不同尺寸的object在训练过程中的梯度回传，这就是SNIP。 从Table1可以看出效果提升非常明显。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/18194124-d9b20915b3d90d57.png" alt></p>
<p>​                                                    Figure5是关于Table1中不同实验的训练数据展示。</p>
<h2 id="SNIP"><a href="#SNIP" class="headerlink" title="SNIP"></a>SNIP</h2><p>这篇文章基于对数据集的分析，提出一种新的训练模型的方式：Scale Normalization for Image Pyramids (SNIP)，该算法主要包含两个改进点：</p>
<p><strong>1、为了减少前面所提到的domain-shift，在梯度回传时只将和预训练模型所基于的训练数据尺寸相对应的ROI的梯度进行回传。</strong></p>
<p><strong>2、借鉴了multi-scale training的思想，引入图像金字塔来处理数据集中不同尺寸的数据。</strong></p>
<p><strong>从前面的分析可以看出，我们希望有一个算法能够既get到多尺度的目标信息，又能减少迁移误差带来的影响，因此就诞生了SNIP。SNIP借鉴了Multi-Scale Training(MST)的思想，在MST方法中，由于训练数据中尺寸极大或极小的目标会影响实验结果，因此SNIP的做法就是只对尺寸在指定范围内的目标回传损失（该范围需接近预训练模型的训练数据尺寸），也就是说训练过程实际上只是针对这些目标进行的，这样就能减少迁移误差带来的影响。又因为训练过程采用了类似MST的做法，所以每个目标在训练时都会有几个不同的尺寸，那么总有一个尺寸在指定的尺寸范围内。</strong>需要注意的是对目标的尺寸做限制是在训练过程，而不是预先对训练数据做过滤，训练数据还是基于所有数据进行</p>
<p><strong>Figure6是SNIP算法的示意图。</strong>不管是训练检测器还是RPN网络，都是基于所有ground truth来定义proposal和anchor的标签。正如前面所述，某个ROI在某次训练中是否回传梯度是和预训练模型的数据尺寸相关的，也就是说当某个ROI的面积在指定范围内时，该ROI就是valid，也就是会在此次训练中回传梯度，否则就是无效的（如Figure6中右边的紫色框所示）。</p>
<p>其实就是先选择几个尺寸下相似的目标尺寸——&gt;然后选定这些目标去回传梯度——&gt;这些无效的ROI所对应的invalid ground truth会用来决定RPN网络中先验框——&gt;无效先验框的定义是和invalid ground truth的IOU大于0.3的anchor。所以如图所示三个不同尺度下检测的目标大小近似，有效防止了过大或者过小目标对训练的影响。<br>即：</p>
<ul>
<li>每个pipe-line的RPN只负责一个scale range的proposal生成。</li>
<li>对于大size的feature map，对应的RPN只负责预测被放大的小物体；对于小size的feature map，对应的RPN只负责预测被缩小的大物体；这样的设计保证了每个CNN分支在判别proposal是否为前景时，只需针对最易分类的中等range的proposal进行训练。</li>
<li>在Image Pyramid的基础上加入了 每层scale 的 proposal有效生成范围，发扬本scale的优势，回避其他scale的劣势，大大降低了前景分类任务的难度，从而“作弊式”地实现了Scale Invariance。</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/18194124-c5b361a53d0a4132.jpg" alt></p>
<p><strong>关于RPN网络中不同标签的anchor比例作者也做了分析</strong>，我们知道在RPN网络中，一个anchor的标签是根据该anchor和ground truth的IOU来决定的，<strong>只有两种情况下才会认为某个anchor的标签是正样本（标签为1）：</strong></p>
<p><strong>1、假如该anchor和某个ground truth的IOU超过某个阈值（阈值默认采用是0.7），那么该ancho就是正样本。</strong></p>
<p><strong>2、假如一个ground truth和所有anchor的IOU都没超过该阈值，那么和该ground truth的IOU最大的那个anchor就是正样本。</strong></p>
<p>同样，作者将conv4的输出作为RPN网络的输入，然后设置了15种anchor（5 scales，3 aspect ratios），接下来就有意思了，作者发现在COCO数据集上（图像大小为800 x 1200），只有30%的ground truth满足前面第一种情况！即便将阈值调整为0.5，也只有58%的ground truth满足第一种情况！这说明什么？</p>
<p><strong>说明即便阈值等于0.5，仍有40%的正样本anchor和ground truth的IOU小于0.5</strong>（这些anchor是因为满足前面的情况2才被定义为正样本）！显然，这样的正样本质量不算很高。而这篇文章因为引入多种分辨率的图像作为输入，所以在一定程度上缓解了这种现象。另外，作者也尝试将conv4和conv5的特征做融合并预测，不过这部分文章只是一笔带过，还需要看源码才能知道具体是怎么做的。</p>
<h2 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h2><p>Table2是SNIP算法和其他算法的对比。第二行的multi-scale test显然比第一行的single scale效果要好。第三行，在multi-scale test的基础上加入multi-scale train的时候，会发现在大尺寸目标（APL）的检测效果上要比只有multi-scale test的时候差。这个原因我们在前面也介绍过了，主要是因为训练数据中那些尺寸极大和极小的object对训练产生了负作用。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/18194124-9c7a6d9280067a8a.png" alt></p>
<p>Table4是几个目标检测算法结果的对比。D-RFCN表示Deformable RFCN。D-RFCN+SNIP(RCN+RPN)表示在Deformable RFCN算法的检测模块和RPN网络中同时加入SNIP。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SNIP/18194124-466c29b67f2c10d5.png" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>BitComet配置</title>
    <url>/2022/01/12/BitComet%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>本文记录对BitComet的一些配置修改，用于备份。</p>
<h2 id="BitComet"><a href="#BitComet" class="headerlink" title="BitComet"></a>BitComet</h2><p>BitComet（比特彗星）是一款完全免费的BT下载软件，支持断点续传和边下载边播放下载管理软件，也称BT下载客户端，同时也是一个集BT/HTTP/FTP于一体的下载管理器。官网下载地址：<a href="http://www.bitcomet.com/en/downloading?platform=win32">BitComet - Downloading</a></p>
<p>不过还是建议去找第三方修改版能开启种子市场的，有意想不到的福利哦😋</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>确保你的网络为公网，路由器也需打开端口映射，没公网的可打电话申请或使用穿透工具等，这里就不介绍了，确保打开软件，右下角两绿灯亮起：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/1.jpg" alt></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h3><p>我这里设置下载不限速，也可以根据自己的带宽设置。上传建议比自己最大上传带宽小，不要设置太大，但也不能设置太低（有上传才有下载，人人为我，我为人人！），我这里设置780KB/s。</p>
<p>监听端口建议自己指定一个，不推荐<code>6881-6885</code> ，<code>16881-16885</code>范围内和一些特殊的端口。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/2.jpg" alt></p>
<h3 id="下载目录"><a href="#下载目录" class="headerlink" title="下载目录"></a>下载目录</h3><p>自己设置合适的下载目录。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/3.jpg" alt></p>
<h3 id="任务队列"><a href="#任务队列" class="headerlink" title="任务队列"></a>任务队列</h3><p>推荐做种任务数拉满，下载任务数不要太大。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/4.jpg" alt></p>
<h3 id="BT下载"><a href="#BT下载" class="headerlink" title="BT下载"></a>BT下载</h3><p>勾选加入DHT，自动反吸血，协议优先，种子存档、种子市场打开，上传无限制或根据自己上传带宽设置。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/5.jpg" alt></p>
<h3 id="Tracker"><a href="#Tracker" class="headerlink" title="Tracker"></a>Tracker</h3><p>网上可以找一些tracker服务器列表，进行添加，我这里用的列表是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://github.itzmx.com/1265578519/OpenTracker/master/tracker.txt</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/6.jpg" alt></p>
<h3 id="电驴下载"><a href="#电驴下载" class="headerlink" title="电驴下载"></a>电驴下载</h3><p>需要支持eD2k网络的，可安装插件。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/7.jpg" alt></p>
<h3 id="长效种子"><a href="#长效种子" class="headerlink" title="长效种子"></a>长效种子</h3><p>推荐启用，上传限速可自动，也可根据自己的上传带宽设置。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/8.jpg" alt></p>
<h3 id="系统集成"><a href="#系统集成" class="headerlink" title="系统集成"></a>系统集成</h3><p>默认关联、浏览器插件等，根据自己的需要设置即可。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/9.jpg" alt></p>
<h3 id="界面外观"><a href="#界面外观" class="headerlink" title="界面外观"></a>界面外观</h3><p>根据自己的喜好设置外观、操作。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/10.jpg" alt></p>
<h3 id="高级设置"><a href="#高级设置" class="headerlink" title="高级设置"></a>高级设置</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/11.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/12.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/13.jpg" alt></p>
<p>比较重要的设置：</p>
<ul>
<li>bittorrent.max_connections_per_ltseed：每个长效种子的最大连接数（1-10），推荐拉满，设置10。</li>
<li>bittorrent.max_connections_per_task：每任务最大连接数（0为自动），推荐设置个适当的值，不要太大，这里我设置200。</li>
<li>network.max_connecting_connections：最大同时尝试的TCP连接个数（0为自动），推荐设置个适当的值，不要太大，这里我设置跟bittorrent.max_connections_per_task一样。</li>
<li>torrent_share.max_metadata_dl_task：并发下载元数据的最大数量（1-1000），推荐拉满。</li>
<li>torrent_share.metadata_dl_timeout：下载元数据的超时秒数（10-3600），设值最低。</li>
<li>ui.preview_program_path：视频预览程序路径，也就是边看边播所用播放器的路径，这里我设置成使用potplayer</li>
</ul>
<h3 id="磁盘缓存"><a href="#磁盘缓存" class="headerlink" title="磁盘缓存"></a>磁盘缓存</h3><p>勾选在最大最小值范围内自动调整缓存大小即可，也可以自己设置最大最小，一般最小可设128M，最大可设你内存大小。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/14.jpg" alt></p>
<h2 id="下载表现"><a href="#下载表现" class="headerlink" title="下载表现"></a>下载表现</h2><p>配置完毕后，随便找了个种子下载，速度还是不错的。😊</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/bitcomet/15.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>BitComet</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN结构无痛涨点技巧：ACNet</title>
    <url>/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>CNN的结构创新在这两年已经变得相对很少了，同时要做出有影响力并且Solid的工作也变得越来越难，最近CNN结构方面的创新主要包含两个方面：</p>
<ul>
<li>网络结构搜索，以Google Brain的EfficientNet为代表作。</li>
<li>获取更好的特征表达，主要是将特征复用，特征细化做得更加极致，以HRNet，Res2Net等为代表作。</li>
</ul>
<p>本文要介绍的是ICCV 2019的一个新CNN架构ACNet（全称为Asymmetric Convolution  Net），因此这篇文章的目的是讲清楚ACNet的原理并总结它的核心思想，另外借助作者开源的Pytorch代码端来加深理解。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>ACNet的切入点为获取更好的特征表达，但和其它方法最大的区别在于它没有带来额外的超参数，而且在推理阶段没有增加计算量，这是十分具有吸引力的。</p>
<p>在正式介绍ACNet之前，首先来明确一下关于卷积计算的一个等式，这个等式表达的意思就是<strong>「对于输入特征图$I$，先进行$K^{(1)}$和$I$卷积，$K^{(2)}$和$I$卷积后再对结果进行相加，与先进行$K^{(1)}$和$K^{(2)}$的逐点相加后再和$I$进行卷积得到的结果是一致的」</strong>。这也是ACNet在推理阶段不增加任何计算量的理论基础。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/640.png" alt></p>
<h2 id="ACNet原理"><a href="#ACNet原理" class="headerlink" title="ACNet原理"></a>ACNet原理</h2><p>下面的Figure1展示了ACNet的思想：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/641.png" alt></p>
<p>宏观上来看<strong>「ACNet分为训练和推理阶段，训练阶段重点在于强化特征提取，实现效果提升。而测试阶段重点在于卷积核融合，不增加任何计算量」</strong>。</p>
<ul>
<li><p><strong>「训练阶段」</strong>：因为3 x 3卷积是大多数网络的基础组件，因此ACNet的实验都是针对3 x 3卷积进行的。训练阶段就是将现有网络中的每一个3 x 3卷积换成3 x 1卷积+1 x 3卷积+3 x 3卷积共三个卷积层，最终将这三个卷积层的计算结果进行融合获得卷积层的输出。因为这个过程中引入的1 x 3卷积和3 x 1卷积是非对称的，所以将其命名为Asymmetric Convolution。</p>
</li>
<li><p><strong>「推理阶段」</strong>：如上图右半部分所示，这部分主要是对三个卷积核进行融合。这部分在实现过程中就是使用融合后的卷积核参数来初始化现有的网络，因此在推理阶段，网络结构和原始网络是完全一样的了，只不过网络参数采用了特征提取能力更强的参数即融合后的卷积核参数，因此在推理阶段不会增加计算量。</p>
</li>
</ul>
<p>总结一下就是ACNet在训练阶段强化了原始网络的特征提取能力，在推理阶段融合卷积核达到不增加计算量的目的。虽然训练时间增加了一些时间，但却换来了在推理阶段速度无痛的精度提升，怎么看都是一笔非常划算的交易。下面的Table3展示了在一些经典网络上应用ACNet的结果，对于AlexNet精度提升了比较多，而对ResNet和DenseNet精度则提升不到一个百分点，不过考虑到这个提升是白赚的也还是非常值得肯定的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/642.png" alt></p>
<h2 id="为什么ACNet能涨点？"><a href="#为什么ACNet能涨点？" class="headerlink" title="为什么ACNet能涨点？"></a>为什么ACNet能涨点？</h2><p>为什么ACNet这个看起来十分简单的操作能为各种网络带来涨点？论文中提到，ACNet有一个特点是<strong>「它提升了模型对图像翻转和旋转的鲁棒性」</strong>，例如训练好后的1 x 3卷积和在图像翻转后仍然能提取正确的特征（如Figure4左图所示，2个红色矩形框就是图像翻转前后的特征提取操作，在输入图像的相同位置处提取出来的特征还是一样的）。那么假设训练阶段只用3 x 3卷积核，当图像上下翻转之后，如Figure4右图所示，提取出来的特征显然是不一样的。</p>
<p>因此，引入1 x 3这样的水平卷积核可以提升模型对图像上下翻转的鲁棒性，竖直方向的卷积核同理。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/643.png" alt></p>
<p>下面的Table4则继续从实验角度解释了这种鲁棒性：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/644.png" alt></p>
<h2 id="推理阶段的卷积核融合"><a href="#推理阶段的卷积核融合" class="headerlink" title="推理阶段的卷积核融合"></a>推理阶段的卷积核融合</h2><p>推理阶段的融合操作如Figure3所示，在论文中提到具体的融合操作是和BN层一起的，然后融合操作时发生在BN之后的。但是其实也可以把融合操作放在BN层之前，也就是三个卷积层计算完之后就开始融合。论文对这两种融合方式进行了实验，在上面的Table4中BN in branch这一列有√的话表示融合是在BN之后，可以看到这种方式使得效果确实会更好一些。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ACNet/645.png" alt></p>
<h2 id="Pytorch代码实现"><a href="#Pytorch代码实现" class="headerlink" title="Pytorch代码实现"></a>Pytorch代码实现</h2><p>我们来看一下作者的ACNet基础结构Pytorch实现，即将原始的3 x 3卷积变成：3 x 3 + 3 x 1 + 1 x 3：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 去掉因为3x3卷积的padding多出来的行或者列</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CropLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#   E.g., (-1, 0) means this layer should crop the first and last rows of the feature map. And (0, -1) crops the first and last columns</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, crop_set</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CropLayer, self).__init__()</span><br><span class="line">        self.rows_to_crop = - crop_set[<span class="number">0</span>]</span><br><span class="line">        self.cols_to_crop = - crop_set[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> self.rows_to_crop &gt;= <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> self.cols_to_crop &gt;= <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>[:, :, self.rows_to_crop:-self.rows_to_crop, self.cols_to_crop:-self.cols_to_crop]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 论文提出的3x3+1x3+3x1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ACBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, deploy=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ACBlock, self).__init__()</span><br><span class="line">        self.deploy = deploy</span><br><span class="line">        <span class="keyword">if</span> deploy:</span><br><span class="line">            self.fused_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(kernel_size,kernel_size), stride=stride,</span><br><span class="line">                                      padding=padding, dilation=dilation, groups=groups, bias=<span class="literal">True</span>, padding_mode=padding_mode)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.square_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,</span><br><span class="line">                                         kernel_size=(kernel_size, kernel_size), stride=stride,</span><br><span class="line">                                         padding=padding, dilation=dilation, groups=groups, bias=<span class="literal">False</span>,</span><br><span class="line">                                         padding_mode=padding_mode)</span><br><span class="line">            self.square_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line"></span><br><span class="line">            center_offset_from_origin_border = padding - kernel_size // <span class="number">2</span></span><br><span class="line">            ver_pad_or_crop = (center_offset_from_origin_border + <span class="number">1</span>, center_offset_from_origin_border)</span><br><span class="line">            hor_pad_or_crop = (center_offset_from_origin_border, center_offset_from_origin_border + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> center_offset_from_origin_border &gt;= <span class="number">0</span>:</span><br><span class="line">                self.ver_conv_crop_layer = nn.Identity()</span><br><span class="line">                ver_conv_padding = ver_pad_or_crop</span><br><span class="line">                self.hor_conv_crop_layer = nn.Identity()</span><br><span class="line">                hor_conv_padding = hor_pad_or_crop</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.ver_conv_crop_layer = CropLayer(crop_set=ver_pad_or_crop)</span><br><span class="line">                ver_conv_padding = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">                self.hor_conv_crop_layer = CropLayer(crop_set=hor_pad_or_crop)</span><br><span class="line">                hor_conv_padding = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">            self.ver_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                      stride=stride,</span><br><span class="line">                                      padding=ver_conv_padding, dilation=dilation, groups=groups, bias=<span class="literal">False</span>,</span><br><span class="line">                                      padding_mode=padding_mode)</span><br><span class="line"></span><br><span class="line">            self.hor_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                      stride=stride,</span><br><span class="line">                                      padding=hor_conv_padding, dilation=dilation, groups=groups, bias=<span class="literal">False</span>,</span><br><span class="line">                                      padding_mode=padding_mode)</span><br><span class="line">            self.ver_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line">            self.hor_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.deploy:</span><br><span class="line">            <span class="keyword">return</span> self.fused_conv(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            square_outputs = self.square_conv(<span class="built_in">input</span>)</span><br><span class="line">            square_outputs = self.square_bn(square_outputs)</span><br><span class="line">            <span class="comment"># print(square_outputs.size())</span></span><br><span class="line">            <span class="comment"># return square_outputs</span></span><br><span class="line">            vertical_outputs = self.ver_conv_crop_layer(<span class="built_in">input</span>)</span><br><span class="line">            vertical_outputs = self.ver_conv(vertical_outputs)</span><br><span class="line">            vertical_outputs = self.ver_bn(vertical_outputs)</span><br><span class="line">            <span class="comment"># print(vertical_outputs.size())</span></span><br><span class="line">            horizontal_outputs = self.hor_conv_crop_layer(<span class="built_in">input</span>)</span><br><span class="line">            horizontal_outputs = self.hor_conv(horizontal_outputs)</span><br><span class="line">            horizontal_outputs = self.hor_bn(horizontal_outputs)</span><br><span class="line">            <span class="comment"># print(horizontal_outputs.size())</span></span><br><span class="line">            <span class="keyword">return</span> square_outputs + vertical_outputs + horizontal_outputs</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然后在推理阶段进行卷积核融合的代码实现地址为：<code>https://github.com/DingXiaoH/ACNet/blob/master/acnet/acnet_fusion.py</code>，对照Figure3就比较好理解了，介于篇幅这里就不贴这段代码了。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>从实验结果中可以看到，在推理阶段即使融合操作放在BN层之前，相比原始网络仍有一定提升（AlexNet的56.18% vs 55.92%，ResNet-18的70.82% vs 70.36%），作者没有讲解这部分的原理，某位大佬提出的观点，如下：</p>
<blockquote>
<p>这部分的原因个人理解是来自梯度差异化，原来只有一个3 x 3卷积层，梯度可以看出一份，而添加了1 x 3和3 x 1卷积层后，部分位置的梯度变为2份和3份，也是更加细化了。而且理论上可以融合无数个卷积层不断逼近现有网络的效果极限，融合方式不限于相加（训练和推理阶段一致即可），融合的卷积层也不限于1 x 3或3 x 1尺寸。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文简要讲述了ACNet这个无痛的调参方法，这种方法创新点是非常棒的，我们不一定需要重型BackBone去提取特征，也不一定需要复杂的结构复用特征，像ACNet这样的优雅并且有效的作品确实让人眼前一亮。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake Error at /usr/share/cmake-3.5/Modules/FindQt4.cmake:634 (message)</title>
    <url>/2020/01/19/CMake%20Error/</url>
    <content><![CDATA[<p>编译工程时出现cmake找不到Qt4的问题,如下:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMake Warning at /usr/share/cmake-3.5/Modules/FindQt4.cmake:626 (message):</span><br><span class="line">/usr/bin/qmake-qt4 reported QT_INSTALL_LIBS as &quot;/usr/lib/x86_64-linux-gnu&quot;</span><br><span class="line"> but QtCore could not be found there.  </span><br><span class="line"> Qt is NOT installed correctly for the target build environment.</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CMake Error at /usr/share/cmake-3.5/Modules/FindQt4.cmake:634 (message):</span><br><span class="line">  Could NOT find QtCore. </span><br></pre></td></tr></table></figure><br>解决办法<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install cmake gcc g++ qt&#123;4,5&#125;-qmake libqt4-dev</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>CVPR 2017 ResNeXt（ResNet进化版）</title>
    <url>/2020/04/10/CVPR-2017-ResNeXt%EF%BC%88ResNet%E8%BF%9B%E5%8C%96%E7%89%88%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>传统的卷积神经网络在提高性能时都是加深和加宽网络，但随着超参数数量的增加(如通道数，卷积核大小等)网络变得非常难调，且网络的计算开销和网络结构设计也变得越来越难。此外这些大模型针对性比较强，即在特定数据集上表现好的网络放到新数据集上就需要修改很多的参数才能工作良好，因此可扩展性比较一般。针对上述问题，Saining Xie, Ross Girshick, Kaiming He在CVPR2017上提出了ResNeXt。</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul>
<li>网络结构更加简单和模块化。</li>
<li>大量减少了需要手动调节的超参数，扩展性更强。</li>
<li>和ResNet相比，相同的参数个数，结果更好。具体来说，一个101层的ResNeXt网络和200层的ResNet准确度差不多，但是计算量只有后者的一半。</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>ResNeXt的网络结构如Table1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/640.webp" alt></p>
<p>Table 1的左边网络为ResNet-50，Table 1的右边网络为ResNeXt-50，括号代表残差块，括号外面的数字代表残差块的堆叠次数，而C代表的ResNeXt引入的卷积分组数，同时可以看到这两个网络的FLOPs基本一致，也即是说模型复杂度一致。那ResNeXt有什么优点呢？这要先从分组来说起。</p>
<h3 id="ResNeXt残差模块"><a href="#ResNeXt残差模块" class="headerlink" title="ResNeXt残差模块"></a>ResNeXt残差模块</h3><p>分组数在论文中又被称为基数(cardinality)，是对GoogleNet中分立合并思想和VGG/ResNet中堆叠思想的一种结合，ResNet的残差模块和ResNeXt的残差模块如Figure1所示。可以看到ResNeXt残差模块有32个基数(分组数)，并且每个被聚合的拓扑结构就完全一样，这里是1 x 1 + 3 x 3 + 1 x 1的组件，这也是和Inception结构的最大区别。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/641.webp" alt></p>
<p>然后论文从理论角度来分析了一下这个ResNeXt残差模块，用全连接层举例来讲，全连接层的公式可以表示为：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/642.webp" alt></p>
<p>然后Figure2就清晰的展示了全连接层分离变化合并(<code>split-transform-merge</code>)的处理过程：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/643.webp" alt></p>
<p>而ResNeXt残差模块实际上就是将其中的$w_{i} x_{i}$替换成了更一般的函数，用公式表示如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/644.png" alt></p>
<p>其中$C$就是上一节提到的分组数/基数，而$T_{i}(x)$代表的是相同的拓扑结构，在Figure1中就是<code>1x1+3x3+1x1</code>卷积堆叠。</p>
<h3 id="等价模式"><a href="#等价模式" class="headerlink" title="等价模式"></a>等价模式</h3><p>而Figure1中的ResNeXt残差模块有两种等价的模型，如Figure3所示。其中Figure3（a）前面已经讲过了。而Figure3（b）表示的是使用了两层卷积后concat，然后再卷积，比较类似于Inception-ResNet。Figure3（c）使用的是原始的组卷积。论文指出这三种结构是完全等价的，并且最后做出来的实验结果完全一样，而在实验部分展示的是Figure3（c）的结果，因为Figure3（c）的结构比较简洁并且速度更快。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/645.webp" alt></p>
<h3 id="模型容量"><a href="#模型容量" class="headerlink" title="模型容量"></a>模型容量</h3><p>下面的Table2说明了Figure1左右两个结构即ResNet结构和ResNeXt结构的参数量差不多，其中第二行的$d$表示每个路径的中间channel数量，而第三行代表整个模块的宽度，是第一行$C$和第二行$d$的乘积。关于这两个模型容量也就是FLOPs的计算如公式(4)。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/646.png" alt></p>
<p>FLOPs计算公式如下，可以看到FLOPs基本相等。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/647.webp" alt></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>在实验中ResNeXt相比于ResNet区别仅仅是其中的block，其他都不变，作者的实验结果如Figure5所示。可以看到相同层数的ResNet和ResNeXt的对比：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/648.webp" alt></p>
<p>其中，32 x 4d表示的是有32个相同的路径，然后每个路径的宽度都为4，即如Figure3展示的那样。可以看到ResNeXt和ResNet的参数复杂度差不多，但是其训练误差和测试误差都降低了。</p>
<p>ResNet和ResNeXt在ImageNet上的对比结果如Table3所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/649.jpg" alt></p>
<p>另外一个重要的实验结果如Table4所示，主要说明了增加基数/分组数和增加宽度和深度的区别。第一个是基准模型，增加深度和宽度分别是第三，第四个，可以看到Top1误差分别降低了0.3%和0.7%。同时第五个加倍了分组数Top1误差降低了1.3%，第六个则把分组数加到了64，Top1误差降低了1.6。由此可以看出，增加分组数比增加深度或宽度会更加有效。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ResNeXt/650.webp" alt></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>ResNeXt这篇论文提出了使用一种平行堆叠相同拓扑结构的残差模块来代替原始的残差模块，在不明显增加参数量的同时提升了模型的准确率，同时由于拓扑结构相同，需要自己调的超参数也减少因此更便于模型的扩展和移值。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>ECCV 2018 Convolutional Block Attention Module</title>
    <url>/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前cv领域借鉴了nlp领域的attention机制以后生产出了很多有用的基于attention机制的论文，attention机制也是在2019年论文中非常火。这篇cbam虽然是在2018年提出的，但是其影响力比较深远，在很多领域都用到了该模块，所以一起来看一下这个模块有什么独到之处，并学着实现它。</p>
<h2 id="什么是注意力机制？"><a href="#什么是注意力机制？" class="headerlink" title="什么是注意力机制？"></a>什么是注意力机制？</h2><p>注意力机制（Attention Mechanism）是机器学习中的一种数据处理方法，广泛应用在自然语言处理、图像识别及语音识别等各种不同类型的机器学习任务中。</p>
<p>通俗来讲：注意力机制就是希望网络能够自动学出来图片或者文字序列中的需要注意的地方。比如人眼在看一幅画的时候，不会将注意力平等地分配给画中的所有像素，而是将更多注意力分配给人们关注的地方。</p>
<p>从实现的角度来讲：注意力机制通过神经网络的操作生成一个掩码mask,，mask上的值一个打分，评价当前需要关注的点的评分。</p>
<p>注意力机制可以分为：</p>
<ul>
<li>通道注意力机制：对通道生成掩码mask，进行打分，代表是SENet, Channel Attention Module</li>
<li>空间注意力机制：对空间进行掩码的生成，进行打分，代表是Spatial Attention Module</li>
<li>混合域注意力机制：同时对通道注意力和空间注意力进行评价打分，代表的有BAM, CBAM</li>
</ul>
<h2 id="怎么实现CBAM？-pytorch为例"><a href="#怎么实现CBAM？-pytorch为例" class="headerlink" title="怎么实现CBAM？(pytorch为例)"></a><strong>怎么实现CBAM？(pytorch为例)</strong></h2><p>CBAM全称是Convolutional Block Attention Module, 是在ECCV2018上发表的注意力机制代表作之一，<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Sanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdf">论文下载地址</a>。</p>
<p>在该论文中，作者研究了网络架构中的注意力，注意力不仅要告诉我们重点关注哪里，还要提高关注点的表示。目标是通过使用注意机制来增加表现力，关注重要特征并抑制不必要的特征。为了强调空间和通道这两个维度上的有意义特征，作者依次应用<strong>通道和空间注意模块</strong>，来分别在通道和空间维度上学习关注什么、在哪里关注。此外，通过了解要强调或抑制的信息也有助于网络内的信息流动。</p>
<p>主要网络架构也很简单，一个是通道注意力模块，另一个是空间注意力模块，CBAM就是先后集成了通道注意力模块和空间注意力模块。</p>
<h3 id="2-1-通道注意力机制"><a href="#2-1-通道注意力机制" class="headerlink" title="2.1 通道注意力机制"></a>2.1 通道注意力机制</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/640.webp" alt></p>
<p>通道注意力机制按照上图进行实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, rotio=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.sharedMLP = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_planes, in_planes // ratio, <span class="number">1</span>, bias=<span class="literal">False</span>), nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_planes // rotio, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avgout = self.sharedMLP(self.avg_pool(x))</span><br><span class="line">        maxout = self.sharedMLP(self.max_pool(x))</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(avgout + maxout)</span><br></pre></td></tr></table></figure>
<h3 id="2-2-空间注意力机制"><a href="#2-2-空间注意力机制" class="headerlink" title="2.2 空间注意力机制"></a>2.2 空间注意力机制</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/641.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">7</span>), <span class="string">&quot;kernel size must be 3 or 7&quot;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(<span class="number">2</span>,<span class="number">1</span>,kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avgout = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        maxout, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avgout, maxout], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br></pre></td></tr></table></figure>
<h3 id="2-3-Convolutional-bottleneck-attention-module"><a href="#2-3-Convolutional-bottleneck-attention-module" class="headerlink" title="2.3 Convolutional bottleneck attention module"></a>2.3 Convolutional bottleneck attention module</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/642.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inplanes, planes, stride=<span class="number">1</span>, downsample=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line">        self.ca = ChannelAttention(planes)</span><br><span class="line">        self.sa = SpatialAttention()</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.ca(out) * out  <span class="comment"># 广播机制</span></span><br><span class="line">        out = self.sa(out) * out  <span class="comment"># 广播机制</span></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">        out += residual</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>为何要先使用通道注意力机制然后再使用空间注意力机制？使用顺序使用这两个模块还是并行的使用两个模块？其实是作者已经做过了相关实验，并且证明了先试用通道然后再使用空间注意力机制这样的组合效果比较好，这也是CBAM的通用组合模式。</p>
<h2 id="在什么情况下可以使用？"><a href="#在什么情况下可以使用？" class="headerlink" title="在什么情况下可以使用？"></a>在什么情况下可以使用？</h2><p>提出CBAM的作者主要对分类网络和目标检测网络进行了实验,证明了CBAM模块确实是有效的。</p>
<p>以ResNet为例，论文中提供了改造的示意图，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/643.webp" alt></p>
<p>也就是在ResNet中的每个block之间添加了CBAM模块，训练数据来自benchmark ImageNet-1K。检测使用的是Faster  R-CNN， Backbone选择的ResNet34，ResNet50，WideResNet18，ResNet50等，还跟SE等进行了对比。</p>
<p><strong>消融实验</strong>：消融实验一般是控制变量，最能看出模型变好起作用的部分在那里。分为三个部分：</p>
<ul>
<li><p>如何更有效地计算channel attention?</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/644.webp" alt>可以看出来，使用avgpool和maxpool可以更好的降低错误率，大概有1-2%的提升，这个组合就是dual pooling，能提供更加精细的信息，有利于提升模型的表现。</p>
</li>
<li><p>如何更有效地计算spatial attention?</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/645.webp" alt></p>
<p>这里的空间注意力机制参数也是有avg，max组成，另外还有一个卷积的参数kernel_size(k)，通过以上实验，可以看出，当前使用通道的平均和通道的最大化，并且设置kernel size=7是最好的。</p>
</li>
<li><p>如何组织这两个部分？</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/646.webp" alt></p>
<p>可以看出，这里与SENet中的SE模块也进行了比较，这里使用CBAM也是超出了SE的表现。除此以外，还进行了顺序和并行的测试，发现，先channel attention然后spatial attention效果最好，所以也是最终的CBAM模块的组成。</p>
<p>在MSCOCO数据及使用了ResNet50，ResNet101为backbone，Faster RCNN为检测器的模型进行目标检测，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/647.webp" alt></p>
<p>在VOC2007数据集中采用了StairNet进行了测试，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CBAM/648.webp" alt></p>
<p>貌似没有找到目标检测部分的代码，CBAM的作用在于对信息进行精细化分配和处理，所以猜测是在backbone的分类器之前添加的CBAM模块。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>CVPR 2018 Cascade R-CNN</title>
    <url>/2020/04/07/CVPR-2018-Cascade-R-CNN/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Cascade R-CNN这个算法是CVPR 2018提出的，通过级联多个检测网络达到不断优化预测结果的目的。但是和普通的级联检测器不同，Cascade R-CNN的多个检测网络是基于不同的IOU阈值进而确定不同的正负样本训练出来的，在COCO数据集上Cascade  R-CNN取得了非常出色的结果，并且也成为了当前目标检测比赛中的有力Trick。</p>
<h2 id="简单回顾R-CNN结构"><a href="#简单回顾R-CNN结构" class="headerlink" title="简单回顾R-CNN结构"></a>简单回顾R-CNN结构</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/v2-11788fb6c9bb4840e17be9a63ab38759_hd.jpg" alt></p>
<p>首先，以经典的Faster R-CNN为例。整个网络可以分为两个阶段，training阶段和inference阶段，如上图所示。</p>
<ul>
<li>training阶段，RPN网络提出了2000左右的proposals，这些proposals被送入到Fast R-CNN结构中，在Fast  R-CNN结构中，首先计算每个proposal和gt之间的iou，通过人为的设定一个IoU阈值（通常为0.5），把这些Proposals分为正样本（前景）和负样本（背景），并对这些正负样本采样，使得他们之间的比例尽量满足（1:3，二者总数量通常为128），之后这些proposals（128个）被送入到Roi Pooling，最后进行类别分类和box回归。</li>
<li>inference阶段，RPN网络提出了300左右的proposals，这些proposals被送入到Fast R-CNN结构中，<strong>和training阶段不同的是，inference阶段没有办法对这些proposals采样（inference阶段肯定不知道gt的，也就没法计算iou）</strong>，所以他们直接进入Roi Pooling，之后进行类别分类和box回归。</li>
</ul>
<p>在这里插一句，在R-CNN中用到IoU阈值的有两个地方，分别是Training时<strong>Positive</strong>与<strong>Negative</strong>判定，和Inference时计算mAP。论文中强调的IoU阈值指的是Training时<strong>Positive</strong>和<strong>Negative</strong>判定处。</p>
<h2 id="出发点"><a href="#出发点" class="headerlink" title="出发点"></a>出发点</h2><p>下面的Figure1展示了Cascade R-CNN的出发点。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/640.jpg" alt></p>
<ul>
<li><p><code>Figure1(a)</code>展示了当IOU阈值等于0.5时的检测结果，可以看到结果图中存在较多误检，因为0.5的阈值会使得正样本中有较多的背景，这是产生误检的主要原因。</p>
</li>
<li><p><code>Figure1(b)</code>展示了当IOU阈值等于0.7时的检测结果，可以看到误检变少了，但是并不一定误检变少了结果就一定更好，因为IOU阈值更大导致正样本越少，那么过拟合的风险就越大。</p>
</li>
<li><p><code>Figure1(c)</code>展示了模型定位表现，其中横坐标表示输入候选框和GT框的IOU值，即proposal的IoU，纵坐标表示输出的候选框和GT框的IOU值， 即经过box reg得到的新的IoU。然后，红，绿，蓝三条曲线分别代表训练检测模型时用的正负样本标签的阈值分别是0.7，0.6，0.5。可以看到<strong>当一个检测模型采用某个IOU阈值（假设u=0.6）来判定正负样本时，那么当输入候选框和GT的IOU在这个阈值（u=0.6）附近时，该检测模型比基于其它阈值的检测模型效果更好</strong>。</p>
</li>
<li><p><code>Figure1(d)</code>展示了使用不同阈值来训练检测模型的表现，可以看出当IOU阈值等于0.7的时候效果下降比较明显，原因是IOU阈值过高导致正样本数量更少，这样<strong>样本</strong>会更加不平衡并且容易导致过拟合。</p>
</li>
</ul>
<h2 id="Cascade-R-CNN原理"><a href="#Cascade-R-CNN原理" class="headerlink" title="Cascade R-CNN原理"></a>Cascade R-CNN原理</h2><p>基于上面的出发点，Cascade R-CNN横空出世。简单来说，Cascade  R-CNN就是由一系列检测器组成的级联检测模型，并且每个检测器都基于不同IOu阈值的正负样本训练得到，前一个检测器的输出作为后一个检测器的输入，并且越往后走，检测器的阈值是越大的。</p>
<p>为什么Cascade R-CNN要这样来设计呢？这和上面的出发点密切相关，从<code>Figure1(c)</code>中我们看出使用不同的IOU阈值训练得到的检测模型对有不同IOU阈值的输入候选框的结果差别较大，因此<strong>我们希望训练每个检测模型用的IOU阈值要尽可能和输入候选框的IOU接近</strong>。并且从<code>Figure1(c)</code>中可以看出三条彩色曲线都在灰度曲线上方，这说明对于这几个阈值来说，<strong>输出的IOU阈值都大于输入的IOU阈值</strong>。根据这一特点，我们就可以拿上一个阶段的输出作为下一个阶段的输入，这样就可以得到越来越高的IOU。</p>
<p>总结一下，<strong>我们很难让一个在指定IOU阈值界定的训练集上训练得到的检测模型对IOU跨度较大的输入候选框都达到最佳，因此采取级联的方式能够让每一个阶段的检测器都专注于检测IOU在某一范围内的候选框，因为输出IOU普遍大于输入IOU，因此检测效果会越来越好。</strong></p>
<h2 id="Cascade-R-CNN网络结构"><a href="#Cascade-R-CNN网络结构" class="headerlink" title="Cascade R-CNN网络结构"></a>Cascade R-CNN网络结构</h2><p>下面的Figure3展示了和Cascade R-CNN有关的几种经典检测网络结构的示意图。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/641.webp" alt></p>
<ul>
<li><p><code>Figure3(a)</code>表示Faster RCNN，因为双阶段类型的目标检测算法基本上都基于Faster RCNN，所以这里也以该算法为BaseLine。其中H0代表的是RPN网络，H1代表的是Faster R-CNN进行检测与分类的head，C1代表最终的分类结果，B1代表最终的bounding box回归结果。</p>
</li>
<li><p><code>Figure3(b)</code>表示迭代式的边界框回归，从图也非常容易看出思想，就是前一个检测模型回归得到的边界框坐标初始化下一个检测模型的边界框，然后继续回归，这样迭代三次后得到结果。</p>
</li>
<li><p><code>Figure3(c)</code>表示Integral Loss，表示对输出边界框的标签界定采用不同的IOU阈值，因为当IOU较高时，虽然预测得到边界框很准确，但是也会丢失一些边界框。（即分类结果基于不同IOU，bbox并没有）关于这个网络的解释看原文更容易理解：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/646.webp" alt><br>这种Trick在比赛中比较常用，就是说按照数据集的评价指标来自定义Loss（一般是把和指标相关的那一项加在原始的Loss后面）往往可以取得更好的效果。</p>
</li>
<li><p><code>Figure3(d)</code>表示Cascade R-CNN，<strong>H1那一部分是一样的，但是Cascade R-CNN得到B1回归后的检测框后，将其输入到H2部分，继续回归，以此类推到H3部分，使得每次对bounding box都提高一定的精度，已达到提高检测框准确度的作用。(注：级联的方式，不再是为了找到hard negatives，而是通过调整bounding boxes，给下一阶段找到一个IoU更高的正样本来训练。)</strong>，和<code>Figure3(b)</code>，<code>Figure3(c)</code>的结构比较像。但和<code>Figure3(b)</code>最主要的区别是Cascade R-CNN中的检测模型是基于前一阶段的输出进行训练，而不是<code>Figure3(b)</code>中3个检测模型都是基于最初始的数据进行训练，（个人理解：<strong>head相同</strong>，相当于基于最开始训练）而且(b)是在验证阶段采用的方式，而cascade-R-CNN是在训练和验证阶段采用的方式。而和<code>Figure3(c)</code>的区别更加明显，Cascade R-CNN中每个Stage的输入候选框都是前一个阶段的候选框输出，而却没有这种级联的思想，仅仅是模型基于不同的IOU阈值进行训练得到。</p>
</li>
</ul>
<h2 id="Cascade-R-CNN的可行性分析"><a href="#Cascade-R-CNN的可行性分析" class="headerlink" title="Cascade R-CNN的可行性分析"></a>Cascade R-CNN的可行性分析</h2><p>上面的<code>Figure3(b)</code>中的迭代回归有两个致命缺点：</p>
<ul>
<li>从<code>Figure1(c)</code>的实验知道基于不同IOU阈值训练的检测模型对不同IOU的候选框输入效果差别很大，因此如果每次迭代都基于相同IOU阈值的数据进行训练获得的检测模型，那么当输入候选框的IOU不在训练的检测模型的IOU附近时，效果不会有太大提升。</li>
<li>下面的<code>Figure2</code>为我们展示了<code>Figure3(b)</code>这种候选框回归在不同阶段的4个坐标回归值的分布情况，可以看到在不同的阶段坐标的分布差异是比较大的，对于这种情况，<code>Figure3(b)</code>的迭代回归模型是无能为力的。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/642.jpg" alt><br>第一行横纵轴分别是回归目标中的box的x方向和y方向偏移量；第二行横纵轴分别是回归目标中的box的宽、高偏差量，$\delta_{x}=\left(g_{x}-b_{x}\right) / b_{w}$, $\delta_{y}=\left(g_{y}-b_{y}\right) / b_{h}$，$\delta_{w}=\log \left(g_{w} / b_{w}\right)$, $\delta_{h}=\log \left(g_{h} / b_{h}\right)$。我们可以看到，从1st stage到2nd stage，proposal的分布其实已经发生很大变化了，因为很多噪声经过box reg实际上也提高了IoU，2nd和3rd中的那些红色点已经属于outliers，如果不提高阈值来去掉它们，就会引入大量噪声干扰，对结果很不利。(head不变，IOU不变还为0.5，去不掉已提高IOU的噪声，也就是红点)从这里也可以看出，阈值的重新选取本质上是一个<strong>resample</strong>的过程，它保证了样本的质量。</li>
</ul>
<p>那么Cascade R-CNN是否可以改善上述问题呢？下面的<code>Figure4</code>展示了Cascade R-CNN在不同阶段预测得到的候选框的IOU值分布情况。可以看到，每经过一个检测器进行坐标回归，候选框越准确，也即是说候选框和GT框的IOU更大。从<code>Figure4</code>可以看出，经过检测器之后IOU大的样本增加了，这就说明了Cascade R-CNN是可行的，因为它不会因为后面的检测器提高阈值导致正样本过少而过拟合。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/643.png" alt></p>
<p>从这张图，我们可以看到，1st stage大于0.5的，到2nd stage大于0.6的，到3rd stage大于0.7的……在这一个过程中proposal的样本数量确实没有特别大的改变，甚至还有稍许提升，和2图结合起来看，应该可以说是非常强有力的证明了。<br>总结起来，就是：</p>
<ul>
<li>cascaded regression不断改变了proposal的分布，并且通过调整阈值的方式重采样（即：$f^{\prime}(x, b)=f_{T} \cdot f_{T-1} \cdot f_{T-2} \cdots f_{1}(x, b)$）</li>
<li>cascaded在train和inference时都会使用，并没有偏差问题</li>
<li>cascaded重采样后的每个检测器，都对重采样后的样本是最优的，没有mismatch问题</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>下面的Table1展示了<code>Figure3</code>中几种模型和Cascade R-CNN的结果对比。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/644.png" alt></p>
<p>然后再来看一下在COCO数据集上的表现，可以看到Cascade R-CNN非常的SOTA了，YOLOV3只有33%的mAP，而Cascade R-CNN则有42.8%的mAP值。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Cascade_R-CNN/645.jpg" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>ConvNeXt：重新设计纯卷积ConvNet</title>
    <url>/2022/01/15/ConvNeXt%EF%BC%9A%E9%87%8D%E6%96%B0%E8%AE%BE%E8%AE%A1%E7%BA%AF%E5%8D%B7%E7%A7%AFConvNet/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近看到一篇挺有意思的文章，来自<strong>Facebook和加州伯克利团队</strong>设计并测试了<strong>纯ConvNet</strong>所能达到的极限命名为<strong>ConvNeXt</strong>。ConvNeXt完全由卷积网络构建，在准确性和可扩展性方面ConvNeXt取得了与Transformer具有竞争力的结果，达到<strong>87.8% ImageNet top-1 准确率</strong>，在COCO检测和ADE20K分割方面优于Swin Transformer，同时保持标准ConvNet的简单性和有效性。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-14ac75970415175b08576cd3153896fa_r.jpg" alt></p>
<p>这张图可以说是整篇论文的精华，光看这张图就知道该做什么了😏。</p>
<p>总结为： ① 宏观设计 ② ResNeXt ③ 反转瓶颈 ④ 卷积核大小 ⑤ 各种逐层微设计</p>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>就是对Transformer的trick进行梳理和模仿，把ResNet50从76.1一步步干到82.0。个人觉得挺有意思的。</p>
<h3 id="训练策略优化（76-1-78-8）"><a href="#训练策略优化（76-1-78-8）" class="headerlink" title="训练策略优化（76.1-78.8）"></a>训练策略优化（76.1-78.8）</h3><p>2021年timm和torchvision团队均有工作讲述如何通过优化训练策略来使resnet50性能提升到80以上。本文考虑到跟Swin Transformer的公平对比，训练策略没有完全follow前面的工作，但仍然可以对ResNet50带来提升。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-7c8fe035b8b08f829d5a771597c15f95_r.jpg" alt></p>
<h3 id="改变stage-compute-ratio（78-8-79-4）"><a href="#改变stage-compute-ratio（78-8-79-4）" class="headerlink" title="改变stage compute ratio（78.8-79.4）"></a>改变stage compute ratio（78.8-79.4）</h3><p>改变layer0到layer3的block数量比例，由标准的(3,4,6,3)改为Swin-T使用的(3,3,9,3)，即1:1:3:1。对于更大的模型，也跟进了Swin所使用的1:1:9:1。</p>
<h3 id="使用Patchify的stem（79-4-79-5）"><a href="#使用Patchify的stem（79-4-79-5）" class="headerlink" title="使用Patchify的stem（79.4-79.5）"></a>使用Patchify的stem（79.4-79.5）</h3><p>就是将传统ResNet中stem层使用的一个stride=2的7x7卷积加最大池化层改成patch，用stride=4的4x4卷积来进行stem，使得滑动窗口不再相交，每次只处理一个patch的信息。跟之前有一篇<a href="https://openreview.net/pdf?id=TVHS5Y4dNvM">「Patches are all you need」</a>(该文章认为是Patches起的作用，而不是Transformer，在ConvNet中应用了Patches也得到了不错的效果)异曲同工之妙。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 标准ResNet</span></span><br><span class="line">stem = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ConvNeXt</span></span><br><span class="line">stem = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">4</span>, stride=<span class="number">4</span>),</span><br><span class="line">    LayerNorm(dims[<span class="number">0</span>], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="ResNeXt化（79-5-80-5）"><a href="#ResNeXt化（79-5-80-5）" class="headerlink" title="ResNeXt化（79.5-80.5）"></a>ResNeXt化（79.5-80.5）</h3><p>ResNeXt的指导准则是“分更多的组，拓宽width”，因此本文直接使用了depthwise conv，即分组数等于输入通道数。这里，作者发现dw conv由于每个卷积核单独处理一个通道，这种形式跟self-attention机制很相似，都是在单个通道内做空间信息的混合加权。将bottleneck中的3x3卷积替换成<strong>dw conv 7×7</strong>，再把网络宽度从<strong>64提升到96</strong>（跟Transformer对齐）。</p>
<p><strong>可以这么理解：注意力模块核心公式就是attention × V，attention是HW×HW矩阵，而V是HW×C矩阵，这个矩阵乘法的权重是通道C共享的，如果换成attention序列长度是1即1×HW，V是HW×C，那么每个输出序列长度是1×C，可以看出自注意力模块是没有跨通道信息聚合的。因此作者认为自注意力层可以和DW Conv等价，用dw conv 7×7替换MSA。</strong></p>
<h3 id="反瓶颈结构（80-5-80-6）"><a href="#反瓶颈结构（80-5-80-6）" class="headerlink" title="反瓶颈结构（80.5-80.6）"></a>反瓶颈结构（80.5-80.6）</h3><p>在标准ResNet中使用的bottleneck是（大维度-小维度-大维度）的形式来减小计算量。后来在MobileNetV2中提出了inverted bottleneck结构，采用（小维度-大维度-小维度）形式，认为这样能让信息在不同维度特征空间之间转换时避免压缩维度带来的信息损失，后来在Transformer的MLP中也使用了类似的结构，中间层全连接层维度数是两端的4倍。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-dd758d2ab5e8f1d02b6d85dc41b3e821_r.jpg" alt></p>
<h3 id="大卷积核（80-6-80-6）"><a href="#大卷积核（80-6-80-6）" class="headerlink" title="大卷积核（80.6-80.6）"></a>大卷积核（80.6-80.6）</h3><p>由于Swin-T中使用了7x7卷积核，这一步主要是为了对齐比较。又因为inverted bottleneck放大了中间卷积层的缘故，直接替换会导致参数量增大，因而作者把dw conv的位置进行了调整，放到了反瓶颈的开头。最终结果相近，说明在7x7在相同参数量下效果是一致的。（<strong>其实就是作者认为自注意力层可以和DW Conv等价，用dw conv 7×7替换MSA</strong>）</p>
<h3 id="用GELU替换ReLU（80-6-80-6）"><a href="#用GELU替换ReLU（80-6-80-6）" class="headerlink" title="用GELU替换ReLU（80.6-80.6）"></a>用GELU替换ReLU（80.6-80.6）</h3><p>主要是为了对齐比较（因为Transformer用了GELU），并没有带来提升。</p>
<h3 id="减少激活层数量（80-6-81-3）"><a href="#减少激活层数量（80-6-81-3）" class="headerlink" title="减少激活层数量（80.6-81.3）"></a>减少激活层数量（80.6-81.3）</h3><p>由于Transformer中只使用了一个激活层，因此在设计上进行了效仿，结果发现只在block中的两个1x1卷积之间使用一层激活层，其他地方不适用，反而带来了0.7个点的提升。这说明太频繁地做非线性投影对于网络特征的信息传递实际上是有害的。</p>
<h3 id="减少归一化层数量（81-3-81-4）"><a href="#减少归一化层数量（81-3-81-4）" class="headerlink" title="减少归一化层数量（81.3-81.4）"></a>减少归一化层数量（81.3-81.4）</h3><p>基于跟减少激活层相同的逻辑，由于Transformer中BN层很少，本文也只保留了1x1卷积之前的一层BN，而两个1x1卷积层之间甚至没有使用归一化层，只做了非线性投影。</p>
<h3 id="用LN替换BN（81-4-81-5）"><a href="#用LN替换BN（81-4-81-5）" class="headerlink" title="用LN替换BN（81.4-81.5）"></a>用LN替换BN（81.4-81.5）</h3><p>由于Transformer中使用了LN，且一些研究发现BN会对网络性能带来一些负面影响，本文为了对齐，将所有的BN替换为LN。<strong>结果玄学起来了，正常来说BN适用于图像，LN适用于序列，LN照理来说会掉点，这里反而提升了😨。估摸着是不是因为前面减少了归一化层数量，只在DW 7×7后做归一，而DW又近似于注意力效果，因此就像LN适合Transformer一样，LN也对其有提升？</strong></p>
<h3 id="单独的下采样层（81-5-82-0）"><a href="#单独的下采样层（81-5-82-0）" class="headerlink" title="单独的下采样层（81.5-82.0）"></a>单独的下采样层（81.5-82.0）</h3><p>标准ResNet的下采样层通常是stride=2的3x3卷积，对于有残差结构的block则在短路连接中使用stride=2的1x1卷积，这使得CNN的下采样层基本与其他层保持了相似的计算策略。而Swin-T中的下采样层是单独的，因此本文用stride=2的2x2卷积进行模拟。又因为这样会使训练不稳定，因此每个下采样层后面增加了LN来稳定训练。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.downsample_layers = nn.ModuleList() </span><br><span class="line"><span class="comment"># stem也可以看成下采样层，一起存到downsample_layers中，推理时通过index进行访问</span></span><br><span class="line">stem = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_chans, dims[<span class="number">0</span>], kernel_size=<span class="number">4</span>, stride=<span class="number">4</span>),</span><br><span class="line">    LayerNorm(dims[<span class="number">0</span>], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>)</span><br><span class="line">)</span><br><span class="line">self.downsample_layers.append(stem)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    downsample_layer = nn.Sequential(</span><br><span class="line">            LayerNorm(dims[i], eps=<span class="number">1e-6</span>, data_format=<span class="string">&quot;channels_first&quot;</span>),</span><br><span class="line">            nn.Conv2d(dims[i], dims[i+<span class="number">1</span>], kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">    )</span><br><span class="line">self.downsample_layers.append(downsample_layer)</span><br><span class="line"><span class="comment"># 由于网络结构是downsample-stage-downsample-stage的形式，所以stem和后面的下采样层中的LN是不会连在一起的</span></span><br></pre></td></tr></table></figure>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>对以上内容进行整合，最终得到了单个block的设计及代码：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/image-20220115100731821.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, drop_path=<span class="number">0.</span>, layer_scale_init_value=<span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 分组卷积+大卷积核</span></span><br><span class="line">        self.dwconv = nn.Conv2d(dim, dim, kernel_size=<span class="number">7</span>, padding=<span class="number">3</span>, groups=dim) </span><br><span class="line">        <span class="comment"># 在1x1之前使用唯一一次LN做归一化</span></span><br><span class="line">        self.norm = LayerNorm(dim, eps=<span class="number">1e-6</span>) </span><br><span class="line">        <span class="comment"># 全连接层跟1x1conv等价，但pytorch计算上fc略快</span></span><br><span class="line">        self.pwconv1 = nn.Linear(dim, <span class="number">4</span> * dim)</span><br><span class="line">        <span class="comment"># 整个block只使用唯一一次激活层</span></span><br><span class="line">        self.act = nn.GELU()</span><br><span class="line">        <span class="comment"># 反瓶颈结构，中间层升维了4倍</span></span><br><span class="line">        self.pwconv2 = nn.Linear(<span class="number">4</span> * dim, dim)</span><br><span class="line">        <span class="comment"># gamma的作用是用于做layer scale训练策略</span></span><br><span class="line">        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), </span><br><span class="line">                                    requires_grad=<span class="literal">True</span>) <span class="keyword">if</span> layer_scale_init_value &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># drop_path是用于stoch. depth训练策略</span></span><br><span class="line">        self.drop_path = DropPath(drop_path) <span class="keyword">if</span> drop_path &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="built_in">input</span> = x</span><br><span class="line">        x = self.dwconv(x)</span><br><span class="line">        <span class="comment"># 由于用FC来做1x1conv，所以需要调换通道顺序</span></span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>) <span class="comment"># (N, C, H, W) -&gt; (N, H, W, C) </span></span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        x = self.pwconv1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.pwconv2(x)</span><br><span class="line">        <span class="keyword">if</span> self.gamma <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.gamma * x</span><br><span class="line">        x = x.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>) <span class="comment"># (N, H, W, C) -&gt; (N, C, H, W)</span></span><br><span class="line"></span><br><span class="line">        x = <span class="built_in">input</span> + self.drop_path(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>通过代码可以注意到，以上Block中两层1x1卷积是用全连接层来实现的，按照作者的说法，这样会比使用卷积层略快。(不过作者是在GPU上进行的实验，有人测试在<strong>CPU上还是使用1x1卷积层的速度更快</strong>，可以根据需要替换)</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>基于前述ConvNeXt架构，构建了ConvNeXt-T/S/B/L对标Swin-T/S/B/L。此外，还构建了一个更大的ConvNeXt-XL以进一步测试ConvNeXt的缩放性。</p>
<ul>
<li>ConvNeXt-T：C = (96, 192, 384, 768)，B = (3, 3, 9, 3)</li>
<li>ConvNeXt-s：C = (96, 192, 384, 768)，B = (3, 3, 27, 3)</li>
<li>ConvNeXt-B：C = (128, 256, 512, 1024)，B = (3, 3, 27, 3)</li>
<li>ConvNeXt-L：C = (192, 384, 768, 1536)，B = (3, 3, 27, 3)</li>
<li>ConvNeXt-XL：C = (256, 512, 1024, 2048)，B = (3, 3, 27, 3)</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-94904b941ad97ee68ff0ad3c3d390726_720w.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-f2c860b262ecaa43fdcf7f29236542d5_r.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-d68c89f10cd728a99f9c3a4dbadfae53_r.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-950dc0387acc5aa79ef525528c0802f7_r.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convnext/v2-ca4f28ca44aaeb71e1991bc9a8adaec7_r.jpg" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然本篇文章各种trick堆叠，但网络本身结构还算简单，通过与Transformer对其，来说明ConvNet还是能打（Transformer给👴爬！），个人还是比较喜欢的。至少比起Transformer来说对于穷人比较友好，卷积网络也不容易出现难收敛的情况。FLOPs凑合，param在分类网络中稍微有点大，应该是由于每个block都使用7×7大卷积，block之间用全连接的关系，但至少比起Transformer还是可以跑得动的😋。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>论文链接：<a href="https://arxiv.org/pdf/2201.03545.pdf">https://arxiv.org/pdf/2201.03545.pdf</a></p>
<p>代码链接：<a href="https://github.com/facebookresearch/ConvNeXt">https://github.com/facebookresearch/ConvNeXt</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>FPN</title>
    <url>/2020/03/02/FPN/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Faster-RCNN选取一个特征提取网络如VGG16做backbone，然后在高层特征（如VGG16后面的conv4）接RPN和检测头进行网络。正是由于Faster-RCNN基于图像的高级特征，这就导致对小目标的检测效果很差。而CV领域常用的处理尺度问题的办法就是特征金字塔，将原图以不同的比例采样，然后得到不同分辨率的图像进行训练和测试，在多数情况下确实是有效的。但是特征金字塔的时间开销非常大，导致在工程中应用是及其困难。FPN从新的角度出发提出了一个独特的特征金字塔网络来避免图像金字塔产生的超高计算量，同时可以较好的处理目标检测中的尺度变化问题，对小目标检测更鲁棒，同时在VOC和COCO数据集上MAP值均超过了Faster-RCNN。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>使用下图来阐释是如何处理尺度变化大的物体检测的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/640.webp" alt></p>
<ul>
<li>上图(a)是处理这类问题最常用的方法，即特征金字塔，这种方法在传统的手动设计特征的方法中非常常用，例如DPM方法使用了接近10种不同的尺度获得了不错的效果。</li>
<li>上图(b)是在CNN提出之后出现的，因为神经网络模型对物体尺度本身有一定的鲁棒性，所以也取得了不错的性能，但最近的研究表明将特征金字塔和CNN结合仍可以提升性能，这说明基于单层特征的检测系统仍存在对尺度变化敏感的缺点。</li>
<li>上图(c)表示除了使用图像金字塔，我们可以使用深度学习本身的多层次结构来提取多尺度特征。最常见的就是SSD算法中利用多个特征层来分别做预测。但这种方式也有一些缺点就是浅层的语义特征比较弱，在处理小物体时表现得不够好。</li>
<li>上图(d)表示本文提出的FPN（Feature Pyramid Network ），它能较好的让各个不同尺度的特征都具有较强的语义信息。FPN结合Faster  RCNN可以在COCO物体检测比赛中取得当前单模型的最佳性能（SOTA）。另外，通过对比实验发现，FPN能让Faster  RCNN中的RPN网络的召回率提高8个点；并且它也能使Fast RCNN的检测性能提升2.3个点（COCO）和3.8个点（VOC）。</li>
</ul>
<h2 id="FPN结构"><a href="#FPN结构" class="headerlink" title="FPN结构"></a>FPN结构</h2><p>下图表示FPN的整体结构：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/641.webp" alt></p>
<p>我们可以看到FPN的整体结构分为<strong>自底向上</strong>和<strong>自顶向下和侧向连接</strong>的过程。接下来我们分别解释一下这两个关键部分。</p>
<h3 id="自底向上"><a href="#自底向上" class="headerlink" title="自底向上"></a>自底向上</h3><p>这一部分就是普通的特征提取网络，特征分辨率不断缩小，容易想到这个特征提取网络可以换成任意Backbone，并且CNN网络一般都是按照特征图大小分为不同的stage，每个stage的特征图长宽差距为2倍。在这个自底向上的结构中，一个stage对应特征金字塔的一个level。以我们要用的ResNet为例，选取conv2、conv3、conv4、conv5层的最后一个残差block层特征作为FPN的特征，记为{C2、C3、C4、C5}，也即是FPN网络的4个级别。这几个特征层相对于原图的步长分别为4、8、16、32。</p>
<h3 id="自上向下和侧向连接"><a href="#自上向下和侧向连接" class="headerlink" title="自上向下和侧向连接"></a>自上向下和侧向连接</h3><p>自上向下是特征图放大的过程，我们一般采用上采样来实现。FPN的巧妙之处就在于从高层特征上采样既可以利用顶层的高级语义特征（有助于分类）又可以利用底层的高分辨率信息（有助于定位）。上采样可以使用插值的方式实现。为了将高层语义特征和底层的精确定位能力结合，论文提出了类似于残差结构的侧向连接。连接将上一层经过上采样后和当前层分辨率一致的特征，通过相加的方法进行融合。同时为了保持所有级别的特征层通道数都保持一致，这里使用1*1卷积来实现。在网上看到一张图，比较好的解释了这个过程：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/642.webp" alt></p>
<p>FPN只是一个特征金字塔结构，需要配合其他目标检测算法才能使用。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="1-FPN对RPN网络的影响"><a href="#1-FPN对RPN网络的影响" class="headerlink" title="1.FPN对RPN网络的影响"></a>1.FPN对RPN网络的影响</h3><p>如下表所示，论文做了6个实验。</p>
<ul>
<li>(a)基于conv4的RPN，原始的RPN。</li>
<li>(b)基于conv5的RPN。</li>
<li>(c) 完整FPN。</li>
<li>(d)只用了自底向上的多层特征，没有自顶向下的特征。</li>
<li>(e)用了自顶向下的特征，但不用侧向连接。</li>
<li>(f)用了自顶向下的特征，也用了横向特征融合，但只用最后的P2做预测。（完整的预测是使用每一个level的特征$P_{k}$做预测）</li>
</ul>
<p>分析表格可知，自顶向下的特征、横向连接、尺度分离、多个层次的预测是提升FPN性能的关键。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/643.webp" alt></p>
<p>为了更好的理解，放一张Faster-RCNN结合FPN的细致结构图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/644.webp" alt></p>
<h2 id="2-FPN对Fast-RCNN的影响"><a href="#2-FPN对Fast-RCNN的影响" class="headerlink" title="2.FPN对Fast RCNN的影响"></a>2.FPN对Fast RCNN的影响</h2><p>使用和实验1相同的规则对Fast RCNN做了实验，结果如下表所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN2/645.png" alt></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文提出了一种简单、有效的建立特征金字塔的方式。它的使用对RPN方法和Fast/Faster RCNN方法都有极大的性能提升。另外，它的训练和测试时间和普通的Faster RCNN方法相差很小。因此，它可以作为图像特征金字塔的一种较好的替代。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>ECCV 2018 RFBNet，在检测中调感受野</title>
    <url>/2020/03/07/ECCV-2018-RFBNet%EF%BC%8C%E5%9C%A8%E6%A3%80%E6%B5%8B%E4%B8%AD%E8%B0%83%E6%84%9F%E5%8F%97%E9%87%8E/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看了不少的目标检测论文了，个人认为多数论文的出发点就两个，一是感受野，二是特征融合。此外，解决数据不平衡和轻量化也是另外两个重要的方向。今天为大家科普一篇ECCV 2018的一篇目标检测网络RFBNet就是从感受野角度来改善了SSD检测器，论文全名为：<strong>Receptive Field Block Net for Accurate and Fast Object Detection</strong>  。这篇论文主要的贡献点主要是在SSD网络中提出了一个<strong>Receptive Field Block (RFB)</strong> 模块，RFB模块主要是在Inception的基础上加入了空洞卷积层从而有效的增大了感受野。另外，RFB模块是嵌在SSD上的，所以检测的速度比较快，精度比SSD更高。</p>
<h2 id="RFB模块"><a href="#RFB模块" class="headerlink" title="RFB模块"></a>RFB模块</h2><p>RFB模块的效果示意图如图所示，其中虚线部分就是指RFB模块。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/640.jpg" alt></p>
<p>RFB模块主要有两个特点：</p>
<ul>
<li><p>RFB模块有多个分支，每个分支的第一层都由特定大小卷积核的卷积核构成，例如图上的1 x 1， 3 x 3，5 x 5。</p>
</li>
<li><p>RFB模块引入了空洞卷积，主要作用是为了增加感受野，空洞卷积之前是应用在分割网络DeepLab中，这里将其应用在检测任务中，以获得更大的感受野，可以更好的编码空间长距离语义。</p>
</li>
</ul>
<p>在RFB模块中，最后将不同尺寸和感受野的输出特征图进行Concat操作，以达到融合不同特征的目的。在图中，RFB模块中使用三种不同大小和颜色的输出叠加来展示。在图的最后一列中将融合后的特征与人类视觉感受野做对比，从图中看出是非常接近的，这也是这篇论文的出发点。</p>
<h2 id="两种RFB结构示意图"><a href="#两种RFB结构示意图" class="headerlink" title="两种RFB结构示意图"></a>两种RFB结构示意图</h2><p>下面的Figure4展示了RFBNet的两种结构。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/641.jpg" alt></p>
<ul>
<li><p>Figure4(a)表示RFB结构，整体上借鉴了Inception的思想。主要不同点在于引入3个空洞卷积层。</p>
</li>
<li><p>Figure4(b)表示RFB-s结构。RFB-s和RFB相比主要有两个改进，一方面用3 x 3卷积层代替5 x 5卷积层，另一方面用1 x 3和3 x 1卷积层代替3 x 3卷积层，主要目的应该是为了减少计算量，类似Inception后面的版本对Inception结构的改进。</p>
</li>
</ul>
<h2 id="RFBNet-300的结构"><a href="#RFBNet-300的结构" class="headerlink" title="RFBNet-300的结构"></a>RFBNet-300的结构</h2><p>下面的Figure5代表RFBNet-300的整体结构图，基本是照搬了SSD，主要有2点不同：</p>
<ul>
<li>BackBone部分用两个RFB结构替换原来新增的两层。</li>
<li><code>conv4_3</code>和<code>conv7_fc</code>在接预测层之前分别接RFB-s和RFB结构。</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/642.jpg" alt></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>下面的Table1展示了RFBNet-300在PASCAL VOC2007 test dev上的测试结果，训练集基于2007和2012的trainval。RFBNet-300在mAP和FPS两方面效果都不错。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/643.jpg" alt></p>
<p>而下面的Table4是在COCO test dev 2015数据集上的测试结果。最后的RFBNet-512E做了两个改变：</p>
<ul>
<li>对<code>conv7_fc</code>的输出特征做了<code>up-sample</code>，然后和<code>conv4_3</code>的输出特征做融合，基于融合后的特征做预测。这种做法实际上是借鉴了FPN算法的思想。</li>
<li>RFB结构中增加了<code>7x7</code>大小的卷积分支。这两点改进对效果的提升有一定帮助，而且带来的计算量也少。</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/644.jpg" alt></p>
<p>下面的Figure6展示了和RFBNet同时期的一些目标检测算法在COCO test-dev数据集上关于效果和速度的直观对比，可以看到RFBNet的速度和精度平衡还是不错的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RFBNet/645.jpg" alt></p>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>RFBNet说白了就是空洞卷积的应用，虽然看起来论文比较水，但至少给我们提供了一个重要信息，在检测中调感受野是行之有效的。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul>
<li>论文原文：<a href="https://arxiv.org/pdf/1711.07767.pdf">https://arxiv.org/pdf/1711.07767.pdf</a></li>
<li>代码实现：<a href="https://github.com/ruinmessi/RFBNet">https://github.com/ruinmessi/RFBNet</a></li>
<li>参考：<a href="https://blog.csdn.net/u014380165/article/details/81556769">https://blog.csdn.net/u014380165/article/details/81556769</a></li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>EndNote样式使用教程</title>
    <url>/2020/12/11/EndNote%E6%A0%B7%E5%BC%8F%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>EndNote主要针对英文文献，所以并没提供符合中华标准的文献样式，而网上找的样式又不太对。因此这里本人根据中华人民共和国国家标准GB/T7714-2005和江南大学论文要求，制作了可供导入使用的样式。</p>
<p>下载链接如下：<br><a href="https://drive.google.com/file/d/1RgwQu1P_yDF_zLhAr2b-q3qFkFm8pNLz/view?usp=sharing">江大开题报告样式</a><br><a href="https://drive.google.com/file/d/1EeGhckTxcrS2fdU2tLck_1vozWer0jU6/view?usp=sharing">江大毕业论文样式</a></p>
<h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p><strong>① 将.ens样式文件放入EndNote安装目录下的Styles文件夹。</strong></p>
<p><strong>② 使用时切换样式即可：</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/4.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/5.png" alt></p>
<p><strong>③ 插入文献效果如下：</strong></p>
<ul>
<li>开题报告：</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/6.jpg" alt></p>
<ul>
<li><p>毕业论文：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/13.png" alt></p>
</li>
</ul>
<p><strong>④ 若参考文献序号后面空格过长可设置悬挂缩进距离：</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/7.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/8.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/9.jpg" alt></p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><h3 id="①-arxiv期刊，请设置参考类型为Manuscript，以方便样式识别文献类型，并按图中字段完善相应内容。"><a href="#①-arxiv期刊，请设置参考类型为Manuscript，以方便样式识别文献类型，并按图中字段完善相应内容。" class="headerlink" title="①  arxiv期刊，请设置参考类型为Manuscript，以方便样式识别文献类型，并按图中字段完善相应内容。"></a>①  arxiv期刊，请设置参考类型为Manuscript，以方便样式识别文献类型，并按图中字段完善相应内容。</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/10.jpg" alt></p>
<h3 id="②-中文文献，请设置参考类型为中文文献，并填写Secondary-Author（与Author一样），以方便样式识别文献类型。"><a href="#②-中文文献，请设置参考类型为中文文献，并填写Secondary-Author（与Author一样），以方便样式识别文献类型。" class="headerlink" title="② 中文文献，请设置参考类型为中文文献，并填写Secondary Author（与Author一样），以方便样式识别文献类型。"></a>② 中文文献，请设置参考类型为中文文献，并填写Secondary Author（与Author一样），以方便样式识别文献类型。</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/12.jpg" alt></p>
<p><strong>中文文献参考类型设置：</strong></p>
<p>点击「编辑」→「首选项」→「参考文献类型」→「修改参考文献类型」（「Edit」→「Preference」→「Reference Types」→「Modify Reference Types 」）</p>
<p>EndNote未使用的文献类型 (Reference Type) 默认为3个 , 它们被命名为 Unused 1，Unused 2和Unused 3 。我们可以利用这几个未作用的文献类型来修改。</p>
<p>如选择Unused 1，在 Generic 项中输入新文献类型名「中文文献」，然后依次修改各项，修改完毕后「OK」关闭保存。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/11.jpg" alt></p>
<h3 id="③-学位论文，则按照如下图，完善相应信息。"><a href="#③-学位论文，则按照如下图，完善相应信息。" class="headerlink" title="③ 学位论文，则按照如下图，完善相应信息。"></a>③ 学位论文，则按照如下图，完善相应信息。</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/14.png" alt></p>
<h3 id="④-会议论文请补充完善会议地点："><a href="#④-会议论文请补充完善会议地点：" class="headerlink" title="④ 会议论文请补充完善会议地点："></a>④ 会议论文请补充完善会议地点：</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/15.png" alt></p>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title>Fast RCNN</title>
    <url>/2020/02/24/Fast-RCNN/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们知道RCNN需要把每一个可能有目标的候选框搜索出来，然后把每个候选框传入CNN提取特征，每一张图片要产生大约2K个候选框，而每个框对应的图像都要传入CNN，这个时间开销肯定是很难承受的。基于RCNN这个致命问题，Fast-RCNN出现了。</p>
<h2 id="算法介绍"><a href="#算法介绍" class="headerlink" title="算法介绍"></a>算法介绍</h2><p>Fast-RCNN是在SPPNet和RCNN的基础上进行改进的。SPPNet的主要贡献是在整张图像上计算全局特征图，然后对于特定的proposal，只需要在全局特征图上取出对应坐标的特征图就可以了。但SPPNet仍然需要将特征保存在磁盘中，速度还是很慢。结合RCNN的思想，论文提出直接将候选框区域应用于特征图，并使用ROI Pooling将其转化为固定大小的特征图，最后再连接两个并行的分类头和回归头完成检测任务。整个算法可以用下面的图来表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/3940902-7569280b566d0e58.png" alt></p>
<h2 id="贡献-amp-创新点"><a href="#贡献-amp-创新点" class="headerlink" title="贡献&amp;创新点"></a>贡献&amp;创新点</h2><ul>
<li>Fast-RCNN 只对整个图像进行一次特征提取，避免R-CNN的上千次特征提取。</li>
<li>使用ROI Pooling层替换最后一层的Max Pooling层，巧妙避免RCNN中的将每个候选框Resize到固定大小的操作。</li>
<li>Fast RCNN在网络的尾部采用并行的全连接层，可同时输出分类结果和窗口回归结果，实现了端到端的多任务训练，且不需要额外的特征存储空间(在R-CNN中特征需要保存到磁盘，以供SVM和线性回归器训练)。</li>
<li>使用SVD矩阵分解算法对网络末端并行的全连接层进行分解，加速运算。</li>
</ul>
<h2 id="ROI-Pooling层"><a href="#ROI-Pooling层" class="headerlink" title="ROI Pooling层"></a>ROI Pooling层</h2><p>Fast-RCNN的核心是ROI池化层，它的作用是输入特征图的大小不定，但输出大小固定的输出特征图。而什么是ROI呢？ROI就是经过区域建议算法(Selective Search)生成的框经过卷积神经网络网络提取特征后的特征图上的区域，每一个ROI对应了原图的一个区域建议框，只有大小变化了，相对位置没有发生改变。这个过程可以用下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Fast_RCNN/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200224140858.jpg" alt></p>
<p>ROI Pooling层的输入有特征图和ROIs，特征图是经过CNN提取后的结果，ROIs表示Selective Search的结果，形状为$N \times 5 \times 1 \times 1$，其中$N$代表ROI的个数，5代表$x, y, w, h$。这里需要注意的是，坐标系的参数是针对原图的。</p>
<h2 id="ROI-Pooling的具体操作"><a href="#ROI-Pooling的具体操作" class="headerlink" title="ROI Pooling的具体操作"></a>ROI Pooling的具体操作</h2><ul>
<li>根据输入图片，将ROI映射到特征图对应位置（映射规则就是直接把各个坐标除以“输入图片和特征图大小的比值”）</li>
<li>将映射后的区域划分为相同大小的sections，其中sections代表输出维度，例如7。</li>
<li>对每个sections进行最大池化操作。</li>
</ul>
<p>最后上传一张经典动态图片，更好的表示这个过程：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Fast_RCNN/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200224140920.gif" alt></p>
<h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><p>Fast-RCNN的作者rgbirshick依然给出了源码，有兴趣可以读一下：<a href="https://github.com/rbgirshick/fast-rcnn">https://github.com/rbgirshick/fast-rcnn</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Fast RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster-RCNN</title>
    <url>/2020/02/26/Faster-RCNN/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们知道RCNN和Fast-RCNN都是双阶段的算法，依赖于候选框搜索算法。而搜索算法是很慢的，这就导致这两个算法不能实时。基于这个重大缺点，Faster-RCNN算法问世。</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><p>Fast-RCNN仍依赖于搜索候选框方法，其中以Selective  Search为主。在Fast-RCNN给出的时间测试结果中，一张图片需要2.3s的前向推理时间，其中2s用于生成2000个ROI。可以看到整个算法的时间消耗几乎都在区域候选框搜索这个步骤了，如果我们能去掉候选框搜索这个过程是不是实时有希望了？Faster-RCNN就干了这件事，论文提出在内部使用深层网络代替候选区域。新的候选区域网络(RPN)在生成ROI的效率大大提升，一张图片只需要10毫秒！！！</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>Faster-RCNN的网络结构如下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Faster_RCNN/640.png" alt></p>
<p>我们可以发现除了添加一个RPN网络之外，其他地方和Fast-RCNN是完全一致的。引用知乎上看到的一张更详细的网络结构如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Faster_RCNN/641.jfif" alt></p>
<h2 id="RPN网络"><a href="#RPN网络" class="headerlink" title="RPN网络"></a>RPN网络</h2><p>RPN网络将第一个卷积网络(backbone，如VGG16,ResNet)的输出特征图作为输入。它在特征图上滑动一个$3 \times 3$的卷积核，以使用卷积网络构建与类别无关的候选区域（候选框建议网络只用关心建议出来的框是否包含物体，而不用关系那个物体是哪一类的），我们将RPN产生的每个框叫做Anchor。</p>
<p>这里这样说肯定还是比较模糊，我引用一张训练时候的RPN的结构图然后固定输入分辨率和backbone为VGG16来解释一下。下面这张图是RPN架构：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Faster_RCNN/642.jfif" alt></p>
<p>我们可以看到anchor的数量是和Feature Map的大小相关，对于特征图中的每一个位置，RPN会做$k$次预测。因此，在这里对每个像素，RPN将输出$4 \times k$个坐标和$2 \times k$个得分。然后由于使用了VGG16做Backbone，所以输入到RPN的特征图大小是原图的$H, W$的$\frac{1}{16}$。对于一个$512 \times 62 \times 37$的feature map，有$62 \times 37 \times 9$约等于20000个anchor。也就是对一张图片，有20000个左右的anchor。这里可以看到RPN的高明之处，一张图片20000个候选框就是猜也能猜得七七八八。但是并不是20000个框我们都需要，我们只需要选取其中的256个。具体的选取规则如下：</p>
<ul>
<li>对于每一个Ground Truth Bounding Box，选择和它IOU最高的一个anchor作为正样本。</li>
<li>对于剩下的anchor，选择和任意一个Ground Truth Bounding Box 的IOU大于0.7的anchor作为正样本，正样本的数目不超过128个。</li>
<li>负样本直接选择和Ground Truth Bounding Box 的IOU&lt;0.3的anchor。正负样本的总数保证为256个。</li>
</ul>
<p>RPN在产生正负样本训练的时候，还会产生ROIs作为Faster-RCNN(ROI-Head)的训练样本。RPN生成ROIs的过程（网络结构图中的ProposalCreator）如下：</p>
<ul>
<li>对于每张图片，利用它的feature map， 计算 (H/16)× (W/16)×9（大概20000）个anchor属于前景的概率，以及对应的位置参数。</li>
<li>选取概率较大的12000个anchor</li>
<li>利用回归的位置参数，修正这12000个anchor的位置，得到RoIs</li>
<li>利用非极大值（(Non-maximum suppression, NMS）抑制，选出概率最大的2000个RoIs</li>
</ul>
<p>在前向推理阶段，12000和2000分别变为6000和3000以提高速度，这个过程不需要反向传播，所以更容易实现。</p>
<p>最后RPN的输出维度是$2000 \times 4$或者$300 \times 4$的tensor。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>在RPN网络中，对于每个Anchor，它们对应的gt_label（就是筛选到这个Anchor的那个ground truth框的label）要么是1要么是0，1代表前景，0代表背景。而gt_loc则是由4个位置参数$(t x, t y, t w, t h)$组成，这样比直接回归坐标更好。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Faster_RCNN/643.webp" alt></p>
<p>计算分类用的是交叉熵损失，而计算回归损失用的是SmoothL1Loss。在计算回归损失的时候只统计前景的损失，忽略背景的损失。</p>
<p>网络在最后对每一个框都有两种损失，即物体属于哪一类的分类损失(21类，加了个背景)，位置在哪的回归损失。所以整个Faster-RCNN的损失是这4个损失之和。网络的目标就是最小化这四个损失之和。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>上面讲了，RPN会产生大约2000个ROIs，这2000个ROIs并不都拿去训练，而是利用Proposal Target Creator选择128个ROIs用以训练。选择的规则如下：</p>
<ul>
<li>RoIs和gt_bboxes 的IoU大于0.5的，选择一些（比如32个）</li>
<li>选择 RoIs和gt_bboxes的IoU小于等于0（或者0.1）的选择一些（比如 128-32=96个）作为负样本</li>
</ul>
<p>同时为了便于训练，对选择出的128个ROIs的对应的ground truth  bbox的坐标进行标准化处理，即减去均值除以标准差。对于分类问题,直接利用交叉熵损失。而对于位置的回归损失，一样采用Smooth_L1Loss，只不过只对正样本计算损失。而且是只对正样本中的这个类别4个参数计算损失。举例来说:</p>
<ul>
<li>一个RoI在经过FC 84后会输出一个84维的loc 向量。如果这个RoI是负样本,则这84维向量不参与计算 L1_Loss。</li>
<li>如果这个RoI是正样本,属于label K,那么它的第 K×4，K×4+1，K×4+2， K×4+3 这4个数参与计算损失，其余的不参与计算损失。</li>
</ul>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>测试的时候保留大约300个ROIs，对每一个计算概率，并利用位置参数调整候选框的位置。最后用NMS筛一遍，就得到结果了。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Feature Pyramid Network</title>
    <url>/2020/04/20/Feature-Pyramid-Network/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>FPN全称是Feature Pyramid Network,  也就是特征金字塔网络，主要是针对图像中目标的多尺度的这个特点提出的，多尺度在目标检测中非常常见，而且对应不同的问题应该设计不同的FPN。FPN是Facebook于2017年提出的用于目标检测的模块化结构，但FPN在很多计算机视觉任务中都有使用，比如姿态估计、语义分割等领域。</p>
<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/640.webp" alt></p>
<p>在深度学习兴起以前，很多传统方法都会使用到<strong>图像金字塔</strong>。图像金字塔如上图所示，就是将图片resize到不同的大小，然后分别得到对应大小的特征，然后进行预测。这种方法虽然可以一定程度上解决多尺度的问题，但是很明显，带来的计算量也非常大。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/641.webp" alt></p>
<p>上图是使用单个feature map进行检测，这种结构在17年的时候是很多人在使用的结构，比如YOLOv1、YOLOv2、Faster  R-CNN中使用的就是这种架构。直接使用这种架构导致预测层的特征尺度比较单一，对小目标检测效果比较差。ps:  YOLOv2中使用了multi-scale training的方式一定程度上缓解了尺度单一的问题，能够让模型适应更多输入尺度。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/642.webp" alt></p>
<p>上图进行了在不同大小的feature map上分别进行预测，具有了多尺度预测的能力，但是特征与特征之间没有融合，遵从这种架构的经典的目标检测架构就是SSD, SSD用了非常多的尺度来进行检测。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/643.webp" alt></p>
<p>然后就是非常经典的FPN架构，FPN可以非常方便地应用到两阶段网络如Faster  R-CNN等或者一阶段网络YOLO、SSD等。FPN通过构造一种独特的特征金字塔来避免图像金字塔中计算量过高的问题，同时能够较好地处理目标检测中的多尺度变化问题，效果能够达到当时的STOA。SSD的一个改进版DSSD就是使用了FPN，取得了比SSD更好的效果。</p>
<p>这里展开描述一下FPN的细节：</p>
<p>为了方便说明，做出以下规定：</p>
<ul>
<li><p>图像backbone部分每个层feature map用$C_{i}$来标记，比如说$C_{3}$代表对应stride$=2^{3}=8$的feature map，通常用$C_{1}, \ldots C_{6}$代表每个feature map。</p>
</li>
<li><p>图像右侧的top-down结构每个feature map用$P_{i}$来标记，比如说$P_{3}$代表对应$C_{3}$大小的feature map。</p>
</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/644.webp" alt></p>
<p>假设当前层为第三层stride=8, 要与stride=16的特征进行融合，那么$C_{3}$先通过1 x 1卷积约束通道数和$P_{4}$层达到一致；来自$P_{4}$通过2倍上采样得到的feature map大小和$C_{3}$一致，最终$P_{3}$是通过$P_{4}$上采样结果和$C_{3}$进行element wise add得到结果。</p>
<p>那么<strong>为什么FPN采用融合以后效果要比使用pyramidal feature hierarchy这种方式要好</strong>呢？有以下几个原因：</p>
<ul>
<li>卷积虽然能够高效地向上提取语义，但是也存在<strong>像素错位问题</strong>，通过上采样还原特征图的方式很好地缓解了像素不准的问题。</li>
<li>backbone可以分为浅层网络和深层网络，浅层网络负责提取目标边缘等底层特征，而深层网络可以构建高级的语义信息，通过使用FPN这种方式，让深层网络更<strong>高级语义的部分的信息能够融合到稍浅层的网络</strong>，指导浅层网络进行识别。</li>
<li>从感受野的角度思考，浅层特征的感受野比较小，深层网络的感受野比较大，浅层网络主要负责小目标的检测，深层的网络负责大目标的检测（比如人脸检测中的SSH就使用到了这个特点）。如下图所示：</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/645.webp" alt></p>
<p>黑色的框是理论感受野，中心呈高斯分布的亮点是实际感受野，FPN中的top-down之路通过融合不同感受野，<strong>两个高斯分布的实际感受野进行融合，能够让高层加强低层所对应的感受野</strong>。</p>
<p>关于感受野这个观点，FPN论文有一张图，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/646.webp" alt></p>
<p>这张图讲的是FPN应用在DeepMask中做实例分割，其中使用了一个5×5的多层感知机来生成一个14×14的分割结果。对应的浅橙色的区域代表的是对应到原图的区域（与理论感受野相似），深橙色区域对应的是典型的目标区域（与实际感受野类似），观察这个图我们可以得到几个结论：</p>
<ul>
<li><p>网络越深、特征图越小对应到原图的范围也就越大。这也就可以解释为什么加上FPN以后，小目标的效果提升了，比如在上图的$P_{3}$到$P_{5}$中，$P_{3}$对应的目标区域要小一些，更符合小目标的大小。</p>
</li>
<li><p>在同一层中，理论感受野的范围要大于实际感受野。</p>
</li>
</ul>
<h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/647.webp" alt></p>
<p>以上是FPN各部分的专有名称，作者详细对比了top-down pathway带来的增益，lateral connection带来的增益，</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/FPN/648.webp" alt></p>
<p>上表中的实验中能得到几个结论：</p>
<ul>
<li>通过(a)和(b)比较，说明随着网络深入，小目标检测效果会变差，大目标检测效果会变好。</li>
<li>通过(d)和(e)比较，说明lateral connections是非常有必要的</li>
<li><p>通过(f)和(c)比较，说明只用最浅层$P_{2}$效果不如使用$P_{2}, P_{3}, P_{4}$</p>
</li>
<li><p>通过(f)和(c)比较，还可以发现由于$P_{2}$的空间分辨率比较高，anchor非常多，可以得到一个结论就是：仅仅是使用非常多的anchor这一点本身是不足以提升准确率的。</p>
</li>
</ul>
<p>文章中还有几个实验将FPN添加到RPN网络、DeepMask结构中，都带来不错的效果，FPN确实是一个比较好的feature fusion方法，在此之后，有很多架构的网络也不断地被提出来，都带来了一定的提升。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul>
<li>浅层网络负责小目标检测，深层网络负责大目标检测，这两部分融合的时候一般是通过简单的add或者concate进行融合的，为什么一定要这样融合？</li>
<li>浅层小目标信息比较丰富，深层网络具有高级语义，能够一定程度上指导小目标的检测，这里的浅层和深层能够添加一个权重来具体决定哪个部分占比比较大吗？</li>
<li>具体怎么决定浅层网络和深层网络的占比？通过先验来固定取值，还是自适应通过网络学习得到相应阈值？</li>
</ul>
<p>其实看论文比较多的读者可能已经想到了，ASFF, BiFPN，BiSeNet，ThunderNet等，这都是比较好解决这个问题的方法。</p>
<p><strong>特征融合方式总结</strong></p>
<ul>
<li>两层特征add，eg: FPN</li>
<li>两层特征concate，eg: YOLOv3</li>
<li>使用注意力机制, eg: BiSeNet, ThunderNet</li>
<li>weighted add, eg: BiFPN</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）</title>
    <url>/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这是一篇图森科技在ICCV 2019的目标检测论文《Scale-Aware Trident Networks for Object Detection》，简称TridentNet，中文翻译为三叉戟网络。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们知道在目标检测任务中，尺度变化一直是很关键的问题。针对尺度变化问题，也有很多的方案被提出，如Figure 1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/640.jpg" alt></p>
<p>其中</p>
<p>(a)图表示多尺度图像金字塔网络，直接对图像进行不同尺度的缩放。</p>
<p>(b)是FPN网络，借鉴了金字塔结构将分辨率信息和语义信息相结合，克服不同层，不同尺度带来的问题。</p>
<p>这两种方法的目的都是让模型对尺寸不同的目标具有不同的感受野。除此之外还有SNIP，SNIP主要包含了两个改进点：</p>
<p>1、为了减少domain-shift，在梯度回传的时候只将和预训练模型所基于的训练数据尺寸相应的ROI的梯度进行回传。</p>
<p>2、借鉴了多尺度训练思想，引入图像金字塔来处理数据集中不同尺寸的数据。虽然图像金字塔的效率比较低，但通过对原图不同比例的缩放，充分利用了模型的表征能力。相比之下，FPN产生多层次的特征，但也牺牲了不同尺度下的特征一致性。</p>
<p>总结一下就是，图像金字塔虽然慢但是精度高。而FPN虽然快，但相比于图像金字塔牺牲了精度。有没有办法将这两者统一起来呢？TridentNet横空出世。</p>
<h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><p>论文提出了TridentNet，基于ResNet-101骨架网络在COCO数据集上达到了单模型48.4的准确率，刷新COCO纪录。TridentNet的主要贡献在于：</p>
<ul>
<li>首次提出感受野(receptive filed)对目标检测任务中不同尺度大小目标的影响，并进行相关实验验证。</li>
<li>提出了适应于多尺度的目标检测框架TridentNet。</li>
<li>使用参数共享的方法，提出了训练3个分支，但测试时只使用其中一个分支，这样保证前向推理的时候不会有额外的参数和计算量增加。</li>
<li>使用ResNet-101为backbone的TridentNet在COCO数据集上达到了48.4的map，真正的SOTA。</li>
</ul>
<h2 id="膨胀卷积"><a href="#膨胀卷积" class="headerlink" title="膨胀卷积"></a>膨胀卷积</h2><p>假设膨胀率为$ds$，使用的卷积核大小为3 x 3，则使用膨胀卷积的感受野大小为$3 + 2\times2\times(ds -1)$，例如：</p>
<ul>
<li>$ds=1$，表示不进行膨胀，感受野大小为3 x 3</li>
<li>$ds = 2$，表示膨胀卷积系数为2，感受野大小为7 x 7</li>
<li>$ds = 4$，表示膨胀卷积系数为4，感受野大小为15 x 15</li>
</ul>
<p>从Table1可以看到，随着感受野的增大，小目标的检测准确性也开始下降，但是大目标的检测准确性开始上升，Table1如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/641.webp" alt></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>Figure2展示了TridentNet的网络结构。</p>
<p>在原始的backbone上做了三点变化：第一点是构造了不同receptive field的parallel multi-branch，第二点是对于trident block中每一个branch的weight是share的。第三点是对于每个branch，训练和测试都只负责一定尺度范围内的样本，也就是所谓的scale-aware</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/642.webp" alt></p>
<p>TridentNet模块包含3个完全一样的分支，唯一不同的只是膨胀卷积的膨胀速率。从上到下，膨胀率分别为1,2,3，分别检测小，中，大的目标。TridentNet的构造和改进是通过将一些常规卷积快替换为三叉戟块(Trident Block)。其中Trident  Block由多个平行分支组成，除了膨胀卷积的膨胀速率之外，每个分支和原始的卷积块有完全相同的结构。下面以ResNet为例，对于一个残差模块，包括三个卷积核即1 x 1，3 x 3，1 x 1。详细结构如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/643.webp" alt></p>
<p>可以看到三个分支由于膨胀卷积的膨胀速率不同使得网络拥有了更多可供选择的感受野。通常用三叉戟块替换主干的最后一个阶段的卷积块，因为三叉戟块产生的感受野有较大的差异，足以执行目标检测任务。同时，三叉戟块的三个分支之间的权重是共享的，只有膨胀速率不同，这种设置使得权值共享更加简单。权值共享有以下几个优点：</p>
<ul>
<li>可以不增加额外的参数量。</li>
<li>和论文的出发点一致，即不同尺度的物体应该以同样的表征能力进行统一的转化。</li>
<li>在不同的感受野下，可以对不同尺度范围训练相同的参数。</li>
</ul>
<h2 id="训练和测试"><a href="#训练和测试" class="headerlink" title="训练和测试"></a>训练和测试</h2><p>TridentNet在训练过程中会对每一个分支进行优化。因此，需要对目标的ground truth的大小进行测试，即：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/644.webp" alt></p>
<p>其中，$w$，$h$代表ground truth的宽和高。$l_{i}$，$u_{i}$代表实验中定义的第$i$个分支的目标最小面积和最大面积 。在COCO数据集上分别为32 x 32和96 x 96。基于此公式实现目标匹配原则，即小的目标走第一个分支，中等目标走第二个分支，大的目标走第三个分支。而不是所有的目标都走一个分支，这样就可以有针对性的训练。在测试时，只用中间的分支进行推理，然后对结果进行NMS后处理，最后输出预测的目标信息。当然这样做会带来一些精度损失，大概在0.5-1个map值，但这样的好处在于不会引入额外的参数，不会增加额外的计算量。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>本文的另外一个值得称道的地方就是实验做的非常棒。首先来看Multi-branch ，Weight-sharing，  Scale-aware有效性证明，如Table2所示。可以看到都比baseline好并且当三部分都加上的时候性能达到最高。注意一下，Table2是在COCO验证集上进行的测试。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/645.webp" alt></p>
<p>然后Table3展示了TridentNet模块分支个数对AP值的影响。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/646.webp" alt></p>
<p>然后TridentNet模块在ResNet不同block中的实验结果如Table4所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/647.webp" alt></p>
<p>然后论文探索了TridentNet各个分支的检测精度，如Table5所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/648.webp" alt></p>
<p>然后论文还给出了TridentNet 中间分支在coco测试的结果，如Table6所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/649.webp" alt></p>
<p>上面的实验都是在COCO验证集上的结果，接下来给出模型在COCO测试集上相对于其他SOAT网络的精度，如Table 7所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/TridentNet/650.webp" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>TridentNet是一种尺度敏感的检测网络，并且训练过程也要进行多尺度训练。检测准确性很高，并且不会有额外的参数，额外的计算量，是ASPP结构的灵活应用。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>JetBrains全系列软件激活教程</title>
    <url>/2022/01/14/JetBrains%E5%85%A8%E7%B3%BB%E5%88%97%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>Jetbrains家的产品有一个很良心的地方，他会允许你试用 30 天（这个数字写死在代码里了）以评估是否你真的需要为它而付费。 因此推荐使用无限重置试用的方法白嫖，最终和永久激活使用无差异，也比破解稳定。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114101810909.png" alt></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>在<code>Settings/Preferences... -&gt; Plugins</code>内手动添加第三方插件仓库地址：<code>https://plugins.zhile.io</code>搜索：IDE Eval Reset插件进行安装。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114101936925.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114102036711.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114102121670.png" alt></p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>一般来说，在 IDE 窗口切出去或切回来时（窗口失去/得到焦点）会触发事件，检测是否长时间（25天）没有重置，给通知让你选择。（初次安装因为无法获取上次重置时间，会直接给予提示）。</p>
<p>您也可以手动唤出插件的主界面：</p>
<p>a. 如果 IDE 没有打开项目，在 Welcome 界面点击 IDE 的菜单：<code>Get Help -&gt; Eval Reset</code></p>
<p>b. 如果 IDE 打开了项目，点击 IDE 的菜单：<code>Help -&gt; Eval Reset</code></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114102222559.png" alt></p>
<p>唤出的插件主界面中包含了一些显示信息，有 2 个按钮和 1 个勾选项：</p>
<ul>
<li>按钮：<code>Reload</code> 用来刷新界面上的显示信息。</li>
<li>按钮：<code>Reset</code> 点击会询问是否重置试用信息并重启 IDE。选择 Yes 则执行重置操作并重启 IDE 生效，选择 No 则什么也不做。（此为手动重置方式）</li>
<li>勾选项：<code>Auto reset before per restart</code> 如果勾选了，则自勾选后每次重启/退出 IDE 时会自动重置试用信息，你无需做额外的事情。（此为自动重置方式，推荐此方法！）</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/jetbrains/image-20220114102304339.png" alt></p>
<h3 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a>一些说明</h3><p>市场付费插件的试用信息也会一并重置。</p>
<p>MyBatisCodeHelperPro 插件有两个版本如下，功能完全相同，安装时须看清楚！</p>
<ul>
<li><a href="https://plugins.jetbrains.com/plugin/14522-mybatiscodehelperpro-marketplace-edition-">MyBatisCodeHelperPro</a> (Marketplace Edition)，<code>可重置</code>！</li>
<li><a href="https://plugins.jetbrains.com/plugin/9837-mybatiscodehelperpro">MyBatisCodeHelperPro</a>，<code>不可重置</code>！</li>
</ul>
<p>对于某些付费插件（如: Iedis 2, MinBatis）来说，你可能需要去取掉 javaagent 配置（如果有）后重启IDE：</p>
<ul>
<li>如果IDE没有打开项目，在 Welcome 界面点击菜单：Configure -&gt; Edit Custom VM Options… -&gt; 移除 -javaagent: 开头的行。</li>
<li>如果IDE打开了项目，点击菜单：Help -&gt; Edit Custom VM Options… -&gt; 移除 -javaagent: 开头的行。</li>
</ul>
<p>重置需要重启IDE生效！</p>
<p>重置后并不弹出 Licenses 对话框让你选择输入 License 或试用，这和之前的重置脚本/插件不同（省去这烦人的一步）。</p>
<p>如果长达 25 天不曾有任何重置动作，IDE 会有通知询问你是否进行重置。</p>
<p>如果勾选：Auto reset before per restart ，重置是静默无感知的。</p>
<p>简单来说：勾选了 Auto reset before per restart 则无需再管，一劳永逸。</p>
<h3 id="支持的产品"><a href="#支持的产品" class="headerlink" title="支持的产品"></a>支持的产品</h3><ul>
<li>IntelliJ IDEA</li>
<li>AppCode</li>
<li>CLion</li>
<li>DataGrip</li>
<li>GoLand</li>
<li>PhpStorm</li>
<li>PyCharm</li>
<li>Rider</li>
<li>RubyMine</li>
<li>WebStorm</li>
</ul>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
      <tags>
        <tag>JetBrains</tag>
      </tags>
  </entry>
  <entry>
    <title>Latex中公式过长问题</title>
    <url>/2020/07/18/Latex%E4%B8%AD%E5%85%AC%E5%BC%8F%E8%BF%87%E9%95%BF%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>latex中公式过长通常有以下几个解决方案：</p>
<p><strong>(1) 使用amsmath package的split环境，将长公式在<code>\\</code>处断开</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;equation&#125;</span><br><span class="line">\begin&#123;split&#125;</span><br><span class="line">F = \&#123;F_&#123;x&#125; \in  F_&#123;c&#125; &amp;: (|S| &gt; |C|) \\</span><br><span class="line">&amp;\quad \cap (\text&#123;minPixels&#125; &lt; |S| &lt; \text&#123;maxPixels&#125;) \\</span><br><span class="line">&amp;\quad \cap (|S_&#123;\text&#123;conected&#125;&#125;| &gt; |S| - \epsilon) \&#125;</span><br><span class="line">\end&#123;split&#125;</span><br><span class="line">\end&#123;equation&#125;</span><br></pre></td></tr></table></figure>
<p><strong>(2) 利用\!命令，如加在=号、+号两侧进行微调</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;eqnarray&#125;</span><br><span class="line">\dot&#123;x&#125;(t)\！=\！\bar&#123;A&#125;_&#123;i&#125;x(t)+\bar&#123;B&#125;_&#123;i_&#123;1&#125;&#125;x(t)+\bar&#123;B&#125;_&#123;i_&#123;2&#125;&#125;x(t)+\bar&#123;B&#125;_&#123;i_&#123;3&#125;&#125;[a_&#123;i&#125;(t)\！+\！b_&#123;i&#125;(t)].</span><br><span class="line">\end&#123;eqnarray&#125;</span><br></pre></td></tr></table></figure>
<p><strong>(3) 缩小公式</strong></p>
<ul>
<li>[编号不缩小]<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;equation&#125;</span><br><span class="line">\resizebox&#123;.9\hsize&#125;&#123;!&#125;&#123;$A+B+C+D+E+F+G+H+I+J+K+L+M+N+O+P+Q+R+S+T+U+V+W+X+Y+Z$&#125;</span><br><span class="line">\end&#123;equation&#125;</span><br></pre></td></tr></table></figure></li>
<li>[编号同步缩小]<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;small&#125;</span><br><span class="line">\begin&#123;equation&#125;</span><br><span class="line">\ldots</span><br><span class="line">\end&#123;equation&#125;</span><br><span class="line">\end&#123;small&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>[补充] LATEX 中具体的间隔大小为：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\quad           1em,em代表一个字符宽度</span><br><span class="line">\qquad          2em</span><br><span class="line">\,              3/18em</span><br><span class="line">\:              4/18em</span><br><span class="line">\;              5/18em</span><br><span class="line">\!             -3/18em（不仅不会增加空格，还会把间距给减小1/6个字符，这个有时可以用到，比如输入模的时候||x||，可以用这个把两个|的间距缩小点，这样更加美观）</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>LabelImg标注工具使用及数据格式解析</title>
    <url>/2022/01/12/LabelImg%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>LabelImg是目标检测数据标注工具，支持两种标注格式：</p>
<ul>
<li>VOC标签格式，标注的标签存储在xml文件</li>
<li>YOLO标签格式，标注的标签存储在txt文件中</li>
</ul>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>确保电脑上安装python3+，其中windows和macOS推荐使用Anaconda等工具快速安装python。这里不再展开介绍。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="自动安装（推荐）"><a href="#自动安装（推荐）" class="headerlink" title="自动安装（推荐）"></a>自动安装（推荐）</h3><p>使用<code>pip</code>安装LabelImg安装是最简单的方式，安装完之后会自动把LabelImg添加到环境变量中。</p>
<p>打开终端输入如下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install labelimg</span><br></pre></td></tr></table></figure>
<p>国内速度慢的可指定镜像源再安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install labelimg -i https://mirrors.aliyun.com/pypi/simple/</span><br></pre></td></tr></table></figure>
<p>注：在部分老电脑上直接安装labelimg最新版有的不能成功，经测试安装1.8.0版本以下老版本可以，出错的可指定版本，安装这之下版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install labelimg==1.8.0</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/clip_image002.jpg" alt></p>
<h3 id="手动安装"><a href="#手动安装" class="headerlink" title="手动安装"></a>手动安装</h3><p>需从官方下载源码：<a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a></p>
<p>从源码开始安装LabelImg，一般比较麻烦，不推荐</p>
<h4 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h4><p>① Python 2 + Qt4</p>
<p>使用如下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install pyqt4-dev-tools</span><br><span class="line">sudo pip install lxml</span><br><span class="line">make qt4py2</span><br><span class="line">python labelImg.py</span><br><span class="line">python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]</span><br></pre></td></tr></table></figure>
<p>② Python 3 + Qt5 (Recommended)</p>
<p>使用如下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install pyqt5-dev-tools</span><br><span class="line">sudo pip3 install -r requirements/requirements-linux-python3.txt</span><br><span class="line">make qt5py3</span><br><span class="line">python3 labelImg.py</span><br><span class="line">python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]</span><br></pre></td></tr></table></figure>
<h4 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a>macOS</h4><p>① Python 2 + Qt4</p>
<p>使用如下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install qt qt4</span><br><span class="line">brew install libxml2</span><br><span class="line">make qt4py2</span><br><span class="line">python labelImg.py</span><br><span class="line">python labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]</span><br></pre></td></tr></table></figure>
<p>② Python 3 + Qt5 (Recommended)</p>
<p>使用如下命令安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install qt</span><br><span class="line">brew install libxml2</span><br><span class="line"> </span><br><span class="line">or using pip</span><br><span class="line"> </span><br><span class="line">pip3 install pyqt5 lxml</span><br><span class="line"> </span><br><span class="line">make qt5py3</span><br><span class="line">python3 labelImg.py</span><br><span class="line">python3 labelImg.py [IMAGE_PATH] [PRE-DEFINED CLASS FILE]</span><br></pre></td></tr></table></figure>
<h4 id="Virtualenv"><a href="#Virtualenv" class="headerlink" title="Virtualenv"></a>Virtualenv</h4><p>使用<code>virtualenv</code>创建虚拟环境可以避免python版本和QT版本带来的一些问题，当然你也可以用<code>conda</code>创建虚拟环境。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install python3</span><br><span class="line">pip3 install pipenv</span><br><span class="line">pipenv run pip install pyqt5==5.13.2 lxml</span><br><span class="line">pipenv run make qt5py3</span><br><span class="line">python3 labelImg.py</span><br></pre></td></tr></table></figure>
<h3 id="更多安装方式"><a href="#更多安装方式" class="headerlink" title="更多安装方式"></a>更多安装方式</h3><p>可参见官方，如docker安装方法，这里不再详细介绍。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="打开软件"><a href="#打开软件" class="headerlink" title="打开软件"></a>打开软件</h3><p>① 如果是<code>pip</code>安装的，由于会自动加入环境变量，因此只要在终端输入<code>LabelImg</code> 或 <code>labelimg</code>即可打开。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112175932198.png" alt></p>
<p>② 如果是手动编译的，需要到软件安装目录打开终端，运行<code>python labelImg.py</code>。</p>
<h3 id="按钮介绍"><a href="#按钮介绍" class="headerlink" title="按钮介绍"></a>按钮介绍</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112180734010.png" alt></p>
<ul>
<li><code>Open Dir</code>：待标注图片数据的路径文件夹</li>
<li><code>Change Save Dir</code>：保存类别标签的路径文件夹</li>
<li><code>PascalVOC</code>：标注的标签保存成VOC格式，在鼠标点一下就变成YOLO，即此时就会把标注的标签变成YOLO格式</li>
<li><code>Create RectBox</code>：点击后鼠标会变成十字架，可以开始画框</li>
</ul>
<h3 id="快捷键介绍"><a href="#快捷键介绍" class="headerlink" title="快捷键介绍"></a>快捷键介绍</h3><ul>
<li><code>W</code>：调出标注的十字架，开始标注</li>
<li><code>A</code>：切换到上一张图片</li>
<li><code>D</code>：切换到下一张图片</li>
<li><code>Ctrl+S</code>：保存标注好的标签</li>
<li><code>del</code>：删除标注的矩形框</li>
<li><code>Ctrl+鼠标滚轮</code>：按住Ctrl，然后滚动鼠标滚轮，可以调整标注图片的显示大小</li>
<li><code>Ctrl+u</code>：选择要标注图片的文件夹</li>
<li><code>Ctrl+r</code>：选择标注好的label标签存放的文件夹</li>
<li><code>↑→↓←</code>：移动标注的矩形框的位置</li>
</ul>
<h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p>点击<code>View</code>显示，推荐选上以下几个选项：</p>
<ul>
<li><code>Auto Save mode</code>：当你切换到下一张图片时，就会自动把上一张标注的图片标签自动保存下来，这样就不用每标注一样图片都按<code>Ctrl+S</code>保存一下了</li>
<li><code>Display Labels</code>：标注好图片之后，会把框和标签都显示出来</li>
<li><code>Advanced Mode</code>：这样标注的十字架就会一直悬浮在窗口，不用每次标完一个目标，再按一次<code>W</code>快捷键或点击<code>Create RectBox</code>，调出标注的十字架。</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112181105527.png" alt></p>
<h3 id="读取标注"><a href="#读取标注" class="headerlink" title="读取标注"></a>读取标注</h3><p>如果已存在标注文件，可点击<code>File</code>-&gt;<code>Open Annotation</code>打开。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112184439055.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112184453555.png" alt></p>
<h3 id="具体标注过程展示"><a href="#具体标注过程展示" class="headerlink" title="具体标注过程展示"></a>具体标注过程展示</h3><p>① 首先，打开图片所在文件夹，这边为方便演示，<code>demo</code>文件夹中只有一张图片，标注保存路径也设置成<code>demo</code>文件夹。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112181957866.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112182257756.png" alt></p>
<p>② 按一次<code>W</code>快捷键或点击<code>Create RectBox</code>，调出标注的十字架，开始画框。画好框后会弹出窗口提示输入类别。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112182440716.png" alt></p>
<p>③ 输入类别，完成标注。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112182611233.png" alt></p>
<p>可看到标注完成后，类别（这里的类别是<code>person</code>）会展示在右边的窗口中，与框对应的颜色显示。</p>
<p>保存后，会看到在设置的标注保存路径中会生成与图片同名的标注文件：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112182740201.png" alt></p>
<p>如果标注需要修正，先确保进入编辑模式（点击<code>Edit RectBox</code>）：</p>
<p>比如框画得不好，可以选中框按<code>Delete</code>删除后，重画。</p>
<p>比如类别需要修改，从右边窗口选择需要修改的类别，右键<code>Edit Label</code>进行修改。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112184045178.png" alt></p>
<h3 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h3><p>如果类别种类确定，可在txt中事先规定好要用到的类别，比如定义了一个<code>predefined_classes.txt</code>，内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">circle_red</span><br><span class="line">circle_gray</span><br><span class="line">rectangle_red</span><br><span class="line">rectangle_gray</span><br><span class="line">fingeprint_red</span><br><span class="line">fingeprint_gray</span><br><span class="line">other</span><br></pre></td></tr></table></figure>
<p>在软件打开时，带上参数，指定图片路径和预定义类别txt的路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">labelimg /path/to/image_file /path/to/predefined_classes.txt</span><br></pre></td></tr></table></figure>
<p>那么标注的时候，会把<code>predefined_classes.txt</code>预定义的标签加载出来，然后只要选择对应的标签即可，不需要手动输入了。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/labelimg/image-20220112185041147.png" alt></p>
<h2 id="数据标签格式解析"><a href="#数据标签格式解析" class="headerlink" title="数据标签格式解析"></a>数据标签格式解析</h2><h3 id="VOC数据格式"><a href="#VOC数据格式" class="headerlink" title="VOC数据格式"></a>VOC数据格式</h3><p>如：标注的<code>000001.jpg</code>图片，标注的标签信息会保存到<code>000001.xml</code>文件中，<code>000001.xml</code>中的信息如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">annotation</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">folder</span>&gt;</span>demo<span class="tag">&lt;/<span class="name">folder</span>&gt;</span> # 文件夹名，不重要</span><br><span class="line">	<span class="tag">&lt;<span class="name">filename</span>&gt;</span>000001.jpg<span class="tag">&lt;/<span class="name">filename</span>&gt;</span> # 图片名，重要</span><br><span class="line">	<span class="tag">&lt;<span class="name">path</span>&gt;</span>C:\Users\Qiyuan-Z\Desktop\demo\000001.jpg<span class="tag">&lt;/<span class="name">path</span>&gt;</span> # 图片路径，不重要</span><br><span class="line">	<span class="tag">&lt;<span class="name">source</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">database</span>&gt;</span>Unknown<span class="tag">&lt;/<span class="name">database</span>&gt;</span> # 数据集名称，不重要</span><br><span class="line">	<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">size</span>&gt;</span> # 图像尺寸，重要</span><br><span class="line">		<span class="tag">&lt;<span class="name">width</span>&gt;</span>468<span class="tag">&lt;/<span class="name">width</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">height</span>&gt;</span>624<span class="tag">&lt;/<span class="name">height</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">depth</span>&gt;</span>3<span class="tag">&lt;/<span class="name">depth</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">size</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">segmented</span>&gt;</span>0<span class="tag">&lt;/<span class="name">segmented</span>&gt;</span> # 是否用于分割，0为否，1为是</span><br><span class="line">	<span class="tag">&lt;<span class="name">object</span>&gt;</span> # 目标信息，重要</span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>person<span class="tag">&lt;/<span class="name">name</span>&gt;</span> # 目标类别</span><br><span class="line">		<span class="tag">&lt;<span class="name">pose</span>&gt;</span>Unspecified<span class="tag">&lt;/<span class="name">pose</span>&gt;</span> # 拍摄角度</span><br><span class="line">		<span class="tag">&lt;<span class="name">truncated</span>&gt;</span>0<span class="tag">&lt;/<span class="name">truncated</span>&gt;</span> # 是否被截断，0为完整</span><br><span class="line">		<span class="tag">&lt;<span class="name">difficult</span>&gt;</span>0<span class="tag">&lt;/<span class="name">difficult</span>&gt;</span> # 是否难识别，0为简单</span><br><span class="line">		<span class="tag">&lt;<span class="name">bndbox</span>&gt;</span> # 左上角和右下角的xy坐标</span><br><span class="line">			<span class="tag">&lt;<span class="name">xmin</span>&gt;</span>172<span class="tag">&lt;/<span class="name">xmin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">ymin</span>&gt;</span>112<span class="tag">&lt;/<span class="name">ymin</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">xmax</span>&gt;</span>317<span class="tag">&lt;/<span class="name">xmax</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">ymax</span>&gt;</span>502<span class="tag">&lt;/<span class="name">ymax</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">bndbox</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">object</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">annotation</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="YOLO数据格式"><a href="#YOLO数据格式" class="headerlink" title="YOLO数据格式"></a>YOLO数据格式</h3><p>如：标注的<code>000001.jpg</code>图片，标注的标签信息会保存到<code>000001.txt</code>文件中（同时会生成一个<code>classes.txt</code>文件），<code>000001.txt</code>中的信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 0.521000 0.235075 0.362000 0.450249</span><br><span class="line">0 0.213000 0.645522 0.418000 0.519900</span><br><span class="line">0 0.794000 0.665423 0.376000 0.470149</span><br></pre></td></tr></table></figure>
<ul>
<li>每一行代表标注的一个目标</li>
<li>第一个数代表标注目标的标签，如第一个目标是circle_red，对应的数字就是0</li>
<li>后面的四个数代表标注框的中心坐标和标注框的相对宽和高</li>
</ul>
<p><code>classes.txt</code>中的信息如下，会按顺序存储标签：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">circle_red</span><br><span class="line">circle_gray</span><br><span class="line">rectangle_red</span><br><span class="line">rectangle_gray</span><br><span class="line">fingeprint_red</span><br><span class="line">fingeprint_gray</span><br><span class="line">other</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Grad-CAM原理和实现</title>
    <url>/2022/01/10/Grad-CAM%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>本文转载于<a href="https://zhuanlan.zhihu.com/p/453689298">⚡哥的知乎专栏</a>，大佬写的真是清晰易懂，菜鸡的我默默留存，好好学习！🙇‍♂️</p>
<p>觉得不错的，大家记得帮电哥点赞👍+收藏⭐呀！</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>① 要做猫狗的二分类任务，网络的分类器是输出为两个神经元的全连接层，两个神经元的输出分别为$z=\left[z_{c}, z_{d}\right]$，其中猫的概率为$p_c$，狗的概率为$p_d$，且$\left[p_{c}, p_{d}\right]=\operatorname{softmax}(z)$。<br>② 要可视化猫这个类别的GradCAM，通过$z_c$对CNN最后一层的所有特征图$A_{i, j}^{k}$求偏导$G_{i, j}^{k}=\frac{\partial z_{c}}{\partial A_{i, j}^{k}}$，其中$A_{i, j}^{k}$表示特征图$A$ shape=(1, C, H, W)的第k通道的(i, j)坐标点，最终的偏导特征图$G$ shape=(1, C, H, W)。</p>
<ul>
<li><p>取最后一层的原因：</p>
<ul>
<li>GradCAM可以用来可视化任何的激活特征图，但论文的主要目的是要解释神经网络得到决策的可能原因。</li>
<li>最后一层特征图有丰富的highlevel语义信息和详细的空间信息，而全连接层完全丢失了空间信息。</li>
</ul>
</li>
<li><p>求偏导的意义：</p>
<ul>
<li>偏导表示输出关于输入的变化率，也就是特征图上变化一个单位，得到的输出变化多少单位。可以反映出输出$z_c$关于$A_{i, j}^{k}$的敏感程度，如果梯度大，则非常敏感，表示该位置更有可能就是猫类。</li>
</ul>
</li>
</ul>
<p>③ 对偏导特征图$G$做全局平均池化GAP，得到一个$C$个元素的权重向量$\alpha=\left[\alpha_{1}, \cdots, \alpha_{k}, \cdots, \alpha_{C}\right]$，$C$是$G$的通道数，$\alpha_{k}=\frac{1}{H W} \sum_{i}^{H} \sum_{j}^{W} G_{i, j}^{k}$。$\alpha_k$表示的是猫类相对于最后一层特征图的第k个通道的平均的敏感程度。</p>
<p>④ 将权重向量$\alpha$与特征图$A$对应通道做线性加权，得到一个二维的激活图$\operatorname{Grad CAM}=\operatorname{ReLU}\left(\sum_{k} \alpha_{k} A^{k}\right)$。</p>
<ul>
<li>ReLU的作用是要求得到激活图里的值和猫类正相关的热力图，而负数部分表示属于狗类，可以表示为对预测为猫类起到抑制作用，因此用ReLU过滤掉这些起抑制作用的部分。</li>
<li>最后将激活图上采样到输入图片大小。</li>
</ul>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision.models.resnet <span class="keyword">import</span> resnet18</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradCAM</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, model: nn.Module, target_layer: <span class="built_in">str</span>, size=(<span class="params"><span class="number">224</span>, <span class="number">224</span></span>), mean=<span class="literal">None</span>, std=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># register hook</span></span><br><span class="line">        <span class="comment"># 可以自己指定层名，没必要一定通过target_layer传递参数</span></span><br><span class="line">        <span class="comment"># self.model.layer4</span></span><br><span class="line">        <span class="comment"># self.model.layer4[1].register_forward_hook(self.__forward_hook)</span></span><br><span class="line">        <span class="comment"># self.model.layer4[1].register_backward_hook(self.__backward_hook)</span></span><br><span class="line">        <span class="built_in">getattr</span>(self.model, target_layer).register_forward_hook(self.__forward_hook)</span><br><span class="line">        <span class="built_in">getattr</span>(self.model, target_layer).register_backward_hook(self.__backward_hook)</span><br><span class="line"></span><br><span class="line">        self.size = size</span><br><span class="line">        self.origin_size = <span class="literal">None</span></span><br><span class="line">        self.mean, self.std = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span><br><span class="line">        <span class="keyword">if</span> mean <span class="keyword">and</span> std:</span><br><span class="line">            self.mean, self.std = mean, std</span><br><span class="line"></span><br><span class="line">        self.grads = []</span><br><span class="line">        self.fmaps = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, img_arr: np.ndarray, label=<span class="literal">None</span>, show=<span class="literal">True</span>, write=<span class="literal">False</span></span>):</span></span><br><span class="line">        img_input = self.__img_preprocess(img_arr.copy())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward</span></span><br><span class="line">        output = self.model(img_input)</span><br><span class="line">        idx = np.argmax(output.cpu().data.numpy())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward</span></span><br><span class="line">        self.model.zero_grad()</span><br><span class="line">        loss = self.__compute_loss(output, label)</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># generate CAM</span></span><br><span class="line">        grads_val = self.grads[<span class="number">0</span>].cpu().data.numpy().squeeze()</span><br><span class="line">        fmap = self.fmaps[<span class="number">0</span>].cpu().data.numpy().squeeze()</span><br><span class="line">        cam = self.__compute_cam(fmap, grads_val)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># show</span></span><br><span class="line">        cam_show = cv2.resize(cam, self.origin_size)</span><br><span class="line">        img_show = img_arr.astype(np.float32) / <span class="number">255</span></span><br><span class="line">        self.__show_cam_on_image(img_show, cam_show, if_show=show, if_write=write)</span><br><span class="line"></span><br><span class="line">        self.fmaps.clear()</span><br><span class="line">        self.grads.clear()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__img_transform</span>(<span class="params">self, img_arr: np.ndarray, transform: torchvision.transforms</span>) -&gt; torch.Tensor:</span></span><br><span class="line">        img = img_arr.copy()  <span class="comment"># [H, W, C]</span></span><br><span class="line">        img = Image.fromarray(np.uint8(img))</span><br><span class="line">        img = transform(img).unsqueeze(<span class="number">0</span>)  <span class="comment"># [N,C,H,W]</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__img_preprocess</span>(<span class="params">self, img_in: np.ndarray</span>) -&gt; torch.Tensor:</span></span><br><span class="line">        self.origin_size = (img_in.shape[<span class="number">1</span>], img_in.shape[<span class="number">0</span>])  <span class="comment"># [H, W, C]</span></span><br><span class="line">        img = img_in.copy()</span><br><span class="line">        img = cv2.resize(img, self.size)</span><br><span class="line">        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line">        transform = transforms.Compose([</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize(self.mean, self.std)</span><br><span class="line">        ])</span><br><span class="line">        img_tensor = self.__img_transform(img, transform)</span><br><span class="line">        <span class="keyword">return</span> img_tensor</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_hook</span>(<span class="params">self, module, grad_in, grad_out</span>):</span></span><br><span class="line">        self.grads.append(grad_out[<span class="number">0</span>].detach())</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_hook</span>(<span class="params">self, module, <span class="built_in">input</span>, output</span>):</span></span><br><span class="line">        self.fmaps.append(output)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_loss</span>(<span class="params">self, logit, index=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> index:</span><br><span class="line">            index = np.argmax(logit.cpu().data.numpy())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = np.array(index)</span><br><span class="line"></span><br><span class="line">        index = index[np.newaxis, np.newaxis]</span><br><span class="line">        index = torch.from_numpy(index)</span><br><span class="line">        one_hot = torch.zeros(<span class="number">1</span>, <span class="number">1000</span>).scatter_(<span class="number">1</span>, index, <span class="number">1</span>)</span><br><span class="line">        one_hot.requires_grad = <span class="literal">True</span></span><br><span class="line">        loss = torch.<span class="built_in">sum</span>(one_hot * logit)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cam</span>(<span class="params">self, feature_map, grads</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        feature_map: np.array [C, H, W]</span></span><br><span class="line"><span class="string">        grads: np.array, [C, H, W]</span></span><br><span class="line"><span class="string">        return: np.array, [H, W]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        cam = np.zeros(feature_map.shape[<span class="number">1</span>:], dtype=np.float32)</span><br><span class="line">        alpha = np.mean(grads, axis=(<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># GAP</span></span><br><span class="line">        <span class="keyword">for</span> k, ak <span class="keyword">in</span> <span class="built_in">enumerate</span>(alpha):</span><br><span class="line">            cam += ak * feature_map[k]  <span class="comment"># linear combination</span></span><br><span class="line">        </span><br><span class="line">        cam = np.maximum(cam, <span class="number">0</span>)  <span class="comment"># relu</span></span><br><span class="line">        cam = cv2.resize(cam, self.size)</span><br><span class="line">        cam = (cam - np.<span class="built_in">min</span>(cam)) / np.<span class="built_in">max</span>(cam)</span><br><span class="line">        <span class="keyword">return</span> cam</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__show_cam_on_image</span>(<span class="params">self, img: np.ndarray, mask: np.ndarray, if_show=<span class="literal">True</span>, if_write=<span class="literal">False</span></span>):</span></span><br><span class="line">        heatmap = cv2.applyColorMap(np.uint8(<span class="number">255</span> * mask), cv2.COLORMAP_JET)</span><br><span class="line">        heatmap = np.float32(heatmap) / <span class="number">255</span></span><br><span class="line">        cam = heatmap + np.float32(img)</span><br><span class="line">        cam = cam / np.<span class="built_in">max</span>(cam)</span><br><span class="line">        cam = np.uint8(<span class="number">255</span> * cam)</span><br><span class="line">        <span class="keyword">if</span> if_write:</span><br><span class="line">            cv2.imwrite(<span class="string">&quot;camcam.jpg&quot;</span>, cam)</span><br><span class="line">        <span class="keyword">if</span> if_show:</span><br><span class="line">            <span class="comment"># 要显示RGB的图片，如果是BGR的 热力图是反过来的</span></span><br><span class="line">            plt.imshow(cam[:, :, ::-<span class="number">1</span>])</span><br><span class="line">            plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用函数</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;test.jpg&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">net = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">grad_cam = GradCAM(net, <span class="string">&#x27;layer4&#x27;</span>, (<span class="number">224</span>, <span class="number">224</span>), [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">grad_cam.forward(img, show=<span class="literal">True</span>, write=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cam/1.jpg" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Latex控制图片位置</title>
    <url>/2020/07/18/Latex%E6%8E%A7%E5%88%B6%E5%9B%BE%E7%89%87%E4%BD%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在LaTex中，\begin{figure}[~]是图片环境，常用选择项[htbp]是浮动格式：</p>
<ul>
<li>[h] ~ here，当前位置。将图形放置在正文文本中给出该图形环境的地方。如果本页所剩页面不够，这一参数将不起作用。</li>
<li>[t] ~ top，顶部。将图形放置在页面的顶部。</li>
<li>[b] ~ bottom，底部。将图形放置在页面的底部。</li>
<li>[p] ~ page of its own，浮动页。将图形放置在一个允许有浮动对象的页面上。</li>
</ul>
<p>一般使用[htb]这样的组合，只用[h]是没有用的。这样组合的意思就是LaTex会尽量满足排在前面的浮动格式，就是h-t-b这个顺序，让排版的效果尽量好。</p>
<p>[!h]只是试图放在当前位置。如果页面剩下的部分放不下，还是会跑到下一页的。一般而言，用[!h]选项通常会出现不能正确放置的问题，所以常用[ht]、[htbp]等。这里加感叹号的意思是忽略“美学”标准。</p>
<p>如果你确实需要把图片放在当前位置，不容改变，可以用 \usepackege{float} 宏包的[H]选项。不过如果这样做，出现放不下的问题时需要手工调整。使用格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;float&#125; </span><br><span class="line">% ... </span><br><span class="line">\begin&#123;figure&#125;[H] </span><br><span class="line">foo </span><br><span class="line">\end&#123;figure&#125;</span><br></pre></td></tr></table></figure>
<p><strong>特别强调，当图片或者表格占据双栏模板的两栏时（即在\begin{figure*} 或 \begin{table*} 时），这些控制选项就失效了。</strong></p>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>论文大多都是以双栏排版，那么在双栏排版中，如何让图片和表格出现在页面底端？上述[!b]等等的一些命令都是针对单栏排版，在双栏中不起作用。</p>
<p>这个问题是排版双栏图表过程中，较为常见的问题。通常，我们排版双栏文章的时候，有些图比较宽，需要让图或者表格跨栏排版，这时我们会用到如下两个环境：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table*&#125;[ht]</span><br><span class="line"> </span><br><span class="line">\end&#123;table*&#125;</span><br></pre></td></tr></table></figure>
<p>和</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;figure*&#125;[ht]</span><br><span class="line">…</span><br><span class="line">\end&#123;figure*&#125;</span><br></pre></td></tr></table></figure>
<p>通常这样的跨栏图会放到页面的顶部。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>若是我们想让图表放置到页面底部的话，可以这样做，在导言区加入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\usepackage&#123;stfloats&#125;</span><br></pre></td></tr></table></figure>
<p>插图的话使用如下环境：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;figure*&#125;[bp]</span><br><span class="line">…</span><br><span class="line">\end&#123;figure*&#125;</span><br></pre></td></tr></table></figure>
<p>表格类似使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\begin&#123;table*&#125;[bp]</span><br><span class="line">…</span><br><span class="line">\end&#123;table*&#125;</span><br></pre></td></tr></table></figure>
<p>【示例代码】：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\documentclass[twocolumn]&#123;book&#125;</span><br><span class="line">\usepackage&#123;graphicx&#125;</span><br><span class="line">\usepackage&#123;xcolor,stfloats&#125;</span><br><span class="line">\usepackage&#123;lipsum&#125;%生成随机文本</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\lipsum</span><br><span class="line">\lipsum[2-5]</span><br><span class="line">\begin&#123;figure*&#125;[b]</span><br><span class="line">\centering</span><br><span class="line">\includegraphics[width=12cm]&#123;image&#125;</span><br><span class="line">\end&#123;figure*&#125;</span><br><span class="line">\lipsum[2-5]</span><br><span class="line">\lipsum</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>Perceptual Generative Adversarial Networks for Small Object Detection</title>
    <url>/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/</url>
    <content><![CDATA[<h2 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h2><ul>
<li>小目标检测的一个常用思路是提升图片输入分辨率，来增强小目标的分辨率和生成高分辨率的特征图，但这会导致训练和验证极度费时。</li>
<li>本文提出的PGAN方法对小目标生成高分辨率特征表示，使小目标的特征表示与大目标特征表示类似。</li>
<li>生成器网络通过较前层提取细粒度特征将小目标分辨率较低的特征转换为分辨率较高的特征。</li>
<li>判别器网络不仅用于生成小目标高分辨表示，同时证明带感知损失的生成高分辨率特征对检测准确率是有帮助的。</li>
<li>生成器网络被训练欺骗辨别器通过产生最像大目标表征的小目标，同时提升检测准确率。</li>
<li>辨别器被训练用于提升正确从实际大目标中分辨出生成的高分辨率表征，同时将定位准确率反馈给生成器。</li>
<li>小目标检测典型应用领域：交通标志检测、行人检测</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/PGAN/11659928-8837870deae1ed8d.png" alt></p>
<p>perception branch（感知分支）首先利用仅包含大目标的图片进行训练，然后利用仅包含小目标的图片进行训练，generator network 被训练用于对小目标生成高分辨率的类似大目标的表征。adversarial branch被训练用于区分生成的小目标高分辨率表征与实际大目标的原始表征。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/PGAN/11659928-0359caab80a4ee3a.png" alt></p>
<p>generator 从底层提取细粒度特征，放入深度残差网络，通过element-wise加和操作，将深度残差网络学习到的残差特征与conv5学习到的特征结合，得到高分辨率特征图；discriminator将大目标和小目标的高分辨特征作为输入，adversarial分支用于判断输入相片属于真的大目标的概率值，perception分支用于分类和边界框回归，验证从生成高分辨率特征获得的检测准确率提升。</p>
<p><strong>损失函数</strong></p>
<p>$F_{l}$和 $F_{s}$代表大目标和小目标特征，$G$和$D$代表生成器和判别器，$\Theta_{g}$和$\Theta_{a}$代表生成器和判别器的网络参数</p>
<ul>
<li><p>生成器<br>$\Theta_{g}=\arg \min _{\Theta_{g}} L_{d i s}\left(G_{\Theta_{g}}\left(F_{s}\right)\right)$<br>$L_{d i s}$是判别器网络产生的对抗性损失$L_{d i s_{-} a}$和感知损失$L_{d i s_ p}$的加权组合<br>$L_{d i s}=w_{1} \times L_{d i s_{-} a}+w_{2} \times L_{d i s_{p}}$（作者设w1和w2为1）</p>
<ul>
<li><p>对抗性损失<br>$L_{d i s_{-}a}=-\log D_{\Theta_{a}}\left(G_{\Theta_{g}}\left(F_{s}\right)\right)$（使$D_{\Theta_{a}}\left(G_{ \Theta_{g}}\left(F_{s}\right)\right)$尽可能大）</p>
</li>
<li><p>感知损失</p>
<p>$L_{d i s_{-p}}=L_{c l s}(p, g)+1[g \geq 1] L_{l o c}\left(r_{g}, r^{*}\right)$</p>
<p>$L_{c l s}$和$L_{l o c}$是分类和边界框回归的损失</p>
<p>感知分支输出K + 1个类别的类别级别置信度$p=\left(p_{0}, \dots, p_{k}\right)$，对于每个K对象类，边界框回归偏移$r_{k} = \left(r_{x}^{k}, r_{y}^{k}, r_{w}^{k}, r_{h}^{k}\right)$，真实类别为$g$，真实边界框回归目标$r^{*}$</p>
</li>
</ul>
</li>
<li><p>判别器网络的对抗分支：<br>$\Theta_{a}=\arg \min _{\Theta_{a}} L_{a}\left(G_{\Theta_{g}}\left(F_{s}\right), F_{l}\right)$<br>$L_{a}=-\log D_{\Theta_{a}}\left(F_{l}\right)-\log \left(1-D_{\Theta_{a}}\left(G_{\Theta_{g}}\left(F_{s}\right)\right)\right)$<br>区分当前生成的小对象超分辨表示和原始对象与真实大对象之间的差异。 即使$D_{\Theta_{a}}$尽可能大，$D _{\Theta_{a}}\left(G _{Theta_{g}}\left(F_{s}\right)\right)$尽可能小。</p>
</li>
</ul>
<p><strong>联合对抗损失 </strong><br>$\begin{array}{rl}{\min _{G} \max _{D}} &amp; {L(D, G) \triangleq \mathbb{E}_{F_{l} \sim p_{ \text {data(F }\left._{l}\right)}} \log D\left(F_{l}\right)} \\ {} &amp; {+\mathbb{E}_{F_{s} \sim p_{F_{s}}}\left(F_{s} | f\right)[\log (1-D(\underbrace{F_{s}+G\left(F_{s} | f\right)}_{\text {residual learning }}))]}\end{array}$</p>
<p>即G的目标是使它最小，D的目标使它最大，由于$F_{s}$中包含的信息有限。因此，引入了一个新的条件生成器模型，该模型以额外的辅助信息为条件，即小对象$f$的低级特征，生成器从中通过残差学习在大对象和小对象表示之间生成残差表示。</p>
<p>个人理解：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/PGAN/1.png" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>NMS后处理相关</title>
    <url>/2020/03/03/NMS%E5%90%8E%E5%A4%84%E7%90%86%E7%9B%B8%E5%85%B3/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>非极大值抑制(Non-Maximum  Suppression，NMS)，顾名思义就是抑制不是极大值的元素。在目标检测任务，例如行人检测中，滑动窗口经过特征提取和分类器识别后，每个窗口都会得到一个分数。但滑动窗口会导致很多窗口和其它窗口存在包含大部分交叉的情况。这个时候就需要用到NMS来选取那些邻域里分数最高，同时抑制那些分数低的窗口。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>在目标检测任务中，定义最后的候选框集合为$B$，每个候选框对应的置信度是$S$，IOU阈值设为$T$，然后NMS的算法过程可以表示如下：</p>
<ul>
<li><p>选择具有最大score的候选框$M$</p>
</li>
<li><p>将$M$从集合$B$中移除并加入到最终的检测结果$D$中</p>
</li>
<li><p>将$B$中剩余检测框中和$M$的交并比(IOU)大于阈值$T$的框从$B$中移除</p>
</li>
<li><p>重复上面的步骤，直到$B$为空</p>
</li>
</ul>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>rgb大神实现Faster-RCNN中的单类别物体nms代码解释如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> --------------------------------------------------------</span><br><span class="line"><span class="comment"># Fast R-CNN</span></span><br><span class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Ross Girshick</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_cpu_nms</span>(<span class="params">dets, thresh</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#x1、y1、x2、y2、以及score赋值</span></span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    x2 = dets[:, <span class="number">2</span>]</span><br><span class="line">    y2 = dets[:, <span class="number">3</span>]</span><br><span class="line">    scores = dets[:, <span class="number">4</span>]</span><br><span class="line">	<span class="comment">#每一个检测框的面积</span></span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">    <span class="comment">#按照score置信度降序排序</span></span><br><span class="line">    order = scores.argsort()[::-<span class="number">1</span>]</span><br><span class="line">    <span class="comment">#保留的结果框集合</span></span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        i = order[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#保留该类剩余box中得分最高的一个</span></span><br><span class="line">        keep.append(i)</span><br><span class="line">        <span class="comment"># 得到相交区域,左上及右下</span></span><br><span class="line">        xx1 = np.maximum(x1[i], x1[order[<span class="number">1</span>:]])</span><br><span class="line">        yy1 = np.maximum(y1[i], y1[order[<span class="number">1</span>:]])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[order[<span class="number">1</span>:]])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[order[<span class="number">1</span>:]])</span><br><span class="line">	    <span class="comment">#计算相交的面积,不重叠时面积为0</span></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        inter = w * h</span><br><span class="line">        <span class="comment">#计算IoU：重叠面积 /（面积1+面积2-重叠面积）</span></span><br><span class="line">        ovr = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter)</span><br><span class="line">		<span class="comment"># 保留IoU小于阈值的box</span></span><br><span class="line">        inds = np.where(ovr &lt;= thresh)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 因为ovr数组的长度比order数组少一个,所以这里要将所有下标后移一位</span></span><br><span class="line">        order = order[inds + <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> keep</span><br></pre></td></tr></table></figure>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/nms/640.webp" alt></p>
<h2 id="Soft-NMS"><a href="#Soft-NMS" class="headerlink" title="Soft-NMS"></a>Soft-NMS</h2><p>上面说的NMS算法有一个缺点就是当两个候选框的重叠度很高时，NMS会将具有较低置信度的框去掉，也就是将其置信度变成0，如下图所示，红色框和绿色框是当前的检测结果，二者的得分分别是0.95和0.80。如果按照传统的NMS进行处理，首先选中得分最高的红色框，然后绿色框就会因为与之重叠面积过大而被删掉。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/nms/641.webp" alt></p>
<p>因此为了改善这个缺点，Soft-NMS被提出，核心思路就是不要粗鲁地删除所有IOU大于阈值的框，而是降低其置信度。这个方法的论文地址为：<a href="https://arxiv.org/pdf/1704.04503.pdf">https://arxiv.org/pdf/1704.04503.pdf</a> 。算法伪代码如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/nms/642.jpg" alt></p>
<p>正如作者所说，改一行代码就OK了。这里的$f$函数可以是线性函数，也可以是高斯函数。我们来对比一下：</p>
<ul>
<li><p>线性函数：</p>
<script type="math/tex; mode=display">
s_{i}=\left\{\begin{array}{ll}s_{i}, & \text { iou }\left(\mathcal{M}, b_{i}\right)<N_{t} \\ s_{i}\left(1-\mathrm{i} o \mathrm{u}\left(\mathcal{M}, b_{i}\right)\right), & \text { iou }\left(\mathcal{M}, b_{i}\right) \geq N_{t}\end{array}\right.</script></li>
<li><p>高斯函数：</p>
<script type="math/tex; mode=display">
\boldsymbol{s}_{i}=\boldsymbol{s}_{i} e^{\frac{-\mathrm{iou}\left(\mathcal{M}, \boldsymbol{b}_{i}\right)^{2}}{\sigma}}, \forall b_{i} \notin \mathcal{D}</script></li>
</ul>
<h2 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h2><p>作者的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_soft_nms</span>(<span class="params">np.ndarray[<span class="built_in">float</span>, ndim=<span class="number">2</span>] boxes, <span class="built_in">float</span> sigma=<span class="number">0.5</span>, <span class="built_in">float</span> Nt=<span class="number">0.3</span>, <span class="built_in">float</span> threshold=<span class="number">0.001</span>, unsigned <span class="built_in">int</span> method=<span class="number">0</span></span>):</span></span><br><span class="line">    cdef unsigned <span class="built_in">int</span> N = boxes.shape[<span class="number">0</span>]</span><br><span class="line">    cdef <span class="built_in">float</span> iw, ih, box_area</span><br><span class="line">    cdef <span class="built_in">float</span> ua</span><br><span class="line">    cdef <span class="built_in">int</span> pos = <span class="number">0</span></span><br><span class="line">    cdef <span class="built_in">float</span> maxscore = <span class="number">0</span></span><br><span class="line">    cdef <span class="built_in">int</span> maxpos = <span class="number">0</span></span><br><span class="line">    cdef <span class="built_in">float</span> x1,x2,y1,y2,tx1,tx2,ty1,ty2,ts,area,weight,ov</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        maxscore = boxes[i, <span class="number">4</span>]</span><br><span class="line">        maxpos = i</span><br><span class="line"></span><br><span class="line">        tx1 = boxes[i,<span class="number">0</span>]</span><br><span class="line">        ty1 = boxes[i,<span class="number">1</span>]</span><br><span class="line">        tx2 = boxes[i,<span class="number">2</span>]</span><br><span class="line">        ty2 = boxes[i,<span class="number">3</span>]</span><br><span class="line">        ts = boxes[i,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">    <span class="comment"># get max box</span></span><br><span class="line">        <span class="keyword">while</span> pos &lt; N:</span><br><span class="line">            <span class="keyword">if</span> maxscore &lt; boxes[pos, <span class="number">4</span>]:</span><br><span class="line">                maxscore = boxes[pos, <span class="number">4</span>]</span><br><span class="line">                maxpos = pos</span><br><span class="line">            pos = pos + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add max box as a detection</span></span><br><span class="line">        boxes[i,<span class="number">0</span>] = boxes[maxpos,<span class="number">0</span>]</span><br><span class="line">        boxes[i,<span class="number">1</span>] = boxes[maxpos,<span class="number">1</span>]</span><br><span class="line">        boxes[i,<span class="number">2</span>] = boxes[maxpos,<span class="number">2</span>]</span><br><span class="line">        boxes[i,<span class="number">3</span>] = boxes[maxpos,<span class="number">3</span>]</span><br><span class="line">        boxes[i,<span class="number">4</span>] = boxes[maxpos,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># swap ith box with position of max box</span></span><br><span class="line">        boxes[maxpos,<span class="number">0</span>] = tx1</span><br><span class="line">        boxes[maxpos,<span class="number">1</span>] = ty1</span><br><span class="line">        boxes[maxpos,<span class="number">2</span>] = tx2</span><br><span class="line">        boxes[maxpos,<span class="number">3</span>] = ty2</span><br><span class="line">        boxes[maxpos,<span class="number">4</span>] = ts</span><br><span class="line"></span><br><span class="line">        tx1 = boxes[i,<span class="number">0</span>]</span><br><span class="line">        ty1 = boxes[i,<span class="number">1</span>]</span><br><span class="line">        tx2 = boxes[i,<span class="number">2</span>]</span><br><span class="line">        ty2 = boxes[i,<span class="number">3</span>]</span><br><span class="line">        ts = boxes[i,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">    <span class="comment"># NMS iterations, note that N changes if detection boxes fall below threshold</span></span><br><span class="line">        <span class="keyword">while</span> pos &lt; N:</span><br><span class="line">            x1 = boxes[pos, <span class="number">0</span>]</span><br><span class="line">            y1 = boxes[pos, <span class="number">1</span>]</span><br><span class="line">            x2 = boxes[pos, <span class="number">2</span>]</span><br><span class="line">            y2 = boxes[pos, <span class="number">3</span>]</span><br><span class="line">            s = boxes[pos, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">            area = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">            iw = (<span class="built_in">min</span>(tx2, x2) - <span class="built_in">max</span>(tx1, x1) + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> iw &gt; <span class="number">0</span>:</span><br><span class="line">                ih = (<span class="built_in">min</span>(ty2, y2) - <span class="built_in">max</span>(ty1, y1) + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> ih &gt; <span class="number">0</span>:</span><br><span class="line">                    ua = <span class="built_in">float</span>((tx2 - tx1 + <span class="number">1</span>) * (ty2 - ty1 + <span class="number">1</span>) + area - iw * ih)</span><br><span class="line">                    ov = iw * ih / ua <span class="comment">#iou between max box and detection box</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> method == <span class="number">1</span>: <span class="comment"># linear</span></span><br><span class="line">                        <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">                            weight = <span class="number">1</span> - ov</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            weight = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> method == <span class="number">2</span>: <span class="comment"># gaussian</span></span><br><span class="line">                        weight = np.exp(-(ov * ov)/sigma)</span><br><span class="line">                    <span class="keyword">else</span>: <span class="comment"># original NMS</span></span><br><span class="line">                        <span class="keyword">if</span> ov &gt; Nt:</span><br><span class="line">                            weight = <span class="number">0</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            weight = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    boxes[pos, <span class="number">4</span>] = weight*boxes[pos, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if box score falls below threshold, discard the box by swapping with last box</span></span><br><span class="line">            <span class="comment"># update N</span></span><br><span class="line">                    <span class="keyword">if</span> boxes[pos, <span class="number">4</span>] &lt; threshold:</span><br><span class="line">                        boxes[pos,<span class="number">0</span>] = boxes[N-<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">                        boxes[pos,<span class="number">1</span>] = boxes[N-<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">                        boxes[pos,<span class="number">2</span>] = boxes[N-<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">                        boxes[pos,<span class="number">3</span>] = boxes[N-<span class="number">1</span>, <span class="number">3</span>]</span><br><span class="line">                        boxes[pos,<span class="number">4</span>] = boxes[N-<span class="number">1</span>, <span class="number">4</span>]</span><br><span class="line">                        N = N - <span class="number">1</span></span><br><span class="line">                        pos = pos - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            pos = pos + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    keep = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N)]</span><br><span class="line">    <span class="keyword">return</span> keep</span><br></pre></td></tr></table></figure>
<h2 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/nms/643.webp" alt></p>
<p>左边是使用了NMS的效果，右边是使用了Soft-NMS的效果</p>
<h2 id="论文的实验结果"><a href="#论文的实验结果" class="headerlink" title="论文的实验结果"></a>论文的实验结果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/nms/644.jpg" alt></p>
<p>可以看到在MS-COCO数据集上mAP[0.5:0.95]可以获得大约1%的提升，如果应用到训练阶段的proposal选取过程理论上也能获得提升。顺便说一句，soft-NMS在不是基于Proposal的方法如SSD，YOLO中没什么提升。这里猜测原因可能是因为YOLO和SSD产生的框重叠率较低引起的。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Permmision denied解决方法</title>
    <url>/2019/12/21/Permmision%20denied%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>这是因为要管理员权限的，而ubuntu又不想给普通用户赋予管理员权限。所以这里开启root账号</p>
<h2 id="首先设置-root-密码"><a href="#首先设置-root-密码" class="headerlink" title="首先设置 root 密码"></a>首先设置 root 密码</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo passwd</span><br></pre></td></tr></table></figure>
<p>会出现以下画面：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[sudo] password for luban:                        //输入当前普通用户的密码</span><br><span class="line"></span><br><span class="line">Enter new UNIX password:                          //给root设置密码</span><br><span class="line"></span><br><span class="line">Retype new UNIX password:                         //确认输入密码</span><br><span class="line"></span><br><span class="line">passwd: password updated successfully</span><br></pre></td></tr></table></figure></p>
<h2 id="开启root"><a href="#开启root" class="headerlink" title="开启root"></a>开启root</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su root</span><br></pre></td></tr></table></figure>
<h2 id="修改文件权限"><a href="#修改文件权限" class="headerlink" title="修改文件权限"></a>修改文件权限</h2><p>为了获得执行权限，借助chmod指令修改文件权限即可。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod 777 文件夹或文件路径</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>NIPS 2016 R-FCN（来自微软何凯明团队）</title>
    <url>/2020/03/05/NIPS-2016-R-FCN%EF%BC%88%E6%9D%A5%E8%87%AA%E5%BE%AE%E8%BD%AF%E4%BD%95%E5%87%AF%E6%98%8E%E5%9B%A2%E9%98%9F%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>R-FCN全称为Region-based Fully Convolutional Networks，是由微软的何凯明团队在NIPS 2016上提出来的，仍然是双阶段的目标检检测算法。论文地址和官方开源代码见文后。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>R-FCN论文的发表时间比YOLO,SSD出来的都晚一些，并且这个算法更像是针对Faster-RCNN的一种改进，并且扔属于two-stage算法。那个R-FCN具体要解决什么问题呢？我们不妨先来看看R-FCN之前的典型的two-stage算法分别是在解决什么？</p>
<ul>
<li>rcnn证明cnn具有良好的特征提取能力，也是第一个将cnn用来做目标检测任务的算法。</li>
<li>fast-rcnn提出ROI-Pooling将需要应用到多个候选框的骨干CNN网络进行共享，加快速度的同时也提升了准确率。</li>
<li>faster-rcnn解决了候选框搜索耗时过多的问题，提出RPN全卷积网络用于学习提取候选框，速度更快且精度更高。</li>
</ul>
<p>而Faster-RCNN的一个缺点在于在ROI Pooling之后全是全连接层，从而将ROI  Pooling之后的特征图映射为分类和回归两个任务。而越来越多的基础CNN架构如GoogleNet，ResNet等全卷积网络证明不要全连接层，网络的效果不仅会更好并且还可以适应不同尺度的输入图片。因为着眼于Faster-RCNN的全连接层负载很重这一痛点，R-FCN出世了。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>R-FCN中主要有2个重要的点，第一个是将ROI Pooling后面的全连接层都用卷积层所代替，第二个是对ROI Pooling的魔改。</p>
<h2 id="R-FCN整体结构"><a href="#R-FCN整体结构" class="headerlink" title="R-FCN整体结构"></a>R-FCN整体结构</h2><p>我们知道，对于Faster-RCNN是会对每一个候选框区域执行ROI  Pooling操作之后单独跑后面的分类和回归分支的。实际上是分成了几个subnetwork，第一个用来在整张图上做比较耗时的conv，这些操作与region无关，是计算共享的。第二个subnetwork是用来产生候选的boundingbox（如RPN），第三个subnetwork用来分类或进一步对box进行regression（如Fast RCNN），这个subnetwork和region是有关系的，必须每个region单独跑网络，衔接在这个subnetwork和前两个subnetwork中间的就是ROI pooling。我们希望的是，耗时的卷积都尽量移到前面共享的subnetwork上。因此R-FCN希望耗时的卷积都尽量移动到前面共享的网络中。基于此，和Faster-RCNN用ResNet做Backbone的处理方式不同(前面<code>91</code>层共享，然后插入<code>ROIPooling</code>，后面<code>10</code>层不共享)，R-FCN把所有的<code>101</code>层都设置为共享网络，最后用来做预测的只有一个卷积层，大大减少了计算量。这一点参见Table1。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/640.webp" alt></p>
<p>R-FCN可以分成以下四个部分：</p>
<ul>
<li>Backbone网络，如ResNet101网络。</li>
<li>一个区域建议网络(RPN)。</li>
<li>一个正例敏感的预测层。</li>
<li>最后的ROI Pooling+投票的决策层。</li>
</ul>
<p>R-FCN的网络结构图如下所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/641.jpg" alt></p>
<p>可以看到整体结构和Faster-RCNN比较像，都有RPN网络来训练生成候选框，而ROI Pooling是不一样的，接下来就仔细讲讲。</p>
<h2 id="R-FCN的ROIPooling"><a href="#R-FCN的ROIPooling" class="headerlink" title="R-FCN的ROIPooling"></a>R-FCN的ROIPooling</h2><p>我们省略一下R-FCN和Faster-RCNN网络结构完全相同的部分，着眼于R-FCN的变化之处即ROIPooling，关键部分如论文中的Figure1所示。我们接下来就针对这张图来仔细分析。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/642.webp" alt></p>
<ul>
<li><strong>Backbone architecture</strong>: ResNet 101—去掉原始ResNet101的最后一层全连接层，保留前100层，再接一个1 x 1 x 1024的全卷积层（100层输出是2048，为了降维，再引入了一个1 x 1的卷积层）。</li>
<li><strong>$k^{2} \times(C+1)$的conv</strong>: ResNet101的输出是W x H x 1024，用$k^{2} \times(C+1)$个1024 x 1 x 1的卷积核去卷积即可得到$k^{2} \times(C+1)$个大小为W x H的position sensitive的score map。这步的卷积操作就是在做prediction。k = 3，表示把一个ROI划分成3 x 3，对应的9个位置分别是：上左（左上角），上中，上右，中左，中中，中右，下左，下中，下右（右下角）</li>
<li><strong>$k^{2} \times(C+1)$个feature map的物理意义</strong>: 共有k x k = 9个颜色，每个颜色的立体块（W x H x (C+1)）表示的是不同位置存在目标的概率值（第一块黄色表示的是左上角位置，最后一块淡蓝色表示的是右下角位置）。共有$k^{2} \times(C+1)$个feature map。每个feature map，z(i,j,c)是第i+k(j-1)个立体块上的第c个map（1&lt;= i,j &lt;=3）。(i,j)决定了9种位置的某一种位置，假设为左上角位置（i=j=1），c决定了哪一类，假设为person类。在z(i,j,c)这个feature map上的某一个像素的位置是（x,y），像素值是value，则value表示的是原图对应的(x,y)这个位置上可能是人（c=‘person’）且是人的左上部位（i=j=1）的概率值。</li>
<li><strong>ROI pooling</strong>: 就是faster RCNN中的ROI pooling，也就是一层的SPP结构。主要用来将不同大小的ROI对应的feature map映射成同样维度的特征，思路是不论对多大的ROI，规定在上面画一个n x n 个bin的网格，每个网格里的所有像素值做一个pooling（平均），这样不论图像多大，pooling后的ROI特征维度都是n x n。注意一点ROI pooling是每个feature map单独做，不是多个channel一起的。</li>
<li><strong>vote投票</strong>：k x k个bin直接进行求和（每个类单独做）得到每一类的score，并进行softmax得到每类的最终得分，并用于计算损失</li>
</ul>
<p>可以看到原始图像经过Backbone的卷积神经网络之后得到了最后一层特征图，接下来就应该是提取当前特征图的ROI区域了。这个地方ROIPooling不像Faster-RCNN那样直接提取，而是重新设计了一个位置敏感的ROIPooling：将Faster-RCNN中的ROI划分成k x k大小，即是说将ROI区域分成k x k个小区域（论文中取k = 3，即将ROI区域分成9个部分）。然后假设目标检测数据集的目标类别一共有C类，同时加上一个背景类就是C + 1类，最后我们希望网络对每个类别都有各自的位置响应。因此最后ROIPooling层的特征维度是$k^{2} \times(C+1)$代表每一个类别在某个位置(一共9个)的位置敏感度map，其中每个map的大小和ROIPooling前面那个Backbone网络得到的特征图尺寸完全一致。</p>
<p>那么具体是如何从位置敏感<code>map</code>得到最后那个C + 1个通道，并且尺寸为k x k的特征图呢？如下所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/643.jpg" alt></p>
<p>Figure3展示了在人这<strong>一类</strong>目标上是如何从位置敏感map得到最后输出图，这里k = 3，那么位置敏感<code>map</code>可以用下面的表格来表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/644.webp" alt></p>
<p>其中$\operatorname{Pos}_{x}^{y}$代表位置为$x$（即图中的<code>左上</code>，<code>中上</code>，<code>右下</code>，<code>左中</code>，<code>中间</code>，<code>右中</code>，<code>左下</code>，<code>中下</code>，<code>右下</code>9个位置）对应的类别集合为$y$的位置敏感<code>map</code>，每个表格的内容对应位置敏感<code>map</code>中一种颜色的部分特征图(C + 1个通道)，位置敏感<code>map</code>每个C + 1通道分别从上到下，从左到右对应了上面的表格。这里假设Figure3中的Person类对应的是第一个分类，那么Figure3的处理过程就是对下表对应的特征图进行操作：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/645.webp" alt></p>
<p>具体的操作流程表示为：</p>
<ul>
<li><p>1、抽取特定类别(这里为人这个类别)对应的$k \times k=3 \times 3=9$个位置的特征图，如Figure3中部所示。</p>
</li>
<li><p>2、对抽取出来的部分进行求均值，然后按照位置组成一个$k \times k=3 \times 3$大小的矩阵。</p>
</li>
<li><p>3、对这个$k \times k$大小的矩阵求和，得到一个值。</p>
</li>
<li><p>4、对其他每个类别都执行1-3步骤，最终得到一个$1 \times(C+1)$的向量。将这个向量进行<code>softmax</code>，从而判别特征图上的这个ROI区域对应的目标类别是什么。</p>
</li>
</ul>
<h2 id="R-FCN的目标框回归"><a href="#R-FCN的目标框回归" class="headerlink" title="R-FCN的目标框回归"></a><strong>R-FCN的目标框回归</strong></h2><p>上面详细讲解了R-FCN提出的ROIPooling的改进之处以及对于目标分类的处理方法，不要忘记目标检测还有一个框回归的过程，所以这里来说一下如何微调ROI区域使得框更加精确，这部分和分类实际上是类似的。我们知道位置敏感<code>map</code>是有$k^{2}(C+1)$个通道的，我们依然从Backbone的最后一个特征层部分接触一个有$4 \times k^{2}$个通道的特征图(和位置敏感map并列)，用来做ROI框回归，如下面的表格所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/646.webp" alt></p>
<p>然后执行和分类一样的步骤得到一个1 x 4的向量即代表ROI区域的$x, y, w, h$。计算损失函数和前面Faster-RCNN的一致，均为多任务损失联合训练，分类使用交叉熵，定位使用L1-smooth损失函数。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><ul>
<li><p>训练的样本选择策略：使用OHEM策略，原理就是对样本按loss进行排序，选择前面loss较小的，这个策略主要用来对负样本进行筛选，使得正负样本更加平衡。</p>
</li>
<li><p>训练细节：</p>
<ul>
<li>SGD+带动量的优化方式，其中动量momentum = 0.9。</li>
<li>权重惩罚为0.0005。</li>
<li>单尺度训练，将图片$\min (\text {height}, \text {width})$设置为600。</li>
<li>8块GPU，每一块GPU训练一张图片并且随机选择128个ROI区域进行梯度下降。</li>
<li>在前20k次迭代，学习率为0.001，后面10k次迭代为0.0001。</li>
<li>使用和Faster-RCNN中一致的训练方式。</li>
<li>使用<code>atrous</code>（hole）算法。增加感受野的同时降低下采样次数。并且使用了这一策略在VOC 2007上可以提升2个点的map。</li>
</ul>
</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/647.webp" alt></p>
<p>可以看到R-FCN在没有OHEM的策略下精度完全吊打了Faster-RCNN，其中<code>fail</code>表示的应该是当k = 1的时候应该是模型无法收敛。</p>
<h3 id="在PASCAL-VOC数据集上的测试结果"><a href="#在PASCAL-VOC数据集上的测试结果" class="headerlink" title="在PASCAL VOC数据集上的测试结果"></a>在PASCAL VOC数据集上的测试结果</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/648.jpg" alt></p>
<p>可以看到R-FCN使用ResNet101做特征提取网络，最终在VOC的测试集上获得了83.6%的map值，并且相比于Faster-RCNN测试时间加速了2倍以上。论文还给出了一些消融研究：</p>
<ul>
<li><p>深度影响对比，可以看出ResNet-101表现最好。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/649.png" alt></p>
</li>
<li><p>候选区域选择算法对比：RPN比SS，EB好。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/650.png" alt></p>
</li>
</ul>
<h3 id="在MS-COCO数据集的测试结果"><a href="#在MS-COCO数据集的测试结果" class="headerlink" title="在MS COCO数据集的测试结果"></a>在MS COCO数据集的测试结果</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/651.png" alt></p>
<h2 id="可视化效果展示"><a href="#可视化效果展示" class="headerlink" title="可视化效果展示"></a>可视化效果展示</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/R-FCN/652.webp" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>R-FCN在Faster-RCNN的基础上致力于解决全连接网络做分类和回归速度过慢的问题，将分类和回归分支换成了全卷积网络，并提出了一个位置敏感ROIPooling用于指定不同特征图是负责检测目标的不同位置，然后ROIPooling之后把不同位置得到的特征图进行组合就能复现原来的位置信息。不仅在精度上大幅度超越Faster-RCNN，并且速度是Faster-RCNN的2倍以上。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>论文原文：<a href="https://arxiv.org/pdf/1605.06409v2.pdf">https://arxiv.org/pdf/1605.06409v2.pdf</a></p>
<p>官方源码复现：<a href="https://github.com/daijifeng001/r-fcn">https://github.com/daijifeng001/r-fcn</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Potplayer添加直播源</title>
    <url>/2020/06/13/Potplayer%E6%B7%BB%E5%8A%A0%E7%9B%B4%E6%92%AD%E6%BA%90/</url>
    <content><![CDATA[<p>具体操作先打开 PotPlayer，右键选择 <strong>打开</strong> -&gt; <strong>打开链接</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/player/640.webp" alt></p>
<p>接下来复制<strong>直播源到 Potplayer 里</strong>，点击确定</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/player/641.webp" alt></p>
<p><strong>这里成功添加了1015个中国区域的电视频道，而且清晰度都在1080P</strong>，不仅有央视，还有所有卫视和一些地方台</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/player/642.webp" alt></p>
<p>直播源可以在Github上找到，这里放出链接 <a href="https://github.com/iptv-org/iptv/blob/master/README.md">点此跳转</a></p>
<p>里面名叫iptv的仓库收集了全世界将近100个国家的频道，总计达到8000多。并按类别，语言和国家进行了分类。这里图中只展示了一小部分。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/player/643.webp" alt></p>
<p>比如中国对应的是：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/player/644.webp" alt></p>
<p>除此以外，还有日本，美国，英国等，需要的可以自行寻找添加。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>potplayer</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch卷积与BatchNorm的融合</title>
    <url>/2022/01/18/PyTorch%E5%8D%B7%E7%A7%AF%E4%B8%8EBatchNorm%E7%9A%84%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>卷积的工作：</p>
<script type="math/tex; mode=display">z=w * x+b</script><p>BN的工作：</p>
<script type="math/tex; mode=display">y=\gamma \frac{z-\mu}{\sqrt{\sigma^{2}+\epsilon}}+\beta</script><p>把卷积带入BN：</p>
<script type="math/tex; mode=display">y=\gamma \frac{w * x+b-\mu}{\sqrt{\sigma^{2}+\epsilon}}+\beta</script><p>融合后的新卷积：</p>
<script type="math/tex; mode=display">w^{\prime}=\gamma \frac{w}{\sqrt{\sigma^{2}+\epsilon}}</script><script type="math/tex; mode=display">b^{\prime}=\gamma \frac{b-\mu}{\sqrt{\sigma^{2}+\epsilon}}+\beta</script><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> cuda</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br><span class="line">torch.cuda.manual_seed(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原样返回，占位用的，免得报错</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DummyModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(DummyModule, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 核心函数，把conv和bn进行融合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fuse</span>(<span class="params">conv, bn</span>):</span></span><br><span class="line">    w = conv.weight</span><br><span class="line">    mean = bn.running_mean</span><br><span class="line">    var_sqrt = torch.sqrt(bn.running_var + bn.eps)</span><br><span class="line"></span><br><span class="line">    beta = bn.weight</span><br><span class="line">    gamma = bn.bias</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> conv.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        b = conv.bias</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        b = mean.new_zeros(mean.shape)</span><br><span class="line"></span><br><span class="line">    w = w * (beta / var_sqrt).reshape([conv.out_channels, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    b = (b - mean)/var_sqrt * beta + gamma</span><br><span class="line"></span><br><span class="line">    fused_conv = nn.Conv2d(</span><br><span class="line">        conv.in_channels,</span><br><span class="line">        conv.out_channels,</span><br><span class="line">        conv.kernel_size,</span><br><span class="line">        conv.stride,</span><br><span class="line">        conv.padding,</span><br><span class="line">        conv.dilation,</span><br><span class="line">        conv.groups,</span><br><span class="line">        bias=<span class="literal">True</span>,</span><br><span class="line">        padding_mode=conv.padding_mode</span><br><span class="line">    )</span><br><span class="line">    fused_conv.weight = nn.Parameter(w)</span><br><span class="line">    fused_conv.bias = nn.Parameter(b)</span><br><span class="line">    <span class="keyword">return</span> fused_conv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对整个网络的bn进行融合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fuse_module</span>(<span class="params">m</span>):</span></span><br><span class="line">    children = <span class="built_in">list</span>(m.named_children())</span><br><span class="line">    conv = <span class="literal">None</span></span><br><span class="line">    conv_name = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 遍历整个网路的层</span></span><br><span class="line">    <span class="keyword">for</span> name, child <span class="keyword">in</span> children:</span><br><span class="line">        <span class="comment"># 如果该层为bn且上一层为conv，则融合</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(child, nn.BatchNorm2d) <span class="keyword">and</span> conv:</span><br><span class="line">            bc = fuse(conv, child)</span><br><span class="line">            m._modules[conv_name] = bc</span><br><span class="line">            m._modules[name] = DummyModule()</span><br><span class="line">            conv = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># 如果该层为conv，记录该层</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(child, nn.Conv2d):</span><br><span class="line">            conv = child</span><br><span class="line">            conv_name = name</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 递归</span></span><br><span class="line">            fuse_module(child)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证融合后网络与原网络的差异</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">validate</span>(<span class="params">net, cuda=torch.cuda.is_available(<span class="params"></span>)</span>):</span></span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    fused_net = deepcopy(net)</span><br><span class="line">    fused_net.<span class="built_in">eval</span>()</span><br><span class="line">    fuse_module(fused_net)</span><br><span class="line"></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    origin_time = <span class="number">0</span></span><br><span class="line">    fused_time = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cuda:</span><br><span class="line">        net.cuda()</span><br><span class="line">        fused_net.cuda()</span><br><span class="line">    n = <span class="number">1</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            x = torch.randn(size=(<span class="number">32</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">            <span class="keyword">if</span> cuda:</span><br><span class="line">                x = x.cuda()</span><br><span class="line"></span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            start = time()</span><br><span class="line">            out_origin = net(x)</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            end = time()</span><br><span class="line">            origin_time += end - start</span><br><span class="line"></span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            start = time()</span><br><span class="line">            out_fused = fused_net(x)</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            end = time()</span><br><span class="line">            fused_time += end - start</span><br><span class="line"></span><br><span class="line">            error += (out_origin - out_fused).<span class="built_in">abs</span>().<span class="built_in">max</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;origin time: <span class="subst">&#123;origin_time / n&#125;</span>s fused time: <span class="subst">&#123;fused_time / n&#125;</span>s error:<span class="subst">&#123;error / n&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> torchvision</span><br><span class="line">    net = torchvision.models.mobilenet_v2(<span class="literal">True</span>)</span><br><span class="line">    net.<span class="built_in">eval</span>()</span><br><span class="line">    validate(net, cuda=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>这个融合优化属于经济上净赚的事情，精度理论上无损（实际上有损，但是很小），速度有20%-30%的提升，尤其是BN层特别多的情况。</p>
<p>以下为在CPU上测速的情况：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>ResNet</th>
<th>Before</th>
<th>After</th>
</tr>
</thead>
<tbody>
<tr>
<td>ResNet18</td>
<td>0.088</td>
<td>0.076</td>
</tr>
<tr>
<td>ResNet34</td>
<td>0.157</td>
<td>0.124</td>
</tr>
<tr>
<td>ResNet50</td>
<td>0.275</td>
<td>0.185</td>
</tr>
<tr>
<td>ResNet152</td>
<td>0.728</td>
<td>0.406</td>
</tr>
</tbody>
</table>
</div>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p><a href="https://zhuanlan.zhihu.com/p/49329030">PyTorch 卷积与BatchNorm的融合 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5与Opencv的小小融合</title>
    <url>/2019/12/19/PyQt5%E4%B8%8EOpencv%E7%9A%84%E5%B0%8F%E5%B0%8F%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<h2 id="一些核心代码"><a href="#一些核心代码" class="headerlink" title="一些核心代码"></a>一些核心代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myLabel</span>(<span class="params">QLabel</span>):</span></span><br><span class="line">    x0 = <span class="number">0</span></span><br><span class="line">    y0 = <span class="number">0</span></span><br><span class="line">    x1 = <span class="number">0</span></span><br><span class="line">    y1 = <span class="number">0</span></span><br><span class="line">    flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mousePressEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">        self.flag = <span class="literal">True</span></span><br><span class="line">        self.x0 = event.x()</span><br><span class="line">        self.y0 = event.y()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouseReleaseEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">        self.flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mouseMoveEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.flag:</span><br><span class="line">            self.x1 = event.x()</span><br><span class="line">            self.y1 = event.y()</span><br><span class="line">            self.update()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">paintEvent</span>(<span class="params">self, event</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().paintEvent(event)</span><br><span class="line">        rect =QRect(self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br><span class="line">        painter = QPainter(self)</span><br><span class="line">        painter.setPen(QPen(Qt.red,<span class="number">4</span>,Qt.SolidLine))</span><br><span class="line">        painter.drawRect(rect)</span><br><span class="line"></span><br><span class="line">        pqscreen  = QGuiApplication.primaryScreen()</span><br><span class="line">        pixmap2 = pqscreen.grabWindow(self.winId(), self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br><span class="line">        pixmap2.save(<span class="string">&#x27;555.png&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Example</span>(<span class="params">QWidget</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.initUI()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initUI</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.resize(<span class="number">675</span>, <span class="number">300</span>)</span><br><span class="line">        self.setWindowTitle(<span class="string">&#x27;关注微信公众号：学点编程吧--opencv、PyQt5的小小融合&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.lb = myLabel(self)</span><br><span class="line">        self.lb.setGeometry(QRect(<span class="number">140</span>, <span class="number">30</span>, <span class="number">511</span>, <span class="number">241</span>))</span><br><span class="line"></span><br><span class="line">        img = cv2.imread(<span class="string">&#x27;xxx.jpg&#x27;</span>)</span><br><span class="line">        height, width, bytesPerComponent = img.shape</span><br><span class="line">        bytesPerLine = <span class="number">3</span> * width</span><br><span class="line">        cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)</span><br><span class="line">        QImg = QImage(img.data, width, height, bytesPerLine, QImage.Format_RGB888)</span><br><span class="line">        pixmap = QPixmap.fromImage(QImg)</span><br><span class="line"></span><br><span class="line">        self.lb.setPixmap(pixmap)</span><br><span class="line">        self.lb.setCursor(Qt.CrossCursor)</span><br><span class="line"></span><br><span class="line">        self.show()</span><br></pre></td></tr></table></figure>
<h2 id="实现大体思路"><a href="#实现大体思路" class="headerlink" title="实现大体思路"></a>实现大体思路</h2><ul>
<li>重新实现QLabel类，在类中重新实现了鼠标的点击、拖动、释放、以及绘画事件</li>
<li>在窗体上新建了一个label标签，然后载入图片</li>
<li>label标签载入的图像是由Opencv实现的</li>
</ul>
<h2 id="鼠标画矩形的思路"><a href="#鼠标画矩形的思路" class="headerlink" title="鼠标画矩形的思路"></a>鼠标画矩形的思路</h2><ul>
<li>新建一个矩形是否完成标志flag，默认是Flase，表示未完成</li>
<li>鼠标点击的时候，记录当前鼠标所在位置的坐标，flag标志置为True，表示开始画矩形了</li>
<li>鼠标拖动的时候，因为flag为True，所以记录当前鼠标所在位置的坐标</li>
<li>鼠标释放的时候，flag置为False，表示矩形画完了，准备画下一个了</li>
</ul>
<h2 id="代码讲解"><a href="#代码讲解" class="headerlink" title="代码讲解"></a>代码讲解</h2><h3 id="Opencv图像的转换"><a href="#Opencv图像的转换" class="headerlink" title="Opencv图像的转换"></a>Opencv图像的转换</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&#x27;xxx.jpg&#x27;</span>)</span><br><span class="line">height, width, bytesPerComponent = img.shape</span><br><span class="line">bytesPerLine = <span class="number">3</span> * width</span><br><span class="line">cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)</span><br><span class="line">QImg = QImage(img.data, width, height, bytesPerLine, QImage.Format_RGB888)</span><br><span class="line">pixmap = QPixmap.fromImage(QImg)</span><br></pre></td></tr></table></figure>
<p>这个就是Opencv和PyQt对象的转化了。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv2.imread(<span class="string">&#x27;xxx.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure><br>使用Opencv读取图像。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">height, width, bytesPerComponent = img.shape</span><br></pre></td></tr></table></figure><br>在OpenCV-Python绑定中，图像使用NumPy数组的属性(这就解释了为什么要更新numpy)来表示图像的尺寸和通道信息。此时如果我们输出img.shape，将得到(200, 360, 3)。最后的3表示这是一个RGB图像。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)</span><br></pre></td></tr></table></figure><br>将图像从一个颜色空间转换为另一个颜色空间。<br>Python中的函数要求是这样的：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Python：cv2.cvtColor（src，code [，dst [，dstCn]]）→dst</span><br></pre></td></tr></table></figure><br>参数：</p>
<ol>
<li>src - 输入图像：8位无符号，16位无符号（CV_16UC …）或单精度浮点数。</li>
<li>dst - 输出与src相同大小和深度的图像。</li>
<li>code - 颜色空间转换代码（请参阅下面的说明）。</li>
<li>dstCn - 目标图像中的通道数量；如果参数是0，则通道的数量是从src和代码自动导出的。</li>
</ol>
<p>该函数将输入图像从一个颜色空间转换为另一个颜色空间。在从RGB颜色空间转换到RGB颜色空间的情况下，通道的顺序应明确指定（RGB或BGR）。请注意，OpenCV中的默认颜色格式通常被称为RGB，但实际上是BGR（字节相反）。因此，标准（24位）彩色图像中的第一个字节将是一个8位蓝色分量，第二个字节将是绿色，而第三个字节将是红色。第四，五，六字节将是第二个像素（蓝色，然后是绿色，然后是红色），依此类推。</p>
<p>这里我们就是要求从Opencv的BGR图像转换成RGB图像了。为什么？因为要转换成PyQt5可以识别的啊！<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bytesPerLine = <span class="number">3</span> * width</span><br><span class="line">QImg = QImage(img.data, width, height, bytesPerLine, QImage.Format_RGB888)</span><br></pre></td></tr></table></figure><br>QImage类提供了独立于硬件的图像表示形式，允许直接访问像素数据，并可用作绘画设备。Qt提供了四个类来处理图像数据：QImage，QPixmap，QBitmap和QPicture。QImage是为I/O设计和优化的，并且可以直接进行像素访问和操作，而QPixmap则是针对在屏幕上显示图像而设计和优化的。 </p>
<p>QBitmap只是一个继承QPixmap的便利类，深度为1。最后，QPicture类是一个记录和重放QPainter命令的绘图设备。</p>
<p>因为QImage是一个QPaintDevice子类，QPainter可以用来直接绘制图像。在QImage上使用QPainter时，可以在当前GUI线程之外的另一个线程中执行绘制。QImage提供了一系列功能，可用于获取有关图像的各种信息。也有几个功能，使图像转换。<br>详见官网介绍：<a href="https://doc.qt.io/qt-5/qimage.html">QImage Class | Qt GUI 5.10</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QImg = QImage(img.data, width, height, bytesPerLine, QImage.Format_RGB888)</span><br></pre></td></tr></table></figure>
<p>函数原型是：<strong>QImage(str, int, int, int, QImage.Format)</strong>，用给定的宽度，高度和格式构造一个使用现有内存缓冲区数据的图像。宽度和高度必须以像素指定。bytesPerLine指定每行的字节数。</p>
<p><strong>这里有个疑问：为什么bytesPerLine = 3 * width？</strong><br>我的理解是：当1个像素占3个字节，此时图像为真彩色图像。</p>
<p><strong>QImage.Format_RGB888</strong>表示的是图像存储使用8-8-8 24位RGB格式。当然还有更多的格式，详见QImage的官方介绍，限于篇幅这里不展开。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pixmap = QPixmap.fromImage(QImg)</span><br></pre></td></tr></table></figure><br>这个很好理解，就是想QImage对象转换成QPixmap对象，便于下步我们将Label标签中设置图像。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.lb.setPixmap(pixmap)</span><br></pre></td></tr></table></figure><br>设置标签的图像信息。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.lb.setCursor(Qt.CrossCursor)</span><br></pre></td></tr></table></figure><br>设置鼠标在QLabel对象中的样式，只是为了画画好看些而已，没其它的意思。除了这个十字架的，还有其它很多样式，如下图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/opencv/v2-cf7bf8978adbaa898f059207f52f3d5b_hd.jpg" alt></p>
<h3 id="鼠标事件"><a href="#鼠标事件" class="headerlink" title="鼠标事件"></a>鼠标事件</h3><p>按照上文中我们介绍的思路，我们自定义了一个QLabel类myLabel，当然是继承了QLabel。然后我们用几个类变量记录鼠标的坐标和矩形是否完成的标志。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mousePressEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">    self.flag = <span class="literal">True</span></span><br><span class="line">    self.x0 = event.x()</span><br><span class="line">    self.y0 = event.y()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouseReleaseEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">    self.flag = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mouseMoveEvent</span>(<span class="params">self,event</span>):</span></span><br><span class="line">    <span class="keyword">if</span> self.flag:</span><br><span class="line">        self.x1 = event.x()</span><br><span class="line">        self.y1 = event.y()</span><br><span class="line">        self.update()</span><br></pre></td></tr></table></figure><br>这里就是重载了鼠标产生的几个事件，是我们自定义的。分别记录了点击鼠标后初始的鼠标坐标，以及释放鼠标后的鼠标坐标。并在鼠标移动的时候更新UI。也就是我们上面所说的鼠标画矩形的思路。</p>
<h3 id="画矩形"><a href="#画矩形" class="headerlink" title="画矩形"></a>画矩形</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paintEvent</span>(<span class="params">self, event</span>):</span></span><br><span class="line">    <span class="built_in">super</span>().paintEvent(event)</span><br><span class="line">    rect =QRect(self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br><span class="line">    painter = QPainter(self)</span><br><span class="line">    painter.setPen(QPen(Qt.red,<span class="number">4</span>,Qt.SolidLine))</span><br><span class="line">    painter.drawRect(rect)</span><br><span class="line"></span><br><span class="line">    pqscreen  = QGuiApplication.primaryScreen()</span><br><span class="line">    pixmap2 = pqscreen.grabWindow(self.winId(), self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br><span class="line">    pixmap2.save(<span class="string">&#x27;555.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这个是关键点啊！<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">super</span>().paintEvent(event)</span><br></pre></td></tr></table></figure><br>调用父类的paintEvent()，这个是为了显示你设置的效果。否则会是一片空白。大家可以试试注释这句话，看看效果啊！<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rect =QRect(self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br></pre></td></tr></table></figure><br>QRect类使用整数精度在平面中定义一个矩形。矩形通常表示为左上角和大小。QRect的大小（宽度和高度）始终等同于构成其渲染基础的数学矩形。QRect可以用一组左，上，宽和高整数，或者从QPoint和QSize构成。以下代码创建两个相同的矩形。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QRect(<span class="number">100</span>, <span class="number">200</span>, <span class="number">11</span>, <span class="number">16</span>)</span><br><span class="line">QRect(QPoint(<span class="number">100</span>, <span class="number">200</span>), QSize(<span class="number">11</span>, <span class="number">16</span>))</span><br><span class="line">painter = QPainter(self)</span><br><span class="line">painter.setPen(QPen(Qt.red,<span class="number">4</span>,Qt.SolidLine))</span><br><span class="line">painter.drawRect(rect)</span><br></pre></td></tr></table></figure><br>构建一个QPainter对象，设置它的画笔，然后画一个矩形。貌似感觉好简单！^_^”</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pqscreen  = QGuiApplication.primaryScreen()</span><br><span class="line">pixmap2 = pqscreen.grabWindow(self.winId(), self.x0, self.y0, <span class="built_in">abs</span>(self.x1-self.x0), <span class="built_in">abs</span>(self.y1-self.y0))</span><br><span class="line">pixmap2.save(<span class="string">&#x27;555.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>截屏的原理呢，主要还是运用QScreen类中的grabWindow方法。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">QScreen.grabWindow(WId window, <span class="built_in">int</span> x = <span class="number">0</span>, <span class="built_in">int</span> y = <span class="number">0</span>, <span class="built_in">int</span> width = -<span class="number">1</span>, <span class="built_in">int</span> height = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure><br>大致意思是创建并返回通过抓取由QRect（x，y，width，height）限制的给定窗口构造的像素图。</p>
<p>参数（x，y）指定窗口中的偏移量，而（宽度，高度）指定要复制的区域。如果宽度为负数，则该函数将所有内容复制到窗口的右边界。如果高度为负数，则该函数将所有内容复制到窗口的底部。</p>
<p>窗口系统标识符（WId）可以使用QWidget.winId（）函数进行检索。grabWindow（）函数从屏幕抓取像素，而不是从窗口抓取像素，即，如果有另一个窗口部分或全部覆盖抓取的像素，则也会从上面的窗口获取像素。鼠标光标一般不会被抓取。详见官网介绍：QScreen Class | Qt GUI 5.10</p>
<p>由于QScreen类无构造函数，所以我们使用QGuiApplication.primaryScreen()创建了一个Qscreen类对象。最后使用pixmap2.save(‘555.png’)，保存具体的截图。</p>
<p>如果你想保存的图片没有红框，可以参考这里：<br><a href="http://www.xdbcb8.com/forum/topic/%e3%80%8apyqt5%e4%b8%8eopencv%e7%9a%84%e5%b0%8f%e5%b0%8f%e8%9e%8d%e5%90%88%e3%80%8b%e8%bf%99%e7%af%87%e6%96%87%e7%ab%a0%e4%b8%ad%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e4%bf%9d%e5%ad%98%e4%b8%8b%e6%9d%a5">《pyqt5与opencv的小小融合》这篇文章中如何实现保存下来</a></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Opencv</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>Pycharm连接远程服务器并实现远程调试</title>
    <url>/2020/01/26/Pycharm%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B9%B6%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<h2 id="Pycharm连接远程服务器"><a href="#Pycharm连接远程服务器" class="headerlink" title="Pycharm连接远程服务器"></a>Pycharm连接远程服务器</h2><ul>
<li>进入配置页面<br>Pycharm菜单栏，如下图所示，依次点击 Tools -&gt; Deployment -&gt; Configration…<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161124726.png" alt></li>
<li>配置连接服务器<br>如下图。name随便写个就行。<br>Connection下，协议最好选择sftp，接下来填写服务器主机IP，用户名，密码。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/2018082916114659.png" alt><br>点击Test SFTP connection会发现，如果连接成功会提示你如下<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161158768.png" alt><br>在Mapping下，选择连接windows下的那部分代码和服务器上代码相连，本地Local path，服务器path，apply，OK，表示已经把本地的代码和服务器代码连接上了。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161217756.png" alt></li>
<li>上传代码，使得本地代码和服务器代码保持同步<br>点击Upload to name（刚才填写的远程服务器名字），即可上传代码。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161235445.png" alt><br>若配置有多个不同服务器或同一个服务器配置了多个 服务器上传路径（Deployment Path），可选择 Upload to…，上传到不同的服务器/路径。</li>
</ul>
<h2 id="配置远程Python解释器"><a href="#配置远程Python解释器" class="headerlink" title="配置远程Python解释器"></a>配置远程Python解释器</h2><p>使用服务器调试Python程序的前提时在服务器上安装了Python解释器，如果没安装，请先安装。</p>
<ul>
<li>将Python解释器设置为远程服务器上的<br>在菜单栏，File -&gt; Settings… -&gt; Project ×× -&gt; Project Interpreter，点击右侧 Add按钮，添加解释器。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161249360.png" alt><br>选择SSH Interpreter，填写服务器的 Host 地址，端口Port，用户名Username，填好后，下一步Next。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161306837.png" alt><br>填写密码 Password，下一步Next。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161340812.png" alt><br>选择远程服务器上Python解释器的位置，服务器上的远程同步文件夹Sync folders（即之前配置的服务器Path），可以选择多个。如果不知道Python安装在哪，可以远程连接服务器后，使用 命令 which python 找到Python安装位置。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm%20remote%20control/20180829161653972.jpg" alt><br>Finish，配置结束。该项目现在使用的就是远程服务器上的Python解释器了。以后的项目若想/不想使用该解释器，手动更改解释器即可。</li>
</ul>
<h2 id="使用远程解释器运行本地Python程序"><a href="#使用远程解释器运行本地Python程序" class="headerlink" title="使用远程解释器运行本地Python程序"></a>使用远程解释器运行本地Python程序</h2><p>将测试代码上传至远程服务器（Tooles -&gt; Deployment -&gt; Upload to ××）。<br>Run测试代码，可以看到现在代码是在远程服务器上运行了。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pycharm</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>Python新环境下快速安装依赖包的小技巧</title>
    <url>/2019/12/14/Python%E6%96%B0%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E5%8C%85%E7%9A%84%E5%B0%8F%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>当你新创一个Python环境时，若还用pip一个个装你所需要的库，明显效率十分低下。这里有个小技巧，你可以从已配置好的旧环境中，导出一个requirements.txt 文件，用于记录所有依赖包及其精确的版本号。以便新环境部署。</p>
<p>在旧环境中执行以下命令，生成requirements.txt文件：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure><br>requirements.txt中的内容类似如下，记录了你旧有环境的依赖包及其精确的版本号：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">appdirs==1.4.3</span><br><span class="line">backports.functools-lru-cache==1.5</span><br><span class="line">beautifulsoup4==4.5.3</span><br><span class="line">bs4==0.0.1</span><br><span class="line">cycler==0.10.0</span><br><span class="line">kiwisolver==1.0.1</span><br><span class="line">lxml==3.7.3</span><br><span class="line">matplotlib==2.2.0</span><br><span class="line">numpy==1.14.1</span><br><span class="line">pandas==0.22.0</span><br><span class="line">pyparsing==2.2.0</span><br><span class="line">python-dateutil==2.6.1</span><br><span class="line">pytz==2018.3</span><br><span class="line">six==1.11.0</span><br><span class="line">virtualenv==15.1.0</span><br></pre></td></tr></table></figure><br>这时你可以把requirements.txt拷入新配置的Python目录下，执行以下命令：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><br>则会按照requirements.txt中所写的依赖包和版本依序进行安装。<br>注意：<br>若迁入的系统不同或Python版本不同，在安装过程中可能会因为找不到相应的依赖包版本而报错<br>这时你可以进入requirements.txt把报错的依赖包后的版本信息去掉，保存，重新执行命令即可，它会自动下载匹配的最新版本。<br>也可以把==改成&lt;=，代表它会搜索不大于此版本的最高版本进行安装。<br>由于pip下载源在国外，若无合适的VPN，此期间下载过程会十分漫长，这里提供几个常用的国内镜像源：</p>
<ul>
<li>清华大学 <a href="https://pypi.tuna.tsinghua.edu.cn/simple/">https://pypi.tuna.tsinghua.edu.cn/simple/</a></li>
<li>中国科学技术大学 <a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a></li>
<li>阿里云 <a href="https://mirrors.aliyun.com/pypi/simple/">https://mirrors.aliyun.com/pypi/simple/</a></li>
<li>豆瓣 <a href="https://pypi.douban.com/simple/">https://pypi.douban.com/simple/</a></li>
<li>华中科技大学 <a href="https://pypi.hustunique.com/">https://pypi.hustunique.com/</a></li>
</ul>
<p>可以在使用pip的时候，加上参数-i和镜像地址，指定下载源，加速下载过程，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch基于Apex的混合精度加速</title>
    <url>/2020/08/20/Pytorch%E5%9F%BA%E4%BA%8EApex%E7%9A%84%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E5%8A%A0%E9%80%9F/</url>
    <content><![CDATA[<h1 id="Pytorch-gt-1-6-0"><a href="#Pytorch-gt-1-6-0" class="headerlink" title="Pytorch &gt;= 1.6.0"></a>Pytorch &gt;= 1.6.0</h1><p>pytorch1.6开始官方支持了混合精度训练。使用方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> autocast <span class="keyword">as</span> autocast, GradScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建model，默认是torch.FloatTensor</span></span><br><span class="line">model = Net().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), ...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练最开始之前实例化一个GradScaler对象</span></span><br><span class="line">scaler = GradScaler()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> epochs:</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> data:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向过程(model + loss)开启 autocast</span></span><br><span class="line">        <span class="keyword">with</span> autocast():</span><br><span class="line">            output = model(<span class="built_in">input</span>)</span><br><span class="line">            loss = loss_fn(output, target)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Scales loss，这是因为半精度的数值范围有限，因此需要用它放大</span></span><br><span class="line">        scaler.scale(loss).backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scaler.step() unscale之前放大后的梯度，但是scale太多可能出现inf或NaN</span></span><br><span class="line">        <span class="comment"># 故其会判断是否出现了inf/NaN</span></span><br><span class="line">        <span class="comment"># 如果梯度的值不是 infs 或者 NaNs, 那么调用optimizer.step()来更新权重,</span></span><br><span class="line">        <span class="comment"># 如果检测到出现了inf或者NaN，就跳过这次梯度更新，同时动态调整scaler的大小</span></span><br><span class="line">        scaler.step(optimizer)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 查看是否要更新scaler</span></span><br><span class="line">        scaler.update()</span><br></pre></td></tr></table></figure>
<h1 id="Pytorch-lt-1-6-0"><a href="#Pytorch-lt-1-6-0" class="headerlink" title="Pytorch &lt; 1.6.0"></a>Pytorch &lt; 1.6.0</h1><p>pytorch1.6版本前需要配合第三方插件使用混合精度。</p>
<h2 id="Apex"><a href="#Apex" class="headerlink" title="Apex"></a>Apex</h2><p><a href="https://github.com/NVIDIA/apex">Apex</a>是由Nvidia维护的一个支持混合精度分布式训练的第三方Pytorch扩展。可以用短短三行代码就能实现不同程度的混合精度加速，使训练时间和显存占用直接缩小一半。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>以下是安装 apex 的方法. apex克隆在哪里都无所谓</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/NVIDIA/apex</span><br><span class="line">cd apex</span><br><span class="line">pip install -v --no-cache-dir --global-option=&quot;--pyprof&quot; --global-option=&quot;--cpp_ext&quot; --global-option=&quot;--cuda_ext&quot; ./</span><br></pre></td></tr></table></figure>
<p>以下代码用于验证是否安装成功：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> apex.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP</span><br><span class="line">    <span class="keyword">from</span> apex.fp16_utils <span class="keyword">import</span> *</span><br><span class="line">    <span class="keyword">from</span> apex <span class="keyword">import</span> amp, optimizers</span><br><span class="line">    <span class="keyword">from</span> apex.multi_tensor_apply <span class="keyword">import</span> multi_tensor_applier</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">raise</span> ImportError(<span class="string">&quot;Please install apex from https://www.github.com/nvidia/apex to run this example.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>卸载命令为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip uninstall apex</span><br></pre></td></tr></table></figure>
<h2 id="支持列表"><a href="#支持列表" class="headerlink" title="支持列表"></a>支持列表</h2><p>判断你的GPU是否支持FP16：支持的有拥有Tensor Core的GPU(2080Ti、Titan、Tesla等)，不支持的(Pascal系列)就不建议折腾了。</p>
<p>如果你的GPU是以下GPU的其中一种: 请调整nvcc与pytorch.cuda至10.0</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GeForce GTX 1650</span><br><span class="line">GeForce GTX 1660</span><br><span class="line">GeForce GTX 1660 Ti</span><br><span class="line">GeForce RTX 2060</span><br><span class="line">GeForce RTX 2060 Super</span><br><span class="line">GeForce RTX 2070</span><br><span class="line">GeForce RTX 2070 Super</span><br><span class="line">GeForce RTX 2080</span><br><span class="line">GeForce RTX 2080 Super</span><br><span class="line">GeForce RTX 2080 Ti</span><br><span class="line">Titan RTX</span><br><span class="line">Quadro RTX 4000</span><br><span class="line">Quadro RTX 5000</span><br><span class="line">Quadro RTX 6000</span><br><span class="line">Quadro RTX 8000</span><br><span class="line">Tesla T4</span><br></pre></td></tr></table></figure>
<p>如果你打算调整Pytorch Version来适应APEX(推荐)</p>
<p>首先用 <code>nvcc --version</code> 命令调查你的nvcc版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2018 NVIDIA Corporation</span><br><span class="line">Built on Tue_Jun_12_23:07:04_CDT_2018</span><br><span class="line">Cuda compilation tools, release 9.2, V9.2.148</span><br></pre></td></tr></table></figure>
<p>再进入python看看pytorch cuda版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; torch.version.cuda</span><br><span class="line">&#x27;9.0.176&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>3090ti自带cuda为11.1，但是并没有匹配的torch版本，这里为了安上apex，可以通过修改<code>setup.py</code>尝试禁用次要版本检查。</p>
<p>找到如下函数，注释掉原语句，返回空值：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> def check_cuda_torch_binary_vs_bare_metal(cuda_dir):</span><br><span class="line">+    return</span><br></pre></td></tr></table></figure>
<p>修改后，重新安装apex即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -v --no-cache-dir --global-option=&quot;--cpp_ext&quot; --global-option=&quot;--cuda_ext&quot; ./</span><br></pre></td></tr></table></figure>
<p>我在安装了带有cuda-11.0的pytorch的同时，针对整个系统的cuda-11.1成功构建了apex！</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>导入包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br></pre></td></tr></table></figure>
<p>在你创建后net(model)和optimizer后添加代码(注意顺序)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">net = net.cuda()</span><br><span class="line">net, optimizer = amp.initialize(net, optimizer, opt_level=<span class="string">&quot;O1&quot;</span>) <span class="comment"># 这里是“欧一”，不是“零一”</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if you need to use multiple GPU, uncomment this line</span></span><br><span class="line"><span class="comment"># net = torch.nn.DataParallel(net, device_ids=[i for i in range(torch.cuda.device_count())])</span></span><br></pre></td></tr></table></figure>
<p>然后把你的loss.backward()换成 ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">    scaled_loss.backward()</span><br></pre></td></tr></table></figure>
<p>如果你有用Pytorch自带的BCELoss或F.binary_cross_entropy, 请把他们替换成BCEWithLogitsLoss或F.binary_cross_entropy_with_logists并用logists 作为输入.</p>
<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><h3 id="opt-level"><a href="#opt-level" class="headerlink" title="opt level"></a>opt level</h3><p>其中只有一个opt_level需要用户自行配置：</p>
<ul>
<li><p>oe：纯FP32训练，可以作为accuracy的baseline；</p>
</li>
<li><p>o1：混合精度训练(推荐使用)，根据黑白名单自动决定使用FP16(GEMM，卷积)还是FP32(Softmax)进行计算。</p>
</li>
<li><p>02：“几乎FP16”混合精度训练，不存在黑白名单，除了Batch norm，几乎都是用FP16计算。</p>
</li>
<li><p>o3：纯FP16训练，很不稳定，但是可以作为speed的baseline；</p>
</li>
</ul>
<h3 id="动态损失放大（Dynamic-Loss-Scaling）"><a href="#动态损失放大（Dynamic-Loss-Scaling）" class="headerlink" title="动态损失放大（Dynamic Loss Scaling）"></a>动态损失放大（Dynamic Loss Scaling）</h3><p>AMP默认使用动态损失放大，为了充分利用FP16的范围，缓解舍入误差，尽量使用最高的放大倍($2^{24}$)，如果产生了上溢出(Overflow)，则跳过参数更新，缩小放大倍数使其不溢出，在一定步数后(比如2000步)会再尝试使用大的scale来充分利用FP16的范围：</p>
<h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><ol>
<li><strong>减少显存占用</strong>    现在模型越来越大，当你使用Bert这一类的预训练模型时，往往显存就被模型及模型计算占去大半，当想要使用更大的Batch Size的时候会显得捉襟见肘。由于FP16的内存占用只有FP32的一半，自然地就可以帮助训练过程节省一半的显存空间。</li>
<li><strong>加快训练和推断的计算</strong>    与普通的空间时间Trade-off的加速方法不同，FP16除了能节约内存，还能同时节省模型的训练时间。在大部分的测试中，基于FP16的加速方法能够给模型训练带来多一倍的加速体验（爽感类似于两倍速看肥皂剧）。</li>
<li><strong>张量核心的普及</strong>    硬件的发展同样也推动着模型计算的加速，随着Nvidia张量核心(Tensor Core)的普及，16bit计算也一步步走向成熟，低精度计算也是未来深度学习的一个重要趋势，再不学习就out啦。</li>
</ol>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch快速安装教程</title>
    <url>/2020/01/26/Pytorch%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>进入<a href="https://pytorch.org/">官网</a>，按照你的环境选择，得到下载命令，这里以windows为例，Ubuntu同理</p>
<h2 id="conda安装"><a href="#conda安装" class="headerlink" title="conda安装"></a>conda安装</h2><p>官网得到命令如图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pytorch_install/Snipaste_2020-01-26_14-06-32.jpg" alt><br>但由于墙的原因直接使用此命令下载很慢，因此请更换conda源为国内镜像<br>并将命令中 -c pytorch去掉<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=10.1</span><br></pre></td></tr></table></figure><br>即可调用国内镜像下载。</p>
<h2 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h2><p>官网得到命令如图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pytorch_install/Snipaste_2020-01-26_14-06-05.jpg" alt><br>红色框出部分为官网建议版本，但由于墙的原因直接使用此命令下载很慢，因此将pip下载地址改成国内镜像即可<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install torch==1.4.0 torchvision==0.5.0 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch版YOLOv3中的代码配置和数据集构建</title>
    <url>/2020/02/15/Pytorch%E7%89%88YOLOv3%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E9%85%8D%E7%BD%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<h3 id="1-环境搭建"><a href="#1-环境搭建" class="headerlink" title="1. 环境搭建"></a>1. 环境搭建</h3><ol>
<li>将github库download下来。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/ultralytics/yolov3.git</span><br></pre></td></tr></table></figure>
<ol>
<li>建议在linux环境下使用anaconda进行搭建</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n yolov3 python=3.7</span><br></pre></td></tr></table></figure>
<ol>
<li>安装需要的软件</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<p>环境要求：</p>
<ul>
<li>python &gt;= 3.7</li>
<li>pytorch &gt;= 1.1</li>
<li>numpy</li>
<li>tqdm</li>
<li>opencv-python</li>
</ul>
<p>其中只需要注意pytorch的安装：</p>
<p>到<a href="https://pytorch.org/">https://pytorch.org/</a>中根据操作系统，python版本，cuda版本等选择命令即可。</p>
<h3 id="2-数据集构建"><a href="#2-数据集构建" class="headerlink" title="2. 数据集构建"></a>2. 数据集构建</h3><h4 id="1-xml文件生成需要Labelimg软件"><a href="#1-xml文件生成需要Labelimg软件" class="headerlink" title="1. xml文件生成需要Labelimg软件"></a>1. xml文件生成需要Labelimg软件</h4><p>在Windows下使用LabelImg软件进行标注：</p>
<ul>
<li>使用快捷键：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Ctrl + u  加载目录中的所有图像，鼠标点击Open dir同功能</span><br><span class="line">Ctrl + r  更改默认注释目标目录(xml文件保存的地址)</span><br><span class="line">Ctrl + s  保存</span><br><span class="line">Ctrl + d  复制当前标签和矩形框</span><br><span class="line">space     将当前图像标记为已验证</span><br><span class="line">w         创建一个矩形框</span><br><span class="line">d         下一张图片</span><br><span class="line">a         上一张图片</span><br><span class="line">del       删除选定的矩形框</span><br><span class="line">Ctrl++    放大</span><br><span class="line">Ctrl--    缩小</span><br><span class="line">↑→↓←        键盘箭头移动选定的矩形框</span><br></pre></td></tr></table></figure>
<h4 id="2-VOC2007-数据集格式"><a href="#2-VOC2007-数据集格式" class="headerlink" title="2. VOC2007 数据集格式"></a>2. VOC2007 数据集格式</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-data</span><br><span class="line">    - VOCdevkit2007</span><br><span class="line">        - VOC2007</span><br><span class="line">            - Annotations (标签XML文件，用对应的图片处理工具人工生成的)</span><br><span class="line">            - ImageSets (生成的方法是用sh或者MATLAB语言生成)</span><br><span class="line">                - Main</span><br><span class="line">                    - test.txt</span><br><span class="line">                    - train.txt</span><br><span class="line">                    - trainval.txt</span><br><span class="line">                    - val.txt</span><br><span class="line">            - JPEGImages(原始文件)</span><br><span class="line">            - labels (xml文件对应的txt文件)</span><br></pre></td></tr></table></figure>
<p>通过以上软件主要构造好JPEGImages和Annotations文件夹中内容,Main文件夹中的txt文件可以通过以下python脚本生成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">  </span><br><span class="line">trainval_percent = <span class="number">0.9</span></span><br><span class="line">train_percent = <span class="number">1</span></span><br><span class="line">xmlfilepath = <span class="string">&#x27;Annotations&#x27;</span></span><br><span class="line">txtsavepath = <span class="string">&#x27;ImageSets\Main&#x27;</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line">  </span><br><span class="line">num=<span class="built_in">len</span>(total_xml)</span><br><span class="line"><span class="built_in">list</span>=<span class="built_in">range</span>(num)</span><br><span class="line">tv=<span class="built_in">int</span>(num*trainval_percent)</span><br><span class="line">tr=<span class="built_in">int</span>(tv*train_percent)</span><br><span class="line">trainval= random.sample(<span class="built_in">list</span>,tv)</span><br><span class="line">train=random.sample(trainval,tr)</span><br><span class="line">  </span><br><span class="line">ftrainval = <span class="built_in">open</span>(<span class="string">&#x27;ImageSets/Main/trainval.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">ftest = <span class="built_in">open</span>(<span class="string">&#x27;ImageSets/Main/test.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">ftrain = <span class="built_in">open</span>(<span class="string">&#x27;ImageSets/Main/train.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">fval = <span class="built_in">open</span>(<span class="string">&#x27;ImageSets/Main/val.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i  <span class="keyword">in</span> <span class="built_in">list</span>:</span><br><span class="line">    name=total_xml[i][:-<span class="number">4</span>]+<span class="string">&#x27;\n&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftrain.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftest.write(name)</span><br><span class="line">  </span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest.close()</span><br></pre></td></tr></table></figure>
<p>接下来生成labels文件夹中的txt文件，voc_label.py文件具体内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Tue Oct  2 11:42:13 2018</span></span><br><span class="line"><span class="string">将本文件放到VOC2007目录下，然后就可以直接运行</span></span><br><span class="line"><span class="string">需要修改的地方：</span></span><br><span class="line"><span class="string">1. sets中替换为自己的数据集</span></span><br><span class="line"><span class="string">2. classes中替换为自己的类别</span></span><br><span class="line"><span class="string">3. 将本文件放到VOC2007目录下</span></span><br><span class="line"><span class="string">4. 直接开始运行</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir, getcwd</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join</span><br><span class="line">sets=[(<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;train&#x27;</span>), (<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;val&#x27;</span>), (<span class="string">&#x27;2007&#x27;</span>, <span class="string">&#x27;test&#x27;</span>)]  <span class="comment">#替换为自己的数据集</span></span><br><span class="line">classes = [<span class="string">&quot;person&quot;</span>]     <span class="comment">#修改为自己的类别</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#进行归一化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span>(<span class="params">size, box</span>):</span></span><br><span class="line">    dw = <span class="number">1.</span>/(size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span>/(size[<span class="number">1</span>])</span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span> - <span class="number">1</span></span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    x = x*dw</span><br><span class="line">    w = w*dw</span><br><span class="line">    y = y*dh</span><br><span class="line">    h = h*dh</span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_annotation</span>(<span class="params">year, image_id</span>):</span></span><br><span class="line">    in_file = <span class="built_in">open</span>(<span class="string">&#x27;VOC%s/Annotations/%s.xml&#x27;</span>%(year, image_id))  <span class="comment">#将数据集放于当前目录下</span></span><br><span class="line">    out_file = <span class="built_in">open</span>(<span class="string">&#x27;VOC%s/labels/%s.txt&#x27;</span>%(year, image_id), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    tree=ET.parse(in_file)</span><br><span class="line">    root = tree.getroot()</span><br><span class="line">    size = root.find(<span class="string">&#x27;size&#x27;</span>)</span><br><span class="line">    w = <span class="built_in">int</span>(size.find(<span class="string">&#x27;width&#x27;</span>).text)</span><br><span class="line">    h = <span class="built_in">int</span>(size.find(<span class="string">&#x27;height&#x27;</span>).text)</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> root.<span class="built_in">iter</span>(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        difficult = obj.find(<span class="string">&#x27;difficult&#x27;</span>).text</span><br><span class="line">        cls = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">not</span> <span class="keyword">in</span> classes <span class="keyword">or</span> <span class="built_in">int</span>(difficult)==<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        cls_id = classes.index(cls)</span><br><span class="line">        xmlbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        b = (<span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;xmax&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymin&#x27;</span>).text), <span class="built_in">float</span>(xmlbox.find(<span class="string">&#x27;ymax&#x27;</span>).text))</span><br><span class="line">        bb = convert((w,h), b)</span><br><span class="line">        out_file.write(<span class="built_in">str</span>(cls_id) + <span class="string">&quot; &quot;</span> + <span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(a) <span class="keyword">for</span> a <span class="keyword">in</span> bb]) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">wd = getcwd()</span><br><span class="line"><span class="keyword">for</span> year, image_set <span class="keyword">in</span> sets:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;VOC%s/labels/&#x27;</span>%(year)):</span><br><span class="line">        os.makedirs(<span class="string">&#x27;VOC%s/labels/&#x27;</span>%(year))</span><br><span class="line">    image_ids = <span class="built_in">open</span>(<span class="string">&#x27;VOC%s/ImageSets/Main/%s.txt&#x27;</span>%(year, image_set)).read().strip().split()</span><br><span class="line">    list_file = <span class="built_in">open</span>(<span class="string">&#x27;%s_%s.txt&#x27;</span>%(year, image_set), <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        list_file.write(<span class="string">&#x27;VOC%s/JPEGImages/%s.jpg\n&#x27;</span>%(year, image_id))</span><br><span class="line">        convert_annotation(year, image_id)</span><br><span class="line">    list_file.close()</span><br></pre></td></tr></table></figure>
<p>到底为止，VOC格式数据集构造完毕，但是还需要继续构造符合darknet格式的数据集(coco)。</p>
<p>需要说明的是：如果打算使用coco评价标准，需要构造coco中json格式，如果要求不高，只需要VOC格式即可，使用作者写的mAP计算程序即可。</p>
<h4 id="3-创建-names-file"><a href="#3-创建-names-file" class="headerlink" title="3. 创建*.names file,"></a>3. 创建*.names file,</h4><p>其中保存的是你的所有的类别，每行一个类别，如data/coco.names：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">person</span><br></pre></td></tr></table></figure>
<h4 id="4-更新data-coco-data-其中保存的是很多配置信息"><a href="#4-更新data-coco-data-其中保存的是很多配置信息" class="headerlink" title="4. 更新data/coco.data,其中保存的是很多配置信息"></a>4. 更新data/coco.data,其中保存的是很多配置信息</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classes = 1 # 改成你的数据集的类别个数</span><br><span class="line">train = ./data/2007_train.txt # 通过voc_label.py文件生成的txt文件</span><br><span class="line">valid = ./data/2007_test.txt # 通过voc_label.py文件生成的txt文件</span><br><span class="line">names = data/coco.names # 记录类别</span><br><span class="line">backup = backup/ # 在本库中没有用到</span><br><span class="line">eval = coco # 选择map计算方式</span><br></pre></td></tr></table></figure>
<h4 id="5-更新cfg文件，修改类别相关信息"><a href="#5-更新cfg文件，修改类别相关信息" class="headerlink" title="5. 更新cfg文件，修改类别相关信息"></a>5. 更新cfg文件，修改类别相关信息</h4><p>打开cfg文件夹下的yolov3.cfg文件，大体而言，cfg文件记录的是整个网络的结构，是核心部分。</p>
<p>只需要更改每个[yolo]层前边卷积层的filter个数即可：</p>
<blockquote>
<p>每一个[region/yolo]层前的最后一个卷积层中的 filters=预测框的个数(mask对应的个数，比如mask=0,1,2,  代表使用了anchors中的前三对，这里预测框个数就应该是3*(classes+5)  ,5的意义是5个坐标（论文中的tx,ty,tw,th,po），3的意义就是用了3个anchor。</p>
</blockquote>
<p>举个例子：假如我有三个类，n = 3, 那么filter  = 3 × (n+5) = 24</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=255 # 改为 24</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask = 6,7,8</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes=80 # 改为 3</span><br><span class="line">num=9</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .7</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure>
<h4 id="6-数据集格式说明"><a href="#6-数据集格式说明" class="headerlink" title="6. 数据集格式说明"></a>6. 数据集格式说明</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- yolov3</span><br><span class="line">    - data</span><br><span class="line">      - 2007_train.txt</span><br><span class="line">      - 2007_test.txt</span><br><span class="line">      - coco.names</span><br><span class="line">      - coco.data</span><br><span class="line">      - annotations(json files)</span><br><span class="line">      - images(将2007_train.txt中的图片放到train2014文件夹中，test同理)</span><br><span class="line">        - train2014</span><br><span class="line">          - 0001.jpg</span><br><span class="line">          - 0002.jpg</span><br><span class="line">        - val2014</span><br><span class="line">          - 0003.jpg</span><br><span class="line">          - 0004.jpg</span><br><span class="line">      - labels（voc_labels.py生成的内容需要重新组织一下）</span><br><span class="line">        - train2014</span><br><span class="line">          - 0001.txt</span><br><span class="line">          - 0002.txt</span><br><span class="line">        - val2014</span><br><span class="line">          - 0003.txt</span><br><span class="line">          - 0004.txt</span><br><span class="line">      - samples(存放待测试图片)</span><br></pre></td></tr></table></figure>
<p>2007_train.txt内容示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home/dpj/yolov3-master/data/images/val2014/Cow_1192.jpg</span><br><span class="line">/home/dpj/yolov3-master/data/images/val2014/Cow_1196.jpg</span><br><span class="line">.....</span><br></pre></td></tr></table></figure>
<p>注意images和labels文件架构一致性，因为txt是通过简单的替换得到的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">images -&gt; labels</span><br><span class="line">.jpg -&gt; .txt</span><br></pre></td></tr></table></figure>
<p>具体内容可以在datasets.py文件中找到详细的替换。</p>
<h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3. 训练模型"></a>3. 训练模型</h3><p>预训练模型：</p>
<ul>
<li><p>Darknet <code>*.weights</code> format: <a href="https://pjreddie.com/media/files/yolov3.weights">https://pjreddie.com/media/files/yolov3.weights</a></p>
</li>
<li><p>PyTorch <code>*.pt</code> format: </p>
<p><a href="https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0">https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0</a></p>
</li>
</ul>
<p>开始训练：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py --data data/coco.data --cfg cfg/yolov3.cfg</span><br></pre></td></tr></table></figure>
<p>如果日志正常输出那证明可以运行了</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/640.webp" alt></p>
<p>如果中断了，可以恢复训练</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py --data data/coco.data --cfg cfg/yolov3.cfg --resume</span><br></pre></td></tr></table></figure>
<h3 id="4-测试模型"><a href="#4-测试模型" class="headerlink" title="4. 测试模型"></a>4. 测试模型</h3><p>将待测试图片放到data/samples中，然后运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python detect.py --cfg cfg/yolov3.cfg --weights weights/best.pt</span><br></pre></td></tr></table></figure>
<p>目前该文件中也可以放入视频进行视频目标检测。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/641.webp" alt></p>
<ul>
<li>Image: <code>--source file.jpg</code></li>
<li>Video: <code>--source file.mp4</code></li>
<li>Directory: <code>--source dir/</code></li>
<li>Webcam: <code>--source 0</code></li>
<li>RTSP stream: <code>--source rtsp://170.93.143.139/rtplive/470011e600ef003a004ee33696235daa</code></li>
<li>HTTP stream: <code>--source http://wmccpinetop.axiscam.net/mjpg/video.mjpg</code></li>
</ul>
<h3 id="5-评估模型"><a href="#5-评估模型" class="headerlink" title="5. 评估模型"></a>5. 评估模型</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python test.py --weights weights/best.pt</span><br></pre></td></tr></table></figure>
<p>如果使用cocoAPI使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ python3 test.py --img-size 608 --iou-thr 0.6 --weights ultralytics68.pt --cfg yolov3-spp.cfg</span><br><span class="line"></span><br><span class="line">Namespace(batch_size=32, cfg=&#x27;yolov3-spp.cfg&#x27;, conf_thres=0.001, data=&#x27;data/coco2014.data&#x27;, device=&#x27;&#x27;, img_size=608, iou_thres=0.6, save_json=True, task=&#x27;test&#x27;, weights=&#x27;ultralytics68.pt&#x27;)</span><br><span class="line">Using CUDA device0 _CudaDeviceProperties(name=&#x27;Tesla V100-SXM2-16GB&#x27;, total_memory=16130MB)</span><br><span class="line">               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 157/157 [03:30&lt;00:00,  1.16it/s]</span><br><span class="line">                 all     5e+03  3.51e+04    0.0353     0.891     0.606    0.0673</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.615</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.437</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448</span><br><span class="line"> Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.337</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.438</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658</span><br><span class="line"> Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746</span><br></pre></td></tr></table></figure>
<p><strong>mAP计算</strong></p>
<ul>
<li>mAP@0.5 run at <code>--iou-thr 0.5</code>, mAP@0.5…0.95 run at <code>--iou-thr 0.7</code></li>
</ul>
<h3 id="6-可视化"><a href="#6-可视化" class="headerlink" title="6. 可视化"></a>6. 可视化</h3><p>可以使用<code>python -c from utils import utils;utils.plot_results()</code></p>
<p>创建drawLog.py</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def plot_results():</span><br><span class="line">    # Plot YOLO training results file &#x27;results.txt&#x27;</span><br><span class="line">    import glob</span><br><span class="line">    import numpy as np</span><br><span class="line">    import matplotlib.pyplot as plt</span><br><span class="line">    #import os; os.system(&#x27;rm -rf results.txt &amp;&amp; wget https://storage.googleapis.com/ultralytics/results_v1_0.txt&#x27;)</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(16, 8))</span><br><span class="line">    s = [&#x27;X&#x27;, &#x27;Y&#x27;, &#x27;Width&#x27;, &#x27;Height&#x27;, &#x27;Objectness&#x27;, &#x27;Classification&#x27;, &#x27;Total Loss&#x27;, &#x27;Precision&#x27;, &#x27;Recall&#x27;, &#x27;mAP&#x27;]</span><br><span class="line">    files = sorted(glob.glob(&#x27;results.txt&#x27;))</span><br><span class="line">    for f in files:</span><br><span class="line">        results = np.loadtxt(f, usecols=[2, 3, 4, 5, 6, 7, 8, 17, 18, 16]).T  # column 16 is mAP</span><br><span class="line">        n = results.shape[1]</span><br><span class="line">        for i in range(10):</span><br><span class="line">            plt.subplot(2, 5, i + 1)</span><br><span class="line">            plt.plot(range(1, n), results[i, 1:], marker=&#x27;.&#x27;, label=f)</span><br><span class="line">            plt.title(s[i])</span><br><span class="line">            if i == 0:</span><br><span class="line">                plt.legend()</span><br><span class="line">    plt.savefig(&#x27;./plot.png&#x27;)</span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    plot_results()</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/642.webp" alt></p>
<p><strong>7. 数据集配套代码</strong></p>
<p>如果你看到这里了，恭喜你，你可以避开以上略显复杂的数据处理。这里提供了一套代码，集成了以上脚本，只需要你有jpg图片和对应的xml文件，就可以直接生成符合要求的数据集，然后按照要求修改一些代码即可。</p>
<p>代码地址：<a href="https://github.com/pprp/voc2007_for_yolo_torch">https://github.com/pprp/voc2007_for_yolo_torch</a></p>
<p>请按照readme中进行处理就可以得到数据集。</p>
<blockquote>
<p>后记：这套代码一直由一个外国的团队进行维护，也添加了很多新的trick。目前已获得了3.3k个star，1k  fork。不仅如此，其团队会经常回复issue，目前也有接近1k的issue。只要处理过一遍数据，就会了解到这个库的亮点，非常容易配置，不需要进行编译等操作，易用性极强。再加上提供的配套数据处理代码，在短短10多分钟就可以配置好。(✪ω✪)</p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>RetinaNet（引入Focal Loss）</title>
    <url>/2020/03/06/RetinaNet%EF%BC%88%E5%BC%95%E5%85%A5Focal-Loss%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天来介绍一下目标检测算法中RetinaNet，这篇论文是CVPR2018的作品，Kaiming He大神也是作者之一，同时这篇论文提出的Focal  Loss也对工程上训练更好的目标检测模型做出了很大贡献，论文地址为：<a href="https://arxiv.org/pdf/1708.02002.pdf">https://arxiv.org/pdf/1708.02002.pdf</a></p>
<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>前面介绍了一些One-Stage目标检测算法和Two-Stage目标检测算法，这些算法在精度和速度上都各有特点，现在画个图总结一下之前介绍的各种算法的速度和精度：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/640.png" alt></p>
<p>可以看到One-Stage算法的精度相对于Two_Stage偏低，然后作者把这种问题的原因归结于<strong>正负类别不平衡</strong>（简单难分类别不平衡）。因此论文通过重新设计标准的交叉熵损失来解决这种难易样本不平衡的问题，即文章的核心Focal Loss。结合了Focal  Loss的One-Stage的目标检测器被称为RetinaNet，该检测器在COCO数据集上MAP值可以和FPN（特征金字塔目标检测器）和MaskRCNN接近。</p>
<h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><h3 id="什么是hard-esay-postive-negtive-example"><a href="#什么是hard-esay-postive-negtive-example" class="headerlink" title="什么是hard/esay postive/negtive example"></a>什么是hard/esay postive/negtive example</h3><p>网上找到一张图解释在目标检测任务的一张图中什么是hard/easy postive/negtive example。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/641.webp" alt></p>
<p>候选框可以分成postive/negtive两类。当bbox(由anchor加上偏移量得到)与ground  truth间的IOU大于我们设置的阈值（一般取0.5）时，会认为该bbox属于positive  example，如果IOU小于下门限就认为该bbox属于negative example。</p>
<h3 id="为什么One-Stage检测算法精度偏低"><a href="#为什么One-Stage检测算法精度偏低" class="headerlink" title="为什么One-Stage检测算法精度偏低"></a>为什么One-Stage检测算法精度偏低</h3><p>论文认为One-Stage算法准确度低是由于类别失衡引起的。因为在一张普通图片中，目标的所占的比例远远小于背景所占的比例，所以两类候选框例子中以negtive example为主。这就导致了：</p>
<ul>
<li>(1)针对所有的negtive example，数量过多造成它的loss太大，以至于主导了损失函数，不利于收敛。</li>
<li>(2)针对单个negtive example来说，大多数的negative example不在前景和背景的过渡区域上，分类很明确(这种易分类的negative称为easy  negative)，训练时对应的背景类score会很大，换句话说就是单个example的loss很小，反向计算时梯度小。梯度小造成easy  negative example对参数的收敛作用很有限，我们更需要loss大的对参数收敛影响也更大的example，即hard  positive/negative example。</li>
</ul>
<p>因此如果One-Stage算法如果无脑的将所有bbox拿去做分类损失，因为bbox中属于background的bbox太多了，所以如果分类器无脑地把所有bbox统一归类为background，accuracy也可以刷得很高。这就导致分类器训练失败了，自然检测精度就偏低了。对于YOLO和SSD来讲，他们也确实没有无脑将所有的bbox拿去做分类损失，如在SSD中利用Hard-Negtive-Mining的方式将正负样本的比例控制在1:3，YOLO通过损失函数中权重惩罚的方式增大正样本对损失函数的影响等。但它们虽然可以处理第1个问题，但对于第2个问题就无能为了，这也是Focal Loss出现的原因。</p>
<h3 id="Faster-RCNN为什么精度更高"><a href="#Faster-RCNN为什么精度更高" class="headerlink" title="Faster-RCNN为什么精度更高"></a>Faster-RCNN为什么精度更高</h3><p>Faster-RCNN在FPN阶段会根据前景分数提出最可能是前景的example，这就会滤除大量背景概率高的easy  negtive样本，这便解决了上面提出的第2个问题。同时，在生成样本给ROIPooling层的时候，会据IOU的大小来调整positive和negative example的比例，比如设置成1：3，这样防止了negative过多的情况(同时防止了easy negative和hard  negative)，就解决了前面的第1个问题。因此，相对于One-Stage检测器，Faster-RCNN的精度更高。</p>
<h2 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h2><p>论文引入了Focal Loss来解决<strong>难易样本数量不平衡</strong>。One-Stage的模板检测器通常会产生10k数量级的框，但只有极少数是正样本，正负样本数量非常不平衡。我们在计算分类的时候常用的损失——交叉熵的公式如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/651.JPG" alt></p>
<p>为了解决<strong>正负样本数量不平衡</strong>的问题，我们经常在交叉熵损失前面加一个参数$\alpha$，即：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/643.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/652.JPG" alt></p>
<p>虽然$\alpha$平衡了正负样本的数量，但实际上，目标检测中大量的候选目标都是易分样本。这些样本的损失很低，但是由于数量极不平衡，易分样本的数量相对来讲太多，最终主导了总的损失。</p>
<p>因此，这篇论文认为<strong>易分样本（即，置信度高的样本）对模型的提升效果非常小，模型应该主要关注与那些难分样本</strong> 。所以Focal Loss横空出世了。一个简单的想法就是只要我们将高置信度(p)样本的损失降低一些就好了吧？也即是下面的公式：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/644.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/653.JPG" alt></p>
<p>我们取$\gamma$等于2来只管感受一下，如果$p=0.9$，那么，$(1-0.9)^{2}=0.001$，损失降低了1000倍。从中，我们易看出focal loss所加的指数式系数可对正负样本对loss的贡献自动调节。当某样本类别比较明确些，它对整体loss的贡献就比较少；而若某样本类别不易区分，则对整体loss的贡献就相对偏大。这样得到的loss最终将集中精力去诱导模型去努力分辨那些难分的目标类别，于是就有效提升了整体的目标检测准度。</p>
<p>最终Focal Loss还结合了公式(2)，这很好理解，公式(3)解决了难易样本的不平衡，公式(2)解决了正负样本的不平衡，将公式(2)与(3)结合使用，同时解决正负难易2个问题！所以最终Focal Loss的形式如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/645.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/654.png" alt></p>
<p>下面这张图展示了Focal Loss取不同的$\gamma$时的损失函数下降。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/646.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/655.png" alt></p>
<p>实验结果展示，当$\gamma=2$，$\alpha=0.25$时，效果最好，这样损失函数训练的过程中关注的样本优先级就是正难&gt;负难&gt;正易&gt;负易了。</p>
<h2 id="RetinaNet"><a href="#RetinaNet" class="headerlink" title="RetinaNet"></a>RetinaNet</h2><p>说完了Focal Loss就回到文章RetinaNet，Focal Loss与ResNet-101-FPN  backbone结合就构成了RetinaNet（one-stage检测器），RetinaNet在COCO  test-dev上达到39.1mAP，速度为5FPS。下图展示了RetinaNet的网络结构：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/647.jpg" alt></p>
<p>训练RetinaNet时有几个值得注意的关键点：</p>
<ul>
<li>训练时FPN每一级的所有example都被用于计算Focal Loss，loss值加到一起用来训练。</li>
<li>测试时FPN每一级只选取score最大的1000个example来做nms。</li>
<li>整个结构不同层的head部分(上图中的c和d部分)共享参数，但分类和回归分支间的参数不共享。</li>
<li>分类分支的最后一级卷积的bias初始化成-log((1-π)/π)。这里π被指定在训练开始时，所有的anchor都需要被标注为带有π置信率的前景。这里取π=0.01，是为了防止在训练的第一个周期大量的背景anchors生成一个巨大的不稳定的loss值。</li>
</ul>
<p>RetinaNet和当时流行的检测算法速度和精度对比如下，可以看到从速度和精度都完成了对其他算法的压制：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/648.webp" alt></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>Table1是关于RetinaNet和Focal Loss的一些实验结果。其中(a)是在交叉熵的基础上加上参数$\alpha$，$\alpha=0.5$就表示传统的交叉熵，可以看出当$\alpha=0.75$的时候效果最好，AP值提升了0.9。(b)是对比不同的参数$\gamma$和$\alpha$的实验结果，可以看出随着$\gamma$的增加，AP提升比较明显。(c)是anchor对AP值的影响。(d)是通过和OHEM的对比可以看出最好的Focal  Loss比最好的OHEM提高了3.2AP。这里OHEM1:3表示在通过OHEM得到的minibatch上强制positive和negative样本的比例为1:3，通过对比可以看出这种强制的操作并没有提升AP。(e)加入了运算时间的对比，可以和前面的Figure2结合起来看，速度方面也有优势。Table2表示RetinaNet和One-Stage检测器的比较，可以看到RetinaNet也是毫不顺色的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RetinaNet/649.jpg" alt></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>keras版本：<a href="https://github.com/fizyr/keras-retinanet">https://github.com/fizyr/keras-retinanet</a><br>pytorch版本: <a href="https://github.com/yhenon/pytorch-retinanet">https://github.com/yhenon/pytorch-retinanet</a><br>caffe-focal loss: <a href="https://github.com/chuanqi305/FocalLoss">https://github.com/chuanqi305/FocalLoss</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>RCNN</title>
    <url>/2020/02/24/RCNN/</url>
    <content><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><h3 id="什么是目标检测"><a href="#什么是目标检测" class="headerlink" title="什么是目标检测"></a>什么是目标检测</h3><p>所谓目标检测就是在一张图像中找到我们关注的目标，并确定它的类别和位置，这是计算机视觉领域最核心的问题之一。由于各类目标不同的外观，颜色，大小以及在成像时光照，遮挡等具有挑战性的问题，目标检测一直处于不断的优化和研究中。</p>
<h3 id="目标检测算法分类"><a href="#目标检测算法分类" class="headerlink" title="目标检测算法分类"></a>目标检测算法分类</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/20180509095302426.png" alt></p>
<p>这张甘特图已经说明了目标检测算法主要分为两类，即：</p>
<ul>
<li>Two Stage目标检测算法。这类算法都是先进行区域候选框生成，就是找到一个可能包含物体的预选框，再通过卷积神经网络进行分类和回归修正，常见算法有R-CNN，SPP-Net，Fast-RCNN，Faster-RCNN和R-FCN等。</li>
<li>One Stage目标检测算法。这类算法不使用候选框生成，直接在网络中提取特征来预测物体的分类和位置。常见的One-Stage算法有：YOLO系列，SSD，RetinaNet。</li>
</ul>
<h2 id="RCNN算法"><a href="#RCNN算法" class="headerlink" title="RCNN算法"></a>RCNN算法</h2><h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><p>RCNN是第一个使用卷积神经网络来对目标候选框提取特征的目标检测算法。同时，RCNN使用了微调(finetune)的技术，使用大数据集上训练好的分类模型的前几层做backbone，进行更有效的特征提取。</p>
<h3 id="RCNN总览"><a href="#RCNN总览" class="headerlink" title="RCNN总览"></a>RCNN总览</h3><p>看下图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/Snipaste_2020-01-07_09-57-14.jpg" alt></p>
<p>首先，R-CNN是将传统图像算法和深度学习技术结合起来的结构，第一部分是需要候选框区域建议，这里一般使用Selective Search的方法提取出候选框，然后再传入CNN做特征提取及分类，后面还借助了机器学习算法做回归修正。</p>
<h3 id="RCNN算法步骤"><a href="#RCNN算法步骤" class="headerlink" title="RCNN算法步骤"></a>RCNN算法步骤</h3><ul>
<li>选择一个预训练 （pre-trained）神经网络（如AlexNet、VGG）。</li>
<li>重新训练全连接层。使用需要检测的目标重新训练（re-train）最后全连接层（connected layer）。即是fintune技术的应用。</li>
<li><p>生成候选框。利用Selective Search算法提取所有的Proposals，一张图片大概产生2000张，然后将图片规整化固定大小，使得其满足CNN的输入要求，最后将feature map存到磁盘(是的，你没有看错，RCNN要把提取到的特征存储到磁盘)，这个过程可以用下图表示：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RCNN/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200224135208.jpg" alt></p>
</li>
<li><p>利用feature map训练SVM来对目标和背景进行分类，这里每一个类一个二元SVM。</p>
</li>
<li><p>训练线性回归器修正目标的位置，如下图所示：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RCNN/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200224135251.jpg" alt></p>
</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RCNN/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20200224135256.jpg" alt></p>
<p>RCNN成为了当时目标检测领域的SOAT算法，虽然现在很少有人使用到了，但论文的思想我们仍可以借鉴。任何事情都要经历一个从无到有的过程。</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>rgbirshick大神，也就是RCNN作者，提供了源码，链接如下：<a href="https://github.com/rbgirshick/rcnn">https://github.com/rbgirshick/rcnn</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD算法的改进版Rainbow SSD</title>
    <url>/2020/04/19/SSD%E7%AE%97%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B%E7%89%88Rainbow-SSD/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这是BMVC 2017的一个SSD的改进算法R-SSD。这里先看一下SSD的网络结构图吧。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/640.png" alt></p>
<p>带有特征图维度信息的更清晰的骨干网络和VGG16的对比图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/641.png" alt></p>
<h2 id="出发点"><a href="#出发点" class="headerlink" title="出发点"></a>出发点</h2><p>一般来说，深度神经网络的特征图数量越多，我们获得的性能一般会更好。但是这并不一定代表着简单的增加特征图的数量就能使得效果变好，这一点在实验部分有说明。这篇论文在SSD的基础上并没有改变BackBone网络，即还是应用稍加修改的VGG16为BackBone。这篇论文的贡献是提出了新的特征融合方式来提升了SSD的效果，这一改进使得SSD可以充分利用特征，虽然速度稍慢于原始的SSD算法，但mAP却获得了较大的提升。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>传统的SSD算法通过不同层的特征来做检测，使得其对尺度变化有较好的鲁棒性，在速度和精度的Trade-Off上也做得比较好，但是SSD有2个明显的问题：</p>
<ul>
<li>在SSD中，不同层的特征图都是独立作为分类网络的输入，因此容易出现相同物体被不同大小的框同时检测出来的情况。</li>
<li>对小目标的检测效果比较差，当然这也是大多数目标检测算法的通病了。</li>
</ul>
<p>因此，这篇算法也主要从这两点出发来改进传统的SSD算法。首先，本文利用分类网络增加不同层之间的特征图联系，减少重复框的出现。然后，增加特征金字塔中特征图的个数，使得网络可以检测更多的小目标。下面的<code>Figure5(a),(c)</code>分别展示了SSD算法出现的上述2个问题，而<code>Figure5(b),(d)</code>分别展示了本文提出的R-SSD算法的改进效果图。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/642.png" alt></p>
<h2 id="Rainbow-SSD核心原理"><a href="#Rainbow-SSD核心原理" class="headerlink" title="Rainbow SSD核心原理"></a>Rainbow SSD核心原理</h2><p>下面的Figure3展示了几种不同的特征融合方式。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/643.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">几种不同的特征融合方式</div>
</center>

<p>我们来尝试解析一下这些图都表示什么？</p>
<ul>
<li><p><code>Figure3(a)</code>：这表示使用<code>pooling</code>方式的特征图融合，我们可以看到<code>(a)</code>最左边的38 x 38的特征图将其做一个<code>pooling</code>之后和接下来那个19 x 19的特征图进行concate，获得了那个一个红加一个橙的特征图。后面同理。</p>
</li>
<li><p><code>Figure3(b)</code>：这表示使用反卷积的方式进行特征融合，注意这里是从右边的1 x 1的紫色特征图往左做concate，因为反卷积是升维，所以从右至左。</p>
</li>
<li><p><code>Figure3(c)</code>：表示<strong>「同时使用Pooling和反卷积做特征融合。」</strong> 这个结构就是本文的Radinbow SSD的核心了，即同时从左至右（<code>pooling</code>，<code>concate</code>）和从右至左（<code>deconvolution</code>，<code>concate</code>）。</p>
</li>
</ul>
<p>可以看到Rainbow SSD里融合后的特征图色彩很像彩虹，这大概就是这个名字的由来了。另外一个关键点是<strong>「在做concate之前都会对特征图做一个normalization操作，因为不同层的特征图的scale是不同的，本文中的normalization方式采用Batch Normalization。」</strong></p>
<p>由于Figure3中的特征融合方式比较特殊，这就导致融合后的每一层特征图的个数都是相同的，都为2816，因此可以共享部分参数，具体来说就是default boxes的参数共享</p>
<p>下面的Table1展示了和SSD算法中的default boxes的数量对比。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/644.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">每一个分类网络(检测头)个数以及box的总个数</div>
</center>

<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>下面的Table3展示了不同的实验对比结果，同时Table2表示只在原始的SSD基础上增加不同特征层数量的<strong>「I-SSD」</strong>算法。通过Table3的实验结果可以看出虽然ISSD也获得了不错的效果，但是它的FPS却偏低。本文的Rainbow SSD效果和FPS都表现不错。R-FCN虽然效果不错，但是速度上不占优势。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/645.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">实验结果</div>
</center>

<p>下面的Figure4展示了在VOC 2007 test上的PR曲线。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/646.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">PR曲线，一般一个PR曲线包住另外一个说明这个模型更好</div>
</center>

<p>下面的Table4则展示了AP和mAP的详细对比。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/647.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">相比于原始的SSD，本文的Rainbow SSD提点明显</div>
</center>

<p>下面的Table5展示了不同Scale的目标召回率的对比，可以看到Rainbow SSD对小目标检测的召回率提升更加明显。</p>
<p><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/RSSD/648.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Rainbow SSD对小目标检测的召回率提升更加明显</div>
</center></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文提出了一种rainbow concatenation方式来组合特征，在增加不同层之间特征图关系的同时也增加了特征图的个数。<strong>「这种融合方式不仅解决了传统SSD算法存在的重复框问题，同时一定程度上解决了小目标的检测问题。」</strong></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD的改进版之DSSD</title>
    <url>/2020/04/19/SSD%E7%9A%84%E6%94%B9%E8%BF%9B%E7%89%88%E4%B9%8BDSSD/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>DSSD全称为<strong>Deconvolutional Single Shot Detector</strong>，即在SSD算法的前面加了一个反卷积单词，这是CVPR 2017的一篇文章，主要是对SSD进行了一个改进。</p>
<h2 id="DSSD算法的贡献"><a href="#DSSD算法的贡献" class="headerlink" title="DSSD算法的贡献"></a>DSSD算法的贡献</h2><p>这篇论文的主要贡献是在常用的目标检测算法中加入了上下文信息。换句话说，常规的目标检测算法一般都是在一个(YOLO，Faster-RCNN)或者多个特征图上进行检测（SSD），但是各个特征层之间的信息并没有有效的结合以及利用，DSSD的贡献正是解决了这一点。</p>
<h2 id="出发点"><a href="#出发点" class="headerlink" title="出发点"></a>出发点</h2><p>我们知道SSD最明显的缺点就是对小目标不够鲁棒，原因是什么呢？我们知道SSD为了解决小目标检测的思路是在尽量多的特征层上进行检测，来更好的匹配小目标，因为分辨率越大的特征图小目标的空间信息就保留得越多。但是，这样做有个问题，那<strong>就是浅层提取的特征图表达能力不够强，也即是说浅层特征图中每个格子也可以判断这个格子中包含的是哪一个类，但是不够那么确定</strong>。具体来说有可能出现 框对了，但是分类出错或者置信度不够好或者将背景误认为目标等等，也就是说SSD同样还是存在误检和漏检的情况。这种情况对于小目标场景出现的概率更大，因此SSD对于小目标的检测仍然不够鲁棒。</p>
<h2 id="DSSD的网络结构"><a href="#DSSD的网络结构" class="headerlink" title="DSSD的网络结构"></a>DSSD的网络结构</h2><p>SSD和DSSD的网络结构如Figure1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/Snipaste_2020-01-08_16-00-32.jpg" alt></p>
<p>经过上一节的分析我们知道SSD对小目标不够鲁棒的主要原因就是特征图的表征能力不够强。为了解决这一点，DSSD就使用了更好的BackBone网络（ResNet）和反卷积层，跳跃链接来给浅层特征图更好的表征能力。那么具体是怎么做的呢？</p>
<p>既然DSSD算法的核心就是提高浅层特征图的表征能力，首先想到的肯定是将基础网络由VGG换成ResNet，下面的Table2说明了在VGG和ResNet上哪些层作为最后的预测特征图。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/640.png" alt></p>
<p>另外需要注意的是这些层可不是随便选择的，大致要和VGG相互对应感受野也要对应，这样才能保证效果会变好，不然也有可能会变差。下面Table3中的实验结果也展示出了浅层的特征更具有表示能力时，在小目标上的效果就会更好。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/641.png" alt></p>
<p>图片大小不够的时候，ResNet的SSD和VGG的SSD效果其实相当，整体甚至还会稍微差一些，到了512*512的尺度上时，ResNet的下过就明显要好了。尤其是标粗的小目标（bird）。</p>
<h2 id="预测模块"><a href="#预测模块" class="headerlink" title="预测模块"></a>预测模块</h2><p>基于ResNet的实验还有一点就是修改网络的预测模块，作者使用了4种不同的预测模块，如Figure2所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/Snipaste_2020-01-08_16-11-49.jpg" alt></p>
<p>从下面的Table4可以看到这确实提升了效果，并且c这种结构比d这种结构更好一些，<strong>这个设计的灵感据说来自于MS-CNN，它指出改善每个任务的分支网络同样可以提高准确率</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/642.png" alt></p>
<p>注意最后一行是使用了<strong>approximate bilinear pooling</strong>(CVPR 2016)的结果。</p>
<h2 id="反卷积模块"><a href="#反卷积模块" class="headerlink" title="反卷积模块"></a>反卷积模块</h2><p>在SSD的网络结构图中的：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/645.png" alt></p>
<p>就代表了本文的主要创新点，即反卷积模块，它的具体结构如Figure3所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/Snipaste_2020-01-08_16-17-17.jpg" alt></p>
<p>这个模块里面被红色框部分圈住的可以有两种连接方式，Eltw Product其实就是矩阵的点积，还有sum的形式就是求和。上一节的Table4展示了这两种操作的精度差距，相关部分截图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/643.png" alt></p>
<p>将ResNet，反卷积模块和预测模块结合在一起就构成了最终的DSSD算法。</p>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>在实验时，使用SSD模型初始化DSSD网络，但是对于default box选取的长宽比例，作者在论文中做了详细的分析和改进。为了得到PASCAL VOC 2007和2012  trainval图片里各个物体对应的真实位置框的长宽比例，作者用K-means以这些真实框内区域面积的平方根作为特征做了一个聚类分析，做聚类的时候增加聚类的个数来提升聚类的准确度，最后确定七类的时候收敛的错误率最低如Table1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSSD/644.png" alt></p>
<p>因为SSD训练时使用的训练图片会重新调整比例变成方形的尺寸，但是在大多数的训练图片都是比较宽的图片，所以相应的真实框的宽度会变小一点。通过这种聚类实验最后确定了预测使用的default box的长宽比例为1、1.6、2和3，作为每一个特征图的default box所使用的长宽比例。</p>
<p>DSSD的作者WeiLiu大神在Caffe框架中将SSD的基础网络改成ResNet101然后重新训练了一个新的SSD模型，以VOC的数据集为例，训练集使用的数据是VOC2007和VOC2012的trainval数据集，测试用的是07的测试集，训练时一共迭代了70k次，使用学习率为1e-3在前40k次iterations，然后调整学习率为1e-4、1e-5再分别训练20k次、10k次iterations。然后用用训练好的SSD模型来初始化DSSD网络。训练DSSD的过程分为两个阶段，第一个阶段，加载SSD模型初始化DSSD网络，并冻结SSD网络的参数，然后只增加反卷积模型(不添加预测模型)，在这样的条件下只训练反卷积模型，设置学习率为1e-3、1e-4分别迭代20k次和10k次；第二个阶段，fine-tune第一阶段的模型，解冻第一阶段训练时候冻结的所有参数，并添加预测模型，设置学习率为1e-3、1e-4再分别训练20k次、20k次iterations。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文表达出，提升浅层特征图的表达能力是可以提高类似的目标检测器对小目标的检测能力的，可以作为我们思考的一个方向。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorRT安装</title>
    <url>/2022/01/07/TensorRT%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="安装PyCuda"><a href="#安装PyCuda" class="headerlink" title="安装PyCuda"></a>安装PyCuda</h2><p>如果通过Python使用TensorRT的话，需要安装PyCuda，只需要执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install pycuda</span><br></pre></td></tr></table></figure>
<p>(注：本人测试环境为Ubuntu16.04，在安装过程中发现PyCuda新版本会编译失败，而<code>pycuda&lt;=2019.1</code>则正常。)</p>
<p>若安装出现问题，需手动编译，可参照<a href="https://wiki.tiker.net/PyCuda/Installation/Linux/">官网</a>教程：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/inducer/pycuda.git # 测试时新版本为2020.1</span><br><span class="line">tar xfz pycuda-VERSION.tar.gz</span><br><span class="line">cd pycuda-VERSION</span><br><span class="line">pip3 install numpy==1.20rc   # 此处一定要注意版本,本人刚开始安装了1.19,一直不成功</span><br><span class="line">python configure.py --cuda-root=/where/ever/you/installed/cuda  # 修改为自己cuda的路径</span><br><span class="line">su -c &quot;make install&quot;</span><br><span class="line"></span><br><span class="line"># 测试</span><br><span class="line">cd pycuda-VERSION/test</span><br><span class="line">python test_driver.py    # &quot;OK&quot;则通过</span><br></pre></td></tr></table></figure>
<h2 id="安装TensorRT"><a href="#安装TensorRT" class="headerlink" title="安装TensorRT"></a>安装TensorRT</h2><p>官方推荐安装cuda10.2或者11.0以上，cuda版本不对的请自行更换。这里推荐安装TensorRT 7.2.3.4及以上版本，太早的版本很多算子不支持，容易踩坑。</p>
<p>以TensorRT 7系列为例，去<a href="https://link.zhihu.com/?target=https%3A//developer.nvidia.com/nvidia-tensorrt-7x-download">官网</a>选择合适版本下载</p>
<p>① 解压缩</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar xzvf TensorRT-7.2.3.4.Ubuntu-16.04.x86_64-gnu.cuda-10.2.cudnn8.1.tar.gz</span><br></pre></td></tr></table></figure>
<p>② 安装TensorRT wheel 文件，根据python版本选择，这里是python3.6</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd TensorRT-7.2.3.4/python</span><br><span class="line">pip install tensorrt-7.2.3.4-cp36-none-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
<p>③ 安装graphsurgeon wheel文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd TensorRT-7.2.3.4/graphsurgeon</span><br><span class="line">pip install graphsurgeon-0.4.5-py2.py3-none-any.whl</span><br></pre></td></tr></table></figure>
<p>④ 配置环境变量</p>
<p>编辑<code>~/.bashrc</code>文件，在文末添加以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=/home/用户名/TensorRT-7.2.3.4/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>(注：自己换成TensorRT-7.2.3.4所在路径)</p>
<p>配置生效：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>TensorRT</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD</title>
    <url>/2020/02/29/SSD/</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>本文提出了仅需要单个卷积神经网络就能完成目标检测的算法，并命名为SSD(Single Shot Detector)。SSD算法将目标框的输出空间离散化为一组在每个特征图位置不同大小和形状的默认框。预测时，网络对位于每个默认框类的物体类别进行打分，并修正默认框位置来更好的匹配物体的位置。此外，SSD网络在不同分辨率的特征图上预测，这样就可以处理大小不同的物体。SSD比那些需要搜索物体候选框的算法简单，因为它完全去除了proposal生成和随后的特征再筛选的过程，把所有的计算封装在一个网络里面。这使得SSD训练起来很容易，可以直接加入到检测系统里面。在PASCAL VOC，COCO,和ILSVRC数据集上的实验也证明，与那些需要object  proposal的算法相比，SSD在保证准确性的同时，速度更快。SSD只需一个完整的框架来训练和测试。在NVIDIA Titan  X对于一个大小是300 x 300的输入图像，SSD在VOC2007测试上的MAP是74.3%，速度是59FPS。对于512 x 512的输入，SSD的MAP是76.9%，比Faster RCNN更准。和其他单阶段的方法比，即便是输入较小的图像，SSD的准确性也会更高。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>目前，目标检测系统基本采用以下的流程：假设物体边框，对每个边框内进行特征再采样，最后使用分类器进行分类。这个流程比较流行，基于Faster-RCNN的方法通过选择性搜索在PASCAL VOC,  COCO和ILSVRC上检测效果都很好。但是这些方法对于嵌入式设备来说计算量过大，甚至需要高端硬件的支持，对于实时系统来说太慢。最快的检测器Faster  RCNN的检测速度也只能到7FPS。人们尝试了很多其他方法来构建更快的检测器，但是增加速度大多以损失检测精度为代价。本文提出了基于目标检测器的网络(object detector)，它不需要为边框进行搜索，但是精度却不降反升。此方法实现了高精度和高速度，在VOC2007  上的测试速度是59FPS，mAP是74.3%；而Faster  R-CNN的mAP是73.2%，速度是7FPS；YOLO的mAP是63.4%，速度的是45FPS。速度的提升得益于去除了边框提议(RPN或者Selective  Search)和随后的特征再采样。使用了一个小卷积滤波器来预测目标分类和边框位置的偏移，对于不同横纵比检测使用不同的滤波器去处理，然后把这些滤波器应用在后面网络阶段的特征图上，这是为了用检测器检测不同比例的图片，这样我们在相对低分辨率的图像上也能获得高精度的输出，还提升了检测速度。本文的贡献如下：</p>
<ul>
<li>提出了SSD算法—-多类别单阶检测器， 要比其它的单阶段检测器（YOLO）快，而且更准确；</li>
<li>SSD的核心部分是，在特征图上应用小卷积滤波器，预测分类得分和一个固定集合的默认边界框的偏移；</li>
<li>为了实现高检测精度，在不同比例的特征图上产生不同的预测，通过纵横比来分开预测；</li>
<li>以上的设计可以端到端训练，精度还高，甚至在低分辨率的图像上效果也不错；</li>
<li>关于速度和精度的试验，主要在PASCAL VOC, COCO 和 ILSVRC数据集上进行，与其它方法进行比较。</li>
</ul>
<h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>SSD基于前馈式卷积神经网络，针对那些方框里的目标检测实例，产生一个固定大小边界框集合和分数，紧接着是一个非极大值抑制步骤来产生最后的检测。网络前半部分是个标准结构(用于高质量图片分类)，成为基网络。然后对网络增加了辅助结构来实现以下特征：</p>
<ul>
<li><p><strong>多比例特征图检测</strong>：在基网络后增加卷积特征层，这些层按大小减少的次序连接，能够进行多尺度预测。</p>
</li>
<li><p><strong>卷积检测预测器</strong>：通过一个卷积滤波器集合，每个新增的特征层可以产生一个预测集合。假设特征层大小为m x n，p个通道，预测参数的基本单元是一个3 x 3 x p的小核，它要么产生一个类别的得分，要么产生一个相对于默认方框的位置偏移。核一共要应用在m x n个位置上，在每个位置上它都有一个输出值。边界框的偏移输出值是相对于默认的位置的。</p>
</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/Snipaste_2020-01-08_14-51-11.jpg" alt></p>
<ul>
<li><strong>默认方框和纵横比</strong>：将每个特征图单元(cell) 与默认边界框的集合关联起来，这是对于网络顶层的多特征图来说的。默认方框用卷积的方式覆盖特征图，这样，每个方框对应的单元(cell)是固定的。在每个特征映射单元上，我们预测相对于默认方框形状的偏移，以及每一类别的分数（表明每一个方框中一个类的出现）。在给定的位置有k个框，对于其中的每一个，计算c类类别的分数，和相对于原来默认方框形状的4个偏移。这就一共有(c + 4) x k个滤波器被应用到特征图的每个位置上；对于m x n的特征图，产生(c + 4) x k x m x n个输出。默认方框跟Faster R-CNN中的Anchor类似，但是作者将它们应用到不同分辨率的特征图上时，由于在一些特征图上有不同的默认框形状，这使得算法对不同尺度的目标有较好的探测作用。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/640.jfif" alt><br>SSD在训练中只需一张输入图像和图像中每个目标的ground truth边界框信息。在卷积操作中，我们产生一个默认方框的集合，这些方框在每个位置有不同的纵横比，在一些特征图中有不同的比例，如上图所示。对于每个默认方框，预测它形状的偏移和类别的置信度$\left(c_{1}, c_{2}, c_{3}, \dots, c_{p}\right)$。训练时，首先将这些默认方框和 ground truth 边界框对应上。就像图中，作者匹配了2个默认方框，一个是猫，一个是狗，它们被认定为positive, 其余部分被认定为 negative. 模型损失函数是 localization loss(smooth L1) 和 confidence  loss(Softmax) 的加权之和。</li>
</ul>
<h2 id="怎么设置default-boxes？"><a href="#怎么设置default-boxes？" class="headerlink" title="怎么设置default boxes？"></a>怎么设置default boxes？</h2><p>SSD中default box的概念有点类似于Faster R-CNN中的anchor。不同于Faster  R-CNN只在最后一个特征层取anchor，SSD在多个特征层上取default box，可以得到不同尺度的default  box。在特征图的每个单元上取不同宽高比的default  box,一般宽高比在{1，2，3，1/2，1/3}中选取，有时还会额外增加一个宽高比为1但具有特殊尺度的box。上面那张图展示了在8 x 8的feature map和4 x 4的feature map上的每个单元取4个不同的default box。原文对于300 x 300的输入，分别在conv4_3，conv7，conv8_2，conv9_2，conv10_2，conv11_2的特征图上的每个单元取4，6，6，6，4，4个default  box.  由于以上特征图的大小分别是38x38，19x19，10x10，5x5，3x3，1x1，所以一共得到38 x 38 x 4 + 19 x 19 x 6 + 10 x 10 x 6 + 5 x 5 x 6 + 3 x 3 x 4 + 1 x 1 x 4 = 8732个default box.对一张300x300的图片输入网络将会针对这8732个default  box预测8732个边界框。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练SSD和训练其他使用区域提议检测器的主要区别是，ground  truth信息在固定检测器输出的情况下需要指定到特定的输出。这样，损失函数和反向传播就可以端到端的应用。训练需要选择默认方框的集合，检测比例，以及hard negative mining（也就是不存在目标的样本集合）和数据增强策略。</p>
<ul>
<li><p><strong>Matching strategy</strong>， 在训练中，需要决定哪个默认框匹配一个 ground truth，由此来训练网络。对于每个从默认方框（不同位置，不同纵横比，不同比例上）中选择的 ground truth 边界框，开始时，根据最高的 jaccard overlap 来匹配 ground truth  边界框和默认方框（与MultiBox一样）。实际操作中，与 MultiBox 不同，当它们的 jaccard  overlap高于阈值0.5时，作者就将默认方框认为 ground  truth。这简化了学习问题，使得网络可以对多个重叠的默认方框预测得到高分，而不是仅挑选一个重合度最高的方框。</p>
</li>
<li><p><strong>Training objective</strong>， SSD的训练目标来自于MultiBox，但是作者将之扩展成可处理多目标分类的问题。$x_{i j}^{p}=1,0$表示匹配第$i$个默认方框和$p$类别第$j$个ground truth边界框。这种匹配策略会出现$\sum_{i} x_{i, j}^{p}&gt;=1$。整体的目标损失函数是定位损失加分类损失： $L(x, c, l, g)=\frac{1}{N}\left(L_{c o n f}(x, c)+\alpha L_{l o c}(x, l, g)\right)$，其中$N$是匹配默认框的个数，如果$N=0$，loss设为0。定位损失是预测边界框$l$和真值边界框参数$g$的Smooth L1 loss。与Faster R-CNN类似，对默认边界框$d$中心$(cx, cy)$的偏移量进行回归，$w$是宽，$h$是高。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/641.webp" alt><br>分类损失是多个类别置信度的 softmax loss：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/642.webp" alt><br>$\alpha$在交叉验证中设为1。</p>
</li>
<li><p><strong>Choosing scales and aspect ratio for default boxes</strong>，为了处理不同的目标比例，有些方法是把图片处理成不同的大小，然后结合不同大小图片的结果。但是在一个网络中利用多个不同层产生的特征图来预测也能产生类似的结果，所有比例的目标还可以共享参数。前面的研究已经证明使用底层的特征图可以提升语义分割质量，因为底层能捕捉到输入图像中的细节信息。受这些方法启发，本文使用了特征图中的高层和低层特征来进行目标检测。网络中不同层级的特征图会有不同的感受野，在SSD中，默认框不一定要和每层中的实际感受野对应。假设我们要用$m$个特征图来预测，每个特征图的默认框尺度计算如下：$s_{k}=s_{\min }+\frac{s_{\max }-s_{\min }}{m-1}(k-1, k \in[1, m])$ ，其中$s_{m i n}$是0.2，$s_{m a x}$是0.9，意味着最低的层的尺度是0.2，最高的层的尺度是0.9，中间层正常间隔分布。对于默认框，使用不同的高宽比，$a_{r} \in 1,2,3, \frac{1}{2}, \frac{1}{3}$。可以计算每个默认框的宽度$w_{k}^{a}=s_{k} \sqrt{a}_{r}$和高度$h_{k}^{a}=s_{k} / \sqrt{a_{r}}$。对于宽高比是1的情况，增加一个尺度是$s_{k}^{\prime}=\sqrt{s_{k} s_{k+1}}$的默认框，这样就在每个特征图位置有6个默认框。将框的中心设为$\left(\frac{i+0.5}{\left|f_{k}\right|}, \frac{j+0.5}{\left|f_{k}\right|}\right)$，其中$\left|f_{k}\right|$是第$k$个正方形特征图的大小。结合诸多特征图的不同位置下所有不同尺度和宽高比的默认框，就有了一个预测结果的集合，覆盖不同大小和形状的输入对象。例如图一中，那条狗与特征图中4 x 4的默认框匹配，但是不和任何8 x 8特征图中的默认框匹配，因为这些默认框有着不同的尺度，与狗的默认框不匹配，因此在训练中被认为是negative。</p>
</li>
<li><p><strong>Hard Negative Mining</strong> ，匹配步骤后，默认框中的大多数都是negative，尤其是候选框个数众多的时候。这就导致 positive 和 negative 训练样本不平衡。这些 negative 样本不全用，而是对于每一个默认框，通过最高置信度损失来对它们进行排序，选择最高的几个，这样negative 和 positive的比例最多是3:1。这样训练更稳定也更快。</p>
</li>
<li><p><strong>Data augmentation</strong> 为了让模型对不同的输入大小和形状更鲁棒，每张训练图片都通过以下步骤随机选择：(1)使用整张原始图片输入；(2)选择图片中的一块，与物体最低的  jaccard overlap 值为0.1, 0.3, 0.5, 0.7,  0.9；(3)随机采样某一块。采样区块的大小在原图片[0.1,1]之间，高宽比介于0.5和2之间。保留真值边界框中的重叠部分，如果它的中心在采样区块内。在采样步骤后，每个采样区块缩放到固定大小，以0.5的概率来水平翻转。</p>
</li>
</ul>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>在PSCAL VOC2012上面：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/643.webp" alt></p>
<p>在COCO数据集上面：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/644.webp" alt></p>
<p>速度和精度的整体对比：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSD/645.png" alt></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>SSD优势是速度比较快，整个过程只需要一步，首先在图片不同位置按照不同尺度和宽高比进行密集抽样，然后利用CNN提取特征后直接进行分类与回归，所以速度比较快，但均匀密集采样会造成正负样本不均衡的情况使得训练比较困难，导致模型准确度有所降低。另外，SSD对小目标的检测没有大目标好，因为随着网络的加深，在高层特征图中小目标的信息丢失掉了，适当增大输入图片的尺寸可以提升小目标的检测效果。</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><a href="https://github.com/weiliu89/caffe/tree/ssd">https://github.com/weiliu89/caffe/tree/ssd</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu clash配置</title>
    <url>/2020/02/05/Ubuntu-clash%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="1-下载安装包"><a href="#1-下载安装包" class="headerlink" title="1. 下载安装包"></a>1. 下载安装包</h2><p>执行 <code>cd &amp;&amp; mkdir clash</code>在用户目录下创建 clash 文件夹，用于存放解压后的文件及配置文件,将下载的压缩文件解压至此，得到一个可执行文件“ clash-linux-amd64 ”。</p>
<p>一般个人的64位电脑下载 clash-linux-amd64.tar.gz 即可。</p>
<p><a href="https://github.com/Dreamacro/clash/releases">下载客户端</a><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/windows-cfw-1.png" alt></p>
<h2 id="2-初始化配置"><a href="#2-初始化配置" class="headerlink" title="2. 初始化配置"></a>2. 初始化配置</h2><p>在终端中执行该文件<code>sudo ./clash-linux-amd64</code>，提示缺少config.yml配置文件，并自动生成/home/当前用户ID/.config/clash文件夹，其中包含两个文件 config.yml 和 Country.mmdb ，若看不到这文件夹，则按<code>ctrl+H</code>显示隐藏文件。其中 Country.mmdb由于墙的原因下载较慢，这里提供<a href="https://quqi.gblhgk.com/s/2796382/PtRJqrmJaeM9Nh17">网盘下载</a>，直接拷贝进/home/当前用户ID/.config/clash中。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp Country.mmdb的路径 ~/home/当前用户ID/.config/clash</span><br></pre></td></tr></table></figure></p>
<h2 id="3-编辑配置"><a href="#3-编辑配置" class="headerlink" title="3. 编辑配置"></a>3. 编辑配置</h2><p>编辑/home/当前用户ID/.config/clash下的 config.yml配置文件，内容为自己的服务器及规则等信息(有些商家会提供相应的yml文件，下载后将内容copy至该文件)，保存更改后复制该文件至先前创建的Clash文件夹(by:这两个文件夹不要弄混，一个是手动建立的，一个是自动创建的，都需要.yml文件)。</p>
<p>在终端 cd 到 Clash 二进制文件所在的目录，执行下载 Clash 配置文件，得到商家提供的服务器及规则等信息<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/linux-clash-2.jpg" alt></p>
<p>将其在/home/当前用户ID/.config/clash下复制一份<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp ~/home/当前用户ID/clash/config.yml ~/home/当前用户ID/.config/clash</span><br></pre></td></tr></table></figure></p>
<h2 id="4-加载配置"><a href="#4-加载配置" class="headerlink" title="4. 加载配置"></a>4. 加载配置</h2><p>重启终端，执行 <code>sudo ./clash-linux-amd64</code>以加载配置文件</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/linux-clash-3.jpg" alt></p>
<h2 id="5-端口访问"><a href="#5-端口访问" class="headerlink" title="5. 端口访问"></a>5. 端口访问</h2><p>访问 <a href="http://clash.razord.top/">Clash Dashboard </a> 可以进行切换节点、测延迟等操作。</p>
<p>Host: <code>127.0.0.1</code>，端口: <code>9090</code><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/linux-clash-4.jpg" alt></p>
<h2 id="6-启动代理"><a href="#6-启动代理" class="headerlink" title="6. 启动代理"></a>6. 启动代理</h2><p>以 Ubuntu 19.04 为例，打开系统设置，选择网络，点击网络代理右边的 ⚙ 按钮，选择手动，填写 HTTP 和 HTTPS 代理为 <code>127.0.0.1:7890</code>，填写 Socks 主机为 <code>127.0.0.1:7891</code>，即可启用系统代理。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/linux-clash-5.jpg" alt></p>
<p>若需关掉代理，则<code>ctrl+c</code>停止终端，并在系统代理设置中重新改为无即可。</p>
<h2 id="7-固定任务栏"><a href="#7-固定任务栏" class="headerlink" title="7. 固定任务栏"></a>7. 固定任务栏</h2><p>若需固定到启动器，则选择合适的图片文件，用作图标，放置于创建的clash文件夹下</p>
<p>使用<code>sudo gedit /usr/share/applications/Clash.desktop</code>在 /usr/share/applications/ 中创建一个文件 Clash.desktop ，步骤及内容如下：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 以下各项根据自己的情况填写</span><br><span class="line">[Desktop Entry]</span><br><span class="line"> Version=0.17.0</span><br><span class="line"> Name=Clash</span><br><span class="line"> Comment=A rule-based tunnel in Go</span><br><span class="line"> Exec=/full/path/to/clash-linux</span><br><span class="line"> Icon=/full/path/to/clash-logo.png</span><br><span class="line"> Terminal=false</span><br><span class="line"> Type=Application</span><br><span class="line"> Categories=Network</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>关键词说明</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Desktop Entry] 文件头</span><br><span class="line">Version    版本</span><br><span class="line">Name    应用名称</span><br><span class="line">Name[xx]    不同语言的应用名称</span><br><span class="line">Comment 注释</span><br><span class="line">Exec    执行文件路径</span><br><span class="line">Icon    图标路径</span><br><span class="line">Terminal    是否使用终端</span><br><span class="line">Type    启动器类型</span><br><span class="line">Categories  应用的类型（内容相关）</span><br></pre></td></tr></table></figure>
<p>上述操作完成后，即可在启动器中看到该应用图标，对其右键单击，选择固定到任务栏，方便以后打开 。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/clash/Snipaste_2020-02-05_23-07-03.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 16.04下配置GPU版CUDA和cuDNN</title>
    <url>/2019/12/14/Ubuntu-16.04%E4%B8%8B%E9%85%8D%E7%BD%AEGPU%E7%89%88CUDA%E5%92%8CcuDNN/</url>
    <content><![CDATA[<p>先介绍下我自己配置的环境</p>
<ul>
<li>Ubuntu 16.04</li>
<li>GTX2080ti显卡</li>
<li>NVIDIA 418.3</li>
<li>CUDA 10.0</li>
<li>cuDNN 7.6.2</li>
</ul>
<p>以下教程针对从零开始的用户，若系统中已装有CUDA和cuDNN，却在当前用户下无法使用，请<a href="#添加环境变量">添加环境变量</a></p>
<h2 id="安装NVIDIA显卡驱动"><a href="#安装NVIDIA显卡驱动" class="headerlink" title="安装NVIDIA显卡驱动"></a>安装NVIDIA显卡驱动</h2><p>1.先在<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">NVIDIA官网</a>上下载对应的驱动程序，可根据自己的GPU的型号下载相应的.run文件<br>例如NVIDIA-Linux-x86_64-3xx.xx.run形式的文件名</p>
<p>2.禁用开源nouveau驱动<strong>（非常重要）</strong><br>Ubuntu系统集成的显卡驱动程序是nouveau，它是第三方为NVIDIA开发的开源驱动，我们需要先将其屏蔽才能安装NVIDIA官方驱动。<br>将驱动添加到黑名单blacklist.conf中，但是由于该文件的属性不允许修改。所以需要先修改文件属性。<br>查看属性<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ls -lh /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><br>修改属性<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod 666 /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><br>用gedit编辑器打开<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><br>在该文件后添加一下几行：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blacklist vga16fb</span><br><span class="line">blacklist nouveau</span><br><span class="line">blacklist rivafb</span><br><span class="line">blacklist rivatv</span><br><span class="line">blacklist nvidiafb</span><br></pre></td></tr></table></figure><br>3.开始安装<br>先按Ctrl + Alt + F1到控制台，关闭当前图形环境<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service lightdm stop</span><br></pre></td></tr></table></figure><br>再安装驱动程序<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod a+x NVIDIA-Linux-x86_64-xxx.run</span><br><span class="line">sudo ./NVIDIA-Linux-x86_64-xxx.run -no-x-check -no-nouveau-check -no-opengl-files</span><br></pre></td></tr></table></figure><br>最后重新启动图形环境<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service lightdm start</span><br></pre></td></tr></table></figure><br>在终端里输入：nvidia-smi ，输出以下图片的代码则安装成功<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CUDA%26cuDNN/2019051413224071.png" alt></p>
<h2 id="cuda-10-0安装"><a href="#cuda-10-0安装" class="headerlink" title="cuda 10.0安装"></a>cuda 10.0安装</h2><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">官方下载</a><br><a href="https://pan.baidu.com/s/1piTbzIIL3wTx1dCeUDDiOw">网盘下载</a> 提取码: aarn<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod a+x cuda_10.0.130_410.48_linux.run // 获取权限</span><br><span class="line">sudo sh cuda_10.0.130_410.48_linux.run --tmpdir=/home/max/temp</span><br></pre></td></tr></table></figure><br>这里加 —tmpdir 主要是直接运行后，会提示空间不足的问题<br>接下来进入英文选择界面按住空格键可以快速浏览<br>在安装过程中选项选择：<br>accept #同意安装<br>n #不安装Driver，因为已安装驱动<strong>（这里需要强调一下）</strong><br>y #安装CUDA Toolkit</p>
<h1 id="安装到默认目录"><a href="#安装到默认目录" class="headerlink" title="安装到默认目录"></a>安装到默认目录</h1><p>y #创建安装目录的软链接<br>n #不复制Samples，因为在安装目录下有/samples</p>
<h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><p>home文件下 ctrl+H显示隐藏文件 打开 .bashrc文件在最后添加<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-10.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure><br>终端运行如下命令，保存操作<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><br>检查cuda是否安装成功<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvcc -V</span><br><span class="line">nvcc --version</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CUDA%26cuDNN/20190514132130343.png" alt></p>
<h2 id="cuDnn-10-0安装"><a href="#cuDnn-10-0安装" class="headerlink" title="cuDnn 10.0安装"></a>cuDnn 10.0安装</h2><p><a href="https://developer.nvidia.com/rdp/cudnn-archive">官方下载</a><br><a href="https://www.jianguoyun.com/p/DdS0_A4QlZ_3Bhjw8LEC">网盘下载</a><br>注意：需跟CUDA版本对应<br>切换到下载目录进行解压：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo tar -zxvf ./cudnn-10.0-linux-x64-xxx.tgz </span><br></pre></td></tr></table></figure><br>解压下载的文件，可以看到cuda文件夹，在当前目录打开终端，执行如下命令：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include/</span><br><span class="line"> </span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/</span><br><span class="line"> </span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h</span><br><span class="line"> </span><br><span class="line">sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure><br>在终端输入<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</span><br></pre></td></tr></table></figure><br>如果出现下图所示版本信息，说明安装成功<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/CUDA%26cuDNN/20180815114007852.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Python</tag>
        <tag>CUDA</tag>
        <tag>cuDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu16.04下Tensorflow-gpu安装</title>
    <url>/2019/12/14/Ubuntu16.04%E4%B8%8BTensorflow-gpu%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>在开始之前，请先确定安装好显卡驱动、CUDA、cuDNN，可以参考我的<a href="https://qiyuan-z.github.io/2019/03/19/Ubuntu-16.04下配置GPU版CUDA和cuDNN/">另一篇博客</a></p>
<ol>
<li>安装Numpy<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install numpy</span><br></pre></td></tr></table></figure></li>
<li>安装Tensorflow-gpu<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install tensorflow-gpu</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Python</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下pip安装numba</title>
    <url>/2020/05/18/Ubuntu%E4%B8%8Bpip%E5%AE%89%E8%A3%85numba/</url>
    <content><![CDATA[<h2 id="错误提醒"><a href="#错误提醒" class="headerlink" title="错误提醒"></a>错误提醒</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: No module named numba</span><br></pre></td></tr></table></figure>
<h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><p>注意：在安装numba之前必须安装llvm</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install llvm-8*</span><br></pre></td></tr></table></figure>
<p>导入环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alias llvm-config=&quot;llvm-config-8&quot;</span><br><span class="line">export LLVM_CONFIG=&quot;/usr/bin/llvm-config-8&quot;</span><br></pre></td></tr></table></figure>
<p>然后安装llvm</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install llvmlite</span><br></pre></td></tr></table></figure>
<p>最后安装numba</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numba</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下Rime安装配置</title>
    <url>/2020/01/26/Ubuntu%E4%B8%8BRime%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>官方网站及文档：<a href="https://rime.im/">https://rime.im/</a><br>输入法平台：iBus</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install ibus-rime</span><br></pre></td></tr></table></figure>
<p>在设置区域和语言选择输入法为Rime<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/rime/1762213-d899b160aa87f944.png" alt><br>根据个人喜好修改配置文件：一般用户直接修改default.yaml即可。修改前最好备份一下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/.config/ibus/rime/default.yaml</span><br><span class="line"></span><br><span class="line">schema_list:   </span><br><span class="line">  - schema: luna_pinyin_simp #simp是简体，第一位是默认输入法 </span><br><span class="line">menu:</span><br><span class="line">  page_size: 9 #每页候选词个数</span><br><span class="line">ascii_composer:</span><br><span class="line">  switch_key:</span><br><span class="line">    Shift_L: commit_code #左shift提交字母</span><br></pre></td></tr></table></figure>
<p>重启ibus-deamon<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ibus restart</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下screen的使用</title>
    <url>/2020/03/05/Ubuntu%E4%B8%8Bscreen%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>系统管理员经常需要SSH或者telent远程登录到linux服务器，经常运行一些需要很长时间才能完成的任务，比如系统备份、ftp 传输等等。通常情况下我们都是为每一个这样的任务开一个远程终端窗口，因为它们执行的时间太长了。必须等待它们执行完毕，在此期间不能关掉窗口或者断开连接，否则这个任务就会被杀掉，一切半途而废了。</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>GNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。</p>
<p>GNU Screen可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能。</p>
<p>我们可以使用screen命令，来让保证退出ssh之后程序继续在后台跑。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>首先可以先查看是否安装screen，通过命令<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">screen -ls</span><br></pre></td></tr></table></figure><br>若出现</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">The program &#x27;screen&#x27; is currently not installed. You can install it by typing:</span><br><span class="line">sudo apt install screen</span><br></pre></td></tr></table></figure>
<p>说明尚未安装，按照提示，通过命令，安装screen：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install screen</span><br></pre></td></tr></table></figure></p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><ul>
<li><p>新建窗口<br>1）可直接通过命令<code>screen</code>新建一个窗口，并进入窗口。但通过这种方式新建的窗口没有名字，只有系统分配给它的一个id。当需要恢复窗口时，只能通过id号来恢复。<br>2）通过命令<code>screen -S name</code>，这样就可以新建一个名字为name的窗口，同样系统也会分配给它一个id，当恢复该窗口时既可以通过id号也可以通过窗口名。</p>
</li>
<li><p>分离会话<br>退出当前新建的窗口，通过快键键Ctrl+a+d实现分离，此时窗口会跳出[detached]的提示，并回到主窗口。</p>
</li>
<li><p>恢复会话窗口<br>首先查看当前有哪些screen窗口，通过命令：<br><code>screen -ls</code> 将列出窗口列表<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/screen/787798-20181026175344791-956631152.png" alt></p>
<p>由以上可知，当前有两个窗口，其中test窗口已经被杀死，test2窗口分离。可以通过以下命令恢复test2窗口：<code>screen -r test2</code> 或 <code>screen -r 27582</code>这样就返回了test2窗口</p>
</li>
<li><p>杀死会话窗口<br>通过命令<code>kill -9 threadnum</code><br>注意此处只能通过id号来杀死窗口。</p>
</li>
<li><p>清除死去窗口<br>通过命令<code>screen -wipe</code><br>这个命令将自动清除所有处于dead状态的窗口</p>
</li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下virtualenv的使用与pycharm的基本配置</title>
    <url>/2019/12/13/Ubuntu%E4%B8%8Bvirtualenv%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8Epycharm%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h2 id="安装virtualenv"><a href="#安装virtualenv" class="headerlink" title="安装virtualenv"></a>安装virtualenv</h2><p>virtualenv是 Python 多版本管理的利器，不同版本的开发调试全靠它了（没有多版本尽量也装上吧）<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip install virtualenv</span><br></pre></td></tr></table></figure></p>
<h2 id="创建一个virtualenv环境"><a href="#创建一个virtualenv环境" class="headerlink" title="创建一个virtualenv环境"></a>创建一个virtualenv环境</h2><p>使用如下语句：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">virtualenv + 路径</span><br></pre></td></tr></table></figure><br>以这种方式创建环境将不包含系统的python包，新的环境里面只有pip、setuptools和wheel这些包，则许多包要用pip重新安装。</p>
<p>若需指定python版本：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">virtualenv –p python3 + 路径</span><br></pre></td></tr></table></figure></p>
<h2 id="激活virtualenv环境"><a href="#激活virtualenv环境" class="headerlink" title="激活virtualenv环境"></a>激活virtualenv环境</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source 路径/bin/activate</span><br></pre></td></tr></table></figure>
<p>也可以直接进到所创环境的bin目录中右键终端，运行source activate<br>注意：激活只对当前终端有效，如果新打开了一个终端的话，重新运行上面的命令。 激活后终端前面会多一个(**)的东西，提示当前virtualenv的名称。</p>
<p>激活后可以在当前终端通过python 文件名.py的方式运行python脚本，如果脚本中使用了当前环境中没有的包，将会报错。</p>
<p>可以在激活环境后使用pip安装对应的包。<strong>注意不要使用sudo</strong>，否则包会安装到系统当中去，而不是当前的virtualenv目录中。</p>
<h2 id="退出virtualenv环境"><a href="#退出virtualenv环境" class="headerlink" title="退出virtualenv环境"></a>退出virtualenv环境</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">deactivate</span><br></pre></td></tr></table></figure>
<p>也可直接关闭当前终端。</p>
<h2 id="删除virtualenv环境"><a href="#删除virtualenv环境" class="headerlink" title="删除virtualenv环境"></a>删除virtualenv环境</h2><p>直接删除对应目录即可删除virtualenv环境，不会对系统产生任何影响，所以在virtualenv中可以放心操作。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -rvf  + 路径</span><br></pre></td></tr></table></figure><br><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/virtualenv/5aafafdaa2aca.webp" alt></p>
<h2 id="Pycharm配置"><a href="#Pycharm配置" class="headerlink" title="Pycharm配置"></a>Pycharm配置</h2><p>新建项目<br><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/virtualenv/5aafb0d3811f2.webp" alt></p>
<ul>
<li><p>New environment using Virtualenv: 将在项目的目录下创建一个virtualenv环境，然后使用它当作当前项目的python解释器，默认不包含系统的python包。<br>相当于： virtualenv + 路径</p>
</li>
<li><p>location:为新建的环境的位置，默认为当前工程下的venv。</p>
</li>
<li><p>Base interpreter:基于系统中的python版本，新建的环境中的python版本与此一致，可以选择python2或者python3, 取决于项目的需要，相当于virtualenv –p python版本 +路径。<br>勾选Inherit global site-packages，包含系统的python包，相当于： virtualenv –system-site-packages + 路径<br>勾选Make available to all projects，下次新建项目的时候会在Existing interpreter中找到这个环境， 可以重复使用这个环境。</p>
</li>
<li><p>Existing interpreter：使用已有的python环境，点击后会出现后面的设置会出现这个界面，分别是virtualenv, conda和系统的python环境。可以选择已有的virtualenv环境，或者直接使用系统的python解释器。 Conda是anaconda(一个科学计算的python发行版)的包管理器，也可以用来建立python环境。</p>
</li>
</ul>
<p>会发现生成的项目中有一个叫venv的文件夹，它实质上和直接用virtualenv创建的一样。<br><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/virtualenv/5aafb2bd99f29.webp" alt><br>可以用virtualenv的管理方法管理它，比如安装numpy，安装之后可以在pycharm正常使用。（注意在virtualenv中<strong>不要使用sudo</strong>）<br><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/virtualenv/5aafb2bdb011c.webp" alt><br>也可以在pycharm中使用 file-settings-project-project interpreter中管理环境中的python包，可以对该环境下的python包进行删除和安装。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Python</tag>
        <tag>virtualenv</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下安装Pycharm</title>
    <url>/2019/12/13/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85Pycharm/</url>
    <content><![CDATA[<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>有社区版和专业版，专业版需要激活，社区版免费，我下载的是社区版。<br><a href="https://www.jetbrains.com/pycharm/download/#section=linux">官方下载</a><br><a href="https://www.jianguoyun.com/p/DfZJG3QQlZ_3Bhj8mrEC">网盘下载</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>进入download目录，对下载好的Pycharm压缩包进行解压操作，选中文件右键提取到此处即可。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D1664510513%2C942693123%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br>进入解压后的Pycharm文件夹，进入bin目录，可以看到很多文件，其中有一个文件叫做pycharm.sh。也就是下图中所选中的文件：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D101055722%2C4258535600%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br>此时在bin文件夹下右键打开终端，输入运行命令, 执行Pycharm程序<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./pycharm.sh</span><br></pre></td></tr></table></figure><br>如果提示没有权限，大家可以添加sudo命令进行操作：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ./pycharm.sh</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D805484803%2C1629350165%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br>大家点击OK即可进入下一步操作，根据提示的内容进行勾选同意协议，然后点击continue进入下一步，大家可以点击don’t send进入下一步，选择喜欢的界面风格，然后再次点击next进入下一步，直到提示start启动程序。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D227808303%2C3066408894%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D22323540%2C1357101677%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D1914658415%2C2906990210%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt><br>为了方便以后的使用，我们可以将Pycharm的图标（快捷键）锁定到启动器。之后不用再去在终端中启动Pycharm了，直接点击图标启动即可。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/u%3D1149108563%2C3867497858%26fm%3D173%26app%3D49%26f%3DJPEG.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下安装更新pip</title>
    <url>/2019/12/13/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85%E6%9B%B4%E6%96%B0pip/</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install python-pip</span><br></pre></td></tr></table></figure>
<p>若同时装有Python2、Python3上条命令装的是pip2，若还需装pip3，则再执行以下命令<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install python3-pip</span><br></pre></td></tr></table></figure></p>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>安装成功后进行更新：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip install --upgrade pip</span><br></pre></td></tr></table></figure><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip3 install --upgrade pip</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下如何添加新用户并增加管理员权限</title>
    <url>/2019/12/12/Ubuntu%E4%B8%8B%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%94%A8%E6%88%B7%E5%B9%B6%E5%A2%9E%E5%8A%A0%E7%AE%A1%E7%90%86%E5%91%98%E6%9D%83%E9%99%90/</url>
    <content><![CDATA[<h2 id="添加新用户"><a href="#添加新用户" class="headerlink" title="添加新用户"></a>添加新用户</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo adduser xxx #xxx为用户名</span><br></pre></td></tr></table></figure>
<p>输入密码后，出现如下信息：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">正在添加用户&quot;xxx&quot;…</span><br><span class="line">正在添加新组&quot;xxx&quot; (1003)…</span><br><span class="line">正在添加新用户&quot;xxx&quot; (1003) 到组&quot;xxx&quot;…</span><br><span class="line">创建主目录&quot;/home/xxx&quot;…</span><br><span class="line">正在从&quot;/etc/skel&quot;复制文件…</span><br><span class="line">输入新的 UNIX 密码：</span><br><span class="line">重新输入新的 UNIX 密码：</span><br><span class="line">passwd：已成功更新密码</span><br><span class="line">正在改变 xxx 的用户信息</span><br><span class="line">请输入新值，或直接敲回车以使用默认值</span><br><span class="line">        全名 [ ]：</span><br><span class="line">        房间号码 [ ]：</span><br><span class="line">        工作电话 [ ]：</span><br><span class="line">        家庭电话 [ ]：</span><br><span class="line">        其它 [ ]：</span><br><span class="line">这些信息是否正确？ [Y/n] y</span><br></pre></td></tr></table></figure><br>到这里，新用户添加成功。</p>
<h2 id="增加管理员权限"><a href="#增加管理员权限" class="headerlink" title="增加管理员权限"></a>增加管理员权限</h2><p>需要让此用户有root权限，执行命令：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo nano /etc/sudoers</span><br></pre></td></tr></table></figure><br>往下拉，修改文件并添加：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xxx ALL=(ALL：ALL) ALL #xxx为你之前所创的用户名</span><br></pre></td></tr></table></figure><br>添加完成按下Ctrl + X保存并退出，再次按下Enter,完成<br>现在你可以点击右上角，看到你新创的用户，点击并切换了！</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu增加swap交换空间</title>
    <url>/2020/08/24/Ubuntu%E5%A2%9E%E5%8A%A0swap%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>我在训练模型的过程中，经常跑着中途发生了<code>can not allocate memory</code>的异常，从而使程序中断，其中发现是由于swap空间设置太小，导致交换内存溢出。因此本文介绍增加swap空间的方法。</p>
<h2 id="查看当前系统的swap大小"><a href="#查看当前系统的swap大小" class="headerlink" title="查看当前系统的swap大小"></a>查看当前系统的swap大小</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">free -m</span><br></pre></td></tr></table></figure>
<p>m 是以兆为单位， g是以GB为单位， 默认是kb</p>
<p>如下图，当前系统只有1G的交换空间：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/1.png" alt></p>
<h2 id="创建一个swap文件"><a href="#创建一个swap文件" class="headerlink" title="创建一个swap文件"></a>创建一个swap文件</h2><p>swap交换空间其实就是硬盘上一个特定的文件，只不过这个文件只有内存在读写，比较大些。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /home/roo/swapfile</span><br><span class="line"></span><br><span class="line">cd /home/roo/swapfile</span><br><span class="line"></span><br><span class="line">sudo dd if=/dev/zero of=swap bs=1G count=61</span><br></pre></td></tr></table></figure>
<p><code>mkdir /home/roo/swapfile</code> 是先在/home/roo目录下创建了一个名为swapfile的文件夹<br>cd 进入swapfile文件夹， 然后创建一个大小为61G的，名为swap的空文件。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/2.png" alt></p>
<p>命令解释：</p>
<ul>
<li><code>/home/roo/</code> 可以更换为自己的路径</li>
<li><code>bs</code>为单位，默认为kb， 如设置为1024，则代表1M</li>
<li><code>count</code>为数量，扩增大小为$count \times bs$</li>
</ul>
<h2 id="转换swap文件"><a href="#转换swap文件" class="headerlink" title="转换swap文件"></a>转换swap文件</h2><p>将生成的文件转换成swap类型的文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo mkswap -f swap</span><br></pre></td></tr></table></figure>
<p>如下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/3.png" alt></p>
<h2 id="激活swap文件"><a href="#激活swap文件" class="headerlink" title="激活swap文件"></a>激活swap文件</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo swapon swap</span><br></pre></td></tr></table></figure>
<p>卸载的话使用 swapoff</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo swapoff swap</span><br></pre></td></tr></table></figure>
<p>最后再次使用free查看，如下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/4.png" alt></p>
<h2 id="永久生效"><a href="#永久生效" class="headerlink" title="永久生效"></a>永久生效</h2><p>虽然交换空间到此已经扩展成功了，但是电脑重启的话，还是会恢复默认的swap大小。如果要一直使用这个swap，要把它写入/etc/fstab文件中。</p>
<p>编辑文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo nano /etc/fstab</span><br></pre></td></tr></table></figure>
<p>加入以下内容(路径根据自己设置的修改)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home/roo/swapfile/swap none swap defaults 0 0</span><br></pre></td></tr></table></figure>
<p>如下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/5.png" alt></p>
<h2 id="推荐swap大小"><a href="#推荐swap大小" class="headerlink" title="推荐swap大小"></a>推荐swap大小</h2><p>以下列出Ubuntu系统根据RAM大小推荐设置的swap大小：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/swap/6.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu快速搭建C++开发环境（VS Code编辑器）</title>
    <url>/2020/01/19/Ubuntu%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAC++%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%88VS-Code%E7%BC%96%E8%BE%91%E5%99%A8%EF%BC%89/</url>
    <content><![CDATA[<p>以下安装的是g++-8和Visual Studio Code，此方法适用于Ubuntu 14.04 64位、Ubuntu 16.04 32位/64位、Ubuntu 18.04 (Ubuntu 14.04 32位及以下系统无效)。打开终端并且输入以下命令即可。</p>
<h2 id="安装g-8"><a href="#安装g-8" class="headerlink" title="安装g++-8"></a>安装g++-8</h2><ul>
<li>安装software-properties-common：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install software-properties-common</span><br></pre></td></tr></table></figure></li>
<li>添加PPA到库并更新（会提示按回车继续执行，此时按回车即可）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ubuntu-toolchain-r/test</span><br></pre></td></tr></table></figure></li>
<li>更新软件信息：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></li>
<li>安装g++：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install g++-8</span><br></pre></td></tr></table></figure></li>
<li>将g++指向g++-8：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ln -sf /usr/bin/g++-8 /usr/bin/g++</span><br></pre></td></tr></table></figure></li>
<li>显示g++版本号，如果正常显示版本号意味着安装成功：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g++ --version</span><br></pre></td></tr></table></figure>
<h2 id="安装Visual-Studio-Code"><a href="#安装Visual-Studio-Code" class="headerlink" title="安装Visual Studio Code"></a>安装Visual Studio Code</h2></li>
<li>安装libgconf库：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install -y libgconf-2-4</span><br></pre></td></tr></table></figure></li>
<li>安装git：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install git</span><br></pre></td></tr></table></figure></li>
<li>添加PPA到库并更新（会提示按回车继续执行，此时按回车即可）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make</span><br></pre></td></tr></table></figure></li>
<li>更新软件信息：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></li>
<li>安装ubuntu-make：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install ubuntu-make</span><br></pre></td></tr></table></figure></li>
<li>通过ubuntu-make安装Visual Studio Code；过程中会询问安装路径，此时不需要修改直接按回车即可；然后会询问是否接受协议，此时输入a然后回车即可：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo umake ide visual-studio-code</span><br></pre></td></tr></table></figure></li>
<li>创建软链接到程序目录下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ln -sf `env | grep ^HOME= | cut -c 6-`/.local/share/umake/ide/visual-studio-code/bin/code /usr/bin/code</span><br></pre></td></tr></table></figure></li>
<li>创建项目目录：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir ~/Projects</span><br></pre></td></tr></table></figure></li>
<li>显示Visual Studio Code版本号，如果正常显示版本号意味着安装成功：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">code --version</span><br></pre></td></tr></table></figure></li>
<li>运行VS Code：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">code</span><br></pre></td></tr></table></figure></li>
<li>安装中文语言包：<br>1.按下键盘Ctrl+Shift+X<br>2.在输入框里输入Chinese<br>3.按下中文(简体)后面的install<br>4.安装完后按下Ctrl+Shift+P打开命令面板<br>5.输入config后选择配置语言命令<br>6.选择Configure Display Language<br>7.将”locale”:”en”改成”locale”: “zh-cn”，然后按下键盘Ctrl+S保存源文件<br>8.关闭VS Code<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-047109e9a0a075af.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-8c9880935d6bcbe8.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-43717f65ac98f10e.png" alt><h2 id="创建第一个C-项目（以下步骤除非有特殊说明，否则每次创建项目都要执行一次）："><a href="#创建第一个C-项目（以下步骤除非有特殊说明，否则每次创建项目都要执行一次）：" class="headerlink" title="创建第一个C++项目（以下步骤除非有特殊说明，否则每次创建项目都要执行一次）："></a>创建第一个C++项目（以下步骤除非有特殊说明，否则每次创建项目都要执行一次）：</h2></li>
<li>创建项目目录cppdemo，用于学习创建第一个C++项目，并进入cppdemo目录中：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir ~/Projects/cppdemo &amp;&amp; cd ~/Projects/cppdemo</span><br></pre></td></tr></table></figure></li>
<li>创建配置目录：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir ./.vscode</span><br></pre></td></tr></table></figure></li>
<li>添加编译配置文件（输入以下内容然后按回车）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; .vscode/tasks.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;version&quot;: &quot;2.0.0&quot;,</span><br><span class="line">    &quot;tasks&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;label&quot;: &quot;build&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;shell&quot;,</span><br><span class="line">            &quot;command&quot;: &quot;g++&quot;,</span><br><span class="line">            &quot;args&quot;: [</span><br><span class="line">                &quot;-std=c++17&quot;,</span><br><span class="line">                &quot;-Wall&quot;,</span><br><span class="line">                &quot;-Wextra&quot;,</span><br><span class="line">                &quot;-g&quot;,</span><br><span class="line">                &quot;-ggdb&quot;,</span><br><span class="line">                &quot;mycpp.cpp&quot;,</span><br><span class="line">                &quot;-o&quot;,</span><br><span class="line">                &quot;demoapp.out&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;group&quot;: &quot;build&quot;,</span><br><span class="line">            &quot;presentation&quot;: &#123;</span><br><span class="line">                &quot;reveal&quot;: &quot;always&quot;,</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;problemMatcher&quot;: &quot;\$gcc&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li>
<li>添加运行配置文件（输入以下内容然后按回车）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat &gt; .vscode/launch.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;(gdb) Launch&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;cppdbg&quot;,</span><br><span class="line">            &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">            &quot;program&quot;: &quot;\$&#123;workspaceFolder&#125;/demoapp.out&quot;,</span><br><span class="line">            &quot;args&quot;: [],</span><br><span class="line">            &quot;stopAtEntry&quot;: false,</span><br><span class="line">            &quot;cwd&quot;: &quot;\$&#123;workspaceFolder&#125;&quot;,</span><br><span class="line">            &quot;environment&quot;: [],</span><br><span class="line">            &quot;externalConsole&quot;: true,</span><br><span class="line">            &quot;MIMode&quot;: &quot;gdb&quot;,</span><br><span class="line">            &quot;setupCommands&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;,</span><br><span class="line">                    &quot;text&quot;: &quot;-enable-pretty-printing&quot;,</span><br><span class="line">                    &quot;ignoreFailures&quot;: true</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            &quot;preLaunchTask&quot;: &quot;build&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></li>
<li>添加智能提示配置文件（输入以下内容然后按回车）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if [ `getconf LONG_BIT` -eq &quot;64&quot; ]; then</span><br><span class="line">cat &gt; .vscode/c_cpp_properties.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;Linux&quot;,</span><br><span class="line">            &quot;includePath&quot;: [</span><br><span class="line">                &quot;/usr/include/c++/8&quot;,</span><br><span class="line">                &quot;/usr/include/x86_64-linux-gnu/c++/8&quot;,</span><br><span class="line">                &quot;/usr/include/c++/8/backward&quot;,</span><br><span class="line">                &quot;/usr/lib/gcc/x86_64-linux-gnu/8/include&quot;,</span><br><span class="line">                &quot;/usr/local/include&quot;,</span><br><span class="line">                &quot;/usr/lib/gcc/x86_64-linux-gnu/8/include-fixed&quot;,</span><br><span class="line">                &quot;/usr/include/x86_64-linux-gnu&quot;,</span><br><span class="line">                &quot;/usr/include&quot;,</span><br><span class="line">                &quot;$&#123;workspaceRoot&#125;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;defines&quot;: [],</span><br><span class="line">            &quot;intelliSenseMode&quot;: &quot;clang-x64&quot;,</span><br><span class="line">            &quot;browse&quot;: &#123;</span><br><span class="line">                &quot;path&quot;: [</span><br><span class="line">                    &quot;/usr/include/c++/8&quot;,</span><br><span class="line">                    &quot;/usr/include/x86_64-linux-gnu/c++/8&quot;,</span><br><span class="line">                    &quot;/usr/include/c++/8/backward&quot;,</span><br><span class="line">                    &quot;/usr/lib/gcc/x86_64-linux-gnu/8/include&quot;,</span><br><span class="line">                    &quot;/usr/local/include&quot;,</span><br><span class="line">                    &quot;/usr/lib/gcc/x86_64-linux-gnu/8/include-fixed&quot;,</span><br><span class="line">                    &quot;/usr/include/x86_64-linux-gnu&quot;,</span><br><span class="line">                    &quot;/usr/include&quot;,</span><br><span class="line">                    &quot;$&#123;workspaceRoot&#125;&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;limitSymbolsToIncludedHeaders&quot;: true,</span><br><span class="line">                &quot;databaseFilename&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;version&quot;: 3</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">else</span><br><span class="line">cat &gt; .vscode/c_cpp_properties.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;Linux&quot;,</span><br><span class="line">            &quot;includePath&quot;: [</span><br><span class="line">                &quot;/usr/include/c++/8&quot;,</span><br><span class="line">                &quot;/usr/include/i386-linux-gnu/c++/8&quot;,</span><br><span class="line">                &quot;/usr/include/c++/8/backward&quot;,</span><br><span class="line">                &quot;/usr/lib/gcc/i686-linux-gnu/8/include&quot;,</span><br><span class="line">                &quot;/usr/local/include&quot;,</span><br><span class="line">                &quot;/usr/lib/gcc/i686-linux-gnu/8/include-fixed&quot;,</span><br><span class="line">                &quot;/usr/include/i386-linux-gnu&quot;,</span><br><span class="line">                &quot;/usr/include&quot;,</span><br><span class="line">                &quot;$&#123;workspaceRoot&#125;&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;defines&quot;: [],</span><br><span class="line">            &quot;intelliSenseMode&quot;: &quot;clang-x64&quot;,</span><br><span class="line">            &quot;browse&quot;: &#123;</span><br><span class="line">                &quot;path&quot;: [</span><br><span class="line">                    &quot;/usr/include/c++/8&quot;,</span><br><span class="line">                    &quot;/usr/include/i386-linux-gnu/c++/8&quot;,</span><br><span class="line">                    &quot;/usr/include/c++/8/backward&quot;,</span><br><span class="line">                    &quot;/usr/lib/gcc/i686-linux-gnu/8/include&quot;,</span><br><span class="line">                    &quot;/usr/local/include&quot;,</span><br><span class="line">                    &quot;/usr/lib/gcc/i686-linux-gnu/8/include-fixed&quot;,</span><br><span class="line">                    &quot;/usr/include/i386-linux-gnu&quot;,</span><br><span class="line">                    &quot;/usr/include&quot;,</span><br><span class="line">                    &quot;$&#123;workspaceRoot&#125;&quot;</span><br><span class="line">                ],</span><br><span class="line">                &quot;limitSymbolsToIncludedHeaders&quot;: true,</span><br><span class="line">                &quot;databaseFilename&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;version&quot;: 3</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li>
<li>创建C++源文件mycpp.cpp（代码就是写在这个文件）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch mycpp.cpp</span><br></pre></td></tr></table></figure></li>
<li>用Visual Studio Code打开当前工作环境（不要忽略最后的点哟）：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">code .</span><br></pre></td></tr></table></figure></li>
<li>双击mycpp.cpp打开文件，第一次会提示安装C++插件，点击安装，然后等待右下角消息安装完成（只需执行一次，以后都不需要再执行）。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-84d0b75234245983.png" alt></li>
<li>双击打开mycpp.cpp，然后输入以下代码：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    std::cout &lt;&lt; &quot;小古银的C++教程&quot; &lt;&lt; std::endl;</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-5c0e4151fa446bb1.png" alt></li>
<li>按下Ctrl+Shift+B，然后选择build，就会开始编译。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-9086cfb5ebae16ca.png" alt></li>
<li>编译完后，在终端窗口按回车键关闭终端。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-422767a1784b76a6.png" alt></li>
<li>点击菜单栏中的终端，然后点击新建终端，就会打开终端窗口。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-86304c028d93ecc7.png" alt></li>
<li>然后在终端输入以下内容，就会运行程序：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./demoapp.out</span><br></pre></td></tr></table></figure></li>
<li>运行程序将会显示小古银的C++教程。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VScode/11655830-4ecc19bb3b0c9794.png" alt><br>此时，第一个项目，也就是第一个程序就完成了。</li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>C++</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu多版本CUDA安装与切换</title>
    <url>/2022/01/04/Ubuntu%E5%A4%9A%E7%89%88%E6%9C%ACcuda%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%87%E6%8D%A2/</url>
    <content><![CDATA[<p>本文主要介绍CUDA多版本如何共存与切换，这里以cuda10.1为例。</p>
<h2 id="安装新版本cuda"><a href="#安装新版本cuda" class="headerlink" title="安装新版本cuda"></a>安装新版本cuda</h2><p>去<a href="https://developer.nvidia.com/cuda-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10">官网</a>选择对应安装包，这里选择runfile类型的安装文件<code>cuda_10.1.243_418.87.00_linux.run</code>。</p>
<p>执行以下命令，开始安装：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo sh cuda_10.1.243_418.87.00_linux.run</span><br></pre></td></tr></table></figure></p>
<p>依次出现如下界面：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/sw1.png" alt></p>
<p>选择continue，继续。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/sw2.png" alt></p>
<p>输入accept，回车接受。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/sw3.png" alt></p>
<ul>
<li>是否安装显卡驱动，本机已有，这里一般取消勾选</li>
<li>是否安装工具包，默认勾选</li>
<li>是否安装样例， 默认勾选</li>
<li>是否安装演示套件，默认勾选</li>
<li>是否安装文档，默认勾选</li>
</ul>
<p>勾选完毕，点击install开始安装。</p>
<p>过程中会叫你选择是否创建指向cuda的链接：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Do you want to install a symbolic link at /usr/local/cuda?</span><br><span class="line">(y)es/(n)o/(q)uit:</span><br></pre></td></tr></table></figure>
<p>如果马上想要使用当前版本，这里就选yes，否则就选no，等有需要时再设置。</p>
<h2 id="安装cuDNN"><a href="#安装cuDNN" class="headerlink" title="安装cuDNN"></a>安装cuDNN</h2><p>同样去<a href="https://developer.nvidia.com/rdp/cudnn-archive">官网</a>下载好与CUDA版本对应的安装包，文件格式为tar压缩文件<code>cudnn-10.1-linux-x64-v7.6.4.38.tgz</code>。</p>
<p>① 进行解压</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar -zxvf cudnn-10.1-linux-x64-v7.6.4.38.tgz</span><br></pre></td></tr></table></figure>
<p>② 将解压后的文件复制到新版本cuda目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp cuda/include/cudnn.h  /usr/local/cuda-10.1/include</span><br><span class="line">sudo cp cuda/lib64/libcudnn*  /usr/local/cuda-10.1/lib64</span><br></pre></td></tr></table></figure>
<p>③ 更改权限</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod a+r /usr/local/cuda-10.1/include/cudnn.h  /usr/local/cuda-10.1/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>修改 ~/.bashrc 文件，在末尾添加：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64</span><br><span class="line">export PATH=$PATH:/usr/local/cuda/bin</span><br><span class="line">export CUDA_HOME=$CUDA_HOME:/usr/local/cuda</span><br></pre></td></tr></table></figure>
<p>按此设置后，以后更换CUDA版本无需再动环境配置。</p>
<h2 id="多版本切换"><a href="#多版本切换" class="headerlink" title="多版本切换"></a>多版本切换</h2><p>CUDA默认安装在<code>/usr/local</code>下，可至此目录查看已安装版本。</p>
<p>使用stat命令可查看当前CUDA软链接指向哪个CUDA版本：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/sw4.png" alt></p>
<p>切换版本只需将软链接指向新的CUDA版本：</p>
<p>① 删除原来的链接：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /usr/local/cuda</span><br></pre></td></tr></table></figure>
<p>② 建立新链接，指向指定的CUDA版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ln -s /usr/local/cuda-10.1 /usr/local/cuda</span><br></pre></td></tr></table></figure>
<p>切换完毕后可再次通过<code>stat</code>命令或<code>nvcc -V</code>查看：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/sw5.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>CUDA</tag>
        <tag>cuDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu配置SSH和Xshell连接服务器的教程</title>
    <url>/2020/01/26/Ubuntu%E9%85%8D%E7%BD%AESSH%E5%92%8CXshell%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>SSH分为客户端 openssh-client 和服务器 openssh-server，可以利用以下命令确认电脑<br>上是否安装了客户端和服务器。如果只是想远程登陆别的机器只需要安装客户端（Ubuntu默认安装了客户端），如果要本机的SSH服务就需要安装服务器。<br>首先确认ssh-server是否已经启动了，下面是已经启动过了。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dpkg -l | grep ssh</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161410.jpg" alt><br>客户端 openssh-client 和服务器 openssh-server安装命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt install openssh-client</span><br><span class="line">sudo apt install openssh-server</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161511.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161512.jpg" alt><br>查看网卡对应的服务器IP地址和用户名<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ifconfig | grep inet</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161513.jpg" alt><br>远程登录和复制文件，需要我们进入Xshell输入命令。<br>首先登陆Xshell，新建会话，点击连接。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161614.jpg" alt><br>输入登陆服务器IP（刚才查得的），端口22（默认），选择协议SSH。之后确认和连接，<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161615.jpg" alt><br>首次登陆需要用户名和密码，输入进去你Ubuntu的用户名和密码。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161617.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161718.jpg" alt><br>查看信息是否连接，进入服务器。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/2019111014161719.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>SSH</tag>
        <tag>Xshell</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu美化</title>
    <url>/2020/01/19/Ubuntu%E7%BE%8E%E5%8C%96/</url>
    <content><![CDATA[<ul>
<li>安装Unity-tweak-tool<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install unity-tweak-tool</span><br></pre></td></tr></table></figure>
<img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ubuntu_modify/20180909004455285.png" alt></li>
<li>更新源<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:noobslab/themes</span><br><span class="line">sudo apt-add-repository ppa:numix/ppa </span><br><span class="line">sudo apt update</span><br></pre></td></tr></table></figure></li>
<li>安装主题<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:noobslab/themes  </span><br><span class="line">sudo apt-get update  </span><br><span class="line">sudo apt-get install flatabulous-theme </span><br><span class="line">sudo apt-get install arc-theme</span><br></pre></td></tr></table></figure></li>
<li>安装图标<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:noobslab/icons  </span><br><span class="line">sudo apt-get update  </span><br><span class="line">sudo apt-get install ultra-flat-icons </span><br><span class="line">sudo apt-get install numix-icon-theme-circle</span><br></pre></td></tr></table></figure></li>
<li>选择主题<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ubuntu_modify/20180909005108750.png" alt></li>
<li>选择图标<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ubuntu_modify/20180909005211146.png" alt></li>
<li>最终效果<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ubuntu_modify/20180909005447430.jpg" alt></li>
</ul>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10和Ubuntu双系统下时间不对问题</title>
    <url>/2020/01/19/Win10%E5%92%8CUbuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%97%B6%E9%97%B4%E4%B8%8D%E5%AF%B9%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>电脑安装完win10和Ubuntu双系统后，Ubuntu时间总会和Windows时间相差8小时，这是因为windows认为bios时间是本地时间，Ubuntu认为bios时间是UTC时间，所以我们需要将Ubuntu时间改成本地时间。</p>
<p>执行这条语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">timedatectl set-local-rtc 1 --adjust-system-clock</span><br></pre></td></tr></table></figure>
<p>重启进入windows，时间设置中点击立即同步即可解决。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu配置v2ray详细教程</title>
    <url>/2020/02/23/Ubuntu%E9%85%8D%E7%BD%AEv2ray%E8%AF%A6%E7%BB%86%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>🌟Linux/Windows/macOS 跨平台 v2ray GUI 🔨 使用 c++ 编写，支持订阅，扫描二维码，支持自定义路由编辑 🌟。使用 Qt 框架的跨平台 v2ray 客户端。支持 Windows, Linux, macOS。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ul>
<li><p>下载<code>V2ray</code>客户端，这里以最简单的<code>AppImage</code>文件为例,下载链接：<br><a href="https://github.com/Qv2ray/Qv2ray/releases/download/v1.99.6/Qv2ray-refs.tags.v1.99.6-linux.AppImage">https://github.com/Qv2ray/Qv2ray/releases/download/v1.99.6/Qv2ray-refs.tags.v1.99.6-linux.AppImage</a><br>或者打开网站：<a href="https://github.com/Qv2ray/Qv2ray/releases/tag/v1.99.6">https://github.com/Qv2ray/Qv2ray/releases/tag/v1.99.6</a> 选择下图文件<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580651760-1.png" alt><br><strong>注意：建议下载1.99.6及以上版本，其它版本可能出现找不到openssl库。</strong></p>
</li>
<li><p>下载核心文件，下载链接：<br><a href="https://github.com/v2ray/v2ray-core/releases/download/v4.22.1/v2ray-linux-64.zip">https://github.com/v2ray/v2ray-core/releases/download/v4.22.1/v2ray-linux-64.zip</a><br>或者打开网站：<a href="https://github.com/v2ray/v2ray-core/releases/">https://github.com/v2ray/v2ray-core/releases/</a> 选择下图文件<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580651801-2.png" alt></p>
</li>
<li><p>进入v2ray下载的根目录，执行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo chmod +x ./Qv2ray-refs.tags.v1.99.6-linux.AppImage</span><br></pre></td></tr></table></figure>
</li>
<li><p>仍然在v2ray根目录下打开终端，输入以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./Qv2ray-refs.tags.v1.99.6-linux.AppImage</span><br></pre></td></tr></table></figure>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2></li>
</ul>
<p>执行后会出现主界面，点击首选项</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580652261-3-1580634671283.png" alt></p>
<p>在常规设置里面按照图示操作,最后点击ok保存：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580652339-4.png" alt></p>
<p>回到主界面，点击订阅：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580652363-5.png" alt></p>
<p>然后按照下图要求填入相应内容,然后点击ok：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580655824-6.png" alt></p>
<p>进入网站-&gt;个人中心，按照下图说明复制链接到上图中：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580652405-7.png" alt></p>
<p>将软件的代理模式打开，如下图所示；</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580653297-8.png" alt></p>
<p>一切准备好后点击主界面的连接，开始科学上网</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580653343-9.png" alt></p>
<p>墙外的世界在欢迎你!</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/v2ray/1580653648-tzyy_2020-02-02_22-27-02.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows10安装ubuntu16.04双系统教程</title>
    <url>/2020/01/19/Windows10%E5%AE%89%E8%A3%85ubuntu16.04%E5%8F%8C%E7%B3%BB%E7%BB%9F%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>BIOS模式有传统的MBR模式和新式UEFI模式，这将对安装双系统的方法产生直接影响。目前来看，大部分电脑都属于新式UEFI模式，不过也存在一些老机子仍然属于传统MBR模式。本教程只介绍新式UEFI模式下的双系统安装方法，如果你的电脑属于传统MBR模式，强烈建议你重装windows系统来更新BIOS模式到UEFI。</p>
<h2 id="制作系统盘"><a href="#制作系统盘" class="headerlink" title="制作系统盘"></a>制作系统盘</h2><p>需要准备以下工具：<br>①ubuntu系统镜像<br>②刻录软件，推荐”软碟通”，会提示注册，选择继续试用就好<br>③一个大于 2G 的 U 盘<br>1.安装并打开软碟通，插上 U 盘，并且最好备份你的 U 盘，因为之后需要格式化；<br>2.进入软碟通，选择文件，浏览到你的ubuntu镜像所在的目录，选择ubuntu镜像文件，双击打开，如图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422030.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422031.jpg" alt><br>3.在软碟通界面菜单栏选择”启动”，选择”写入硬盘映像”，如图所示：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422032.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422033.jpg" alt><br>接下来很重要，注意次序：<br>1）看你的硬盘驱动器是否对应的是你的 U 盘（必须是） ，一般默认是；<br>2）看映像文件是否对应你的 ubuntu 镜像；<br>3）如果上述均没有错误，选择格式化，之后就会格式化你的 U 盘；<br>4）在 U 盘格式化完毕之后，选择写入，之后就是慢慢等待了，等待写入完毕；</p>
<h2 id="在windows下创建空白分区"><a href="#在windows下创建空白分区" class="headerlink" title="在windows下创建空白分区"></a>在windows下创建空白分区</h2><p>说明：这一步是为ubuntu系统分配空间，单硬盘和双硬盘存在一点区别。<br>1.”此电脑”点击右键，点击”管理”，点击”磁盘管理”：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422034.jpg" alt><br>2.为ubuntu分配空间<br>（1）如果是单硬盘，任选一个盘，在该盘点击右键，选择压缩卷，如下，输入压缩空间量，单位为M，如果空间充足，建议分出80G或100G，空间不足也可以分60G（1G=1024M）：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/20190520082545559.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422136.jpg" alt><br>（2）如果是双硬盘，需要先在系统盘分出200M的空白分区用来安装ubuntu的启动项，然后再在另一块硬盘分出空间，在该盘点击右键，选择压缩卷，如下，输入压缩空间量，单位为M,如果空间充足，建议分出80G或100G，空间不足也可以分60G（1G=1024M）<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422138.jpg" alt></p>
<h2 id="用做好的系统盘安装系统"><a href="#用做好的系统盘安装系统" class="headerlink" title="用做好的系统盘安装系统"></a>用做好的系统盘安装系统</h2><p>先点击桌面右下角：电源图标→电源设置→电源和睡眠→其他电源设置→选择电源按钮的功能→更改当前不可用的设置，将“关机设置”中的快速启动项关闭，保存修改。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/20190520084629381.png" alt>若呈灰色，无法修改，win+r进入gpedit.msc将系统配置中的关机选项，快速启动改为禁用，重启完即可更改。<br>1.插好系统盘，重启电脑，开机进bios，在Security页面，关掉secure boot（不同电脑secure boot可能在不同位置），然后到Boot页面，如果有Fast Boot这一项（部分联想电脑有），也把它关掉，没有忽略；然后保存更改，在Boot页面下方启动项选择 USB启动，回车，如果顺利进入安装页面，继续往下做；如果点击USB启动项无法进入，保存并退出，电脑会重启，根据自己电脑按相应的键进boot manager，找到USB启动项，回车即可进入。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422139.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422140.jpg" alt><br>2.然后会进入这个界面，选择Install Ubuntu，回车确认<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422141.jpg" alt><br>3.安装过程记住断网，否则很慢<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422143.jpg" alt><br>全不选，边安装边下载更新很慢，点击”继续”<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/20171229140050194.png" alt><br>出现以下或类似界面，一定要选择”其他选项”，因为需要手动分区<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422145.jpg" alt><br>分区界面如下<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422246.jpg" alt><br>在这里，我们进行手动分区，选择留出的空闲分区，点击”+”进行分区，如下：<br>1）efi：如果是单硬盘，在唯一的一个空闲分区上添加，大小200M，逻辑分区，空间起始位置，用于efi；如果是双硬盘，找到事先分好的200M空闲分区添加，逻辑分区，空间起始位置，用于efi。这个分区必不可少，用于安装ubuntu启动项。<br>2）swap:中文是”交换空间”，充当ubuntu的虚拟内存，一般的大小与电脑物理内存一样，可以将其分为 8G，逻辑分区，空间起始位置，用于”swap”或”交换空间”<br>3）/:这是ubuntu 的根目录,用于安装系统和软件，相当于windows的C盘，我们将其分为 20G，主分区，空间起始位置，用于”ext4日志文件系统”，挂载点为”/“（根据你的磁盘空间调整，可以大一点，毕竟ubuntu装软件都是默认装在根目录的）<br>4）/home:相当于windows的其他盘，剩下的全分给它，逻辑分区，空间起始位置，用于”ext4日志文件系统”，挂载点为”/home”<br>分区完毕，在分区界面的下方，选择安装启动项的位置，我们刚刚不是创建了200M的efi分区吗，现在你看看这个区前面的编号是多少，比如是/dev/sda1,不同的机子会有不同的编号，下拉列表选择这个efi分区编号（这里一定要注意，windows的启动项也是efi文件，大小大概是100M，而我们创建的ubuntu的efi大小是200M，一定要选对），之后点击”Install Now”<br>设置地区不重要，按你需要设置，也可以直接继续，不影响<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422248.jpg" alt><br>键盘布局默认是英语的，建议不改（默认中文也行）<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422249.jpg" alt><br>这里设置用户，自己输入就可以了，例如英文字母，尽量简单点，密码也简单点<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422250.jpg" alt><br>系统开始安装，耐心等待安装完毕就可以了<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422251.jpg" alt><br>全部完成之后，会提醒你重启，把U盘拔了，点”现在重启”，如果卡死就强制关机再重启就好<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422252.jpg" alt><br>重启后你会看到以下界面，第一项是ubuntu启动项，第二项是ubuntu高级设置，第三项是windows启动项，第四项不用管，默认选择的是第一个，回车进ubuntu系统<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/dual_system/2019121214422253.jpg" alt><br>若没有出现，则进入bios将启动顺序改为Ubuntu先。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Windows10</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows下VSCode使用SSH连接报Bad owner or permissions on C:\\Users\\Administrator/.ssh/config错误问题解决</title>
    <url>/2020/02/25/Windows%E4%B8%8BVSCode%E4%BD%BF%E7%94%A8SSH%E8%BF%9E%E6%8E%A5%E6%8A%A5Bad-owner-or-permissions-on-CUsersAdministrator.sshconfig%E9%94%99%E8%AF%AF%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在 Windows 系统下的 VSCode 安装 <strong>Remote - SSH</strong> 扩展后，使用扩展配置 SSH 并进行远程连接，可能会发生 <strong>Bad owner or permissions on C:\Users\Administrator/.ssh/config</strong> 错误，造成无法进行 SSH 远程连接的问题。</p>
<p>原因是由于使用 <strong>Remote - SSH</strong> 扩展所依赖的 <strong>Remote - SSH: Editing Configuration Files</strong> 扩展编辑了 <strong>C:\Users\Administrator.ssh\config</strong> 文件后，此文件的权限发生了改变：<br> <img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode ssh/image-2fd80730.png.jfif" alt></p>
<p>如上图所示，编辑了 <strong>%USER_HOME%.ssh\config</strong> 文件后，不但在 VSCode 中由于配置文件权限问题而无法进行 SSH 远程连接，就连使用系统的 <strong>PowerShell</strong> 进行 SSH 连接时也会报此错误，而把此配置文件删除后，使用  <strong>PowerShell</strong> 即可正常进行远程连接。但 VSCode 的 SSH 连接又依赖此配置文件，所以就产生了冲突，要么只有 <strong>PowerShell</strong> 能用，要么就都不能用。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><ol>
<li><p>在 GitHub 上下载 <a href="https://github.com/PowerShell/openssh-portable"><strong>openssh-portable</strong></a> 项目，其 Git 命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/PowerShell/openssh-portable.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载完成后进入 <strong>openssh-portable</strong> 项目中的 <a href="https://github.com/PowerShell/openssh-portable/tree/latestw_all/contrib/win32/openssh"><code>contrib\win32\openssh</code></a> 目录，在此目录中打开 PowerShell 命令行，执行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">.\FixUserFilePermissions.ps1 -Confirm:$false</span><br></pre></td></tr></table></figure>
<ul>
<li><p>执行此命令时若提示错误 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">无法加载文件 FixUserFil ePermissions.ps1，因为在此系统上禁止运行脚本</span><br></pre></td></tr></table></figure>
<p>则先执行以下命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Set-ExecutionPolicy RemoteSigned</span><br></pre></td></tr></table></figure>
<p>然后输入 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Y</span><br></pre></td></tr></table></figure>
<p> 回车确认后再重新执行，执行完毕后可以再执行<code>Set-ExecutionPolicy RemoteSigned</code>输入 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">N</span><br></pre></td></tr></table></figure>
<p> 恢复默认配置</p>
</li>
</ul>
</li>
<li><p>操作完成后，在 VSCode 中编辑 <strong>C:\Users\Administrator.ssh\config</strong> 文件将不会影响此文件的权限，在 VSCode 和 PowerShell 中均可正常进行 SSH 远程连接：</p>
<ul>
<li><p>在 VSCode 中通过 Remote - SSH 进行 SSH 远程连接：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode ssh/image-c923ced8.png" alt></p>
</li>
<li><p>在 PowerShell 中进行 SSH 远程连接：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode ssh/93310FA6D4F64FA7BF7BEBE7357A79E6-cf86116a.jpeg" alt></p>
</li>
</ul>
</li>
</ol>
<h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>在其他位置建好config文件，并在插件设置中添加路径即可</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode ssh/20200212142410779.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows如何通过VNC从远程控制Ubuntu</title>
    <url>/2020/02/18/Windows%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87VNC%E4%BB%8E%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6Ubuntu/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>VNC 工具是提供你一个可以远程图像化桌面的方式。其实 VNC 是一种软件的统称。只要你的 Linux 架设好了一个服务器 (Server) 的 VNC，客户端比如你的 Mac，手机，只要安装任何一种 VNC 客户端软件就能链接上服务器端的电脑。</p>
<h2 id="Ubuntu服务端安装"><a href="#Ubuntu服务端安装" class="headerlink" title="Ubuntu服务端安装"></a>Ubuntu服务端安装</h2><p>打开 Terminal，输入:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install x11vnc</span><br></pre></td></tr></table></figure><br>确认你的 Linux 用户密码，就能安装这个最常用的 x11vnc 软件。这个软件的使用，设置非常简单。安装好后，最好给你的 x11vnc 设置一个用于连接的密码，输入<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x11vnc -storepasswd</span><br></pre></td></tr></table></figure><br>会出现以下画面，设置你的密码：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Enter VNC password:</span><br><span class="line">Verify password:</span><br><span class="line">Write password to /home/morvan/.vnc/passwd?  [y]/n y</span><br><span class="line">Password written to: /home/morvan/.vnc/passwd</span><br></pre></td></tr></table></figure><br>开启服务:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x11vnc -auth guess -once -loop -noxdamage -repeat -rfbauth /home/USERNAME/.vnc/passwd -rfbport 5900 -shared</span><br></pre></td></tr></table></figure></p>
<p><strong>注意：/home/USERNAME/.vnc/passwd 中的USERNAME需要换成你自己的用户名。</strong></p>
<p>设为开机启动：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /lib/systemd/system/x11vnc.service</span><br></pre></td></tr></table></figure><br>在打开的页面中插入以下代码，保存<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Start x11vnc at startup.</span><br><span class="line">After=multi-user.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/bin/x11vnc -auth guess -once -loop -noxdamage -repeat -rfbauth /home/USERNAME/.vnc/passwd -rfbport 5900 -shared</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br></pre></td></tr></table></figure><br>接着执行：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable x11vnc.service</span><br></pre></td></tr></table></figure><br>好了，此时服务端配置完毕。</p>
<h2 id="Windows客户端安装"><a href="#Windows客户端安装" class="headerlink" title="Windows客户端安装"></a>Windows客户端安装</h2><p>我这里用的是RealVNC的VNC Viewer，<a href="https://www.realvnc.com/en/connect/download/viewer/">下载地址</a></p>
<p>打开客户端，输入你要连接的服务端的IP</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VNC/Snipaste_2020-02-18_18-11-36.jpg" alt></p>
<p>接着输入你所设置的密码即可连接，效果如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/VNC/Snipaste_2020-02-18_18-12-44.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>VNC</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOV1损失函数代码详解(detection_layer.c)</title>
    <url>/2020/02/26/YOLOV1%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(detection_layer.c)/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>灵魂拷问，你真的懂YOLOV1的损失函数吗？进一步，懂了损失函数，你清楚它的反向求导过程吗？为了解决这俩问题，本文就结合DarkNet中的YOLOV1的损失函数代码实现(在<code>src/detection_layer.c</code>中)来帮助你理解。</p>
<h2 id="损失函数公式"><a href="#损失函数公式" class="headerlink" title="损失函数公式"></a>损失函数公式</h2><p>YOLOV1的损失函数就是这样，不做过多解释了。需要注意的一个点是，在反向传播求导的时候，各个变量的梯度其实应该都有一个<strong>系数2</strong>的，但是代码中全部都省掉了，这对整个优化过程其实是没有影响的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/660.png" alt></p>
<h2 id="代码详细解析"><a href="#代码详细解析" class="headerlink" title="代码详细解析"></a>代码详细解析</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构建detection层，yolov1中最后一层</span></span><br><span class="line"><span class="comment"> * @param batch 一个batch包含图片的张数</span></span><br><span class="line"><span class="comment"> * @param inputs detection层一张输入图片元素个数</span></span><br><span class="line"><span class="comment"> * @param n yolov1一个grid cell预测bbox的数量 2</span></span><br><span class="line"><span class="comment"> * @param side // grid cell的大小 7</span></span><br><span class="line"><span class="comment"> * @param classes yolov1 预测类的个数</span></span><br><span class="line"><span class="comment"> * @param coords 一个bbox包含的坐标数量 4</span></span><br><span class="line"><span class="comment"> * @param rescore</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">detection_layer <span class="title">make_detection_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> inputs, <span class="keyword">int</span> n, <span class="keyword">int</span> side, <span class="keyword">int</span> classes, <span class="keyword">int</span> coords, <span class="keyword">int</span> rescore)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    detection_layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    l.type = DETECTION;</span><br><span class="line">	<span class="comment">// 这些变量都可以参考darknet.h中的注释</span></span><br><span class="line">    l.n = n; <span class="comment">//一个cell中预测多少个box</span></span><br><span class="line">    l.batch = batch; <span class="comment">//一个batch中包含图片的张数</span></span><br><span class="line">    l.inputs = inputs; <span class="comment">//detection层一张输入图片的元素个数</span></span><br><span class="line">    l.classes = classes; <span class="comment">//类别数</span></span><br><span class="line">    l.coords = coords; <span class="comment">//一个bbox包含的坐标数量</span></span><br><span class="line">    l.rescore = rescore;</span><br><span class="line">    l.side = side; <span class="comment">//grid cell的大小 7</span></span><br><span class="line">    l.w = side; <span class="comment">//grid cell的宽度</span></span><br><span class="line">    l.h = side; <span class="comment">//grid cell的高度</span></span><br><span class="line">    <span class="built_in">assert</span>(side*side*((<span class="number">1</span> + l.coords)*l.n + l.classes) == inputs); <span class="comment">//7*7*(1 + 4) * 2 + 30 ) = 7*7*30</span></span><br><span class="line">    l.cost = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//detection层的总损失</span></span><br><span class="line">    l.outputs = l.inputs; <span class="comment">//detection层对应输入图片的输出元素个数，detection层不改变输入输出大小</span></span><br><span class="line">    l.truths = l.side*l.side*(<span class="number">1</span>+l.coords+l.classes); <span class="comment">//GT:7*7*(1+4+20) 只有一个bbox和置信度</span></span><br><span class="line">    l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// detection层所有输出（包含整个batch的）</span></span><br><span class="line">    l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//detection层误差项（包含整个batch的）</span></span><br><span class="line"></span><br><span class="line">    l.forward = forward_detection_layer; <span class="comment">//前向传播</span></span><br><span class="line">    l.backward = backward_detection_layer; <span class="comment">//反向传播</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    l.forward_gpu = forward_detection_layer_gpu;</span><br><span class="line">    l.backward_gpu = backward_detection_layer_gpu;</span><br><span class="line">    l.output_gpu = <span class="built_in">cuda_make_array</span>(l.output, batch*l.outputs);</span><br><span class="line">    l.delta_gpu = <span class="built_in">cuda_make_array</span>(l.delta, batch*l.outputs);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Detection Layer\n&quot;</span>);</span><br><span class="line">    <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * detection层前向传播函数</span></span><br><span class="line"><span class="comment"> * @param l 当前detection层</span></span><br><span class="line"><span class="comment"> * @param net 整个网络</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_detection_layer</span><span class="params">(<span class="keyword">const</span> detection_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> locations = l.side*l.side; <span class="comment">//grid cell的数量7*7=49</span></span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="built_in">memcpy</span>(l.output, state.input, l.outputs*l.batch*<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="comment">//if(l.reorg) reorg(l.output, l.w*l.h, size*l.n, l.batch, 1);</span></span><br><span class="line">    <span class="keyword">int</span> b;</span><br><span class="line">    <span class="keyword">if</span> (l.softmax)&#123; <span class="comment">//yolo v1这里为0，并没有使用</span></span><br><span class="line">        <span class="keyword">for</span>(b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</span><br><span class="line">            <span class="keyword">int</span> index = b*l.inputs;</span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; locations; ++i) &#123;</span><br><span class="line">                <span class="keyword">int</span> offset = i*l.classes;</span><br><span class="line">                <span class="built_in">softmax</span>(l.output + index + offset, l.classes, <span class="number">1</span>,</span><br><span class="line">                        l.output + index + offset, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(state.train)&#123;</span><br><span class="line">        <span class="keyword">float</span> avg_iou = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">float</span> avg_cat = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">float</span> avg_allcat = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">float</span> avg_obj = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">float</span> avg_anyobj = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        *(l.cost) = <span class="number">0</span>; <span class="comment">//detection层的总损失</span></span><br><span class="line">        <span class="keyword">int</span> size = l.inputs * l.batch; <span class="comment">//误差项的个数</span></span><br><span class="line">        <span class="built_in">memset</span>(l.delta, <span class="number">0</span>, size * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//误差项初始化</span></span><br><span class="line">        <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</span><br><span class="line">            <span class="keyword">int</span> index = b*l.inputs; <span class="comment">//第b个batch的起始位置</span></span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; locations; ++i) &#123; <span class="comment">//第i个grid cell，一共有7*7个</span></span><br><span class="line">                <span class="keyword">int</span> truth_index = (b*locations + i)*(<span class="number">1</span>+l.coords+l.classes); <span class="comment">//获取第i个grid cell的bbox的GT</span></span><br><span class="line">                <span class="keyword">int</span> is_obj = state.truth[truth_index]; <span class="comment">//获取第i个grid cell是否包含物体</span></span><br><span class="line">                <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.n; ++j) &#123; <span class="comment">// 获取yolov1 第i个grid cell预测的两个bbox，与GT比较</span></span><br><span class="line">                    <span class="keyword">int</span> p_index = index + locations*l.classes + i*l.n + j; <span class="comment">// 获取第j个预测的bbox起始位置</span></span><br><span class="line">                    l.delta[p_index] = l.noobject_scale*(<span class="number">0</span> - l.output[p_index]); <span class="comment">// bbox中不含object的置信度误差项， noobject_scale=0.5 Loss 1-4(1-4指的是公式)</span></span><br><span class="line">                    *(l.cost) += l.noobject_scale*<span class="built_in">pow</span>(l.output[p_index], <span class="number">2</span>); <span class="comment">//第i个grid cell中第j个预测bbox中，不含object的置信度损失计算，Loss 1-4</span></span><br><span class="line">                    avg_anyobj += l.output[p_index]; <span class="comment">//bbox中不含object的置信度求和</span></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">int</span> best_index = <span class="number">-1</span>;</span><br><span class="line">                <span class="keyword">float</span> best_iou = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">float</span> best_rmse = <span class="number">20</span>; <span class="comment">//best bbox的rmse阈值</span></span><br><span class="line"> </span><br><span class="line">                <span class="keyword">if</span> (!is_obj)&#123; <span class="comment">// 当前第i个grid cell, 第j个bbox不含object, 则loss计算完成</span></span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">// 当前第i个grid cell, 第j个bbox含有object，继续计算坐标预测损失Loss 1-1,1-2，confidence预测损失Loss 1-3，类别预测损失Loss 1-5</span></span><br><span class="line">                <span class="keyword">int</span> class_index = index + i*l.classes;<span class="comment">// 获取第i个grid cell的classes起始位置</span></span><br><span class="line">                <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; l.classes; ++j) &#123;</span><br><span class="line">					<span class="comment">//第i个grid cell预测分类误差项</span></span><br><span class="line">                    l.delta[class_index+j] = l.class_scale * (state.truth[truth_index+<span class="number">1</span>+j] - l.output[class_index+j]); <span class="comment">// 第i个grid cell预测分类误差项</span></span><br><span class="line">                    *(l.cost) += l.class_scale * <span class="built_in">pow</span>(state.truth[truth_index+<span class="number">1</span>+j] - l.output[class_index+j], <span class="number">2</span>); <span class="comment">// 类别预测损失计算， Loss 1-5</span></span><br><span class="line">                    <span class="keyword">if</span>(state.truth[truth_index + <span class="number">1</span> + j]) avg_cat += l.output[class_index+j]; <span class="comment">// GT对应的grid cell预测分类值求和</span></span><br><span class="line">                    avg_allcat += l.output[class_index+j]; <span class="comment">// 所有grid cell预测分类值求和</span></span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">// 获取第i个grid cell, GT BBOX的[x, y, w, h], float_to_box 第一个参数是bbox起始位置</span></span><br><span class="line">                box truth = <span class="built_in">float_to_box</span>(state.truth + truth_index + <span class="number">1</span> + l.classes);</span><br><span class="line">                truth.x /= l.side;</span><br><span class="line">                truth.y /= l.side;</span><br><span class="line"></span><br><span class="line">				<span class="comment">//坐标预测损失计算 Loss 1-1, 1-2</span></span><br><span class="line">				<span class="comment">// 找到第i个grid cell的best bbox</span></span><br><span class="line">                <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; l.n; ++j)&#123;</span><br><span class="line">					<span class="comment">//第i个grid cell预测第j个bbox的起始位置</span></span><br><span class="line">                    <span class="keyword">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + j) * l.coords;</span><br><span class="line">                    box out = <span class="built_in">float_to_box</span>(l.output + box_index); <span class="comment">// 获取预测bbox的[x,y,w,h]</span></span><br><span class="line">					<span class="comment">//yolo v1 直接回归的是 7*x, 所以与GT bbox 计算IOU, 需要先除以7</span></span><br><span class="line">                    out.x /= l.side;</span><br><span class="line">                    out.y /= l.side;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (l.sqrt)&#123;</span><br><span class="line">						<span class="comment">//yolo v1直接回归的sqrt(w), 所以与GT bbox 计算IOU前，需要pow一下</span></span><br><span class="line">                        out.w = out.w*out.w;</span><br><span class="line">                        out.h = out.h*out.h;</span><br><span class="line">                    &#125;</span><br><span class="line">					<span class="comment">//计算预测bbox与 GT bbox之间的IOU</span></span><br><span class="line">                    <span class="keyword">float</span> iou  = <span class="built_in">box_iou</span>(out, truth);</span><br><span class="line">                    <span class="comment">//iou = 0;</span></span><br><span class="line">					<span class="comment">//计算预测bbox的[x,y]与GT bbox的[x,y]之间的均方差损失 Loss 1-1</span></span><br><span class="line">                    <span class="keyword">float</span> rmse = <span class="built_in">box_rmse</span>(out, truth);</span><br><span class="line">					<span class="comment">// 找到第i个grid cell预测最大的那个bbox</span></span><br><span class="line">                    <span class="keyword">if</span>(best_iou &gt; <span class="number">0</span> || iou &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                        <span class="keyword">if</span>(iou &gt; best_iou)&#123;</span><br><span class="line">                            best_iou = iou;</span><br><span class="line">                            best_index = j;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123; <span class="comment">// 均方差最小的</span></span><br><span class="line">                        <span class="keyword">if</span>(rmse &lt; best_rmse)&#123;</span><br><span class="line">                            best_rmse = rmse;</span><br><span class="line">                            best_index = j;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">// 强制指定一个bbox</span></span><br><span class="line">                <span class="keyword">if</span>(l.forced)&#123;</span><br><span class="line">					<span class="comment">// GT bbox w*h &lt; 0.1,强制最好的bbox index是1</span></span><br><span class="line">                    <span class="keyword">if</span>(truth.w*truth.h &lt; <span class="number">.1</span>)&#123;</span><br><span class="line">                        best_index = <span class="number">1</span>;</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                        best_index = <span class="number">0</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">//随机选择最佳bbox</span></span><br><span class="line">                <span class="keyword">if</span>(l.random &amp;&amp; *(state.net.seen) &lt; <span class="number">64000</span>)&#123;</span><br><span class="line">                    best_index = <span class="built_in">rand</span>()%l.n;</span><br><span class="line">                &#125;</span><br><span class="line">				</span><br><span class="line">				<span class="comment">// 模型预测的bbox起始位置</span></span><br><span class="line">                <span class="keyword">int</span> box_index = index + locations*(l.classes + l.n) + (i*l.n + best_index) * l.coords;</span><br><span class="line">                <span class="keyword">int</span> tbox_index = truth_index + <span class="number">1</span> + l.classes;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 获取最佳bbox的[x, y, w, h]</span></span><br><span class="line">                box out = <span class="built_in">float_to_box</span>(l.output + box_index);</span><br><span class="line">                out.x /= l.side; <span class="comment">// 归一化x</span></span><br><span class="line">                out.y /= l.side;</span><br><span class="line">                <span class="keyword">if</span> (l.sqrt) &#123; <span class="comment">// yolo v1直接回归的sqrt(w), 所以与GT bbox 计算IOU前，需要pow一下</span></span><br><span class="line">                    out.w = out.w*out.w;</span><br><span class="line">                    out.h = out.h*out.h;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">float</span> iou  = <span class="built_in">box_iou</span>(out, truth); <span class="comment">// 计算二者IOU</span></span><br><span class="line"></span><br><span class="line">                <span class="comment">//printf(&quot;%d,&quot;, best_index);</span></span><br><span class="line">				<span class="comment">// 获取第i个grid cell，best bbox的起始位置</span></span><br><span class="line">                <span class="keyword">int</span> p_index = index + locations*l.classes + i*l.n + best_index;</span><br><span class="line">				<span class="comment">// 减去之前计算不含object的confidence预测损失</span></span><br><span class="line">                *(l.cost) -= l.noobject_scale * <span class="built_in">pow</span>(l.output[p_index], <span class="number">2</span>);</span><br><span class="line">				<span class="comment">// 含有object的confidence的预测损失</span></span><br><span class="line">                *(l.cost) += l.object_scale * <span class="built_in">pow</span>(<span class="number">1</span>-l.output[p_index], <span class="number">2</span>);</span><br><span class="line">				<span class="comment">// bbox中含object的置信度求和</span></span><br><span class="line">                avg_obj += l.output[p_index];</span><br><span class="line">				<span class="comment">// 第i个含有object的那个best bbox,grid cell预测分类误差项</span></span><br><span class="line">                l.delta[p_index] = l.object_scale * (<span class="number">1.</span>-l.output[p_index]);</span><br><span class="line">				<span class="comment">//yolo v1这里为0，并没有使用</span></span><br><span class="line">                <span class="keyword">if</span>(l.rescore)&#123;</span><br><span class="line">                    l.delta[p_index] = l.object_scale * (iou - l.output[p_index]);</span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">// 第i个grid cell的x对应误差项计算</span></span><br><span class="line">                l.delta[box_index+<span class="number">0</span>] = l.coord_scale*(state.truth[tbox_index + <span class="number">0</span>] - l.output[box_index + <span class="number">0</span>]);</span><br><span class="line">				<span class="comment">// 第i个grid cell的y对应误差项计算</span></span><br><span class="line">                l.delta[box_index+<span class="number">1</span>] = l.coord_scale*(state.truth[tbox_index + <span class="number">1</span>] - l.output[box_index + <span class="number">1</span>]);</span><br><span class="line">				<span class="comment">// 第i个grid cell的w对应误差项计算</span></span><br><span class="line">                l.delta[box_index+<span class="number">2</span>] = l.coord_scale*(state.truth[tbox_index + <span class="number">2</span>] - l.output[box_index + <span class="number">2</span>]);</span><br><span class="line">				<span class="comment">// 第i个grid cell的h对应误差项计算</span></span><br><span class="line">                l.delta[box_index+<span class="number">3</span>] = l.coord_scale*(state.truth[tbox_index + <span class="number">3</span>] - l.output[box_index + <span class="number">3</span>]);</span><br><span class="line">                <span class="keyword">if</span>(l.sqrt)&#123;</span><br><span class="line">					<span class="comment">// Loss 1-2计算, GT bbox需要开根号</span></span><br><span class="line">                    l.delta[box_index+<span class="number">2</span>] = l.coord_scale*(<span class="built_in">sqrt</span>(state.truth[tbox_index + <span class="number">2</span>]) - l.output[box_index + <span class="number">2</span>]);</span><br><span class="line">                    l.delta[box_index+<span class="number">3</span>] = l.coord_scale*(<span class="built_in">sqrt</span>(state.truth[tbox_index + <span class="number">3</span>]) - l.output[box_index + <span class="number">3</span>]);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                *(l.cost) += <span class="built_in">pow</span>(<span class="number">1</span>-iou, <span class="number">2</span>);</span><br><span class="line">                avg_iou += iou; <span class="comment">// 包含object的grid cell，best bbox 与 GT bbox的IOU求和</span></span><br><span class="line">                ++count;  <span class="comment">// 训练阶段，截止到本batch的训练完，包含object总数量</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="comment">// 一个batch中所有图片处理完</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">float</span>* costs = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(l.batch * locations * l.n, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">            <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">                <span class="keyword">int</span> index = b*l.inputs;</span><br><span class="line">                <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; locations; ++i) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.n; ++j) &#123;</span><br><span class="line">                        <span class="keyword">int</span> p_index = index + locations*l.classes + i*l.n + j;</span><br><span class="line">                        costs[b*locations*l.n + i*l.n + j] = l.delta[p_index]*l.delta[p_index];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> indexes[<span class="number">100</span>];</span><br><span class="line">            <span class="built_in">top_k</span>(costs, l.batch*locations*l.n, <span class="number">100</span>, indexes);</span><br><span class="line">            <span class="keyword">float</span> cutoff = costs[indexes[<span class="number">99</span>]];</span><br><span class="line">            <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">                <span class="keyword">int</span> index = b*l.inputs;</span><br><span class="line">                <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; locations; ++i) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.n; ++j) &#123;</span><br><span class="line">                        <span class="keyword">int</span> p_index = index + locations*l.classes + i*l.n + j;</span><br><span class="line">                        <span class="keyword">if</span> (l.delta[p_index]*l.delta[p_index] &lt; cutoff) l.delta[p_index] = <span class="number">0</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">free</span>(costs);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">//一个batch的总损失计算</span></span><br><span class="line">        *(l.cost) = <span class="built_in">pow</span>(<span class="built_in">mag_array</span>(l.delta, l.outputs * l.batch), <span class="number">2</span>); <span class="comment">// 一个batch的总损失计算</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Detection Avg IOU: %f, Pos Cat: %f, All Cat: %f, Pos Obj: %f, Any Obj: %f, count: %d\n&quot;</span>, avg_iou/count, avg_cat/count, avg_allcat/(count*l.classes), avg_obj/count, avg_anyobj/(l.batch*locations*l.n), count);</span><br><span class="line">        <span class="comment">//if(l.reorg) reorg(l.delta, l.w*l.h, size*l.n, l.batch, 0);</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * detection层反向传播函数</span></span><br><span class="line"><span class="comment"> * @param l 当前detection层</span></span><br><span class="line"><span class="comment"> * @param net 整个网络</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_detection_layer</span><span class="params">(<span class="keyword">const</span> detection_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">axpy_cpu</span>(l.batch*l.inputs, <span class="number">1</span>, l.delta, <span class="number">1</span>, state.delta, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * yolo v1 Infence 阶段，解析7*7*30</span></span><br><span class="line"><span class="comment"> * @param l 当前detection层</span></span><br><span class="line"><span class="comment"> * @param w 输入图片的宽度</span></span><br><span class="line"><span class="comment"> * @param h 输入图片的高度</span></span><br><span class="line"><span class="comment"> * @param thresh confidence阈值</span></span><br><span class="line"><span class="comment"> * @param dets 用于保存结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">get_detection_detections</span><span class="params">(layer l, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">float</span> thresh, detection *dets)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i, j, n;</span><br><span class="line">	<span class="keyword">float</span> *predictions = l.output;</span><br><span class="line">	<span class="comment">//int per_cell = 5*num+classes;</span></span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.side*l.side; ++i) &#123;</span><br><span class="line">		<span class="keyword">int</span> row = i / l.side; <span class="comment">//获取grid cell的行号</span></span><br><span class="line">		<span class="keyword">int</span> col = i % l.side; <span class="comment">//获取grid cell的列号</span></span><br><span class="line">		<span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123; <span class="comment">//遍历两个box</span></span><br><span class="line">			<span class="keyword">int</span> index = i*l.n + n;</span><br><span class="line">			<span class="keyword">int</span> p_index = l.side*l.side*l.classes + i*l.n + n;</span><br><span class="line">			<span class="keyword">float</span> scale = predictions[p_index];</span><br><span class="line">			<span class="keyword">int</span> box_index = l.side*l.side*(l.classes + l.n) + (i*l.n + n) * <span class="number">4</span>;</span><br><span class="line">			box b;</span><br><span class="line">			b.x = (predictions[box_index + <span class="number">0</span>] + col) / l.side * w; <span class="comment">// 坐标转换为真实值</span></span><br><span class="line">			b.y = (predictions[box_index + <span class="number">1</span>] + row) / l.side * h;</span><br><span class="line">			b.w = <span class="built_in">pow</span>(predictions[box_index + <span class="number">2</span>], (l.sqrt ? <span class="number">2</span> : <span class="number">1</span>)) * w;</span><br><span class="line">			b.h = <span class="built_in">pow</span>(predictions[box_index + <span class="number">3</span>], (l.sqrt ? <span class="number">2</span> : <span class="number">1</span>)) * h;</span><br><span class="line">			dets[index].bbox = b;</span><br><span class="line">			dets[index].objectness = scale; <span class="comment">// 保存框置信度得分</span></span><br><span class="line">			<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.classes; ++j) &#123;</span><br><span class="line">				<span class="keyword">int</span> class_index = i*l.classes;</span><br><span class="line">				<span class="keyword">float</span> prob = scale*predictions[class_index + j]; <span class="comment">// 类别置信度得分=条件类别概率×框置信度得分</span></span><br><span class="line">				dets[index].prob[j] = (prob &gt; thresh) ? prob : <span class="number">0</span>; <span class="comment">// 低于阈值一律置为0</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv1</title>
    <url>/2020/02/27/YOLOv1/</url>
    <content><![CDATA[<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ul>
<li>将整张图作为网络的输入，直接在输出层回归bounding box的位置和所属类别。</li>
<li>速度快，One-Stage检测算法开山之作。</li>
</ul>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>回顾YOLO之前的目标检测算法，都是基于产生大量可能包含物体的先验框，然后用分类器判断每个先验框对应的边界框里是否包含待检测物体，以及物体所属类别的概率或者置信度，同时需要后处理修正边界框，最后基于一些准则过滤掉置信度不高和重叠度较高的边界框，进而得到检测结果。这种基于先产生候选区域再进行检测的方法虽然有较高的精度，但速度非常慢。YOLO直接将目标检测堪称一个回归问题进行处理，将候选区和检测两个阶段合二为一。YOLO的检测过程如下所示：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/640.webp" alt><br>事实上，YOLO并没有真正的去掉候选区，而是直接将输入图片划分成7 x 7=49个网格，每个网格预测两个边界框，一共预测49 x 2=98个边界框。可以近似理解为在输入图片上粗略的选取98个候选区，这98个候选区覆盖了图片的整个区域，进而用回归预测这98个候选框对应的边界框。</p>
<h2 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a>原理介绍</h2><p>YOLO将输入图像划分为S x S的栅格，每个栅格负责检测中心落在该栅格中的物体。每一个栅格预测B个bounding boxes，以及这些bounding boxes的confidence scores。这个confidence  scores反映了模型对于这个栅格的预测：该栅格是否含有物体，以及这个box的坐标预测的有多准。公式定义如下： </p>
<script type="math/tex; mode=display">
confidence =\operatorname{Pr}(\text { Object }) * I O U_{\text {pred}}^{\text {truth}}</script><p>如果这个栅格中不存在一个object，则confidence score应该为0。相反，confidence score则为预测框与真实框框之间的交并比。YOLO对每个bounding  box有5个predictions：x，y，w，h和 confidence。坐标x，y代表了预测的bounding  box的中心与栅格边界的相对值。坐标w，h代表了预测的bounding  box的width、height相对于整幅图像width,height的比例。confidence就是预测的bounding  box和ground truth box的IOU值。每一个栅格还要预测C个conditional class probability（条件类别概率）：$Pr(Class_i|Object)$。即在一个栅格包含一个Object的前提下，它属于某个类的概率。我们只为每个栅格预测一组（C个）类概率，而不考虑框B的数量。如图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/641.webp" alt><br>它将图像划分为S × S网格，并且每个网格单元预测B个边界框，对这些框的置信度以及C类概率。这些预测值被编码为S × S × (B × 5 + C)张量。为了评估PASCAL VOC上的YOLO，我们使用S = 7，B = 2。PASCAL VOC有20个标记类，因此C = 20。我们的最终预测是7 × 7 × 30张量。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>我们将此模型作为卷积神经网络实施并在PASCAL  VOC检测数据集上进行评估。网络的初始卷积层从图像中提取特征，而全连接的层预测输出概率和坐标。YOLO网络借鉴了GoogLeNet分类网络结构。不同的是，YOLO未使用inception  module，而是使用1 x 1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3 x 3卷积层简单替代。完整的网络结构如图所示，最终的输出结果是一个7 x 7 x 30的张量。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/642.webp" alt></p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>首先利用ImageNet 1000-class的分类任务数据集Pretrain卷积层。使用上述网络中的前20 个卷积层，加上一个 average-pooling  layer，最后加一个全连接层，作为 Pretrain 的网络。训练大约一周的时间，使得在ImageNet  2012的验证数据集Top-5的精度达到 88%，这个结果跟 GoogleNet 的效果相当。</p>
<p>将Pretrain的结果的前20层卷积层应用到Detection中，并加入剩下的4个卷积层及2个全连接。同时为了获取更精细化的结果，将输入图像的分辨率由 224<em> 224 提升到 448</em> 448。将所有的预测结果都归一化到 0~1, 使用 Leaky RELU 作为激活函数。Leaky  RELU的公式如下：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/643.png" alt></p>
<p>Leaky RELU可以解决RELU的梯度消失问题。</p>
<p>损失函数的设计目标就是让坐标（x,y,w,h），confidence，classification 这个三个方面达到很好的平衡。简单的全部采用了sum-squared error loss来做这件事会有以下不足：</p>
<ul>
<li>8维的localization error和20维的classification error同等重要显然是不合理的。</li>
<li>如果一些栅格中没有object（一幅图中这种栅格很多），那么就会将这些栅格中的bounding box的confidence置为0，相比于较少的有object的栅格，这些不包含物体的栅格对梯度更新的贡献会远大于包含物体的栅格对梯度更新的贡献，这会导致网络不稳定甚至发散。</li>
</ul>
<p>为了解决这些问题，YOLO的损失函数的定义如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/20180511204751564.png" alt></p>
<p>YOLO的损失函数更重视8维的坐标预测，给这些损失前面赋予更大的loss weight, 记为 λcoord ，在pascal VOC训练中取5（上图蓝色框）。 对没有object的bbox的confidence loss，赋予小的loss weight，记为 λnoobj ，在pascal VOC训练中取0.5（上图橙色框）。 有object的bbox的confidence loss (上图红色框) 和类别的loss （上图紫色框）的loss weight正常取1。对不同大小的bbox预测中，相比于大bbox预测偏一点，小box预测偏相同的尺寸对IOU的影响更大。而sum-square error loss中对同样的偏移loss是一样。为了缓和这个问题，作者用了一个巧妙的办法，就是将box的width和height取平方根代替原本的height和width。如下图：small bbox的横轴值的偏移与big bbox一样都为0.1，反应到y轴上的loss（下图绿色）比big box(下图红色)要大。即放大了small boxx的误差，使网络更注重于小尺度bbox的误差。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/644.webp" alt></p>
<p>在 YOLO中，每个栅格预测多个bounding box，但在网络模型的训练中，希望每一个物体最后由一个bounding box  predictor来负责预测。因此，当前哪一个predictor预测的bounding box与ground truth  box的IOU最大，这个predictor就负责predict  object。这会使得每个predictor可以专门的负责特定的物体检测。随着训练的进行，每一个predictor对特定的物体尺寸、长宽比的物体的类别的预测会越来越好。</p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>测试的时候，每个网格预测的class信息$\left(\operatorname{Pr}\left(\text {Class}_{i} | \text {Object}\right)\right)$和bounding box预测的confidence信息$\left(\operatorname{Pr}(\text { Object }) * I O U_{\text {pred }}^{\text {truth }}\right)$相乘，就得到每个bounding box的class-specific confidence score。</p>
<script type="math/tex; mode=display">
P_r(Class_i|Object) ∗ P_r(Object) ∗ IOU^{truth}_{pred} = P_r(Class_i) ∗ IOU^{truth}_{pred}</script><ul>
<li><p>等式左边第一项就是每个网格预测的类别信息，第二三项就是每个bounding box预测的confidence。这个乘积即encode了预测的box属于某一类的概率，也有该box准确度的信息。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/645.webp" alt></p>
</li>
<li><p>对每一个网格的每一个bbox执行同样操作：7 x 7 x 2 = 98 bbox （每个bbox既有对应的class信息又有坐标信息）<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/646.webp" alt></p>
</li>
<li><p>得到每个bbox的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/647.webp" alt></p>
<p>NMS的过程如下：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/648.gif" alt></p>
</li>
</ul>
<h2 id="算法优缺点"><a href="#算法优缺点" class="headerlink" title="算法优缺点"></a>算法优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>就像在训练中一样，图像的检测只需要一个网络评估。在PASCAL VOC上，网络预测每个图像的98个边界框和每个框的类概率。YOLO在测试时间速度非常快，因为它只需要一个网络预测，而不像基于分类器的方法，所以速度很快。</li>
<li>速度快，YOLO将物体检测作为回归问题进行求解，整个检测网络pipeline简单。在titan x GPU上，在保证检测准确率的前提下（63.4% mAP，VOC 2007 test set），可以达到45fps的检测速度。</li>
<li>背景误检率低。YOLO在训练和推理过程中能看到整张图像的整体信息，而基于region proposal的物体检测方法（如rcnn/fast  rcnn），在检测过程中，只看到候选框内的局部图像信息。因此，若当图像背景（非物体）中的部分数据被包含在候选框中送入检测网络进行检测时，容易被误检测成物体。测试证明，YOLO对于背景图像的误检率低于fast rcnn误检率的一半。</li>
<li>通用性强。YOLO对于艺术类作品中的物体检测同样适用。它对非自然图像物体的检测率远远高于DPM和RCNN系列检测方法。</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>每个 grid cell 只预测一个 类别的 Bounding Boxes，而且最后只取置信度最大的那个 Box。这就导致如果多个不同物体(或者同类物体的不同实体)的中心落在同一个网格中，会造成漏检。</li>
<li>预测的 Box 对于尺度的变化比较敏感，在尺度上的泛化能力比较差。</li>
<li>识别物体位置精准性差。</li>
<li>召回率低。</li>
</ul>
<h3 id="和其它算法对比"><a href="#和其它算法对比" class="headerlink" title="和其它算法对比"></a>和其它算法对比</h3><p>Table1给出了YOLO与其他物体检测方法，在检测速度和准确性方面的比较结果（使用VOC 2007数据集）。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/649.png" alt></p>
<p>论文中，作者还给出了YOLO与Fast RCNN在各方面的识别误差比例，如Table4所示。YOLO对背景内容的误判率（4.75%）比Fast  RCNN的误判率（13.6%）低很多。但是YOLO的定位准确率较差，占总误差比例的19.0%，而Fast RCNN仅为8.6%。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv1/650.png" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>YOLOv1最大的开创性贡献在于将物体检测作为一个回归问题进行求解，输入图像经过一次inference，便能得到图像中所有物体的位置和其所属类别及相应的置信概率。而rcnn/fast rcnn/faster rcnn将检测结果分为两部分求解：物体类别（分类问题），物体位置即bounding  box（回归问题），所以YOLO的目标检测速度很快。</li>
<li>YOLO仍然是一个速度换精度的算法，目标检测的精度不如RCNN</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv2损失函数详解</title>
    <url>/2020/03/01/YOLOv2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>YOLOv2详细讲解了YOLOv2的算法原理，但官方论文没有像YOLOv1那样提供YOLOv2的损失函数，难怪Ng说YOLO是目标检测中最难懂的算法。今天我们尝试结合DarkNet的源码来分析YOLOv2的损失函数。</p>
<h2 id="关键点回顾"><a href="#关键点回顾" class="headerlink" title="关键点回顾"></a>关键点回顾</h2><h3 id="直接位置预测"><a href="#直接位置预测" class="headerlink" title="直接位置预测"></a>直接位置预测</h3><p>YOLOv2借鉴RPN网络使用Anchor boxes来预测边界框相对于先验框的offsets。边界框的实际中心位置$(x, y)$需要利用预测的坐标偏移值$\left(t_{x}, t_{y}\right)$，先验框的尺度$\left(w_{a}, h_{a}\right)$以及中心坐标$\left(x_{a}, y_{a}\right)$来计算，这里的${x}_{a}$和${y}_{a}$也即是特征图每个位置的中心点：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/644.png" alt></p>
<p>上面的公式也是Faster-RCNN中预测边界框的方式。但上面的预测方式是没有约束的，预测的边界框容易向任何方向偏移，例如当$t_{x}=1$时边界框将向右偏移Anchor的一个宽度大小，导致每个位置预测的边界框可以落在图片的任意位置，这就导致模型训练的不稳定性，在训练的时候要花很长时间才可以得到正确的offsets。所以，YOLOv2弃用了这种预测方式，而是沿用YOLOv1的方法，就是预测边界框中心点相对于对应cell左上角位置的相对偏移值，为了将边界框中心点约束在当前cell中，使用sigmoid函数处理偏移值，这样预测的偏移值在(0,1)范围内（每个cell的尺度看做1）。</p>
<p>综上，根据边界框预测的4个偏移值$t_{x}, t_{y}, t_{w}, t_{h}$，可以使用如下公式来计算边界框实际中心位置和长宽，公式在图中：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/645.webp" alt></p>
<p>其中，$\left(c_{x}, c_{y}\right)$为cell的左上角坐标。在Fig3中，当前的cell的左上角坐标为$(1,1)$。由于sigmoid函数的处理，边界框的中心位置会被约束在当前cell的内部，防止偏移过多，然后$p_{w}$和$p_{h}$是先验框的宽度与高度，它们的值也是相对于特征图（这里是13 x 13，我们把特征图的长宽记作H，W）大小的，在特征图中的cell长宽均为1。这样我们就可以算出边界框相对于整个特征图的位置和大小了，公式如下：</p>
<script type="math/tex; mode=display">
b_{x}=\left(\sigma\left(t_{x}\right)+c_{x}\right) / W \quad b_{y}=\left(\sigma\left(t_{y}\right)+c_{y}\right) / H \quad b_{w}=p_{w} e^{t_{w}} / W \quad b_{h}=p_{h} e^{t_{h}} / H</script><p>我们如果将上面边界框的4个值乘以输入图像长宽，就可以得到边界框在原图中的位置和大小了。</p>
<h3 id="细粒度特征"><a href="#细粒度特征" class="headerlink" title="细粒度特征"></a>细粒度特征</h3><p>YOLOv2提取Darknet-19最后一个max pool层的输入，得到26x26x512的特征图。经过1x1x64的卷积以降低特征图的维度，得到26x26x64的特征图，然后经过pass  through层的处理变成13x13x256的特征图（抽取原特征图每个2x2的局部区域组成新的channel，即原特征图大小降低4倍，channel增加4倍），再与13x13x1024大小的特征图连接，变成13x13x1280的特征图，最后在这些特征图上做预测。使用Fine-Grained Features，YOLOv2的性能提升了1%。这个过程可以在下面的YOLOv2的结构图中看得很清楚：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/646.webp" alt></p>
<p>这个地方今天还要补充一点，那就是passthrough层到底是怎么操作的，在DarkNet中passthough层叫作reorg_layer，可以用下图来表示这个操作：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/649.webp" alt></p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>YOLOv2的训练分为三个阶段，具体就不再赘述了。这里主要重新关注一下训练后的维度变化，我们从上一小节可以看到最后YOLOv2的输出维度是$13 \times 13 \times 125$。这个125使用下面的公式来计算的：</p>
<script type="math/tex; mode=display">
numanchors \times(5+\text {num\_classes})</script><p>和训练采用的数据集有关系。由于anchors数为5，对于VOC数据集输出的channels数就是125，而对于COCO数据集则为425。这里以VOC数据集为例，最终的预测矩阵为$T$，shape为$\left[\text {batch}_{\text {size}}, 13,13,125\right]$，可以将其reshape成[batch_size, $13,13,5,25]$，这样$T[:, :, :, :, 0: 4]$是边界框的位置和大小$\left(t_{x}, t_{y}, t_{w}, t_{h}\right)$，$T[:, :, :, :, 4]$表示边界框的置信度$t_{o}$，$T[:, :, :, :, 5:]$而表示类别预测值。</p>
<h2 id="YOLOv2的模型结构"><a href="#YOLOv2的模型结构" class="headerlink" title="YOLOv2的模型结构"></a>YOLOv2的模型结构</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/650.webp" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/651.webp" alt></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>接下来就说一说今天的主题，损失函数。损失函数我看网上的众多讲解，发现有两种解释。</p>
<h3 id="解释1"><a href="#解释1" class="headerlink" title="解释1"></a>解释1</h3><p>YOLOv2的损失函数和YOLOv1一样，对于训练集中的ground truth，中心落在哪个cell，那么该cell的5个Anchor  box对应的边界框就负责预测它，具体由哪一个预测同样也是根据IOU计算后的阈值来确定的，最后选IOU值最大的那个。这也是建立在每个Cell至多含有一个目标的情下，实际上也基本不会出现多余1个的情况。和ground  truth匹配上的先验框负责计算坐标误差，置信度误差以及分类误差，而其它4个边界框只计算置信度误差。这个解释参考的YOLOv2实现是darkflow。源码地址为：<a href="https://github.com/thtrieu/darkflow">https://github.com/thtrieu/darkflow</a></p>
<h3 id="解释2"><a href="#解释2" class="headerlink" title="解释2"></a>解释2</h3><p>在官方提供的Darknet中，YOLOv2的损失函数可以不是和YOLOv1一样的，损失函数可以用下图来进行表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/661.webp" alt></p>
<p>可以看到这个损失函数是相当复杂的，损失函数的定义在Darknet/src/region_layer.c中。对于上面这一堆公式，我们先简单看一下，然后我们在源码中去找到对应部分。这里的$W$和$H$代表的是特征图的高宽，都为13，而$A$指的是Anchor个数，YOLOv2中是5，各个$\lambda$值是各个loss部分的权重系数。我们将损失函数分成3大部分来解释：</p>
<ul>
<li><p>第一部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/662.png" alt><br>第一项需要好好解释一下，这个loss是计算background的置信度误差，这也是YOLO系列算法的特色，但是用哪些预测框来预测背景呢？这里需要计算各个预测框和所有的ground  truth之间的IOU值，并且取最大值记作MaxIOU，如果该值小于一定的阈值，YOLOv2论文取了0.6，那么这个预测框就标记为background，需要计算$\lambda_{n o o b j}$这么多倍的损失函数。为什么这个公式可以这样表达呢？因为我们有物体的话，那么$\lambda_{n o o b j}=0$，如果没有物体$\lambda_{\text {noob} j}=1$，我们把这个值带入到下面的公式就可以推出第一项啦！<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/663.webp" alt></p>
</li>
<li><p>第二部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/664.png" alt><br>这一部分是计算Anchor boxes和预测框的坐标误差，但是只在前12800个iter计算，这一项应该是促进网络学习到Anchor的形状。</p>
</li>
<li><p>第三部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/665.webp" alt><br>这一部分计算的是和ground truth匹配的预测框各部分的损失总和，包括坐标损失，置信度损失以及分类损失。<br><strong>3.1 坐标损失</strong> 这里的匹配原则是指对于某个特定的ground truth，首先要计算其中心点落在哪个cell上，然后计算这个cell的5个先验框和grond  truth的IOU值，计算IOU值的时候不考虑坐标只考虑形状，所以先将Anchor boxes和ground  truth的中心都偏移到同一位置，然后计算出对应的IOU值，IOU值最大的先验框和ground  truth匹配，对应的预测框用来预测这个ground truth。<br><strong>3.2 置信度损失</strong> 在计算obj置信度时， 增加了一项权重系数，也被称为rescore参数，当其为1时，损失是预测框和ground truth的真实IOU值(darknet中采用了这种实现方式)。而对于没有和ground  truth匹配的先验框，除去那些Max_IOU低于阈值的，其它就全部忽略。YOLOv2和SSD与RPN网络的处理方式有很大不同，因为它们可以将一个ground truth分配给多个先验框。<br><strong>3.3 分类损失</strong> 这个和YOLOv1一致，没什么好说的了。</p>
</li>
</ul>
<p>我看了一篇讲解YOLOv2损失函数非常好的文章：<a href="https://www.cnblogs.com/YiXiaoZhou/p/7429481.html">https://www.cnblogs.com/YiXiaoZhou/p/7429481.html</a> 。里面还有一个关键点：</p>
<p>在计算boxes的$w$和$h$误差时，YOLOv1中采用的是平方根以降低boxes的大小对误差的影响，而YOLOv2是直接计算，但是根据ground truth的大小对权重系数进行修正：l.coord_scale x (2 - truth.w x truth.h)（这里和都归一化到(0,1))，这样对于尺度较小的boxes其权重系数会更大一些，可以放大误差，起到和YOLOv1计算平方根相似的效果。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>贴一下YOLOv2在Keras上的复现代码，地址为：<a href="https://github.com/yhcc/yolo2">https://github.com/yhcc/yolo2</a> 。网络结构如下，可以结合上面可视化图来看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">darknet</span>(<span class="params">images, n_last_channels=<span class="number">425</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Darknet19 for YOLOv2&quot;&quot;&quot;</span></span><br><span class="line">    net = conv2d(images, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv1&quot;</span>)</span><br><span class="line">    net = maxpool(net, name=<span class="string">&quot;pool1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv2&quot;</span>)</span><br><span class="line">    net = maxpool(net, name=<span class="string">&quot;pool2&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv3_1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">64</span>, <span class="number">1</span>, name=<span class="string">&quot;conv3_2&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv3_3&quot;</span>)</span><br><span class="line">    net = maxpool(net, name=<span class="string">&quot;pool3&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv4_1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">128</span>, <span class="number">1</span>, name=<span class="string">&quot;conv4_2&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv4_3&quot;</span>)</span><br><span class="line">    net = maxpool(net, name=<span class="string">&quot;pool4&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv5_1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">256</span>, <span class="number">1</span>, name=<span class="string">&quot;conv5_2&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv5_3&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">256</span>, <span class="number">1</span>, name=<span class="string">&quot;conv5_4&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv5_5&quot;</span>)</span><br><span class="line">    shortcut = net</span><br><span class="line">    net = maxpool(net, name=<span class="string">&quot;pool5&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv6_1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">512</span>, <span class="number">1</span>, name=<span class="string">&quot;conv6_2&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv6_3&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">512</span>, <span class="number">1</span>, name=<span class="string">&quot;conv6_4&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv6_5&quot;</span>)</span><br><span class="line">    <span class="comment"># ---------</span></span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv7_1&quot;</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv7_2&quot;</span>)</span><br><span class="line">    <span class="comment"># shortcut</span></span><br><span class="line">    shortcut = conv2d(shortcut, <span class="number">64</span>, <span class="number">1</span>, name=<span class="string">&quot;conv_shortcut&quot;</span>)</span><br><span class="line">    shortcut = reorg(shortcut, <span class="number">2</span>)</span><br><span class="line">    net = tf.concat([shortcut, net], axis=-<span class="number">1</span>)</span><br><span class="line">    net = conv2d(net, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&quot;conv8&quot;</span>)</span><br><span class="line">    <span class="comment"># detection layer</span></span><br><span class="line">    net = conv2d(net, n_last_channels, <span class="number">1</span>, batch_normalize=<span class="number">0</span>,</span><br><span class="line">                 activation=<span class="literal">None</span>, use_bias=<span class="literal">True</span>, name=<span class="string">&quot;conv_dec&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure>
<p>然后，网络经过介绍的损失函数优化训练以后，对网络输出结果进行解码得到最终的检测结果，这部分代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">detection_feat, feat_sizes=(<span class="params"><span class="number">13</span>, <span class="number">13</span></span>), num_classes=<span class="number">80</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">           anchors=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;decode from the detection feature&quot;&quot;&quot;</span></span><br><span class="line">    H, W = feat_sizes</span><br><span class="line">    num_anchors = <span class="built_in">len</span>(anchors)</span><br><span class="line">    detetion_results = tf.reshape(detection_feat, [-<span class="number">1</span>, H * W, num_anchors,</span><br><span class="line">                                        num_classes + <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">    bbox_xy = tf.nn.sigmoid(detetion_results[:, :, :, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line">    bbox_wh = tf.exp(detetion_results[:, :, :, <span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">    obj_probs = tf.nn.sigmoid(detetion_results[:, :, :, <span class="number">4</span>])</span><br><span class="line">    class_probs = tf.nn.softmax(detetion_results[:, :, :, <span class="number">5</span>:])</span><br><span class="line"></span><br><span class="line">    anchors = tf.constant(anchors, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">    height_ind = tf.<span class="built_in">range</span>(H, dtype=tf.float32)</span><br><span class="line">    width_ind = tf.<span class="built_in">range</span>(W, dtype=tf.float32)</span><br><span class="line">    x_offset, y_offset = tf.meshgrid(height_ind, width_ind)</span><br><span class="line">    x_offset = tf.reshape(x_offset, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    y_offset = tf.reshape(y_offset, [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># decode</span></span><br><span class="line">    bbox_x = (bbox_xy[:, :, :, <span class="number">0</span>] + x_offset) / W</span><br><span class="line">    bbox_y = (bbox_xy[:, :, :, <span class="number">1</span>] + y_offset) / H</span><br><span class="line">    bbox_w = bbox_wh[:, :, :, <span class="number">0</span>] * anchors[:, <span class="number">0</span>] / W * <span class="number">0.5</span></span><br><span class="line">    bbox_h = bbox_wh[:, :, :, <span class="number">1</span>] * anchors[:, <span class="number">1</span>] / H * <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">    bboxes = tf.stack([bbox_x - bbox_w, bbox_y - bbox_h,</span><br><span class="line">                       bbox_x + bbox_w, bbox_y + bbox_h], axis=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bboxes, obj_probs, class_probs</span><br></pre></td></tr></table></figure>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>这个损失函数最难的地方应该是YOLOv2利用sigmoid函数计算默认框坐标之后怎么梯度回传，这部分可以看下面的代码(来自Darknet源码)：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// box误差函数，计算梯度</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">delta_region_box</span><span class="params">(box truth, <span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">float</span> *delta, <span class="keyword">float</span> scale, <span class="keyword">int</span> stride)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    box pred = <span class="built_in">get_region_box</span>(x, biases, n, index, i, j, w, h, stride);</span><br><span class="line">    <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth);</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// 计算ground truth的offsets值</span></span><br><span class="line">    <span class="keyword">float</span> tx = (truth.x*w - i);</span><br><span class="line">    <span class="keyword">float</span> ty = (truth.y*h - j);</span><br><span class="line">    <span class="keyword">float</span> tw = <span class="built_in">log</span>(truth.w*w / biases[<span class="number">2</span>*n]);</span><br><span class="line">    <span class="keyword">float</span> th = <span class="built_in">log</span>(truth.h*h / biases[<span class="number">2</span>*n + <span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">    delta[index + <span class="number">0</span>*stride] = scale * (tx - x[index + <span class="number">0</span>*stride]);</span><br><span class="line">    delta[index + <span class="number">1</span>*stride] = scale * (ty - x[index + <span class="number">1</span>*stride]);</span><br><span class="line">    delta[index + <span class="number">2</span>*stride] = scale * (tw - x[index + <span class="number">2</span>*stride]);</span><br><span class="line">    delta[index + <span class="number">3</span>*stride] = scale * (th - x[index + <span class="number">3</span>*stride]);</span><br><span class="line">    <span class="keyword">return</span> iou;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结合一下前面介绍的公式，这就是一个逆过程。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv2</title>
    <url>/2020/02/28/YOLOv2/</url>
    <content><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>YOLOv1作为One-Stage目标检测算法的开山之作，速度快是它最大的优势。但我们知道，YOLOv1的定位不够准，并且召回率低。为了提升定位准确度，提高召回率，YOLOv2在YOLOv1的基础上进行了改进。具体的改进方法如图Fig1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/640.webp" alt></p>
<p>可以看到YOLOv2通过增加一些Trick使得v1的map值从63.4提高到了78.6，说明了YOLOv2改进方法的有效性。接下来我们就分析一下这些改进方法。</p>
<h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>这个应该不用多说了，YOLOv2在每个卷积层后面增加了BN层，去掉全连接的dropout。使用BN策略将map值提高了2%。</p>
<h2 id="高分辨率"><a href="#高分辨率" class="headerlink" title="高分辨率"></a>高分辨率</h2><p>当前大多数目标检测网络都喜欢使用主流分类网络如VGG,ResNet来做Backbone，而这些网络大多是在ImageNet上训练的，而分辨率的大小必然会影响到模型在测试集上的表现。所以，YOLOv2将输入的分辨率提升到$448 \times 448$，同时，为了使网络适应高分辨率，YOLOv2先在ImageNet上以$448 \times 448$的分辨率对网络进行10个epoch的微调，让网络适应高分辨率的输入。通过使用高分辨率的输入，YOLOv2将map值提高了约4%。</p>
<h2 id="基于卷积的Anchor机制"><a href="#基于卷积的Anchor机制" class="headerlink" title="基于卷积的Anchor机制"></a>基于卷积的Anchor机制</h2><p>YOLOv1利用全连接层直接对边界框进行预测，导致丢失较多空间信息，定位不准。YOLOv2去掉了YOLOv1中的全连接层，使用Anchor  Boxes预测边界框，同时为了得到更高分辨率的特征图，YOLOv2还去掉了一个池化层。由于图片中的物体都倾向于出现在图片的中心位置，若特征图恰好有一个中心位置，利用这个中心位置预测中心点落入该位置的物体，对这些物体的检测会更容易。所以总希望得到的特征图的宽高都为奇数。YOLOv2通过缩减网络，使用416x416的输入，模型下采样的总步长为32，最后得到13x13的特征图，然后对13x13的特征图的每个cell预测5个anchor boxes，对每个anchor box预测边界框的位置信息、置信度和一套分类概率值。使用anchor boxes之后，YOLOv2可以预测13x13x5=845个边界框，模型的召回率由原来的81%提升到88%，mAP由原来的69.5%降低到69.2%.召回率提升了7%，准确率下降了0.3%。这里我们和SSD以及Faster-RCNN做个对比，Faster  RCNN输入大小为1000*600时的boxes数量大概是6000，在SSD300中boxes数量是8732。显然增加box数量是为了提高object的定位准确率。</p>
<h2 id="维度聚类"><a href="#维度聚类" class="headerlink" title="维度聚类"></a>维度聚类</h2><p>在Faster-RCNN中，Anchor都是手动设定的，YOLOv2使用k-means聚类算法对训练集中的边界框做了聚类分析，尝试找到合适尺寸的Anchor。另外作者发现如果采用标准的k-means聚类，在box的尺寸比较大的时候其误差也更大，而我们希望的是误差和box的尺寸没有太大关系。所以通过IOU定义了如下的距离函数，使得误差和box的大小无关：</p>
<script type="math/tex; mode=display">
d(\text {box }, \text { centroid })=1-I O U(\text { box }, \text { centroid })</script><p>Fig2展示了聚类的簇的个数和IOU之间的关系，两条曲线分别代表了VOC和COCO数据集的测试结果。最后结合不同的K值对召回率的影响，论文选择了K=5，Figure2中右边的示意图是选出来的5个box的大小，这里紫色和黑色也是分别表示两个不同的数据集，可以看出其基本形状是类似的。而且发现聚类的结果和手动设置的anchor box大小差别显著。聚类的结果中多是高瘦的box，而矮胖的box数量较少，这也比较符合数据集中目标的视觉效果。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/641.png" alt></p>
<p>在结果测试时，YOLOv2采用的5种Anchor可以达到的Avg  IOU是61，而Faster-RCNN采用9种Anchor达到的平均IOU是60.9，也即是说本文仅仅选取5种Anchor就可以达到Faster-RCNN中9种Anchor的效果。如Table1所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/642.png" alt></p>
<h2 id="新Backbone-Darknet-19"><a href="#新Backbone-Darknet-19" class="headerlink" title="新Backbone:Darknet-19"></a>新Backbone:Darknet-19</h2><p>YOLOv2采用Darknet-19，其网络结构如下图所示，包括19个卷积层和5个max pooling层，主要采用$3 \times 3$卷积和$1 \times 1$卷积，这里$1 \times 1$卷积可以压缩特征图通道数以降低模型计算量和参数，每个卷积层后使用BN层以加快模型收敛同时防止过拟合。最终采用global avg pool 做预测。采用YOLOv2，模型的mAP值没有显著提升，但计算量减少了。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/643.webp" alt></p>
<h2 id="直接位置预测"><a href="#直接位置预测" class="headerlink" title="直接位置预测"></a>直接位置预测</h2><p>YOLOv2在引入Anchor的时候碰到第2个问题：模型不稳定，尤其是训练刚开始阶段。论文任务这种不稳定主要来自box的(x,y)预测值。我们知道在Faster-RCNN中，是通过预测下图中的$t_x$和$t_y$来得到(x,y)值，也就是预测的是offset。另外关于文中的这个公式，这个地方应该把后面的减号改成加号，这样才能符合公式下面的example。这里$\boldsymbol{x}_{\boldsymbol{a}}$和$\boldsymbol{y}_{\boldsymbol{a}}$是anchor的坐标，$\boldsymbol{w}_{\boldsymbol{a}}$和$\boldsymbol{h}_{\boldsymbol{a}}$是anchor的size，$\boldsymbol{x}$和$\boldsymbol{y}$是坐标的预测值，$\boldsymbol{t}_{\boldsymbol{x}}$和$\boldsymbol{t}_{\boldsymbol{y}}$是偏移量。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/644.png" alt></p>
<p>例子翻译过来是：当预测时$t_{x}=1$，就会把box向右边移动一定距离（具体为anchor box的宽度），预测时$t_{x}=-1$，就会把box向左边移动相同的距离。这个公式没有任何限制，使得无论在什么位置进行预测，任何anchor boxes可以在图像中任意一点结束，模型随机初始化后，需要花很长一段时间才能稳定预测敏感的物体位置。.</p>
<p>注意，高能来了！！！分析了原因之后，YOLOv2没有采用直接预测offset的方法，还是沿用了YOLO算法中直接预测相对于grid  cell的坐标位置的方式。前面提到网络在最后一个卷积层输出13*13大小的特征图，然后每个cell预测5个bounding  box，然后每个bounding box预测5个值：$t_{x}, t_{y}, t_{w}, t_{h}$和$t_o$（这里的$t_{o}$类似YOLOv1中的confidence）。$t_x$和$t_{y}$经过sigmoid函数处理后范围在0到1之间，这样的归一化处理使得模型训练更加稳定。$c_x$和$c_{y}$表示一个cell和图像左上角的横纵距离。$p_w$和$p_h$表示bounding box的宽高，这样$b_x$和$b_y$就是$c_x$和$c_y$这个cell附近的anchor来预测$t_x$和$t<br>_y$得到的结果。如Fig3所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/645.webp" alt></p>
<p>其中，$c_x$和$c_{y}$表示grid cell与图像左上角的横纵坐标距离，黑色虚线框是bounding box，蓝色矩形框就是最终预测的结果。注意，上图右边里面的$\delta\left(t_{x}\right)$可以理解为$s t_{x}$，$\delta\left(t_{y}\right)$可以理解为$s t_{y}$。每一个输出的bounding box是针对于一个特定的anchor，anchor其实是bounding box的width及height的一个参考。$p_{w}$和$p_{h}$是某个anchor box的宽和高，一个格子的$c_{x}$和$c_{y}$单位都是1，$\delta\left(t_{x}\right)$，$\delta\left(t_{y}\right)$是相对于某个格子左上角的偏移量。</p>
<h2 id="细粒度特征"><a href="#细粒度特征" class="headerlink" title="细粒度特征"></a>细粒度特征</h2><p>YOLOv2提取Darknet-19最后一个max pool层的输入，得到26x26x512的特征图。经过1x1x64的卷积以降低特征图的维度，得到26x26x64的特征图，然后经过pass  through层的处理变成13x13x256的特征图（抽取原特征图每个2x2的局部区域组成新的channel，即原特征图大小降低4倍，channel增加4倍），再与13x13x1024大小的特征图连接，变成13x13x1280的特征图，最后在这些特征图上做预测。使用Fine-Grained Features，YOLOv2的性能提升了1%。这个过程可以在下面的YOLOv2的结构图中看得很清楚：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/646.webp" alt></p>
<h2 id="多尺度训练"><a href="#多尺度训练" class="headerlink" title="多尺度训练"></a><strong>多尺度训练</strong></h2><p>YOLOv2中使用的Darknet-19网络结构中只有卷积层和池化层，所以其对输入图片的大小没有限制。YOLOv2采用多尺度输入的方式训练，在训练过程中每隔10个batches,重新随机选择输入图片的尺寸，由于Darknet-19下采样总步长为32，输入图片的尺寸一般选择32的倍数{320,352,…,608}。采用Multi-Scale Training,  可以适应不同大小的图片输入，当采用低分辨率的图片输入时，mAP值略有下降，但速度更快，当采用高分辨率的图片输入时，能得到较高mAP值，但速度有所下降。</p>
<p>这种机制使得网络可以更好地预测不同尺寸的图片，意味着同一个网络可以进行不同分辨率的检测任务，在小尺寸图片上YOLOv2运行更快，在速度和精度上达到了平衡。在小尺寸图片检测中，YOLOv2成绩很好，输入为228 x 228的时候，帧率达到90FPS，mAP几乎和Faster  R-CNN的水准相同。使得其在低性能GPU、高帧率视频、多路视频场景中更加适用。在大尺寸图片检测中，YOLOv2达到了SOAT结果，VOC2007 上mAP为78.6%，仍然高于平均水准，下图是YOLOv2和其他网络的精度对比：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/647.jfif" alt></p>
<p>速度对比：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv2/648.webp" alt></p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>YOLOv2的训练主要包括三个阶段。第一阶段：作者使用Darknet-19在标准1000类的ImageNet上训练了160次，用的随机梯度下降法，starting learning rate 为0.1，polynomial rate decay 为4，weight decay为0.0005  ，momentum 为0.9。训练的时候仍然使用了很多常见的数据扩充方法（data augmentation），包括random crops,  rotations, and hue, saturation, and exposure  shifts。（这些训练参数是基于darknet框架，和caffe不尽相同）初始的224 <em> 224训练后，作者把分辨率上调到了448 </em>  448，然后又训练了10次，学习率调整到了0.001。高分辨率下训练的分类网络在top-1准确率76.5%，top-5准确率93.3%。</p>
<p>第二个阶段：分类网络训练完后，就该训练检测网络了，作者去掉了原网络最后一个卷积层，转而增加了三个3 <em> 3 </em> 1024的卷积层（可参考darknet中cfg文件），并且在每一个上述卷积层后面跟一个1 <em>  1的卷积层，输出维度是检测所需的数量。对于VOC数据集，预测5种boxes大小，每个box包含5个坐标值和20个类别，所以总共是5 </em>  （5+20）= 125个输出维度。同时也添加了转移层（passthrough layer ），从最后那个3 <em> 3 </em>  512的卷积层连到倒数第二层，使模型有了细粒度特征。作者的检测模型以0.001的初始学习率训练了160次，在60次和90次的时候，学习率减为原来的十分之一。其他的方面，weight decay为0.0005，momentum为0.9，依然使用了类似于Faster-RCNN和SSD的数据扩充（data  augmentation）策略。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>YOLOv2借鉴了很多其它目标检测方法的一些技巧，如Faster R-CNN的anchor boxes,  SSD中的多尺度检测。除此之外，YOLOv2在网络设计上做了很多tricks,使它能在保证速度的同时提高检测准确率，Multi-Scale  Training更使得同一个模型适应不同大小的输入，从而可以在速度和精度上进行自由权衡。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3及YOLOv3-Tiny</title>
    <url>/2020/03/02/YOLOv3%E5%8F%8AYOLOv3-Tiny/</url>
    <content><![CDATA[<h2 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h2><p>YOLOv3应该是现在YOLO系列应用的最广泛的算法了，基本就很少有人做工程还用V2了。而YOLOv3的算法原理也很简单，就引入了2个东西，一个是残差模型，一个是FPN架构。</p>
<h2 id="残差模型Darknet-53"><a href="#残差模型Darknet-53" class="headerlink" title="残差模型Darknet-53"></a>残差模型Darknet-53</h2><p>YOLOv3在YOLOv2提出的Darknet-19的基础上引入了残差模块，并进一步加深了网络，改进后的网络有53个卷积层，命名为Darknet-53，网络结构如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/2709767-e65c08c61bfaa7c7.png" alt></p>
<p>同时为了说明Darknet-53的有效性，作者给出了在TitanX上，使用相同的条件将256 x 256的图片分别输入到以Darknet-19，Resnet-101，以及Resnet-152以及Darknet-53为基础网络的分类模型总，实验结果如下表：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv3/640.png" alt></p>
<p>从结果来看，Darknet-53比ResNet-101的性能更好，而且速度是其1.5倍，Darknet-53与ResNet-152性能相似但速度几乎是其2倍。同时，Darknet-53相比于其它网络结构实现了每秒最高的浮点数计算量，说明其网络结构可以更好的利用GPU。</p>
<h2 id="YOLOV3结构"><a href="#YOLOV3结构" class="headerlink" title="YOLOV3结构"></a>YOLOV3结构</h2><p>一张非常详细的结构图，其中YOLOv3有三个输出，维度分别是: (batchsize, 52,52,75 ) (batchsize, 26,26,75 ) (batchsize, 13,13,75 )这里的75代表的$3 \times(20+5)$，其中20代表的是COCO数据集目标类别数，5代表的是每个目标预测框的$t_{x}, t_{y}, t_{w}, t_{h}, t_{o}$，3代表的是某一个特征图的Anchor，也即先验框的数目。所以YOLOv3一共有9个Anchor，不过被平均分在了3个特征层中，这也实现了多尺度检测。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv3/641.webp" alt></p>
<h2 id="多尺度检测"><a href="#多尺度检测" class="headerlink" title="多尺度检测"></a>多尺度检测</h2><p>总结一下，YOLOv3借鉴了FPN的思想，从不同尺度提取特征。相比YOLOv2，YOLOv3提取最后3层特征图，不仅在每个特征图上分别独立做预测，同时通过将小特征图上采样到与大的特征图相同大小，然后与大的特征图拼接做进一步预测。用维度聚类的思想聚类出9种尺度的anchor box，将9种尺度的anchor box均匀的分配给3种尺度的特征图。</p>
<h2 id="补充：YOLOv3-Tiny"><a href="#补充：YOLOv3-Tiny" class="headerlink" title="补充：YOLOv3-Tiny"></a>补充：YOLOv3-Tiny</h2><p>或许对于速度要求比较高的项目，YOLOV3-tiny才是我们的首要选择，这个网络的原理不用多说了，就是在YOLOv3的基础上去掉了一些特征层，只保留了2个独立预测分支，具体的结构图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/YOLOv3/642.jpg" alt></p>
<p>这个是工程下更加常用的。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3中的参数进化</title>
    <url>/2020/02/15/YOLOv3%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E8%BF%9B%E5%8C%96/</url>
    <content><![CDATA[<p>YOLOv3代码中也提供了参数进化(搜索)，可以为对应的数据集进化一套合适的超参数。本文建档分析一下有关这部分的操作方法以及其参数的具体进化方法。</p>
<h2 id="1-超参数"><a href="#1-超参数" class="headerlink" title="1. 超参数"></a>1. 超参数</h2><p>YOLOv3中的超参数在train.py中提供，其中包含了一些数据增强参数设置，具体内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hyp = &#123;&#x27;giou&#x27;: 3.54,  # giou loss gain</span><br><span class="line">       &#x27;cls&#x27;: 37.4,  # cls loss gain</span><br><span class="line">       &#x27;cls_pw&#x27;: 1.0,  # cls BCELoss positive_weight</span><br><span class="line">       &#x27;obj&#x27;: 49.5,  # obj loss gain (*=img_size/320 if img_size != 320)</span><br><span class="line">       &#x27;obj_pw&#x27;: 1.0,  # obj BCELoss positive_weight</span><br><span class="line">       &#x27;iou_t&#x27;: 0.225,  # iou training threshold</span><br><span class="line">       &#x27;lr0&#x27;: 0.00579,  # initial learning rate (SGD=1E-3, Adam=9E-5)</span><br><span class="line">       &#x27;lrf&#x27;: -4.,  # final LambdaLR learning rate = lr0 * (10 ** lrf)</span><br><span class="line">       &#x27;momentum&#x27;: 0.937,  # SGD momentum</span><br><span class="line">       &#x27;weight_decay&#x27;: 0.000484,  # optimizer weight decay</span><br><span class="line">       &#x27;fl_gamma&#x27;: 0.5,  # focal loss gamma</span><br><span class="line">       &#x27;hsv_h&#x27;: 0.0138,  # image HSV-Hue augmentation (fraction)</span><br><span class="line">       &#x27;hsv_s&#x27;: 0.678,  # image HSV-Saturation augmentation (fraction)</span><br><span class="line">       &#x27;hsv_v&#x27;: 0.36,  # image HSV-Value augmentation (fraction)</span><br><span class="line">       &#x27;degrees&#x27;: 1.98,  # image rotation (+/- deg)</span><br><span class="line">       &#x27;translate&#x27;: 0.05,  # image translation (+/- fraction)</span><br><span class="line">       &#x27;scale&#x27;: 0.05,  # image scale (+/- gain)</span><br><span class="line">       &#x27;shear&#x27;: 0.641&#125;  # image shear (+/- deg)</span><br></pre></td></tr></table></figure>
<h2 id="2-使用方法"><a href="#2-使用方法" class="headerlink" title="2. 使用方法"></a>2. 使用方法</h2><p>在训练的时候，train.py提供了一个可选参数<code>--evolve</code>, 这个参数决定了是否进行超参数搜索与进化（默认是不开启超参数搜索的）。</p>
<p>具体使用方法也很简单：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py --data data/voc.data</span><br><span class="line">				--cfg cfg/yolov3-tiny.cfg</span><br><span class="line">				--img-size 416 </span><br><span class="line">				--epochs 273 </span><br><span class="line">				--evolve</span><br></pre></td></tr></table></figure>
<p>实际使用的时候，需要进行修改，train.py中的约444行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):  <span class="comment"># generations to evolve</span></span><br></pre></td></tr></table></figure>
<p>将其中的1修改为你想设置的迭代数，比如200代，如果不设置，结果将会如下图所示，实际上就是只有一代。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/646.webp" alt></p>
<h2 id="3-原理"><a href="#3-原理" class="headerlink" title="3. 原理"></a>3. 原理</h2><p>整个过程比较简单，对于进化过程中的新一代，都选了了适应性最高的前一代（在前几代中）进行突变。以上所有的参数将有约20%的 1-sigma的正态分布几率同时突变。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="number">0.2</span> <span class="comment"># sigma</span></span><br></pre></td></tr></table></figure>
<p>整个进化过程需要搞清楚两个点：</p>
<ol>
<li>如何评判其中一代的好坏？</li>
<li>下一代如何根据上一代进行进化？</li>
</ol>
<p><strong>第一个问题：</strong>判断好坏的标准。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fitness</span>(<span class="params">x</span>):</span></span><br><span class="line">    w = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.8</span>, <span class="number">0.2</span>]</span><br><span class="line">    <span class="comment"># weights for [P, R, mAP, F1]@0.5</span></span><br><span class="line">    <span class="keyword">return</span> (x[:, :<span class="number">4</span>] * w).<span class="built_in">sum</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>YOLOv3进化部分是通过以上的适应度函数判断的，适应度越高，代表这一代的性能越好。而在适应度中，是通过Precision,Recall ,mAP,F1这四个指标作为适应度的评价标准。</p>
<p>其中的w是设置的加权，如果更关心mAP的值，可以提高mAP的权重；如果更关心F1,则设置更高的权重在对应的F1上。这里分配mAP权重为0.8、F1权重为0.2。</p>
<p><strong>第二个问题：</strong>如何进行进化？</p>
<p>进化过程中有<strong>两个重要的参数</strong>:</p>
<p>第一个参数为<strong>parent</strong>, 可选值为<code>single</code>或者<code>weighted</code>，这个参数的作用是：决定如何选择上一代。如果选择single，代表只选择上一代中最好的那个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> parent == <span class="string">&#x27;single&#x27;</span> <span class="keyword">or</span> <span class="built_in">len</span>(x) == <span class="number">1</span>:</span><br><span class="line">	x = x[fitness(x).argmax()]</span><br></pre></td></tr></table></figure>
<p>如果选择weighted，代表选择得分的前10个加权平均的结果作为下一代，具体操作如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">elif</span> parent == <span class="string">&#x27;weighted&#x27;</span>:  <span class="comment"># weighted combination</span></span><br><span class="line">    n = <span class="built_in">min</span>(<span class="number">10</span>, <span class="built_in">len</span>(x))  <span class="comment"># number to merge</span></span><br><span class="line">    x = x[np.argsort(-fitness(x))][:n]  <span class="comment"># top n mutations</span></span><br><span class="line">    w = fitness(x) - fitness(x).<span class="built_in">min</span>()  <span class="comment"># weights</span></span><br><span class="line">    x = (x * w.reshape(n, <span class="number">1</span>)).<span class="built_in">sum</span>(<span class="number">0</span>) / w.<span class="built_in">sum</span>()  <span class="comment"># new parent</span></span><br></pre></td></tr></table></figure>
<p>第二个参数为<strong>method</strong>，可选值为<code>1,2,3</code>, 分别代表使用三种模式来进化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Mutate</span></span><br><span class="line">method = <span class="number">2</span></span><br><span class="line">s = <span class="number">0.2</span>  <span class="comment"># 20% sigma</span></span><br><span class="line">np.random.seed(<span class="built_in">int</span>(time.time()))</span><br><span class="line">g = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">.1</span>, \</span><br><span class="line">              <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])  <span class="comment"># gains</span></span><br><span class="line"><span class="comment"># 这里的g类似加权</span></span><br><span class="line">ng = <span class="built_in">len</span>(g)</span><br><span class="line"><span class="keyword">if</span> method == <span class="number">1</span>:</span><br><span class="line">    v = (np.random.randn(ng) *</span><br><span class="line">         np.random.random() * g * s + <span class="number">1</span>) ** <span class="number">2.0</span></span><br><span class="line"><span class="keyword">elif</span> method == <span class="number">2</span>:</span><br><span class="line">    v = (np.random.randn(ng) *</span><br><span class="line">         np.random.random(ng) * g * s + <span class="number">1</span>) ** <span class="number">2.0</span></span><br><span class="line"><span class="keyword">elif</span> method == <span class="number">3</span>:</span><br><span class="line">    v = np.ones(ng)</span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">all</span>(v == <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 为了防止重复，直到有变化才停下来</span></span><br><span class="line">         r = (np.random.random(ng) &lt; <span class="number">0.1</span>) * np.random.randn(ng)</span><br><span class="line">         <span class="comment"># 10% 的突变几率</span></span><br><span class="line">         v = (g * s * r + <span class="number">1</span>) ** <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(hyp.keys()):</span><br><span class="line">    hyp[k] = x[i + <span class="number">7</span>] * v[i]</span><br><span class="line">    <span class="comment"># 进行突变</span></span><br></pre></td></tr></table></figure>
<p>另外，为了防止突变过程，导致参数出现明显不合理的范围，需要用一个范围进行框定，将超出范围的内容剪切掉。具体方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Clip to limits</span></span><br><span class="line">keys = [<span class="string">&#x27;lr0&#x27;</span>, <span class="string">&#x27;iou_t&#x27;</span>, <span class="string">&#x27;momentum&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;weight_decay&#x27;</span>, <span class="string">&#x27;hsv_s&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;hsv_v&#x27;</span>, <span class="string">&#x27;translate&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;scale&#x27;</span>, <span class="string">&#x27;fl_gamma&#x27;</span>]</span><br><span class="line">limits = [(<span class="number">1e-5</span>, <span class="number">1e-2</span>), (<span class="number">0.00</span>, <span class="number">0.70</span>),</span><br><span class="line">          (<span class="number">0.60</span>, <span class="number">0.98</span>), (<span class="number">0</span>, <span class="number">0.001</span>),</span><br><span class="line">          (<span class="number">0</span>, <span class="number">.9</span>), (<span class="number">0</span>, <span class="number">.9</span>), (<span class="number">0</span>, <span class="number">.9</span>),</span><br><span class="line">          (<span class="number">0</span>, <span class="number">.9</span>), (<span class="number">0</span>, <span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(keys, limits):</span><br><span class="line">    hyp[k] = np.clip(hyp[k], v[<span class="number">0</span>], v[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>最终训练的超参数搜索的结果可视化：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/647.webp" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3模型构建中的YOLOLayer</title>
    <url>/2020/02/18/YOLOv3%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%AD%E7%9A%84YOLOLayer/</url>
    <content><![CDATA[<h2 id="1-Grid创建"><a href="#1-Grid创建" class="headerlink" title="1. Grid创建"></a>1. Grid创建</h2><p>YOLOv3是一个单阶段的目标检测器，将目标划分为不同的grid，每个grid分配3个anchor作为先验框来进行匹配。首先读一下代码中关于grid创建的部分。</p>
<p>首先了解一下pytorch中的API：<code>torch.mershgrid</code></p>
<p>举一个简单的例子就比较清楚了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Python <span class="number">3.7</span><span class="number">.3</span> (default, Apr <span class="number">24</span> <span class="number">2019</span>, <span class="number">15</span>:<span class="number">29</span>:<span class="number">51</span>) [MSC v<span class="number">.1915</span> <span class="number">64</span> bit (AMD64)] :: Anaconda, Inc. on win32</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.arange(<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x,y = torch.meshgrid(a,b)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>单纯看输入输出，可能不是很明白，列举一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&quot;(&quot;</span>, x[i,j], <span class="string">&quot;,&quot;</span> ,y[i,j],<span class="string">&quot;)&quot;</span>)</span><br><span class="line">...</span><br><span class="line">( tensor(<span class="number">0</span>) , tensor(<span class="number">0</span>) )</span><br><span class="line">( tensor(<span class="number">0</span>) , tensor(<span class="number">1</span>) )</span><br><span class="line">( tensor(<span class="number">0</span>) , tensor(<span class="number">2</span>) )</span><br><span class="line">( tensor(<span class="number">0</span>) , tensor(<span class="number">3</span>) )</span><br><span class="line">( tensor(<span class="number">1</span>) , tensor(<span class="number">0</span>) )</span><br><span class="line">( tensor(<span class="number">1</span>) , tensor(<span class="number">1</span>) )</span><br><span class="line">( tensor(<span class="number">1</span>) , tensor(<span class="number">2</span>) )</span><br><span class="line">( tensor(<span class="number">1</span>) , tensor(<span class="number">3</span>) )</span><br><span class="line">( tensor(<span class="number">2</span>) , tensor(<span class="number">0</span>) )</span><br><span class="line">( tensor(<span class="number">2</span>) , tensor(<span class="number">1</span>) )</span><br><span class="line">( tensor(<span class="number">2</span>) , tensor(<span class="number">2</span>) )</span><br><span class="line">( tensor(<span class="number">2</span>) , tensor(<span class="number">3</span>) )</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.stack((x,y),<span class="number">2</span>)</span><br><span class="line">tensor([[[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">4</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">4</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">2</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">         [<span class="number">2</span>, <span class="number">4</span>]]])</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>现在就比较清楚了，划分了3×4的网格，通过遍历得到的x和y就能遍历全部格子。</p>
<p>下面是yolov3中提供的代码(需要注意的是这是针对某一层YOLOLayer，而不是所有的YOLOLayer：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_grids</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 img_size=<span class="number">416</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 ng=(<span class="params"><span class="number">13</span>, <span class="number">13</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="function">                 device=<span class="string">&#x27;cpu&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="built_in">type</span>=torch.float32</span>):</span></span><br><span class="line">    nx, ny = ng  <span class="comment"># 网格尺寸</span></span><br><span class="line">    self.img_size = <span class="built_in">max</span>(img_size)</span><br><span class="line">    <span class="comment">#下采样倍数为32</span></span><br><span class="line">    self.stride = self.img_size / <span class="built_in">max</span>(ng)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分网格，构建相对左上角的偏移量</span></span><br><span class="line">    yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])</span><br><span class="line">    <span class="comment"># 通过以上例子很容易理解</span></span><br><span class="line">    self.grid_xy = torch.stack((xv, yv), <span class="number">2</span>).to(device).<span class="built_in">type</span>(<span class="built_in">type</span>).view(</span><br><span class="line">        (<span class="number">1</span>, <span class="number">1</span>, ny, nx, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理anchor，将其除以下采样倍数</span></span><br><span class="line">    self.anchor_vec = self.anchors.to(device) / self.stride</span><br><span class="line">    self.anchor_wh = self.anchor_vec.view(<span class="number">1</span>, self.na, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                          <span class="number">2</span>).to(device).<span class="built_in">type</span>(<span class="built_in">type</span>)</span><br><span class="line">    self.ng = torch.Tensor(ng).to(device)</span><br><span class="line">    self.nx = nx</span><br><span class="line">    self.ny = ny</span><br></pre></td></tr></table></figure>
<h2 id="2-YOLOLayer"><a href="#2-YOLOLayer" class="headerlink" title="2. YOLOLayer"></a>2. YOLOLayer</h2><p>在之前的文章中讲过，YOLO层前一层卷积层的filter个数具有特殊的要求，计算方法为：</p>
<p>如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/653.webp" alt></p>
<p><strong>训练过程：</strong></p>
<p>YOLOLayer的作用就是对上一个卷积层得到的张量进行处理，具体可以看training过程涉及的代码(暂时不关心ONNX部分的代码)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YOLOLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, anchors, nc, img_size, yolo_index, arc</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(YOLOLayer, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.anchors = torch.Tensor(anchors)</span><br><span class="line">        self.na = <span class="built_in">len</span>(anchors)  <span class="comment"># 该YOLOLayer分配给每个grid的anchor的个数</span></span><br><span class="line">        self.nc = nc  <span class="comment"># 类别个数</span></span><br><span class="line">        self.no = nc + <span class="number">5</span>  <span class="comment"># 每个格子对应输出的维度 class + 5 中5代表x,y,w,h,conf</span></span><br><span class="line">        self.nx = <span class="number">0</span>  <span class="comment"># 初始化x方向上的格子数量</span></span><br><span class="line">        self.ny = <span class="number">0</span>  <span class="comment"># 初始化y方向上的格子数量</span></span><br><span class="line">        self.arc = arc</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ONNX_EXPORT:  <span class="comment"># grids must be computed in __init__</span></span><br><span class="line">            stride = [<span class="number">32</span>, <span class="number">16</span>, <span class="number">8</span>][yolo_index]  <span class="comment"># stride of this layer</span></span><br><span class="line">            nx = <span class="built_in">int</span>(img_size[<span class="number">1</span>] / stride)  <span class="comment"># number x grid points</span></span><br><span class="line">            ny = <span class="built_in">int</span>(img_size[<span class="number">0</span>] / stride)  <span class="comment"># number y grid points</span></span><br><span class="line">            create_grids(self, img_size, (nx, ny))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, p, img_size, var=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        onnx代表开放式神经网络交换</span></span><br><span class="line"><span class="string">        pytorch中的模型都可以导出或转换为标准ONNX格式</span></span><br><span class="line"><span class="string">        在模型采用ONNX格式后，即可在各种平台和设备上运行</span></span><br><span class="line"><span class="string">        在这里ONNX代表规范化的推理过程</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> ONNX_EXPORT:</span><br><span class="line">            bs = <span class="number">1</span>  <span class="comment"># batch size</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            bs, _, ny, nx = p.shape  <span class="comment"># bs, 255, 13, 13</span></span><br><span class="line">            <span class="keyword">if</span> (self.nx, self.ny) != (nx, ny):</span><br><span class="line">                create_grids(self, img_size, (nx, ny), p.device, p.dtype)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># p.view(bs, 255, 13, 13) -- &gt; (bs, 3, 13, 13, 85)</span></span><br><span class="line">        <span class="comment"># (bs, anchors, grid, grid, classes + xywh)</span></span><br><span class="line">        p = p.view(bs, self.na, self.no, self.ny,</span><br><span class="line">                   self.nx).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>).contiguous()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.training:</span><br><span class="line">            <span class="keyword">return</span> p</span><br></pre></td></tr></table></figure>
<p>在理解以上代码的时候，需要理解每一个通道所代表的意义，原先的P是由上一层卷积得到的feature map, 形状为(以80个类别、输入416、下采样32倍为例)：【batch size, anchor×(80+5), 13,  13】，在训练的过程中，将feature map通过张量操作转化的形状为：【batch size, anchor, 13, 13, 85】。</p>
<p><strong>测试过程：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># p的形状目前为：【bs, anchor_num, gridx,gridy,xywhc+class】</span></span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># 测试推理过程</span></span><br><span class="line">   <span class="comment"># s = 1.5  # scale_xy  (pxy = pxy * s - (s - 1) / 2)</span></span><br><span class="line">   io = p.clone()  <span class="comment"># 测试过程输出就是io</span></span><br><span class="line">   io[..., :<span class="number">2</span>] = torch.sigmoid(io[..., :<span class="number">2</span>]) + self.grid_xy  <span class="comment"># xy</span></span><br><span class="line">   <span class="comment"># grid_xy是左上角再加上偏移量io[...:2]代表xy偏移</span></span><br><span class="line">   io[..., <span class="number">2</span>:<span class="number">4</span>] = torch.exp(</span><br><span class="line">       io[..., <span class="number">2</span>:<span class="number">4</span>]) * self.anchor_wh  <span class="comment"># wh yolo method</span></span><br><span class="line">   <span class="comment"># io[..., 2:4] = ((torch.sigmoid(io[..., 2:4]) * 2) ** 3) * self.anchor_wh</span></span><br><span class="line">   <span class="comment"># wh power method</span></span><br><span class="line">   io[..., :<span class="number">4</span>] *= self.stride</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> <span class="string">&#x27;default&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># seperate obj and cls</span></span><br><span class="line">       torch.sigmoid_(io[..., <span class="number">4</span>])</span><br><span class="line">   <span class="keyword">elif</span> <span class="string">&#x27;BCE&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># unified BCE (80 classes)</span></span><br><span class="line">       torch.sigmoid_(io[..., <span class="number">5</span>:])</span><br><span class="line">       io[..., <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line">   <span class="keyword">elif</span> <span class="string">&#x27;CE&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># unified CE (1 background + 80 classes)</span></span><br><span class="line">       io[..., <span class="number">4</span>:] = F.softmax(io[..., <span class="number">4</span>:], dim=<span class="number">4</span>)</span><br><span class="line">       io[..., <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> self.nc == <span class="number">1</span>:</span><br><span class="line">       io[..., <span class="number">5</span>] = <span class="number">1</span></span><br><span class="line">       <span class="comment"># single-class model https://github.com/ultralytics/yolov3/issues/235</span></span><br><span class="line"></span><br><span class="line">   <span class="comment"># reshape from [1, 3, 13, 13, 85] to [1, 507, 85]</span></span><br><span class="line">   <span class="keyword">return</span> io.view(bs, -<span class="number">1</span>, self.no), p</span><br></pre></td></tr></table></figure>
<p>理解以上内容是需要对应以下公式：</p>
<script type="math/tex; mode=display">
\begin{aligned} b_{x}=& \sigma\left(t_{x}\right)+c_{x} \\ b_{y}=& \sigma\left(t_{y}\right)+c_{y} \\ b_{w}=& p_{w} e^{t_{x}} \\ b_{h}=& p_{h} e^{t_{h}} \end{aligned}</script><p><strong>xy部分:</strong></p>
<script type="math/tex; mode=display">
b_{x}=\sigma\left(t_{x}\right)+c_{x}\\
b_{y}=\sigma\left(t_{y}\right)+c_{y}</script><p>$c_{x}, c_{y}$代表的是格子的左上角坐标；$t_{x}, t_{y}$代表的是网络预测的结果； $\sigma$代表sigmoid激活函数。对应代码理解：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">io[..., :<span class="number">2</span>] = torch.sigmoid(io[..., :<span class="number">2</span>]) + self.grid_xy  <span class="comment"># xy</span></span><br><span class="line"><span class="comment"># grid_xy是左上角再加上偏移量io[...:2]代表xy偏移</span></span><br></pre></td></tr></table></figure>
<p><strong>wh部分:</strong></p>
<script type="math/tex; mode=display">
b_{w}=p_{w} e^{t_{x}}\\
b_{h}=p_{h} e^{t_{h}}</script><p>$p_{w}, p_{h}$代表的是anchor先验框在feature map上对应的大小。$t_{w}, t_{h}$代表的是网络学习得到的缩放系数。对应代码理解：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># wh yolo method</span></span><br><span class="line">io[..., <span class="number">2</span>:<span class="number">4</span>] = torch.exp(io[..., <span class="number">2</span>:<span class="number">4</span>]) * self.anchor_wh</span><br></pre></td></tr></table></figure>
<p><strong>class部分：</strong></p>
<p>在类别部分，提供了几种方法，根据arc参数来进行不同模式的选择。以CE（crossEntropy）为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#io：(bs, anchors, grid, grid, xywh+classes)</span></span><br><span class="line">io[..., <span class="number">4</span>:] = F.softmax(io[..., <span class="number">4</span>:], dim=<span class="number">4</span>)<span class="comment"># 使用softmax</span></span><br><span class="line">io[..., <span class="number">4</span>] = <span class="number">1</span> </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3的cfg文件解析</title>
    <url>/2020/02/14/YOLOv3%E7%9A%84cfg%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="1-Net层"><a href="#1-Net层" class="headerlink" title="1. Net层"></a>1. Net层</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[net]</span><br><span class="line">#Testing</span><br><span class="line">#batch=1</span><br><span class="line">#subdivisions=1</span><br><span class="line">#在测试的时候，设置batch=1,subdivisions=1</span><br><span class="line">#Training</span><br><span class="line">batch=16</span><br><span class="line">subdivisions=4</span><br><span class="line">#这里的batch与普遍意义上的batch不是一致的。</span><br><span class="line">#训练的过程中将一次性加载16张图片进内存，然后分4次完成前向传播，每次4张。</span><br><span class="line">#经过16张图片的前向传播以后，进行一次反向传播。</span><br><span class="line">width=416</span><br><span class="line">height=416</span><br><span class="line">channels=3</span><br><span class="line">#设置图片进入网络的宽、高和通道个数。</span><br><span class="line">#由于YOLOv3的下采样一般是32倍，所以宽高必须能被32整除。</span><br><span class="line">#多尺度训练选择为32的倍数最小320*320，最大608*608。</span><br><span class="line">#长和宽越大，对小目标越好，但是占用显存也会高，需要权衡。</span><br><span class="line">momentum=0.9</span><br><span class="line">#动量参数影响着梯度下降到最优值的速度。</span><br><span class="line">decay=0.0005</span><br><span class="line">#权重衰减正则项，防止过拟合。</span><br><span class="line">angle=0</span><br><span class="line">#数据增强，设置旋转角度。</span><br><span class="line">saturation = 1.5</span><br><span class="line">#饱和度</span><br><span class="line">exposure = 1.5</span><br><span class="line">#曝光量</span><br><span class="line">hue=.1</span><br><span class="line">#色调</span><br><span class="line"></span><br><span class="line">learning_rate=0.001</span><br><span class="line">#学习率:刚开始训练时可以将学习率设置的高一点，而一定轮数之后，将其减小。</span><br><span class="line">#在训练过程中，一般根据训练轮数设置动态变化的学习率。</span><br><span class="line">burn_in=1000</span><br><span class="line">#在迭代次数小于burn_in时，其学习率的更新有一种方式，大于burn in时，才采用policy的更新方式</span><br><span class="line">max_batches = 500200</span><br><span class="line">#最大batch</span><br><span class="line">policy=steps</span><br><span class="line">#学习率调整的策略，有以下policy：</span><br><span class="line">#constant, steps, exp, poly, step, sig, RANDOM，constant等方式</span><br><span class="line">#调整学习率的policy，</span><br><span class="line">#有如下policy：constant, steps, exp, poly, step, sig, RANDOM。</span><br><span class="line">#steps#比较好理解，按照steps来改变学习率。</span><br><span class="line"></span><br><span class="line">steps=400000,450000</span><br><span class="line">scales=.1,.1</span><br><span class="line">#在达到40000、45000的时候将学习率乘以对应的scale</span><br><span class="line">#即steps和scale是设置学习率的变化，迭代到40000次时，学习率衰减10倍，45000次迭代时，学习率又会在前一个学习率的基础上衰减10倍</span><br></pre></td></tr></table></figure>
<h2 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2. 卷积层"></a>2. 卷积层</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1    		</span><br><span class="line">#是否做BN操作</span><br><span class="line">filters=32                  </span><br><span class="line">#输出特征图的数量</span><br><span class="line">size=3               		</span><br><span class="line">#卷积核的尺寸</span><br><span class="line">stride=1                	</span><br><span class="line">#做卷积运算的步长</span><br><span class="line">pad=1               		</span><br><span class="line">#卷积时是否进行补零padding；padding的个数与卷积核尺寸有关，为size/2向下取整，如3/2=1</span><br><span class="line">activation=leaky		</span><br><span class="line">#激活函数的类型：logistic，loggy，relu，</span><br><span class="line">#elu，relie，plse，hardtan，lhtan，</span><br><span class="line">#linear，ramp，leaky，tanh，stair</span><br><span class="line"># alexeyAB版添加了mish, swish, nrom_chan等新的激活函数</span><br></pre></td></tr></table></figure>
<p>feature map计算公式：</p>
<script type="math/tex; mode=display">
OutFeature =\frac{\text {InFeature}+2 \times \text { padding }-\text {size}}{\text {stride}}+1</script><h2 id="3-下采样"><a href="#3-下采样" class="headerlink" title="3. 下采样"></a>3. 下采样</h2><p>可以通过调整卷积层参数进行下采样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=3</span><br><span class="line">stride=2</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br></pre></td></tr></table></figure>
<p>可以通过带入以上公式，可以得到OutFeature是InFeature的一半。</p>
<p>也可以使用maxpooling进行下采样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br></pre></td></tr></table></figure>
<h2 id="4-上采样"><a href="#4-上采样" class="headerlink" title="4. 上采样"></a>4. 上采样</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[upsample]</span><br><span class="line">stride=2</span><br></pre></td></tr></table></figure>
<p>上采样是通过线性插值实现的。</p>
<h2 id="5-Shortcut和Route层"><a href="#5-Shortcut和Route层" class="headerlink" title="5. Shortcut和Route层"></a>5. Shortcut和Route层</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[shortcut]</span><br><span class="line">from=-3</span><br><span class="line">activation=linear</span><br><span class="line">#shortcut操作是类似ResNet的跨层连接，参数from是−3，</span><br><span class="line">#意思是shortcut的输出是当前层与先前的倒数第三层相加而得到。</span><br><span class="line"># 通俗来讲就是add操作</span><br><span class="line"></span><br><span class="line">[route]</span><br><span class="line">layers = -1, 36</span><br><span class="line"># 当属性有两个值，就是将上一层和第36层进行concate</span><br><span class="line">#即沿深度的维度连接，这也要求feature map大小是一致的。</span><br><span class="line">[route]</span><br><span class="line">layers = -4</span><br><span class="line">#当属性只有一个值时，它会输出由该值索引的网络层的特征图。</span><br><span class="line">#本例子中就是提取从当前倒数第四个层输出</span><br></pre></td></tr></table></figure>
<h2 id="6-YOLO层"><a href="#6-YOLO层" class="headerlink" title="6. YOLO层"></a>6. YOLO层</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=18</span><br><span class="line">#每一个[region/yolo]层前的最后一个卷积层中的</span><br><span class="line">#filters=num(yolo层个数)*(classes+5) ,5的意义是5个坐标，</span><br><span class="line">#代表论文中的tx,ty,tw,th,po</span><br><span class="line">#这里类别个数为1，（1+5）*3=18</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line">[yolo]	</span><br><span class="line">mask = 6,7,8 				</span><br><span class="line">#训练框mask的值是0,1,2，			</span><br><span class="line">#这意味着使用第一，第二和第三个anchor</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,\</span><br><span class="line">		  59,119,  116,90,  156,198,  373,326</span><br><span class="line"># 总共有三个检测层，共计9个anchor</span><br><span class="line"># 这里的anchor是由kmeans聚类算法得到的。</span><br><span class="line">classes=1 </span><br><span class="line">#类别个数</span><br><span class="line">num=9     			</span><br><span class="line">#每个grid预测的BoundingBox num/yolo层个数</span><br><span class="line">jitter=.3    		</span><br><span class="line">#利用数据抖动产生更多数据，</span><br><span class="line">#属于TTA（Test Time Augmentation）</span><br><span class="line">ignore_thresh = .5</span><br><span class="line"># ignore_thresh 指的是参与计算的IOU阈值大小。</span><br><span class="line">#当预测的检测框与ground true的IOU大于ignore_thresh的时候，</span><br><span class="line">#参与loss的计算，否则，检测框的不参与损失计算。</span><br><span class="line">#目的是控制参与loss计算的检测框的规模，当ignore_thresh过于大，</span><br><span class="line">#接近于1的时候，那么参与检测框回归loss的个数就会比较少，同时也容易造成过拟合；</span><br><span class="line">#而如果ignore_thresh设置的过于小，那么参与计算的会数量规模就会很大。</span><br><span class="line">#同时也容易在进行检测框回归的时候造成欠拟合。</span><br><span class="line">#ignore_thresh 一般选取0.5-0.7之间的一个值</span><br><span class="line"># 小尺度（13*13）用的是0.7，</span><br><span class="line"># 大尺度（26*26）用的是0.5。</span><br></pre></td></tr></table></figure>
<h2 id="7-模块总结"><a href="#7-模块总结" class="headerlink" title="7. 模块总结"></a>7. 模块总结</h2><p>Darket-53结构如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_detection/2709767-e65c08c61bfaa7c7.png" alt></p>
<p>它是由重复的类似于ResNet的模块组成的，其下采样是通过卷积来完成的。通过对cfg文件的观察，提出了以下总结：</p>
<p><strong>不改变feature大小的模块：</strong></p>
<ol>
<li>残差模块：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=256</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[shortcut]</span><br><span class="line">from=-3</span><br><span class="line">activation=linear</span><br></pre></td></tr></table></figure>
<ol>
<li>1×1卷积：可以降低计算量</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=512</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br></pre></td></tr></table></figure>
<ol>
<li>普通3×3卷积：可以对filter个数进行调整</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=1024</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br></pre></td></tr></table></figure>
<p><strong>改变feature map大小</strong></p>
<ol>
<li>feature map减半：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=3</span><br><span class="line">stride=2</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br></pre></td></tr></table></figure>
<ol>
<li>feature map加倍:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=1</span><br></pre></td></tr></table></figure>
<p><strong>特征融合操作</strong></p>
<ol>
<li>使用Route层获取指定的层（13×13）。</li>
<li>添加卷积层进行学习但不改变feature map大小。</li>
<li>进行上采样（26×26）。</li>
<li>从backbone中找到对应feature map大小的层进行Route或者Shortcut（26×26）。</li>
<li>融合完成。</li>
</ol>
<blockquote>
<p>后记：以上是使用darknet过程中收集和总结的一些经验，掌握以上内容并读懂yolov3论文后，就可以着手运行代码了。目前使用与darknet一致的cfg文件解析的有一些，比如原版Darknet，AlexeyAB版本的Darknet，还有一个pytorch版本的yolov3。AlexeyAB版本的添加了很多新特性，比如 [conv_lstm], [scale_channels] SE/ASFF/BiFPN, [local_avgpool], [sam],  [Gaussian_yolo], [reorg3d] (fixed [reorg]),  [batchnorm]等等。而pytorch版本的yolov3可以很方便的添加我们需要的功能。之后我们将会对这个版本进行改进，添加孔洞卷积、SE、CBAM、SK等模块。</p>
</blockquote>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>arxiv文章下载加速</title>
    <url>/2020/01/26/arxiv%E6%96%87%E7%AB%A0%E4%B8%8B%E8%BD%BD%E5%8A%A0%E9%80%9F/</url>
    <content><![CDATA[<p>对于我们这样的深度学习屌丝来说，没钱，没资源，没数据，没时间，只能看看别人的论文生存了，经常会到arxiv上下载一些文章，比如cvpr的文章，但是，由于国内封锁，下载很慢，甚至接连几天打不开arxiv的网站，咋办？</p>
<p>强烈推荐使用中科院arxiv的镜像地址：<a href="http://xxx.itp.ac.cn">http://xxx.itp.ac.cn</a><br>具体使用方法：把要访问 arxiv 链接中的域名从 <a href="https://arxiv.org">https://arxiv.org</a> 换成 <a href="http://xxx.itp.ac.cn">http://xxx.itp.ac.cn</a> ,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">比如:</span><br><span class="line">https://arxiv.org/pdf/1608.00367</span><br><span class="line">换成：</span><br><span class="line">http://xxx.itp.ac.cn/pdf/1608.00367.pdf</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">或者将：</span><br><span class="line">https://arxiv.org/abs/1608.00367</span><br><span class="line">换成：</span><br><span class="line">http://xxx.itp.ac.cn/abs/1608.00367</span><br></pre></td></tr></table></figure>
<p>即可打开，是不是很爽？</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>arxiv</tag>
      </tags>
  </entry>
  <entry>
    <title>keras/tensorflow转onnx</title>
    <url>/2021/09/25/keras%E8%BD%AConnx/</url>
    <content><![CDATA[<p>项目中遇到需要将训练好的keras模型转换成onnx以便部署到嵌入式设备进行RT加速，最开始使用的<a href="[GitHub - onnx/keras-onnx: Convert tf.keras/Keras models to ONNX](https://github.com/onnx/keras-onnx">keras2onnx</a>工具，然而此工具支持性并不好，在转化过程中遇到许多问题。因此决定将keras转成tensorflow格式，再使用支持性较好的<a href="[GitHub - onnx/tensorflow-onnx: Convert TensorFlow, Keras, Tensorflow.js and Tflite models to ONNX](https://github.com/onnx/tensorflow-onnx">tf2onnx</a>工具进行转化。</p>
<h1 id="新版本"><a href="#新版本" class="headerlink" title="新版本"></a>新版本</h1><p>目前keras2onnx停止更新，功能已整合进<a href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a>中，keras模型可直接使用 api <a href="https://github.com/onnx/tensorflow-onnx#from_keras-tf-20-and-newer">tf2onnx.convert.from_keras()</a>完成转换操作</p>
<h2 id="转换步骤："><a href="#转换步骤：" class="headerlink" title="转换步骤："></a>转换步骤：</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tf2onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> rt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model = ResNet50(weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line"><span class="comment"># 设置输入大小</span></span><br><span class="line">spec = (tf.TensorSpec((<span class="literal">None</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>), tf.float32, name=<span class="string">&quot;input&quot;</span>),)</span><br><span class="line"><span class="comment"># 保存onnx路径</span></span><br><span class="line">output_path = model.name + <span class="string">&quot;.onnx&quot;</span></span><br><span class="line"><span class="comment"># 转换</span></span><br><span class="line">tf2onnx.convert.from_keras(model, input_signature=spec, opset=<span class="number">13</span>, output_path=output_path)</span><br></pre></td></tr></table></figure>
<h2 id="API说明："><a href="#API说明：" class="headerlink" title="API说明："></a>API说明：</h2><blockquote>
<p>import tf2onnx</p>
<p>model_proto, external_tensor_storage = tf2onnx.convert.from_keras(model,<br>                input_signature=None, opset=None, custom_ops=None,<br>                custom_op_handlers=None, custom_rewriter=None,<br>                inputs_as_nchw=None, extra_opset=None shape_override=None,<br>                target=None, large_model=False, output_path=None)</p>
<pre><code>Args:
    model: the tf.keras model we want to convert
    input_signature: a tf.TensorSpec or a numpy array defining the shape/dtype of the input
    opset: the opset to be used for the ONNX model, default is the latest
    custom_ops: if a model contains ops not recognized by onnx runtime,
        you can tag these ops with a custom op domain so that the
        runtime can still open the model. Type is a dictionary `&#123;op name: domain&#125;`.
    target: list of workarounds applied to help certain platforms
    custom_op_handlers: dictionary of custom ops handlers
    custom_rewriter: list of custom graph rewriters
    extra_opset: list of extra opset&#39;s, for example the opset&#39;s used by custom ops
    shape_override: dict with inputs that override the shapes given by tensorflow
    inputs_as_nchw: transpose inputs in list from nchw to nhwc
    large_model: use the ONNX external tensor storage format
    output_path: save model to output_path

Returns:
    An ONNX model_proto and an external_tensor_storage dict.
</code></pre></blockquote>
<h1 id="旧版本"><a href="#旧版本" class="headerlink" title="旧版本"></a>旧版本</h1><h2 id="一-所需工具"><a href="#一-所需工具" class="headerlink" title="一.所需工具"></a>一.所需工具</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install tf2onnx</span><br><span class="line">pip install onnx</span><br><span class="line">pip install onnxruntime</span><br></pre></td></tr></table></figure>
<h2 id="二-转换流程"><a href="#二-转换流程" class="headerlink" title="二.转换流程"></a>二.转换流程</h2><p>① h5 to pb<br>② pb to onnx</p>
<h2 id="三-转换过程"><a href="#三-转换过程" class="headerlink" title="三.转换过程"></a>三.转换过程</h2><p>首先准备自己的h5模型；这里要注意h5模型的保存方式，不同保存方式，对应不同加载方式，如下：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">训练:  model.save()    </span><br><span class="line">加载:  model.load_model()</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">训练:  model.save_weights()    </span><br><span class="line">加载:  model = LeNet()</span><br><span class="line">	  model.load_weights(weight_path) </span><br></pre></td></tr></table></figure></p>
<p>① h5转pb</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> graph_util, graph_io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.platform <span class="keyword">import</span> gfile</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">h5_to_pb</span>(<span class="params">h5_weight_path, output_dir, out_prefix=<span class="string">&quot;output_&quot;</span>, log_tensorboard=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.mkdir(output_dir)</span><br><span class="line">    h5_model =  load_model(h5_weight_path) </span><br><span class="line">    out_nodes = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(h5_model.outputs)):</span><br><span class="line">        out_nodes.append(out_prefix + <span class="built_in">str</span>(i + <span class="number">1</span>))</span><br><span class="line">        tf.identity(h5_model.output[i], out_prefix + <span class="built_in">str</span>(i + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    model_name = os.path.splitext(os.path.split(h5_weight_path)[-<span class="number">1</span>])[<span class="number">0</span>] + <span class="string">&#x27;.pb&#x27;</span></span><br><span class="line"></span><br><span class="line">    sess = K.get_session()</span><br><span class="line">    init_graph = sess.graph.as_graph_def()</span><br><span class="line">    main_graph = graph_util.convert_variables_to_constants(sess, init_graph, out_nodes)</span><br><span class="line">    graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">h5_to_pb(h5_weight_path=<span class="string">&#x27;model.h5&#x27;</span>, output_dir=<span class="string">&#x27;./&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>② pb to onnx</p>
<p>这里需要使用<a href="https://netron.app/">netron</a>查看pb模型的输入(input_image)，输出层(identity)名称。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/20210925161631.png" alt></p>
<p>转化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m tf2onnx.convert --<span class="built_in">input</span> ./model.pb  --inputs input_image:<span class="number">0</span> --outputs output_1:<span class="number">0</span> --output ./model.onnx --opset <span class="number">12</span></span><br></pre></td></tr></table></figure>
<p>—input: 待转化的pb模型</p>
<p>—inputs: 模型输入名称，有多个输入可用<code>,</code>分割</p>
<p>—outputs: 模型输出名称，有多个输出可用<code>,</code>分割</p>
<p>—opset: tf2onnx支持所有tf1.x的版本，默认情况下使用的是opset 8。当然在转换的过程中也可以指定固定的版本 —opset 12，即使用tf1.12以上的版本</p>
<h2 id="四-推理测试"><a href="#四-推理测试" class="headerlink" title="四.推理测试"></a>四.推理测试</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> rt</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> img_to_array</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#keras推理</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;1.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">img = cv2.resize(img,(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">img = np.array([img_to_array(img)],dtype=<span class="string">&#x27;float&#x27;</span>)/<span class="number">255.0</span></span><br><span class="line">model = load_model(<span class="string">&#x27;model.h5&#x27;</span>)</span><br><span class="line">predict = model.predict(img)</span><br><span class="line">p = [<span class="built_in">round</span>(i,<span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> predict[<span class="number">0</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n keras :&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#opencv dnn pb</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;1.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">img = cv2.resize(img,(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">img = np.array([img_to_array(img)],dtype=<span class="string">&#x27;float&#x27;</span>)/<span class="number">255.0</span></span><br><span class="line">img = img.transpose((<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">net = cv2.dnn.readNetFromTensorflow(<span class="string">&quot;model.pb&quot;</span>)</span><br><span class="line">net.setInput(img)  </span><br><span class="line">out = net.forward()  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n opencv dnn pb:&#x27;</span>)</span><br><span class="line">p = [<span class="built_in">round</span>(i,<span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> out[<span class="number">0</span>]]</span><br><span class="line"><span class="built_in">print</span>(p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#onnxruntime </span></span><br><span class="line"><span class="comment"># 准备输入</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;1.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">img = cv2.resize(img,(<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">img = np.array([img_to_array(img)],dtype=<span class="string">&#x27;float&#x27;</span>)/<span class="number">255.0</span></span><br><span class="line"><span class="comment"># onnx要求输入格式为float32，需要将双精度进行转换</span></span><br><span class="line">img= img.astype(np.float32)</span><br><span class="line"><span class="comment"># 加载onnx</span></span><br><span class="line">sess=rt.InferenceSession(<span class="string">&#x27;model.onnx&#x27;</span>)</span><br><span class="line"><span class="comment"># 获取输入名称</span></span><br><span class="line">input_name=sess.get_inputs()[<span class="number">0</span>].name</span><br><span class="line"><span class="comment"># 以字典形式对输入传参</span></span><br><span class="line">res=sess.run(<span class="literal">None</span>,&#123;input_name:img&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\n onnxruntime :&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>([<span class="built_in">round</span>(i,<span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> res[<span class="number">0</span>]])</span><br></pre></td></tr></table></figure>
<p>如图推理结果一致即可:</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/20210925163653.png" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Keras</tag>
        <tag>onnx</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu下如何安装搜狗输入法</title>
    <url>/2019/12/13/sougou/</url>
    <content><![CDATA[<h2 id="Ubuntu系统配置"><a href="#Ubuntu系统配置" class="headerlink" title="Ubuntu系统配置"></a>Ubuntu系统配置</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">system settings-&gt;language support-&gt;install/remove languages</span><br></pre></td></tr></table></figure>
<p>在弹出的菜单中选择Chinese(simplified),点击apply<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/20180729142927736.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/20180729142927712.png" alt></p>
<h2 id="配置输入法框架"><a href="#配置输入法框架" class="headerlink" title="配置输入法框架"></a>配置输入法框架</h2><p>搜狗输入法是建立在fcitx框架之上的，所以要将输入法框架选择为fictx<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/20180729142927666.png" alt><br>注意：如果没有fcitx选项，那么你就需要安装fcitx框架之后在进行配置，安装方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:fcitx-team/nightly   //添加FCITX仓库</span><br><span class="line"></span><br><span class="line">sudo apt-get update                              //更新仓库</span><br><span class="line"></span><br><span class="line">sudo apt-get install fcitx                       //安装fcitx输入法框架</span><br></pre></td></tr></table></figure>
<p>配置好输入法框架之后，重启ubuntu系统。重启之后如果配置成功，在任务栏的右上角会出现fcitx的设置选项（一个小键盘图标）<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/20180729142927651.png" alt></p>
<h2 id="去搜狗官网下载输入法for-Linux"><a href="#去搜狗官网下载输入法for-Linux" class="headerlink" title="去搜狗官网下载输入法for Linux"></a>去搜狗官网下载输入法for Linux</h2><p><a href="https://pinyin.sogou.com/linux/">官方下载</a><br><a href="https://www.jianguoyun.com/p/DeShNo0QlZ_3Bhic5rAC">网盘下载</a><br>下载完成之后，在download目录下找到下载的文件，双击安装即可，点击install即可<br>或者在终端的命令窗口中输入如下的指令安装：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i 安装包名称.deb</span><br></pre></td></tr></table></figure><br>如果在安装过程中出现相关依赖文件的错误。则需要先安装其依赖的软件包<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/Snipaste_2019-12-13_14-33-14.jpg" alt><br>在终端窗口来执行以下命令，安装缺少的依赖文件:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get -f install</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/Snipaste_2019-12-13_14-33-49.jpg" alt><br>安装完成后，首先打开右上角系统设置，选择第一行的最后一个选项”Text Entry“，点击左下角的+号，在打开的窗口中找到搜狗输入法Sogou pinyin点击Add添加进去<br>仅显示当前语言一定要去掉那个勾，才可以找到搜狗输入法，然后添加就是<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/sougou/2019050512074094.png" alt><br>这时就可以在右上方小键盘选择搜狗输入法了！</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu apt更换为国内的源</title>
    <url>/2020/01/19/ubuntu-apt%E6%9B%B4%E6%8D%A2%E4%B8%BA%E5%9B%BD%E5%86%85%E7%9A%84%E6%BA%90/</url>
    <content><![CDATA[<p>备份原来的源：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak</span><br></pre></td></tr></table></figure><br>更换源:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/apt/sources.list</span><br></pre></td></tr></table></figure><br>将里面文件内容全部替换成下面：<br><a href="https://wiki.ubuntu.org.cn/%E6%A8%A1%E6%9D%BF:16.04source">点击此处获得最新源</a><br>保存退出<br>执行更新：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu16.04安装opencv教程</title>
    <url>/2020/01/19/ubuntu16.04%E5%AE%89%E8%A3%85opencv%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<p>1.去官网下载opencv，在本教程中选用的是opencv3.4.1，其他版本的配置方法异曲同工。<a href="http://opencv.org/releases.html">下载链接</a>，选择sources版本 </p>
<p>2.解压下载下来的zip包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">unzip opencv-3.4.1.zip</span><br></pre></td></tr></table></figure>
<p>3.进入到解压后的文件包中</p>
<p>4.安装依赖库和cmake ，如果提醒需要apt-get update，那就先sudo su进入root权限，再sudo apt-get update，然后在执行下面命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install cmake</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install build-essential libgtk2.0-dev libavcodec-dev libavformat-dev libjpeg.dev libtiff4.dev libswscale-dev libjasper-dev  </span><br></pre></td></tr></table></figure>
<p>在第二步中若提示依赖版本问题，原因在于apt源太旧，更换新的源，再进行安装。</p>
<p>5.安装完cmake之后执行命令 ,创建编译文件夹，不创建的会提示（如下图）<br>In-source builds are not allowed.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir my_build_dir</span><br><span class="line">cd my_build_dir</span><br></pre></td></tr></table></figure>
<p>6.cmake一下<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..</span><br></pre></td></tr></table></figure><br>注意：如果已经在新的文件夹中编译，但是还会出现之前的报错，把cmakecache.txt删了再编译就可<br>期间可能会下载一个东西，等待一会儿就OK<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/opencv/20171005220631735.png" alt><br>7.执行命令，漫长的编译过程</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo make</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/opencv/20171005214720292.png" alt><br>8.执行命令<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo make install</span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/opencv/20171005214847504.png" alt><br>9.sudo make install 执行完毕后OpenCV编译过程就结束了，接下来就需要配置一些OpenCV的编译环境首先将OpenCV的库添加到路径，从而可以让系统找到<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/ld.so.conf.d/opencv.conf </span><br></pre></td></tr></table></figure><br>执行此命令后打开的可能是一个空白的文件，不用管，只需要在文件末尾添加<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/local/lib  </span><br></pre></td></tr></table></figure><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/opencv/20171005215009149.png" alt><br>10.执行如下命令使得刚才的配置路径生效<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ldconfig  </span><br></pre></td></tr></table></figure><br>11.配置bash<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/bash.bashrc  </span><br></pre></td></tr></table></figure><br>在最末尾添加<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig  </span><br><span class="line">export PKG_CONFIG_PATH  </span><br></pre></td></tr></table></figure><br>保存，执行如下命令使得配置生效<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source /etc/bash.bashrc  </span><br></pre></td></tr></table></figure><br>更新<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo updatedb  </span><br></pre></td></tr></table></figure><br>12.至此所有的配置都已经完成<br>下面用一个小程序测试一下<br>cd到opencv-3.4.1/samples/cpp/example_cmake目录下<br>我们可以看到这个目录里官方已经给出了一个cmake的example我们可以拿来测试下<br>按顺序执行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cmake .</span><br><span class="line">make</span><br><span class="line">./opencv_example</span><br></pre></td></tr></table></figure>
<p>即可看到打开了摄像头，在左上角有一个hello opencv<br>即表示配置成功</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>windows和ubuntu双系统修改默认启动项</title>
    <url>/2020/03/08/windows%E5%92%8Cubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E5%90%AF%E5%8A%A8%E9%A1%B9/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>安装完ubuntu系统后，打开电脑到选择系统的界面我们发现默认的是ubuntu系统，如果你是经常要进入windows系统的，你手动选择第三个windows启动项就行，但是，假设你按了电源键之后就去搞其他事情了，那默认就进入ubuntu系统了，这个时候你还要再关机重开或者重启，非常麻烦；或者你跟我一样是个强迫症，不管怎么样都要让它默认windows系统，下面就教你怎么做。</p>
<h2 id="更改-etc-default-grub文件："><a href="#更改-etc-default-grub文件：" class="headerlink" title="更改/etc/default/grub文件："></a>更改/etc/default/grub文件：</h2><p>打开终端，输入：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/default/grub</span><br></pre></td></tr></table></figure><br>回车，即可打开文件，如图，鼠标所示位置即为默认优先启动项的序号，ubuntu为0，windows为2，默认是0，改为2即可设置优先启动项为windows（如果在修改文件内容的时候因为是只读文件需要权限才能修改，终端输入：<code>sudo chmod +x /etc/default/grub</code>回车即可）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/boot/1628751-20190421140348008-170002217.png" alt></p>
<p>以上，更改默认启动项的目标完成，下面再<strong>拓展一点东西</strong>：</p>
<p>如图光标处为启动界面等待选择的时间，默认为10,可改小一点，比如8，单位是秒</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/boot/1628751-20190421140829066-310267031.png" alt></p>
<p>修改好之后点保存，命令行输入：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo update-grub</span><br></pre></td></tr></table></figure><br>回车，完成。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu下teamviewer的安装方法</title>
    <url>/2019/12/21/ubuntu%E4%B8%8Bteamviewer%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="去官网下载安装包"><a href="#去官网下载安装包" class="headerlink" title="去官网下载安装包"></a>去官网下载安装包</h2><p><a href="https://www.teamviewer.com/zhcn/download/linux/">官网链接</a><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/teamviewer/20180128120840387.png" alt></p>
<h2 id="在命令行进行安装"><a href="#在命令行进行安装" class="headerlink" title="在命令行进行安装"></a>在命令行进行安装</h2><p>（在下载文件夹下打开命令行，输入：sudo dpkg -i  teamviewer_13.0.6634_amd64.deb）（teamviewer_13.0.6634_amd64.deb为安装包名，根据自己安装包）<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i  teamviewer_13.0.6634_amd64.deb</span><br></pre></td></tr></table></figure></p>
<h2 id="安装出错，一行语句搞定依赖关系"><a href="#安装出错，一行语句搞定依赖关系" class="headerlink" title="安装出错，一行语句搞定依赖关系"></a>安装出错，一行语句搞定依赖关系</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/teamviewer/20180128120923823.png" alt><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install -f</span><br></pre></td></tr></table></figure></p>
<h2 id="再次安装"><a href="#再次安装" class="headerlink" title="再次安装"></a>再次安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo dpkg -i  teamviewer_13.0.6634_amd64.deb</span><br></pre></td></tr></table></figure>
<h2 id="打开teamview"><a href="#打开teamview" class="headerlink" title="打开teamview"></a>打开teamview</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/teamviewer/20180128121156354.png" alt><br>或用命令行启动：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo teamviewer --daemon start </span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Teamviewer</tag>
      </tags>
  </entry>
  <entry>
    <title>不需要预训练模型的目标检测算法DSOD</title>
    <url>/2020/04/10/%E4%B8%8D%E9%9C%80%E8%A6%81%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95DSOD/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>DSOD(Deeply Supervised Object Detectors)是ICCV  2017的一篇文章，它表达了一个非常有意思的东西。这篇论文不是从目标检测的高mAP值或者速度更快出发，而是从另外一个角度切入来说明fine-tune后的检测模型和直接训练的检测模型的差距其实是可以减少的，也即是说一些检测模型可以摆脱fine-tune这一过程，并且相比于fine-tune训练出来的模型效果并不会变差。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>DSOD这一算法是在SSD的基础上进行的改进，可以简单的看成：</p>
<p><strong>DSOD=SSD+DenseNet</strong></p>
<p>作者在论文中提到他也实验了从0开始训练<strong>Region Proposal Based</strong>的检测算法比如Faster RCNN，R-FCN等，但这些模型很难收敛。而One-Stage的目标检测算法比如SSD却可以收敛，虽然效果很一般，因此最后作者使用SSD作为了这篇论文接下来讨论的BaseLine。</p>
<p>然后本文基于SSD改进的DSOD在VOC2007 trainval和2012 trainval数据集上训练模型，然后在VOC2007  testset上测试的表现(77.7%mAP)超过了使用fine-tune策略的SSD300S（69.6%mAP）和SSD300（75.8mAP），原文是这样描述的。</p>
<blockquote>
<p>Our DSOD300 achieves 77.7% mAP, which is much better than the SSD300S  that is trained from scratch using VGG16 (69.6%) without deep  supervision. It is also much better than the fine-tuned results by  SSD300 (75.8%)</p>
</blockquote>
<h2 id="出发点"><a href="#出发点" class="headerlink" title="出发点"></a>出发点</h2><p>这篇文章的出发点是什么呢？作者认为几乎的所有检测网络都在使用fine-tune这一技巧，那么一定要用fine-tune吗？作者列出来了3个原因来尝试说明fine-tune不是必须的。原因如下：</p>
<ul>
<li>预训练的模型一般是在分类图像数据集比如Imagenet上训练的，不一定可以迁移到检测模型的数据上（比如医学图像）。</li>
<li>预训练的模型，其结构都是固定的，因此如果想要再修改的话比较麻烦。</li>
<li>预训练的分类网络的训练目标一般和检测目标不一致，因此预训练的模型对于检测算法而言不一定是最优的选择。</li>
</ul>
<p>基于上面这几点原因，论文提出了一个从0开始的检测模型DSOD，接下来看看是怎么设计的吧。</p>
<h2 id="DSOD网络结构"><a href="#DSOD网络结构" class="headerlink" title="DSOD网络结构"></a>DSOD网络结构</h2><p>下面的Figure1分别展示了SSD的整体结构和DSOD的整体结构。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSOD/640.webp" alt></p>
<p>Figure1左图的<code>plain connection</code>表示SSD网络中的特征融合操作，这里对于的输入300 x 300图像来说，一共融合了6种不同scale的特征。在每个虚线矩形框内都有一个1 x 1的卷积和一个3 x 3的卷积操作，这也可以被叫作BottleNeck，也就是1 x 1卷积主要起到降维从而降低3 x 3卷积计算量的作用。</p>
<p>Figure1右图的<code>dense connection</code>表示本文的DSOD引入了DenseNet的思想。<code>dense connection</code>左边的虚线框部分和<code>plain connection</code>右边的虚线框部分结构一致，区别在于里面的<code>channel</code>个数，<code>dense connection</code>中3 x 3卷积的<code>channel</code>个数是<code>plain connection</code>中3 x 3卷积的一半。主要是因为在<code>plain connection</code>中每个BottleNeck的输入是前面一个BottleNeck的输出，而在<code>dense connection</code>中，<strong>每个bottleneck的输入是前面所有bottleneck的输出的concate</strong>，所以为了降低计算量减少了通道数。</p>
<p>同时，<code>dense connection</code>部分右边的矩形框是下采样模块，包含一个2 x 2的最大池化层（降采样作用）和一个的1 x 1卷积层（降低<code>channel</code>个数的作用），作者也提到先进行降采样再进行1 x 1卷积可以进一步减少计算量。</p>
<p>因此可以看出DSOD即是<strong>SSD+DenseNet</strong>的结果。</p>
<p>DSOD是在SSD的基础上发展而来的，DSOD的不同在于，不管是在backbong还是head部分，DSOD都借鉴了DenseNet的设计思想。</p>
<p>DSOD 网络分两个部分：用于特征提取的backbone，用于目标预测的front-end。backbone子网络类似于DenseNets，包含Stem block，4个dense block，2个过渡层，2个无池化层的过渡层。front-end子网络使用致密的结构融合多尺度预测响应。其中Dense Block就是DenseNet网络的子模块，然后<code>stem block</code>由3 x 3卷积和2 x 2池化组成，后面实验证明了这个<code>stem block</code>可以提高mAP值。下面的Table1详细展示了DSOS网络的结构。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSOD/641.jpg" alt></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>下面的Table3展示了在VOC2007 testset上不同参数的实验结果。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSOD/642.webp" alt></p>
<p>第3，4行的对比可以看出BottleNeck的channel个数越多，mAP相对越高。第5、6行的对比可以看出growth rate从16变成48，可以提高4.8%的mAP。第6，9行的对比可以看出stem block的存在可以提高2.8%的mAP。</p>
<p>下面的Table4则展示了更丰富的结果。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/DSOD/643.webp" alt></p>
<p>可以看出SSD在没有预训练模型的情况下也是可以收敛的，不过效果一般。但如果使用本文的DSOD则可以达到使用预训练模型效果，并且结果还偏好一点。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>DSOD是在SSD的基础上结合了DenseNet的思想，使得网络可以在不使用预训练模型的条件下收敛得和使用预训练模型的BaseLine模型一样好，另外DenseNet的引入也使得相比SSD来说DSOD的参数数量大大减少，注意参数量不等于推理速度会变快。如果专注于特殊图像检测或者难以搞定预训练模型的场景这篇文章的思想是值得借鉴的。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>两阶段实时检测网络ThunderNet</title>
    <url>/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>ThunderNet是旷视和国防科技大学合作提出的目标检测模型，目标是在计算力受限的平台进行实时目标检测。需要关注的地方主要就是提出的两个特征增强模块CEM和SAM,其设计理念和应用的方法都非常值得借鉴。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在移动端的实时目标检测是一个极为重要并且有挑战性的视觉问题。很多基于CNN的检测器都有巨大的计算量，所以在计算受限的场景下难以进行实时推理。论文提出了一个轻量级的两阶段的检测方法-ThunderNet。</p>
<ul>
<li><p>在backbone部分，分析了以往的轻量级backbone的不足并提出了一个专门用于目标检测的轻量级基础网络-SNet。</p>
</li>
<li><p>在detection部分，提出一个有效的RPN和检测头。其中涉及到两个特征增强模块：</p>
<ul>
<li>Context Enhancement Module(CEM) 用于整合局部和全局特征。</li>
<li>Spatial Attention Module(SAM)引入RPN前后背景信息用以优化特征分布。</li>
</ul>
</li>
<li><p>对目标输入分辨率、Backbone、检测头三个部分进行了平衡。</p>
</li>
</ul>
<p>最终ThunderNet可以在ARM设备上达到24.1fps的速度，精度和速度上超过了很多一阶段检测器。</p>
<h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/640.png" alt></p>
<p>首先可以看一下在COCO数据集上轻量级目标检测网络的对比，可以看出来其效率和准确率都超过了Pelee，SSD等一阶段的检测器。</p>
<h3 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h3><p>ThunderNet的Backbone是基于ShuffleNetv2改进得到的<strong>SNet</strong>。由于<strong>输入的分辨率应该和backbone的容量相匹配</strong>，图片的输入分辨率调整为320x320，这极大的降低了模型的计算量。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/641.webp" alt></p>
<p>SNet与ShuffleNetV2区别在于SNet将ShuffleNet中所有的3x3的可分离卷积替换为5x5的可分离卷积。下图是shuffleNetv2中的网络结构：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/642.png" alt></p>
<p>Backbone选取考虑到以下几个因素：</p>
<ol>
<li><p><strong>迁移学习：</strong> 目标检测需要的backbone一般都是在ImageNet上与训练得到的，但是目标检测的backbone和分类器所需要提取的特征是不一致的，简单地将分类模型迁移学习到目标检测中不是最佳选择。</p>
</li>
<li><p><strong>感受野：</strong> CNN中感受野是非常重要的参数，CNN只能获取到感受野以内的信息，所以更大的感受野通常可以获取更多地语义信息，可以更好地编码长距离关系。</p>
</li>
<li><p><strong>浅层和深层的特征：</strong> 浅层的feature map分辨率比较大，获取到的是描述空间细节的底层特征。深层的feature map分辨率比较小，但是保存的是更具有鉴别性的高级语义特征。</p>
<p>通常来讲，对于比较大的backbone来说，定位要比分类难得多，这样就证明了浅层特征对于定位的重要性。但是对于非常小的backbone来说，其特征表达能力比较差，这样就限制了准确率的特征。所以深层和浅层的特征都非常重要。</p>
</li>
</ol>
<p>作者考虑到以上三个因素，并分析了先前轻量级backbone的缺点：</p>
<ul>
<li>ShuffleNetV1的感受野只有121个像素，ShuffleNetv2的感受野只有320个像素，<strong>感受野比较小</strong>。</li>
<li>ShuffleNetv2和MobileNetv2都<strong>缺少浅层的特征</strong>。</li>
<li>Xception由于对计算量的限制导致<strong>高级语义信息不足。</strong></li>
</ul>
<p>所以在设计SNet的时候，着重考虑以上的因素，并提出了三个模型：SNet49（speed）、SNet146(trade off)、SNet535(accuracy)。主要改进点如下：</p>
<ol>
<li>将ShuffleNetv2中的所有3x3的深度可分离卷积<strong>替换为5x5的深度可分离卷积</strong>，两者实际运行速度相差不多，但是有效扩大了有效感受野（参考之前文章目标检测和感受野的总结和思考）</li>
<li>SNet146和SNet535中去掉了Conv5，并且<strong>加宽了浅层网络</strong>，进而生成更多的底层特征。</li>
<li>SNet49将Conv5中的通道个数改为512，也加宽了浅层网络。通过这样操作是为了<strong>平衡浅层网络和深层网络</strong>。</li>
</ol>
<h3 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/643.webp" alt></p>
<p>在以往的两阶段检测器中，RPN和Detection头都太重了，为了和轻量级的网络进行配合以及降低计算量，ThunderNet沿用了Light-Head R-CNN中的大部分设置，并针对计算量比较大的部分进行改动：</p>
<ul>
<li>将RPN中原有256维的3x3卷积替换为5x5的dwconv+1x1conv</li>
<li>设置五个scale{32,64,128,256,512}和5个比例{1:2,3:4,1:1,4:3,2:1}</li>
<li>提出PSRoI align来取代RoI warping, 减少RoI个数等</li>
</ul>
<p>还有很多细节部分的调整，大部分细节都和Light-Head R-CNN是一致的。</p>
<p>接下来就是两个重要的模块,CEM和SAM:</p>
<p><strong>CEM</strong></p>
<p>在Light-Head R-CNN中，使用了Global Convolutional  Network来增大模型的感受野，但也带来了极大的计算量。为了解决这个问题，ThunderNet中提出了CEM来增大感受野，融合多尺度局部信息和全局信息来获取更有鉴别性的特征。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/644.webp" alt></p>
<p>上图是CEM层的结构，其中C4来自backbone的Stage3，C5来自backbone的Stage4。具体操作过程上图很明显，构造了一个多尺度的特征金字塔，然后三个层相加，完成特征的优化。</p>
<p>接触过SENet的读者可能对这个结构有点熟悉，使用Global Avg  pool以后实际上得到了一个通道的Attention,只不过SENet是相乘，而这里直接相加。总体来说这个模块构造的很好，以比较小的计算代价扩大了感受野，提供了多尺度特征。同时也有一些地方需要商量，比如是SENet中的乘法更适合呢？还是直接相加更适合？</p>
<p><strong>SAM</strong></p>
<p>SAM实际上就是利用RPN得到的feature map,然后用一个Attention机制对特征进行优化，具体实现方式见下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/645.png" alt></p>
<p>这个部分设计实际上是比较好的结合了两阶段模型的RPN网络。RPN网络是用来提出proposal的，在RPN中，我们期望背景区域特征不被关注，而更多地关注前景物体特征。RPN有较强的判别前景和背景的能力，所以这里的就用RPN的特征来指导原有特征，实际上是一个Spatial Attention，通过1x1卷积、BN、Sigmoid得到加权的特征图，引导网络学习到正确的前景背景特征分布。</p>
<p>这个模块也是非常精妙的结合了RPN以及空间Attention机制，非常insight，有效地对轻量级网络特征进行了优化,弥补了轻量网络特征比较弱的缺点。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/646.jpg" alt></p>
<p>上表是在VOC2007数据集上的结果，可以看出，ThunderNet在比较好地做到了精度和计算量的权衡，并且证明了两阶段网络也有超越一阶段网络的潜力。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ThunderNet/647.jpg" alt></p>
<p>上表是在COCO数据集上的结果，可以看出效果依然非常出众。SNet49的ThunderNet在与MobileNet-SSD相近的精度下，速度快了5倍；SNet146的ThunderNet与one-stage相比，有更高的精度；SNet535的ThunderNet精度在和大型的一阶段网络（SSD,DSSD）一致的情况下，计算量显著降低。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>ThunderNet作者非常善于思考，在将两阶段检测器进行轻量化设计的这个问题上有独特的想法，很多改进的点都是来自感受野的分析。主要提出了两个重要的模块：<strong>CEM 和SAM</strong></p>
<p>CEM总的来说是融合了一个小型的<strong>FPN+通道注意力机制</strong>，以非常少的计算代价提高了模型的感受野，优化了backbone的特征。</p>
<p>SAM总的来说是用<strong>RPN</strong>的特征加强原有特征，本质上是一种<strong>空间注意力机制</strong>，这种方法或许可以扩展到所有的多阶段检测器中。</p>
<p>而SNet对ShuffleNetV2的改进也在消融实验中得到证明，所以或许其他轻量级网络也可以<strong>借鉴用5x5dwconv替换掉3x3conv的思路</strong>。</p>
<p>ThunderNet成功超越了很多一阶段的方法，也让我们改变了传统两阶段网络计算量大但精度高的印象。虽然很多论文中都用到了空间注意力机制和通道注意力机制，ThunderNet中通过自己独到的想法，比较完美地融合了这两个部分，有理有据，非常有力。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>一些百度网盘的破解方法</title>
    <url>/2020/02/02/%E4%B8%80%E4%BA%9B%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E7%9A%84%E7%A0%B4%E8%A7%A3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="1-脚本"><a href="#1-脚本" class="headerlink" title="1. 脚本"></a>1. 脚本</h2><p>最推荐的方法，失效了再换脚本就好。此方法通过浏览器拓展Violentmonkey或者Tampermonkey来启用，相应脚本可自己去<a href="https://greasyfork.org/zh-CN">GreasyFork</a>搜寻，原理是通过显示直链，然后使用 IDM 来加速下载，有的脚本也可配合aria下载（更推荐使用aria）<br><strong>使用方法：（下载部分）</strong><br>1、选择要下载的文件，点击页面里的 “生成链接” 来获取加速下载地址。<br>2、使用鼠标右键点击链接（注意是右键点击链接），选择“使用 IDM 下载”，然后确定下载。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/7a6a15d5gy1g8s99l1zdqg20qn0euqa8.gif" alt></p>
<p>也可以配合Aria2 manager扩展，添加右键菜单，将生成的链接<strong>导出到 ARIA2 RPC</strong>，由AriaNg下载，不会配置的也可使用下面介绍的Motrix代替。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/Snipaste_2020-02-02_20-12-56.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/Snipaste_2020-02-02_20-13-39.jpg" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/7a6a15d5gy1g952lk3yu0g20sf0fy469.gif" alt></p>
<h2 id="2-Pandownload"><a href="#2-Pandownload" class="headerlink" title="2. Pandownload"></a>2. Pandownload</h2><p>Pandownload可以说是大名鼎鼎的百度云下载器了，但前段时间百度网盘的整改，一度被封，最近时有第三方修改版复活，但体验起来仍不稳定，且有限速的风险，我不推荐用这个。</p>
<h2 id="3-爱奇艺万能联播"><a href="#3-爱奇艺万能联播" class="headerlink" title="3. 爱奇艺万能联播"></a>3. 爱奇艺万能联播</h2><p>爱奇艺作为百度系下的产品，其应用商店提供的万能联播下载器，可以访问百度网盘下载，且不仅针对视频，对其他文件也有加速效果，但并不都是全部，且限速3M，但比起百度自身限速100k要好得多，也不用担心用第三方封号的危险。<br><a href="http://store.iqiyi.com/">官网地址</a></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/Snipaste_2020-02-09_19-30-07.jpg" alt></p>
<h2 id="4-Motrix"><a href="#4-Motrix" class="headerlink" title="4. Motrix"></a>4. Motrix</h2><p>Motrix 是一款开源免费且界面非常清爽简约的全能型下载软件，它跨平台支持 Windows、Mac、Linux 三大系统，可以支持下载 HTTP、FTP、BT、磁力链接以及下载百度网盘等资源。如果你用腻了其他工具，不妨试试 Motrix 吧……</p>
<p>主要是配合脚本，当做aria下载器使用，端口号默认为16800，暂不支持修改</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/baidu_exporter_2x.png%210x0.webp" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/baiduwp/Snipaste_2020-03-21_11-32-09.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>百度网盘</tag>
      </tags>
  </entry>
  <entry>
    <title>使Onedrive同步任意文件夹</title>
    <url>/2020/01/16/%E4%BD%BFOnedrive%E5%90%8C%E6%AD%A5%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E5%A4%B9/</url>
    <content><![CDATA[<p>onedrive默认只同步指定的onedrive文件夹，为了让它同步其他的文件夹，可以在命令行（以管理员身份运行的）使用以下代码创建一个软链接。<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mklink /j &quot;onedrive文件夹地址\需要同步的文件夹名&quot; &quot;需要同步的文件夹地址&quot;</span><br></pre></td></tr></table></figure><br>比如说我的onedrive在D:\Onedrive，我的目标文件夹test在D:\。那么<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mklink /j &quot;D:\Onedrive\test&quot; &quot;D:\test&quot;</span><br></pre></td></tr></table></figure><br>如果成功的的话，会提示<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/onedrive/1392594-20181005094204092-1998469109.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Onedrive</tag>
      </tags>
  </entry>
  <entry>
    <title>使用VS Code+SSH进行远程开发</title>
    <url>/2020/02/14/%E4%BD%BF%E7%94%A8VS-Code+SSH%E8%BF%9B%E8%A1%8C%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h2 id="为什么需要远程开发"><a href="#为什么需要远程开发" class="headerlink" title="为什么需要远程开发"></a>为什么需要远程开发</h2><p>在进行Linux开发的时候，为了方便，通常在Windows上使用代码编辑器编辑代码，交叉编译工具在Linux虚拟机或者服务器上，在开发期间需要不停的进行如下的循环操作：</p>
<ul>
<li>编辑好代码，使用<strong>基于SSH的ftp</strong>将文件上传到服务器</li>
<li><strong>使用SSH远程终端</strong>，在服务器上编译出可执行文件</li>
<li>编译完成后使用<strong>基于SSH的ftp</strong>将文件传回到本地</li>
</ul>
<p>这些操作都是基于SSH的，但是需要终端软件，文件传输软件， 并且不停地切换操作，过程很麻烦。</p>
<p>如果<strong>本地的编辑器可以直接通过SSH打开远程服务器的目录，操作文件，执行命令</strong>，这就称之为远程开发，使用远程开发可以大大方便我们的开发过程。</p>
<h2 id="Visual-Studio-Code-Remote-SSH扩展"><a href="#Visual-Studio-Code-Remote-SSH扩展" class="headerlink" title="Visual Studio Code Remote - SSH扩展"></a>Visual Studio Code Remote - SSH扩展</h2><p>Remote Development extension pack是VS Code在今年5月份发布的扩展，该扩展包括三个扩展：</p>
<ul>
<li>Remote - SSH</li>
<li>Remote - Containers</li>
<li>Remote - WSL</li>
</ul>
<p>这三个扩展分别支持将远程计算机，容器，或Windows子系统Linux（WSL）用作功能齐全的后台开发环境，本地的VS Code只是一个前端的界面，在本文中我们主要讲述如何使用SSH扩展，如图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522113131209.png" alt></p>
<h2 id="确保在命令行可以使用ssh命令"><a href="#确保在命令行可以使用ssh命令" class="headerlink" title="确保在命令行可以使用ssh命令"></a>确保在命令行可以使用ssh命令</h2><ul>
<li>如果使用的系统是<code>Windows10</code>，系统中已经自带了<code>SSH</code>，<strong>不能再使用Git的ssh</strong>：如图：</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190630104856278.png" alt></p>
<ul>
<li>如果使用的系统是<code>Windows7</code>，<strong>不能安装OpenSSH</strong>，只能使用Git中的ssh命令，将Git安装目录中的<code>usr\bin</code>文件夹添加到系统环境变量中，该目录下包含ssh命令的可执行程序；</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522115459170.png" alt></p>
<h2 id="安装SSH扩展"><a href="#安装SSH扩展" class="headerlink" title="安装SSH扩展"></a>安装SSH扩展</h2><p>在VS  Code扩展市场搜索<code>remote</code>，选择<code>Remote-SSH</code>，点击安装：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522114027910.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522114100203.png" alt></p>
<h2 id="远程主机安装SSH服务器"><a href="#远程主机安装SSH服务器" class="headerlink" title="远程主机安装SSH服务器"></a>远程主机安装SSH服务器</h2><p>特别注意：<strong>SSH扩展只能连接64位的Linux操作系统。</strong><br>在远程Linux主机上安装ssh服务器：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure></p>
<h2 id="设置SSH扩展显示登录终端"><a href="#设置SSH扩展显示登录终端" class="headerlink" title="设置SSH扩展显示登录终端"></a>设置SSH扩展显示登录终端</h2><p>打开命令面板<code>ctrl+shift+p</code>，输入<code>ssh</code>，选择设置：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523120834360.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523120925461.png" alt></p>
<h2 id="启动SSH连接远程主机"><a href="#启动SSH连接远程主机" class="headerlink" title="启动SSH连接远程主机"></a>启动SSH连接远程主机</h2><p>SSH启动的方式有两种：</p>
<ul>
<li>使用<code>Ctrl+Shift+P</code>打开命令面板，输入<code>ssh</code>，选择<code>Connect to Host</code>：</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522120252523.png" alt></p>
<ul>
<li><p>直接点击左下角的ssh图标：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190522120345995.png" alt></p>
</li>
</ul>
<p>启动之后输入远程主机的<code>用户名@ip地址</code>，按回车进行连接：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523121056234.png" alt></p>
<p>会显示出SSH登录终端，输入用户的密码即可：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523115727683.png" alt></p>
<p>首次登录后，VS Code会自动弹出一个新的窗口用于远程工作，并且会自动在远程主机上安装VS Code server：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523115814332.png" alt></p>
<p>登录成功后如图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523122154883.png" alt></p>
<h2 id="打开远程目录作为工作区"><a href="#打开远程目录作为工作区" class="headerlink" title="打开远程目录作为工作区"></a>打开远程目录作为工作区</h2><p>点击文件视图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523122256594.png" alt></p>
<p>然后选择要打开的目录：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523122341344.png" alt></p>
<p>打开成功如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523122740634.png" alt></p>
<h2 id="使用远程终端"><a href="#使用远程终端" class="headerlink" title="使用远程终端"></a>使用远程终端</h2><p><strong>直接点击新建终端即可打开Bash</strong>：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523122927502.png" alt></p>
<h2 id="安装扩展"><a href="#安装扩展" class="headerlink" title="安装扩展"></a>安装扩展</h2><p>注意，在远程开发的时候扩展分为本地扩展和远程扩展：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190523123334817.png" alt></p>
<h2 id="记住常用主机"><a href="#记住常用主机" class="headerlink" title="记住常用主机"></a>记住常用主机</h2><p>如图，打开配置文件：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190524091244209.png" alt></p>
<p>选择 一个配置文件：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/2019052409132074.png" alt></p>
<p>按如下格式填写内容，保存：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190524091455578.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/vscode%20ssh/20190524091601192.png" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>华硕路由器刷固件</title>
    <url>/2020/02/03/%E5%8D%8E%E7%A1%95%E8%B7%AF%E7%94%B1%E5%99%A8%E5%88%B7%E5%9B%BA%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>现在市面上的路由器基本上使用的都是官方的固件，这是因为路由器的设备厂商是为了设备的稳定性着想而出发的，还有就是所谓的刷梅林固件也就是刷第三方的固件，最大的作用可以解封一些功能。对于梅林固件来说，这有一半的性质是属于官方的路由器固件，但是还有一半是可以用户自己来进行设置的，其实梅林固件就是一个华硕路由器的自定义固件，是华硕官方的闭源驱动，因此稳定性要好很多，不支持超频，很少出现死机、卡顿的情况。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/185417q0zxbdexeze1x1nb.jpg" alt></p>
<p>其最具特色的便是多了软件中心，在里面安装各种各样的插件可以实现各种功能，比如翻墙，去广告，离线下载，双拨等。</p>
<p>并不是所有的路由器都能刷梅林固件，非华硕的路由器需要与华硕某个版本的硬件一致才能刷，以网件和华硕自身的路由器居多。</p>
<p>我手头的路由器为华硕AC86U，华硕刷梅林固件相对简单，风险低，若其他品牌的路由器请去查找相应教程，此教程只适用于华硕品牌。</p>
<h2 id="固件下载"><a href="#固件下载" class="headerlink" title="固件下载"></a>固件下载</h2><p><a href="https://www.koolcenter.com/">KoolCenter</a>是路由器刷机的论坛，可以去里面下载固件。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2020-02-03_16-18-35.jpg" alt></p>
<p>常用到的为红色框出来的这四个，分别是华硕官改固件、梅林原版固件、梅林改版固件、网件官改固件。</p>
<ul>
<li><p>原厂固件为华硕官方的固件。</p>
</li>
<li><p>原版梅林为国外RMerl大神基于华硕官方固件源代码修改而来的梅林固件。</p>
</li>
<li><p>改版梅林为koolshare开发组基于梅林固件修改而来的带软件中心的梅林改版固件。</p>
</li>
<li><p>官改固件为koolshare开发组基于华硕官方源代码修改而来的带软件中心的官改固件。</p>
</li>
</ul>
<p>这之中常用的为梅林改和官改，相比官改固件，梅林改版固件有更多的功能和bug修复，而官改固件更新较快。好用程度差别不大，稳定性来说也基本无差，选哪个固件基于个人喜好即可。</p>
<p>我用的是梅林改固件，进入文件夹，可以看到可用机型。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2020-02-03_16-32-11.jpg" alt></p>
<p>选择对应机型。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2020-02-03_16-32-28.jpg" alt></p>
<p>选择最新版本固件下载，固件为.w后缀。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2020-02-03_16-32-47.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2020-02-03_16-32-57.jpg" alt></p>
<h2 id="固件安装"><a href="#固件安装" class="headerlink" title="固件安装"></a>固件安装</h2><ul>
<li>选择【系统管理】-【固件升级】，选择下好的 .w 后缀的固件，上传即可</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/k3.png" alt></p>
<ul>
<li>刷机完成后会自动重启，请耐心等待完成</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/k4.png" alt></p>
<ul>
<li><p>刷机完成后在【系统管理】–【恢复/导出/上传设置】恢复出厂设置</p>
</li>
<li><p>在【系统管理】–【系统设置】内勾选：Format JFFS partition at next boot 和 Enable JFFS custom scripts and configs 然后点击应用本页面设置，成功后重启路由器；</p>
</li>
</ul>
<p>（注：双清就是指恢复出厂设置 + 格式化jffs分区）</p>
<p>重启后先将路由器连上网络，然后进入软件中心将软件中心更新到最新版本（如果有）。</p>
<h2 id="软件中心"><a href="#软件中心" class="headerlink" title="软件中心"></a>软件中心</h2><p>完成上述工作，梅林固件就装好了，现在你可以进入软件中心未安装，选择合适的插件安装了，插件就不一一介绍，具体可以百度，我常用的是虚拟内存和shadowsocks。</p>
<p>新版软件中心内不提供shadowsocks插件，我这里通过<a href="https://quqi.gblhgk.com/s/2796382/045bYgimCEJLRiCe">云盘</a>分享，大家可以在【软件中心】-【离线安装】手动安装插件。</p>
<h2 id="后续更新"><a href="#后续更新" class="headerlink" title="后续更新"></a>后续更新</h2><p>按此教程做的，后续更新新版的梅林改时，按B来即可。</p>
<h5 id="A-原厂固件-原版梅林-刷-改版梅林："><a href="#A-原厂固件-原版梅林-刷-改版梅林：" class="headerlink" title="A. 原厂固件/原版梅林 刷 改版梅林："></a>A. 原厂固件/原版梅林 刷 改版梅林：</h5><ol>
<li>在<code>原产固件</code>/<code>原版梅林</code>固件升级页面下直接上传.w 后缀的<code>改版梅林</code>固件文件；</li>
<li>刷机完成后会自动重启，此时刷机完成（刷机完成后可以不恢复出产设置，当然恢复一次更好）；</li>
<li>刷机完成在【系统管理 】–【 系统设置】内勾选：<code>Format JFFS partition at next boot</code> 和 <code>Enable JFFS custom scripts and configs</code> 然后点击<code>应用本页面设置</code>，成功后重启路由器；</li>
<li>重启后先将路由器连上网络，然后进入软件中心将软件中心更新到最新版本（如果有）。</li>
</ol>
<h5 id="B-改版梅林-刷-改版梅林："><a href="#B-改版梅林-刷-改版梅林：" class="headerlink" title="B. 改版梅林 刷 改版梅林："></a>B. 改版梅林 刷 改版梅林：</h5><ol>
<li>刷过<code>改版梅林</code>固件的，在固件升级页面下直接上传.w 后缀的<code>改版梅林</code>文件（如无特殊说明，不需要恢复出产设置）；</li>
<li>刷机后所有已经安装的插件都会被保留，不会受到影响。</li>
</ol>
<h5 id="C-改版梅林-刷-官改固件："><a href="#C-改版梅林-刷-官改固件：" class="headerlink" title="C. 改版梅林 刷 官改固件："></a>C. 改版梅林 刷 官改固件：</h5><ul>
<li>详见：<a href="https://www.koolcenter.com/posts/5">https://www.koolcenter.com/posts/5</a></li>
</ul>
<h5 id="D-官改固件-刷-改版梅林："><a href="#D-官改固件-刷-改版梅林：" class="headerlink" title="D. 官改固件 刷 改版梅林："></a>D. 官改固件 刷 改版梅林：</h5><ul>
<li>详见：<a href="https://www.koolcenter.com/posts/5">https://www.koolcenter.com/posts/5</a></li>
</ul>
<h5 id="E-改版梅林-刷-原厂固件-梅林原版："><a href="#E-改版梅林-刷-原厂固件-梅林原版：" class="headerlink" title="E. 改版梅林 刷 原厂固件/梅林原版："></a>E. 改版梅林 刷 原厂固件/梅林原版：</h5><ol>
<li>在<code>改版梅林</code>固件升级页面下直接上传.w 后缀的<code>原产固件</code>/<code>梅林原版</code>固件文件，刷机完成后机器会自动重启（刷机后可以不恢复出产设置，当然恢复一次更好）；</li>
<li>刷机完成在【系统管理 】–【 系统设置】内勾选：<code>Format JFFS partition at next boot</code> 和 <code>Enable JFFS custom scripts and configs</code> 然后点击<code>应用本页面设置</code>，成功应用后重启路由器即可，此操作可以清除安装在jffs分区的软件中心和所有插件。</li>
</ol>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title>使用frp服务实现对内网机器的远程连接</title>
    <url>/2020/02/16/%E4%BD%BF%E7%94%A8frp%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%AF%B9%E5%86%85%E7%BD%91%E6%9C%BA%E5%99%A8%E7%9A%84%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/</url>
    <content><![CDATA[<h2 id="为何要用"><a href="#为何要用" class="headerlink" title="为何要用"></a>为何要用</h2><p>我们并不是每天都会接触到实验室内网环境。当不在学校时，如何访问内网的资源成了一个头疼的问题。本文旨在提出一种内网穿透解决方案，在外网环境下优雅的访问到内网的任何端口。即使身离学校也可以方便的修改内网模型，访问内网计算资源。 </p>
<h2 id="特殊需要"><a href="#特殊需要" class="headerlink" title="特殊需要"></a>特殊需要</h2><ul>
<li><p>一台公网机（有公网ip的vps， 比如阿里云服务器）</p>
</li>
<li><p>frp 端口转发软件 :<a href="https://github.com/fatedier/frp/releases">下载地址</a></p>
</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>windows不用说，这里讲Ubuntu的安装</p>
<p>选择相应版本，右键复制链接</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/Snipaste_2020-02-16_15-19-58.jpg" alt></p>
<p>打开终端，输入<code>wget 复制的链接地址</code>即可开始下载</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/Snipaste_2020-02-16_15-25-08.jpg" alt></p>
<p>下载完成后，找到安装包，解压即可，解压命令为<code>tar -zxvf 包名</code></p>
<p><strong>公网机、内网机都需要安装，且frp版本要一致。</strong></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="公网机配置"><a href="#公网机配置" class="headerlink" title="公网机配置"></a>公网机配置</h3><p>修改 <strong>frps.ini</strong> 文件，这里使用了最简化的配置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># frps.ini</span></span><br><span class="line">[common]</span><br><span class="line">bind_port = 7000 <span class="comment">#这个端口代表内网机连到公网所需端口，默认7000，可自己定义</span></span><br></pre></td></tr></table></figure>
<p>Windows 启动 frps：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./frps.exe -c ./frps.ini</span><br></pre></td></tr></table></figure>
<p>Ubuntu 启动 frps:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./frps -c ./frps.ini</span><br></pre></td></tr></table></figure>
<p>Ubuntu 在后台开启运行 frp 服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nohup ./frps -c frps.ini &gt;/dev/null 2&gt;&amp;1 &amp; </span><br></pre></td></tr></table></figure>
<h3 id="内网机器配置"><a href="#内网机器配置" class="headerlink" title="内网机器配置"></a>内网机器配置</h3><p>修改 <strong>frpc.ini</strong> 文件，假设 <strong>frps</strong> 所在服务器的公网 IP 为 x.x.x.x；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># frpc.ini</span><br><span class="line">[common]</span><br><span class="line">server_addr = x.x.x.x #这里可以是公网机的域名，也可以是ip</span><br><span class="line">server_port = 7000 #刚刚公网机配置的与内网机交换的端口</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 22 #本地端口号，本地需要转发的端口 默认22 可自己设定</span><br><span class="line">remote_port = 6000  #远程端口号，将端口映射到公网相应的端口 可自己设定</span><br></pre></td></tr></table></figure>
<p>Windows 启动 frpc：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./frpc.exe -c ./frpc.ini</span><br></pre></td></tr></table></figure>
<p>Ubuntu 启动 frpc：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./frpc -c ./frpc.ini</span><br></pre></td></tr></table></figure>
<p>此时，你就可以通过你的外网 IP + 远程端口号来实现对内网相关服务的访问了。</p>
<h2 id="设置开机启动"><a href="#设置开机启动" class="headerlink" title="设置开机启动"></a>设置开机启动</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo gedit /etc/systemd/system/frpc.service</span><br></pre></td></tr></table></figure>
<p>按如下修改</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=frpc daemon</span><br><span class="line">After=syslog.target  network.target</span><br><span class="line">Wants=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">ExecStart=/usr/sbin/frp/frpc -c /etc/frp/frpc.ini</span><br><span class="line">Restart= always</span><br><span class="line">RestartSec=1min</span><br><span class="line">ExecStop=/usr/bin/killall frpc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<p>使用<code>sudo systemctl enable frpc.service</code>启用服务</p>
<p>服务器端（公网机器）同理</p>
<h2 id="白嫖简化步骤"><a href="#白嫖简化步骤" class="headerlink" title="白嫖简化步骤"></a>白嫖简化步骤</h2><p>考虑到很多人负担不起公网机的价格，这里提供发布免费公网域名的网站<br><a href="http://frp.wgpro.com">frp免费公共服务器列表</a></p>
<p>由于域名供应商已经配置好了公网机端，所以我们只需要配置我们需要连接的内网机即可</p>
<p>首先找到可用的服务器，比如</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/Snipaste_2020-02-16_15-47-16.jpg" alt></p>
<p>上面显示它所用的frp版本为0.14.1，所以我们也必须安装<strong>相应的frp版本</strong>在内网机上，否则由于软件版本不匹配，连不上。</p>
<p>按照之前的教程，根据所提供的信息，修改<strong>frpc.ini</strong>，如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/TIM%E5%9B%BE%E7%89%8720200216154853.jpg" alt></p>
<p>这里注意0.17.0版本之前用的是<code>privilege_token = xxxx</code>，而之后的版本用的是<code>token = xxxx</code>，<strong>远程端口号必须设置在服务商所提供的范围内</strong>，如图中TCP/UDP端口为1000-65535，则再此区间任取端口填入就行。</p>
<p>设置完，你便可以通过相应的SSH软件，连接内网机器，主机名为公网域名，端口号为你设置的远程端口</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/TIM%E5%9B%BE%E7%89%8720200216155354.png" alt></p>
<p>有的服务商还提供了二级或三级域名，如图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/frp/Snipaste_2020-02-16_15-58-29.jpg" alt></p>
<p>则 frpc.ini 配置如下格式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">#server_addr一定要写域名形式，不要直接写IP地址</span><br><span class="line">server_addr = frp1.chuantou.org</span><br><span class="line">server_port = 7000</span><br><span class="line">privilege_token = www.xxorg.com</span><br><span class="line"># 标注你的代理名字，随便选择一个跟别人不一样即可</span><br><span class="line">user = myname</span><br><span class="line"></span><br><span class="line">[xxorg] # 可以自己取</span><br><span class="line">type = http</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 80 # 按照图中显示为80</span><br><span class="line"># 自己取一个可用的子域名，你的访问地址将会是http://xxorg.frp1.chuantou.org</span><br><span class="line">subdomain = xxorg</span><br><span class="line"></span><br><span class="line">[tcp3389] # 可以自己取</span><br><span class="line">type = tcp</span><br><span class="line">local_ip = 127.0.0.1</span><br><span class="line">local_port = 3389 # 自己设</span><br><span class="line">remote_port = 53389 #自己设，图中范围为50000-60000</span><br></pre></td></tr></table></figure>
<p>设置完，你便可以通过相应的SSH软件，连接内网机器</p>
<p>如：主机名为<code>http://xxorg.frp1.chuantou.org</code>，端口号为53389</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>frp</tag>
      </tags>
  </entry>
  <entry>
    <title>加速pytorch数据读取</title>
    <url>/2020/09/13/%E5%8A%A0%E9%80%9Fpytorch%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>prefetch_generator是第三方对原本的DataLoader进行重写的函数包，它将任意生成器转换为后台thead生成器，在并行后台thead中预取多批数据。</p>
<p>如果有一个计算量很大的进程（CPU或GPU），在生成器消耗其他资源（磁盘IO/从数据库加载/如果有未使用的内核，则有更多CPU）的同时迭代处理生成器中的小批量，则这非常有用。</p>
<p>默认情况下，这两个进程将不断等待对方完成。如果让生成器在预取模式下工作，它们将并行工作，可能会节省GPU时间。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install prefetch_generator </span><br></pre></td></tr></table></figure>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>之前加载数据集的正确方式是使用<code>torch.utils.data.DataLoader</code>，现在我们只要利用这个库，新建个<code>DataLoaderX</code>类继承<code>DataLoader</code>并重写<code>__iter__</code>方法即可</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新建DataLoaderX类</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from prefetch_generator import BackgroundGenerator</span><br><span class="line"></span><br><span class="line">class DataLoaderX(DataLoader):</span><br><span class="line"></span><br><span class="line">    def __iter__(self):</span><br><span class="line">        return BackgroundGenerator(super().__iter__())</span><br></pre></td></tr></table></figure>
<p>然后用 <code>DataLoaderX</code> 替换原本的 <code>DataLoader</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataset = MyDataset(<span class="string">&quot;.........&quot;</span>)</span><br><span class="line">train_loader = DataLoaderX(dataset=train_dataset, </span><br><span class="line">                           batch_size=batch_size, num_workers=<span class="number">4</span>, shuffle=shuffle)</span><br></pre></td></tr></table></figure>
<h2 id="提速原因"><a href="#提速原因" class="headerlink" title="提速原因"></a>提速原因</h2><p>原本Pytorch默认的DataLoader会创建一些worker线程来预读取新的数据，但是除非这些线程的数据全部都被清空，这些线程才会读下一批数据。使用prefetch_generator在后台加载下一batch的数据，我们可以保证线程不会等待，每个线程都总有至少一个数据在加载。</p>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/prefetch_generator/1.png" alt></p>
<p>在 hdd 硬盘上，用同样的参数、同样的数据，分别用不同的优化方法，训练两个epoch，记录训练的时间。</p>
<p>优化方法分别是：</p>
<ul>
<li><code>original</code>：默认 dataloader，不优化</li>
<li><code>(1)prefetcher_generator</code>：只用 prefetcher_generator 库优化</li>
<li><code>(2)data_prefetcher</code>：只用 data_prefetcher 优化</li>
<li><code>(1)+(2)</code>：同时用 <code>prefetcher_generator</code> 和 <code>data_prefetcher</code> 优化</li>
</ul>
<p>最后将得到的时间，除以不优化时的训练时间。</p>
<p>从图中可以观察到：</p>
<ol>
<li>(1) 和 (2) 两种优化方法都差不多有 10% 左右的训练时间的缩短；</li>
<li>(1) (2) 同时使用，并没有进一步缩短训练时间，反而不如只使用一种优化方法。</li>
</ol>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积层有哪些参数及常用卷积核类型盘点</title>
    <url>/2020/03/04/%E5%8D%B7%E7%A7%AF%E5%B1%82%E6%9C%89%E5%93%AA%E4%BA%9B%E5%8F%82%E6%95%B0%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%B1%BB%E5%9E%8B%E7%9B%98%E7%82%B9/</url>
    <content><![CDATA[<h2 id="卷积核的基本参数"><a href="#卷积核的基本参数" class="headerlink" title="卷积核的基本参数"></a>卷积核的基本参数</h2><p>卷积神经网络的核心操作就是卷积层，这里以caffe框架为例子来介绍一下卷积核都有哪些基本的参数。下面先上一段代码，是caffe的卷积层的配置文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv1&quot;</span><br><span class="line">  type: &quot;Convolution&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv1&quot;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 1</span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: 2</span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 20</span><br><span class="line">    kernel_size: 5</span><br><span class="line">    stride: 1</span><br><span class="line">    weight_filler &#123;</span><br><span class="line">      type: &quot;xavier&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    bias_filler &#123;</span><br><span class="line">      type: &quot;constant&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面我们可以看到卷积层的参数有：</p>
<ul>
<li><code>lr_mult</code>：学习率的系数，最终的学习率是这个参数乘以caffe的solver.prototxt配置文件中的基础学习率<code>base_lr</code>。如果有2个<code>lr_mult</code>，则第一个表示权值的学习率，第二个表示偏置项的学习率。一般偏置项的学习率是权值项的学习率的2倍。</li>
<li><code>num_output</code>：卷积核的输出通道数。若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</li>
<li><code>kernel_size</code>：卷积核的大小。如果卷积核的长和宽不等，需要用<code>kernel_h</code>和<code>kernel_w</code>分别设定其它参数。</li>
<li><code>stride</code>：卷积核的步长，默认为1。当然也可以用<code>stride_h</code>和<code>stride_w</code>来设置。</li>
<li><p><code>pad</code>：扩充边缘，默认为0，不扩充。扩充的时候是左右、上下对称的，比如卷积核的大小为5 x 5，那么<code>pad</code>设置为2，则四个边缘都扩充2个像素，即宽度和高度都扩充了4个像素,这样卷积运算之后的特征图就不会变小。也可以通过<code>pad_h</code>和<code>pad_w</code>来分别设定。</p>
</li>
<li><p><code>weight_filler</code>：权重初始化方式。有<code>xavier</code>，<code>gaussian</code>，及<code>constant</code>等方式。</p>
</li>
<li><p><code>bias_filler</code>: 偏置项的初始化。一般设置为<code>constant</code>,值全为0。</p>
</li>
<li><p><code>bias_term</code>：是否开启偏置项，默认为true，开启。</p>
</li>
<li><p><code>group</code>：分组，默认为1组。如果大于1，我们限制卷积的连接操作在一个子集内。如果我们根据图像的通道来分组，那么第<code>i</code>个输出分组只能与第<code>i</code>个输入分组进行连接。</p>
</li>
<li><p><code>num_input</code>：输入通道数，这个包含在bottom中，所以实际上没有这个参数哦，只是可以这样理解。</p>
</li>
</ul>
<p>现在设输入通道数为<code>c0</code>，输出通道数为<code>c1</code>，那么输入可以表示为$[n, c 0, w 0, h 0]$，输出可以表示为：$[n, c 1, w 1, h 1]$。其中$w 0, h 0$表示输入特征图的长宽，那么输出特征图的长宽$w 1, h 1$可以用下面的公式计算：  </p>
<script type="math/tex; mode=display">
w 1=\left(w 0+2 \times p a d-k e r n e l_{w}\right) / s t r i d e+1</script><script type="math/tex; mode=display">
h 1=\left(h 0+2 \times p a d-\text {kernel}_{h}\right) /stride+1</script><p>如果将<code>stride</code>设为1，前后两次卷积部分存在重叠，如果设置<code>pad=(kernel_size-1)/2</code>，那么输出特征图的高宽都不变。</p>
<h2 id="常用卷积核类型盘点"><a href="#常用卷积核类型盘点" class="headerlink" title="常用卷积核类型盘点"></a>常用卷积核类型盘点</h2><p>卷积核的类型有很多，在工业上做的一些任务来看，最常用的卷积核类型大概有4种，分别是标准卷积，扩张卷积，转置卷积和深度可分离卷积。这里要先说一个感受野的概念，所谓感受野就是是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小。再通俗点的解释是，特征图上的一个点对应输入图上的区域。</p>
<h3 id="标准卷积"><a href="#标准卷积" class="headerlink" title="标准卷积"></a>标准卷积</h3><p>这是最常用的卷积，连续紧密的矩阵形式可以提取图像区域中相邻像素之间的关联性，例如一个3 x 3的卷积核可以获得3 x 3的感受野。如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/640.webp" alt></p>
<h3 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h3><p>转置卷积是先对原始特征矩阵进行填充使其维度扩大到目标输出维度，然后进行普通的卷积操作的过程，其输入到输出的维度变换关系恰好和普通的卷积变换关系相反，但这个变换并不是卷积真正的逆变换操作，我们通常将其称为转置卷积(Transpose  Convolution)而不是反卷积(Deconvolution)。转置卷积常见于目标检测领域中对小目标的检测以及图像分割领域还原输入图像尺度如FCN中。如下图所示，其中下图是输入，上图是输出：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/641.webp" alt></p>
<h3 id="扩张卷积（带孔卷积或空洞卷积）"><a href="#扩张卷积（带孔卷积或空洞卷积）" class="headerlink" title="扩张卷积（带孔卷积或空洞卷积）"></a>扩张卷积（带孔卷积或空洞卷积）</h3><p>这是一种特殊的卷积，引入了一个称为扩展率(Dilation Rate)的参数，使得同样尺寸的卷积核可以获得更大的感受野，相应的在相同感受视野的前提下比普通卷积采用更少的参数。举个例子，同样是3 x 3卷积核，扩张卷积可以获得范围的区域特征，在图像分割领域被广泛应用。如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/642.webp" alt></p>
<h3 id="深度可分离卷积"><a href="#深度可分离卷积" class="headerlink" title="深度可分离卷积"></a>深度可分离卷积</h3><p>这是在轻量级模型算法优化中经常会使用到的一种卷积方式，标准的卷积操作是对原始图像$H \times W \times C$三个方向的卷积运算，假设现在有$K$个相同尺寸卷积核，这样的操作计算量为$H \times W \times C \times K$个。若将长宽与深度方向的卷积操作分离出变为$H \times W$与$C$的两个卷积操作，则同样的卷积核数量$K$，现在的计算量变成了$(H \times W+C) \times K$个，也可以得到相同维度的输出。深度可分离卷积在模型压缩和一些轻量级卷积神经网络中被广泛应用。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络参数设置，提高泛化能力</title>
    <url>/2020/03/05/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%EF%BC%8C%E6%8F%90%E9%AB%98%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B/</url>
    <content><![CDATA[<h2 id="卷积神经网络的参数设置"><a href="#卷积神经网络的参数设置" class="headerlink" title="卷积神经网络的参数设置"></a>卷积神经网络的参数设置</h2><p>这个举个例子来说是最好的，因为直接说会抽象一些，在网上找了一个caffe-ssd的参数设置配置文件<code>solver.prototxt</code>，内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">train_net:&quot;train.prototxt&quot;</span><br><span class="line">test_net:&quot;test.prototxt&quot;</span><br><span class="line">test_iter: 299</span><br><span class="line">test_interval: 200</span><br><span class="line">base_lr: 0.01</span><br><span class="line">display: 20</span><br><span class="line">max_iter: 6720</span><br><span class="line">lr_policy: &quot;step&quot;</span><br><span class="line">gamma: 0.1</span><br><span class="line">power: 0.75</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_decay: 0.0001</span><br><span class="line">snapshot: 224</span><br><span class="line">snapshot_prefix: &quot;snapshot&quot;</span><br><span class="line">solver_mode: GPU</span><br><span class="line">device_id:0</span><br><span class="line">debug_info:false</span><br><span class="line">snapshot_after_train:true</span><br><span class="line">test_initialization:false</span><br><span class="line">average_loss:10</span><br><span class="line">iter_size:1</span><br><span class="line">stepsize:2000</span><br><span class="line">type: SGD</span><br><span class="line">eval_type:&quot;detection&quot;</span><br><span class="line">ap_version:&quot;11point&quot;</span><br><span class="line">show_per_class_result:true</span><br></pre></td></tr></table></figure>
<p>我们就一个个来解析一下。</p>
<ul>
<li><code>train_net</code>：训练的模型文件的路径。</li>
<li><code>test_net</code>：测试的模型文件的路径。</li>
<li><code>test_iter</code>：网络的迭代测试次数。网络一次测试<code>batch_size</code>张图片，因为为了可以将验证集中所有图片都测试一次，这个参数乘以<code>batch_size</code>应该等于验证集中的图片数。</li>
<li><code>test_interval</code>：网络迭代多少次进行一次测试。一次迭代即是将一个<code>batch_size</code>的图片进行训练。这个文件中<code>test_interval</code>设为了<code>200</code>，也就是说每隔<code>200</code>次对网络的准确率进行一次验证。一般来讲，我们是需要将训练集合中的所有图片都跑一次再对准确率进行测试，也就是<code>test_interval</code>乘以<code>batch_size</code>不小于训练集中的图片总数。</li>
<li><code>base_lr</code>：表示网络的基础学习率，学习率过高可能会无法梯度下降，loss保持不变，也可能loss不能收敛。而学习率过低会使网络收敛速度缓慢，也可能导致梯度消失。一般初始学习率设为<code>0.01</code>。</li>
<li><code>display</code>：每隔多少次显示一次。也就是在屏幕上打印一次<code>loss</code>和准确率。</li>
<li><code>max_iter</code>：网络的最大迭代次数。训练集中的图片需要训练多次，所以这个参数一般比较大。</li>
<li><code>lr_policy</code>：学习率变化策略，这里面又分为如下几类：<ul>
<li><code>fixed</code>：保持<code>base_lr</code>不变。</li>
<li><code>step</code>：如果设置为<code>step</code>,则还需要设置一个<code>stepsize</code>,  返回 <code>base_lr * gamma ^ (floor(iter / stepsize))</code>,其中<code>iter</code>表示当前的迭代次数。</li>
<li><code>exp</code>：返回<code>base_lr * gamma^ iter</code>，<code>iter</code>表示当前的迭代次数。</li>
<li><code>inv</code>: 如果设置为<code>inv</code>,还需要设置一个<code>power</code>, 返回<code>base_lr * (1 + gamma * iter) ^ (- power)</code>。</li>
<li><code>multistep</code>：如果设置为<code>multistep</code>,则还需要设置一个<code>stepvalue</code>。这个参数和<code>step</code>很相似，<code>step</code>是均匀等间隔变化，而<code>multistep</code>则是根据 <code>stepvalue</code>值变化。</li>
<li><code>poly</code>：学习率进行多项式误差, 返回 <code>base_lr (1 - iter/max_iter) ^ (power)</code></li>
<li><code>sigmoid</code>：学习率进行<code>sigmod</code>衰减，返回 <code>base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))</code></li>
</ul>
</li>
<li><code>gamma</code>：因为这里学习率衰减策略为<code>step</code>，所以需要设置<code>gamma</code>和<code>power</code>两个参数。</li>
<li><code>power</code>：同上。</li>
<li><code>momentum</code>：上一次梯度更新的权重，一般取值在<code>0.5--0.99</code>之间。通常设为<code>0.9</code>，<code>momentum</code>可以让使用<code>SGD</code>的深度学习方法更加稳定以及快速。</li>
<li><code>weight_decay</code>：权重衰减项，防止过拟合的一个参数。在损失函数中，<code>weight decay</code>是放在正则项（<code>regularization</code>）前面的一个系数，正则项一般指示模型的复杂度，所以<code>weight decay</code>的作用是调节模型复杂度对损失函数的影响，若<code>weight decay</code>很大，则复杂的模型损失函数的值也就大。</li>
<li><code>sanpshot</code>：每多少次保存一次学习的结果，在caffe框架下就是<code>caffemodel</code>。</li>
<li><code>snapshot_prefix</code>：模型保存的路径。</li>
<li><code>solver_model</code>：设置使用<code>GPU</code>还是<code>CPU</code>进行学习训练。</li>
<li><code>device_id</code>：GPU序列号，默认从<code>０</code>开始。</li>
<li><code>debug_info</code>：是否显示<code>debug</code>信息。</li>
<li><code>snapshot_after_train</code>：是否在训练结束后保存一个snapshot文件。便于以后可以在此基础上继续训练。</li>
<li><code>test_initialization</code>：确保内存可以用并输出<code>loss</code>的初始值。</li>
<li><code>average_loss</code>：显示<code>loss</code>为之前<code>average_loss</code>个<code>loss</code>的平均值。</li>
<li><code>iter_size</code>：每处理<code>iter_size*batch_size</code>张图片后进行一次梯度计算。</li>
<li><code>stepsize</code>：每多少次学习率递减。这里是迭代<code>2000</code>次学习率递减。</li>
<li><code>type</code>：优化算法的选择，一共有六种可选：<code>SGD、AdaDelta、AdaGrad、Adam、Nesterov和RMSProp</code>。默认为<code>SGD</code>。</li>
<li><code>eval_type</code>：评价类型。</li>
<li><code>ap_version</code>：计算平均准确率(map值)的方法，有<code>11point、MaxIntegral、Integral</code>三种，<code>l1point</code>是SSD在VOC2007中计算AP的方法，使用了简单的均值计算。<code>MaxInterral</code>是SSD在VOC2012中使用的最大值积分法。<code>Integral</code>是普通积分方法。</li>
<li><code>show_per_class_result</code>：在终端输出每一类的AP（每一类的检测精度）信息。</li>
</ul>
<h2 id="提高卷积神经网络的泛化能力"><a href="#提高卷积神经网络的泛化能力" class="headerlink" title="提高卷积神经网络的泛化能力"></a>提高卷积神经网络的泛化能力</h2><p>在做工程的时候如何提高自己训练出来的模型的泛化能力是一项具有挑战性同时也是一件充满”玄学”的事情。大概可以总结为下面这几点。</p>
<ul>
<li>使用更多的数据。竟可能标注更多的训练数据，这是提高泛化能力最理想的方法，更多的数据让模型得到更充分的学习，自然提高了泛化能力，但实际场景中考虑到标注成本的问题，可能并不能无脑加数据。</li>
<li>使用更大的<code>batch_size</code>。在相同迭代次数和学习率的条件下，每批次采用更多的数据将有助于模型更好的学习到正确的模式，模型输出结果也会更加稳定。</li>
<li>数据过采样。很多情况下我们拿到手的数据都存在类别不均匀的情况，模型这个时候过多的拟合某类数量多的数据导致其输出结果偏向于该类数据，此时如果我们过采样其他类别的数据，使得数据量比较均衡可以一定程度提高泛化能力。</li>
<li>数据增强。数据增强是指在数据有限的情况通过一些几何操作对图像进行变换，使得同类数据的表现形式更加丰富，以此提高模型的泛化能力。数据增强是一门比较大的学问，在分类，检测，分割中数据增强的方式都有区别，我们可以通过研究优秀的开源代码实现的数据增强策略来应用到我们自己的任务中。</li>
<li>修改损失函数。这方面有大量的工作，如目标检测中的Focal Loss, GHM Loss，IOU Loss等都是为了提升模型的泛化能力。</li>
<li>修改网络。如果网络过浅并且参数量过少往往会使得模型的泛化能力不足导致欠拟合，此时一般考虑使用简单的堆叠卷积层增加网络的参数，提高模型的特征提取能力。而如果网络过深且训练数据量比较少，那么就容易导致模型过拟合，此时一般需要简化网络结构减少网络层数或者使用<code>resnet</code>的残差结构以及<code>bn</code>层。</li>
<li>权重惩罚。权重惩罚也即是正则化操作，一般是在损失函数中添加一项权重矩阵的正则项作为惩罚项，用来惩罚损失值较小时网络权重过大的情况，此时往往是网络权值过拟合了数据样本。</li>
<li>Dropout策略。如果网络最后有全连接层可以使用<code>Dropout</code>策略，相当于对深度学习模型做了<code>Ensemble</code>，有助于提高模型的泛化能力。</li>
</ul>
<h2 id="一些调参技巧"><a href="#一些调参技巧" class="headerlink" title="一些调参技巧"></a>一些调参技巧</h2><h3 id="做工程"><a href="#做工程" class="headerlink" title="做工程"></a>做工程</h3><ul>
<li><p>3 x 3卷积是CNN的主流组件。平时有设计一些解决分类，回归任务的网络，里面的卷积核基本都设置为3 x 3，要说原因的话应该去问问<code>VGG16</code>吧。两个3 x 3的卷积核堆叠能获得5 x 5卷积核的感受野并且参数比5 x 5卷积核少，所以是大量推荐使用的。</p>
</li>
<li><p>可以适当使用1 x N卷积。为什么要提这一点呢，这是因为1 X N卷积可以减少计算量，并且1 X N卷积可以在某个方向强调感受野，也就是说假如如果你要对一个长方形形状的目标进行分类，你可以使用1 X N的卷积核搭配3 X 3的卷积核对长边方向设定更大的感受野，或许可以获得泛化性能的提升。</p>
</li>
<li>ACNet结构。这个研究来自于ICCV2019，可以在3 X 3卷积的基础上加上1 X 3和3 X 1的旁路卷积核，最后在推理阶段把三个卷积核都<code>fusion</code>到3 X 3卷积核上，在许多经典CV任务上都可以获得大概1个点的提升。</li>
<li>卷积核权重初始化方式。对于<code>weight</code>的初始化一般都是使用<code>xavier</code>初始化。当然也可以可以尝试何凯明大神的He初始化。对于bias的初始化全置于0。</li>
<li><code>Batch Normalization</code>。这是一直在使用的技巧，可以很大程度的加快收敛速度。建议搭建自己网络的时候尽量加上<code>BN</code>，如果有<code>BN</code>了全连接层就没必要加<code>Dropout</code>了。</li>
<li>目标检测不能盲目去掉<code>fpn</code>结构。在针对自己的数据调检测任务如<code>yolov3</code>的时候不能盲目砍掉<code>fpn</code>结构，尽管你分析出某个分支的Anchor基本不可能会对你预测的目标起作用，但如果你直接去掉分支很可能会带来漏检。</li>
<li>优化器的选择。基本都是带动量的<code>SGD</code>。如果优化不动可以试试<code>Adam</code>。</li>
<li>激活函数。可以先用<code>ReLU</code>做一版，如果想再提升精度可以将<code>ReLU</code>改成<code>PReLU</code>试试。我更倾向于直接使用<code>ReLU</code>。</li>
<li><code>batch_size</code>：在不同类型的任务中，<code>batch_size</code>的影响也不同。</li>
<li>初始学习率。一般是从<code>0.01</code>开始设置，个人认为这个学习率和学习率衰减策略是相关的，但不宜设置的过大过小，<code>0.01</code>和<code>0.1</code>应该是比较常用的。学习率衰减策略一般使用<code>multistep</code>方式，<code>step_size</code>的设置要看视你的的<code>max_iter</code>而定。</li>
<li>数据与处理之<code>zero-center</code>。主要有2个步骤，第一个是减均值，第二个是除以方差。这样做下来最后的输入值域为<code>[-1,1]</code>，一般减均值是最常用的，后面的除以方差用不用可能需要自己动手试验一下看看效果。</li>
<li>残差结构和密集连接。<code>resnet</code>的残差结构和<code>dense net</code>密集连接结构，做工程的时候考虑到速度近乎不可能说完全使用完整版本的<code>resnet</code>和<code>densenet</code>的完整结构，但我们可以自己动手将我们网络的某些模块替换为残差结构和密集连接，替换的时候可以适当降低这俩结构的复杂度，类似于通道数减半，密集连接中只保留一半连接等等。这里需要做一些消融实验来验证改进后的精度。</li>
<li>关于loss。优秀的<code>loss</code>一般是对模型的泛化性能有所改善的，但在用<code>loss</code>的时候往往并不是直接替换<code>loss</code>那么简单，需要仔细思考<code>loss</code>背后的数学原理，要用对地方才可有提升。</li>
<li>找到模型调参时的可靠评价指标。在调整参数训练模型时一定要找到正确的评价指标，没调整一个参数就要记录一下模型的评价指标如准确率，<code>map</code>值，<code>miou</code>值等。并且在调参时建议将调整的参数和在测试集上的精度组合成一个字符串给模型重命令，方便之后快速<code>review</code>。</li>
<li>使用了带<code>backbone</code>的网络，如训练<code>VGG16-SSD</code>建议选择<code>finetune</code>的方式，从头训练不仅费时费力，甚至难以收敛。</li>
</ul>
<h3 id="做比赛"><a href="#做比赛" class="headerlink" title="做比赛"></a>做比赛</h3><ul>
<li><p>特征提取。VGG16，VGG19，ResNet50，Xception是非常好用的几个特征提取模型。建议使用训练好的经典模型对数据集提取特征向量存储到本地，更方便使用，同时可以大幅度降低显存消耗。</p>
</li>
<li><p>ensemle：</p>
<ul>
<li>将不同的经典网络提取出的特征向量，假设<code>VGG16</code>提取出的特征向量维度是<code>[N,c1]</code>,<code>ResNet50</code>提取的特征向量维度是<code>[N，c2]</code>,<code>Xception</code>提取的特征向量维度是<code>[N, c3]</code>，那么我们可以使用三个系数<code>a、b、c</code>将其组合为形状为<code>[N, a*c1+b*c2+c*c3]</code>，其中<code>a、b、c</code>三个参数的取值代表我们使用哪个模型的特征多一些，如果是分类回归比赛，我们在后面接特征处理网络就可以了。可以取不同的<code>a、b、c</code>得到不同的特征，然后对结果做<code>voting</code>，<code>soft-voting</code>等多种处理，一般结果不会太差。</li>
<li>可以使用不同的初始化方式训练出模型，然后做ensemble。</li>
<li>可以使用用不同超参数(如学习率，<code>batch_size</code>，优化器)训练出不同模型，然后做ensemble。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>历届CCF顶会地点查询</title>
    <url>/2020/12/11/%E5%8E%86%E5%B1%8ACCF%E9%A1%B6%E4%BC%9A%E5%9C%B0%E7%82%B9%E6%9F%A5%E8%AF%A2/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>鉴于某些参考文献，在引用会议时需要注明开会地点，然而谷歌学术中并不能提供会议地点，这里提供一些常用会议地点的检索网址。</p>
<h2 id="地点查询"><a href="#地点查询" class="headerlink" title="地点查询"></a>地点查询</h2><p>历届NIPS会议地址：<a href="https://www.datalearner.com/conference/nips/">https://www.datalearner.com/conference/nips/</a><br>历届ECCV会议地址：<a href="https://link.springer.com/conference/eccv">https://link.springer.com/conference/eccv</a><br>历届BMVC会议地址：<a href="https://britishmachinevisionassociation.github.io/bmvc">https://britishmachinevisionassociation.github.io/bmvc</a><br>历届IEEE下的会议地址（如CVPR，ICCV等）请到IEEE下搜论文导出参考文献可得：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/2.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/1.jpg" alt></p>
<p>这里也提供历届ECCV、ICCV、CVPR、WACV地址：<a href="https://www.thecvf.com/?page_id=100">https://www.thecvf.com/?page_id=100</a></p>
<h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>查询到地点后手动添加进EndNote题录的关键字即可：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/wenxian/3.png" alt></p>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title>回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比</title>
    <url>/2020/05/08/%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AL1-loss,-L2-loss%E4%BB%A5%E5%8F%8ASmooth-L1-Loss%E7%9A%84%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结对比下$L_{1}$损失函数，$L_{2}$损失函数以及损$SmoothL_{1}$失函数的优缺点。</p>
<h2 id="均方误差MSE-L-2-Loss"><a href="#均方误差MSE-L-2-Loss" class="headerlink" title="均方误差MSE ($L_{2}$ Loss)"></a>均方误差MSE ($L_{2}$ Loss)</h2><p>均方误差（Mean Square Error,MSE）是模型预测值$f(x)$与真实样本值$y$之间差值平方的平均值，其公式如下</p>
<script type="math/tex; mode=display">
M S E=\frac{\sum_{i=1}^{n}\left(f_{x_{i}}-y_{i}\right)^{2}}{n}</script><p>其中，$\boldsymbol{y}_{i}$和$f\left(x_{i}\right)$分别表示第$i$个样本的真实值及其对应的预测值，$n$为样本的个数。</p>
<p>忽略下标$i$ ，设$n=1$，以$f(x)−y$为横轴，MSE的值为纵轴，得到函数的图形如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/loss/1.png" alt></p>
<p>MSE的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。 而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。</p>
<p>当$y$和$f(x)$也就是真实值和预测值的差值大于1时，会放大误差；而当差值小于1时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差（&gt;1）给予较大的惩罚，较小的误差（&lt;1）给予较小的惩罚。也就是说，对离群点比较敏感，受其影响较大。</p>
<p>如果样本中存在离群点，MSE会给离群点更高的权重，这就会牺牲其他正常点数据的预测效果，最终降低整体的模型性能。 如下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/loss/2.png" alt></p>
<p>可见，使用 MSE 损失函数，受离群点的影响较大，虽然样本中只有 5 个离群点，但是拟合的直线还是比较偏向于离群点。</p>
<h2 id="平均绝对误差-L-1-Loss"><a href="#平均绝对误差-L-1-Loss" class="headerlink" title="平均绝对误差($L_{1}$ Loss)"></a>平均绝对误差($L_{1}$ Loss)</h2><p>平均绝对误差（Mean Absolute Error,MAE) 是指模型预测值$f(x)$和真实值$y$之间距离绝对值的平均值，其公式如下：</p>
<script type="math/tex; mode=display">
M A E=\frac{\sum_{n=1}^{n}\left|f\left(x_{i}\right)-y_{i}\right|}{n}</script><p>忽略下标$i$ ，设$n=1$，以$f(x)−y$为横轴，MAE的值为纵轴，得到函数的图形如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/loss/3.png" alt></p>
<p>MAE曲线连续，但是在$y−f(x)=0$处不可导。而且 MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。但是，无论对于什么样的输入值，都有着稳定的梯度，不会导致梯度爆炸问题，具有较为稳健性的解。</p>
<p>相比于MSE，MAE有个优点就是，对于离群点不那么敏感。因为MAE计算的是误差$y−f(x)$的绝对值，对于任意大小的差值，其惩罚都是固定的。</p>
<p>针对上面带有离群点的数据，MAE的效果要好于MSE。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/loss/4.png" alt></p>
<p>显然，使用 MAE 损失函数，受离群点的影响较小，拟合直线能够较好地表征正常数据的分布情况。</p>
<h2 id="MSE和MAE的选择"><a href="#MSE和MAE的选择" class="headerlink" title="MSE和MAE的选择"></a>MSE和MAE的选择</h2><ul>
<li>从梯度的求解以及收敛上，MSE是优于MAE的。MSE处处可导，而且梯度值也是动态变化的，能够快速的收敛；而MAE在0点处不可导，且其梯度保持不变。对于很小的损失值其梯度也很大，在深度学习中，就需要使用变化的学习率，在损失值很小时降低学习率。</li>
<li>对离群（异常）值的处理上，MAE要明显好于MSE。</li>
</ul>
<p>如果离群点（异常值）需要被检测出来，则可以选择MSE作为损失函数；如果离群点只是当做受损的数据处理，则可以选择MAE作为损失函数。</p>
<p>总之，MAE作为损失函数更稳定，并且对离群值不敏感，但是其导数不连续，求解效率低。另外，在深度学习中，收敛较慢。MSE导数求解速度高，但是其对离群值敏感，不过可以将离群值的导数设为0（导数值大于某个阈值）来避免这种情况。</p>
<p>在某些情况下，上述两种损失函数都不能满足需求。例如，若数据中90%的样本对应的目标值为150，剩下10%在0到30之间。那么使用MAE作为损失函数的模型可能会忽视10%的异常点，而对所有样本的预测值都为150。这是因为模型会按中位数来预测。而使用MSE的模型则会给出很多介于0到30的预测值，因为模型会向异常点偏移。</p>
<p>这种情况下，MSE和MAE都是不可取的，简单的办法是对目标变量进行变换，或者使用别的损失函数，例如：Huber,Log-Cosh以及分位数损失等。</p>
<h2 id="Smooth-L-1-Loss"><a href="#Smooth-L-1-Loss" class="headerlink" title="Smooth $L_{1}$ Loss"></a>Smooth $L_{1}$ Loss</h2><p>在Faster R-CNN以及SSD中对边框的回归使用的损失函数都是Smooth $L_{1}$作为损失函数，</p>
<script type="math/tex; mode=display">
\operatorname{Smooth} L_{1}(x)=\left\{\begin{array}{cc}0.5 x^{2} & \text { if }|x|<1 \\ |x|-0.5 & \text { otherwise }\end{array}\right.</script><p>其中，$x=f(x_{i})−y_{i}$为真实值和预测值的差值。</p>
<p>Smooth $L_{1}$能从两个方面限制梯度：</p>
<ol>
<li>当预测框与 ground truth 差别过大时，梯度值不至于过大；</li>
<li>当预测框与 ground truth 差别很小时，梯度值足够小。</li>
</ol>
<h2 id="对比-L-1-Loss和-L-2-Loss"><a href="#对比-L-1-Loss和-L-2-Loss" class="headerlink" title="对比$L_{1}$ Loss和 $L_{2}$ Loss"></a>对比$L_{1}$ Loss和 $L_{2}$ Loss</h2><p>其中$x$为预测框与groud truth之间的差异：</p>
<script type="math/tex; mode=display">
\begin{aligned} L_{2}(x) &=x^{2}\\ L_{1}(x) &=x\\ \operatorname{smooth}_{L_{1}}(x) &=\left\{\begin{array}{cc}0.5 x^{2} & \text { if }|x|<1 \\ |x|-0.5 & \text { otherwise }\end{array}\right.\end{aligned}</script><p>上面损失函数对$x$的导数为：</p>
<script type="math/tex; mode=display">
\begin{aligned} \frac{\partial L_{2}(x)}{\partial x} &=2 x \\ \frac{\partial L_{1}(x)}{\partial x} &=\left\{\begin{array}{cc}1 & \text { if } x \geq 0 \\ -1 & \text { otherwise }\end{array}\right.\\ \frac{\partial s m o o t h_{L_{1}}(x)}{\partial x} &=\left\{\begin{array}{cc}x & \text { if }|x|<1 \\ \pm 1 & \text { otherwise }\end{array}\right.\end{aligned}</script><p>上面导数可以看出：</p>
<ul>
<li><p>根据公式-4，当$x$增大时，$L_{2}$的损失也增大。 这就导致在训练初期，预测值与groud truth差异过于大时，损失函数对预测值的梯度十分大，训练不稳定。</p>
</li>
<li><p>根据公式-5，$L_{1}$对$x$的导数为常数，在训练的后期，预测值与ground truth差异很小时，$L_{1}$的导数的绝对值仍然为1，而learning rate如果不变，损失函数将在稳定值附近波动，难以继续收敛以达到更高精度。</p>
</li>
<li><p>根据公式-6，$Smooth L_{1}$在$x$较小时，对$x$的梯度也会变小。 而当$x$较大时，对$x$的梯度的上限为1，也不会太大以至于破坏网络参数。$Smooth L_{1}$完美的避开了$L_{1}$和$L_{2}$作为损失函数的缺陷。</p>
</li>
</ul>
<p>$L_{1}$ Loss，$L_{2}$ Loss以及$Smooth L_{1}$放在一起的函数曲线对比</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/loss/5.png" alt></p>
<p>从上面可以看出，该函数实际上就是一个分段函数，在[-1,1]之间实际上就是L2损失，这样解决了L1的不光滑问题，在[-1,1]区间外，实际上就是L1损失，这样就解决了离群点梯度爆炸的问题</p>
<h2 id="实现-PyTorch"><a href="#实现-PyTorch" class="headerlink" title="实现 (PyTorch)"></a>实现 (PyTorch)</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_smooth_l1_loss</span>(<span class="params"><span class="built_in">input</span>, target, reduction=<span class="string">&#x27;none&#x27;</span></span>):</span></span><br><span class="line">    <span class="comment"># type: (Tensor, Tensor) -&gt; Tensor</span></span><br><span class="line">    t = torch.<span class="built_in">abs</span>(<span class="built_in">input</span> - target)</span><br><span class="line">    ret = torch.where(t &lt; <span class="number">1</span>, <span class="number">0.5</span> * t ** <span class="number">2</span>, t - <span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">if</span> reduction != <span class="string">&#x27;none&#x27;</span>:</span><br><span class="line">        ret = torch.mean(ret) <span class="keyword">if</span> reduction == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> torch.<span class="built_in">sum</span>(ret)</span><br><span class="line">    <span class="keyword">return</span> ret      </span><br></pre></td></tr></table></figure>
<p>也可以添加个参数<code>beta</code> 这样就可以控制，什么范围的误差使用MSE，什么范围内的误差使用MAE了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_l1_loss</span>(<span class="params"><span class="built_in">input</span>, target, beta=<span class="number">1.</span> / <span class="number">9</span>, reduction = <span class="string">&#x27;none&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    very similar to the smooth_l1_loss from pytorch, but with</span></span><br><span class="line"><span class="string">    the extra beta parameter</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    n = torch.<span class="built_in">abs</span>(<span class="built_in">input</span> - target)</span><br><span class="line">    cond = n &lt; beta</span><br><span class="line">    ret = torch.where(cond, <span class="number">0.5</span> * n ** <span class="number">2</span> / beta, n - <span class="number">0.5</span> * beta)</span><br><span class="line">    <span class="keyword">if</span> reduction != <span class="string">&#x27;none&#x27;</span>:</span><br><span class="line">        ret = torch.mean(ret) <span class="keyword">if</span> reduction == <span class="string">&#x27;mean&#x27;</span> <span class="keyword">else</span> torch.<span class="built_in">sum</span>(ret)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于大多数CNN网络，我们一般是使用L2-loss而不是L1-loss，因为L2-loss的收敛速度要比L1-loss要快得多。</p>
<p>对于边框预测回归问题，通常也可以选择平方损失函数（L2损失），但L2范数的缺点是当存在离群点（outliers)的时候，这些点会占loss的主要组成部分。比如说真实值为1，预测10次，有一次预测值为1000，其余次的预测值为1左右，显然loss值主要由1000决定。所以FastRCNN采用稍微缓和一点绝对损失函数（smooth L1损失），它是随着误差线性增长，而不是平方增长。</p>
<p>Smooth L1 和 L1 Loss 函数的区别在于，L1 Loss 在0点处导数不唯一，可能影响收敛。Smooth L1的解决办法是在 0 点附近使用平方函数使得它更加平滑。</p>
<p>Smooth L1的优点</p>
<ul>
<li>相比于L1损失函数，可以收敛得更快。</li>
<li>相比于L2损失函数，对离群点、异常值不敏感，梯度变化相对更小，训练时不容易跑飞。</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>在YOLOv3模型中添加Attention机制</title>
    <url>/2020/02/18/%E5%9C%A8YOLOv3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E6%B7%BB%E5%8A%A0Attention%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h2 id="1-规定格式"><a href="#1-规定格式" class="headerlink" title="1. 规定格式"></a>1. 规定格式</h2><p>正如<code>[convolutional]</code>,<code>[maxpool]</code>,<code>[net]</code>,<code>[route]</code>等层在cfg中的定义一样，我们再添加全新的模块的时候，要规定一下cfg的格式。做出以下规定：</p>
<p>在SE模块中，有一个参数为<code>reduction</code>,这个参数默认是16，所以在这个模块中的详细参数我们按照以下内容进行设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[se]</span><br><span class="line">reduction=16</span><br></pre></td></tr></table></figure>
<p>在CBAM模块中，空间注意力机制和通道注意力机制中一共存在两个参数：<code>ratio</code>和<code>kernel_size</code>, 所以这样规定CBAM在cfg文件中的格式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[cbam]</span><br><span class="line">ratio=16</span><br><span class="line">kernelsize=7</span><br></pre></td></tr></table></figure>
<h2 id="2-修改解析部分"><a href="#2-修改解析部分" class="headerlink" title="2. 修改解析部分"></a>2. 修改解析部分</h2><p>由于添加的这些参数都是自定义的，所以需要修改解析cfg文件的函数，之前讲过，需要修改<code>parse_config.py</code>中的部分内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_model_cfg</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="comment"># path参数为: cfg/yolov3-tiny.cfg</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> path.endswith(<span class="string">&#x27;.cfg&#x27;</span>):</span><br><span class="line">        path += <span class="string">&#x27;.cfg&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path) <span class="keyword">and</span> \</span><br><span class="line">    	   os.path.exists(<span class="string">&#x27;cfg&#x27;</span> + os.sep + path):</span><br><span class="line">        path = <span class="string">&#x27;cfg&#x27;</span> + os.sep + path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.read().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去除以#开头的，属于注释部分的内容</span></span><br><span class="line">    lines = [x <span class="keyword">for</span> x <span class="keyword">in</span> lines <span class="keyword">if</span> x <span class="keyword">and</span> <span class="keyword">not</span> x.startswith(<span class="string">&#x27;#&#x27;</span>)]</span><br><span class="line">    lines = [x.rstrip().lstrip() <span class="keyword">for</span> x <span class="keyword">in</span> lines]</span><br><span class="line">    mdefs = []  <span class="comment"># 模块的定义</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&#x27;[&#x27;</span>):  <span class="comment"># 标志着一个模块的开始</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            eg:</span></span><br><span class="line"><span class="string">            [shortcut]</span></span><br><span class="line"><span class="string">            from=-3</span></span><br><span class="line"><span class="string">            activation=linear</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            mdefs.append(&#123;&#125;)</span><br><span class="line">            mdefs[-<span class="number">1</span>][<span class="string">&#x27;type&#x27;</span>] = line[<span class="number">1</span>:-<span class="number">1</span>].rstrip()</span><br><span class="line">            <span class="keyword">if</span> mdefs[-<span class="number">1</span>][<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;convolutional&#x27;</span>:</span><br><span class="line">                mdefs[-<span class="number">1</span>][<span class="string">&#x27;batch_normalize&#x27;</span>] = <span class="number">0</span> </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            key, val = line.split(<span class="string">&quot;=&quot;</span>)</span><br><span class="line">            key = key.rstrip()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;anchors&#x27;</span> <span class="keyword">in</span> key:</span><br><span class="line">                mdefs[-<span class="number">1</span>][key] = np.array([<span class="built_in">float</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> val.split(<span class="string">&#x27;,&#x27;</span>)]).reshape((-<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mdefs[-<span class="number">1</span>][key] = val.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Check all fields are supported</span></span><br><span class="line">    supported = [<span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;batch_normalize&#x27;</span>, <span class="string">&#x27;filters&#x27;</span>, <span class="string">&#x27;size&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;stride&#x27;</span>, <span class="string">&#x27;pad&#x27;</span>, <span class="string">&#x27;activation&#x27;</span>, <span class="string">&#x27;layers&#x27;</span>, \</span><br><span class="line">                 <span class="string">&#x27;groups&#x27;</span>,<span class="string">&#x27;from&#x27;</span>, <span class="string">&#x27;mask&#x27;</span>, <span class="string">&#x27;anchors&#x27;</span>, \</span><br><span class="line">                 <span class="string">&#x27;classes&#x27;</span>, <span class="string">&#x27;num&#x27;</span>, <span class="string">&#x27;jitter&#x27;</span>, <span class="string">&#x27;ignore_thresh&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;truth_thresh&#x27;</span>, <span class="string">&#x27;random&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;stride_x&#x27;</span>, <span class="string">&#x27;stride_y&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    f = []  <span class="comment"># fields</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> mdefs[<span class="number">1</span>:]:</span><br><span class="line">        [f.append(k) <span class="keyword">for</span> k <span class="keyword">in</span> x <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> f]</span><br><span class="line">    u = [x <span class="keyword">for</span> x <span class="keyword">in</span> f <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> supported]  <span class="comment"># unsupported fields</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">not</span> <span class="built_in">any</span>(u), <span class="string">&quot;Unsupported fields %s in %s. See https://github.com/ultralytics/yolov3/issues/631&quot;</span> % (u, path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mdefs</span><br></pre></td></tr></table></figure>
<p>以上内容中，需要改的是supported中的字段，将我们的内容添加进去：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">supported = [<span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;batch_normalize&#x27;</span>, <span class="string">&#x27;filters&#x27;</span>, <span class="string">&#x27;size&#x27;</span>,\</span><br><span class="line">            <span class="string">&#x27;stride&#x27;</span>, <span class="string">&#x27;pad&#x27;</span>, <span class="string">&#x27;activation&#x27;</span>, <span class="string">&#x27;layers&#x27;</span>, \</span><br><span class="line">            <span class="string">&#x27;groups&#x27;</span>,<span class="string">&#x27;from&#x27;</span>, <span class="string">&#x27;mask&#x27;</span>, <span class="string">&#x27;anchors&#x27;</span>, \</span><br><span class="line">            <span class="string">&#x27;classes&#x27;</span>, <span class="string">&#x27;num&#x27;</span>, <span class="string">&#x27;jitter&#x27;</span>, <span class="string">&#x27;ignore_thresh&#x27;</span>,\</span><br><span class="line">            <span class="string">&#x27;truth_thresh&#x27;</span>, <span class="string">&#x27;random&#x27;</span>,\</span><br><span class="line">            <span class="string">&#x27;stride_x&#x27;</span>, <span class="string">&#x27;stride_y&#x27;</span>,\</span><br><span class="line">            <span class="string">&#x27;ratio&#x27;</span>, <span class="string">&#x27;reduction&#x27;</span>, <span class="string">&#x27;kernelsize&#x27;</span>]</span><br></pre></td></tr></table></figure>
<h2 id="3-实现SE和CBAM"><a href="#3-实现SE和CBAM" class="headerlink" title="3. 实现SE和CBAM"></a>3. 实现SE和CBAM</h2><p><strong>SE</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SELayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channel, reduction=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y.expand_as(x)</span><br></pre></td></tr></table></figure>
<p><strong>CBAM</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpatialAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, kernel_size=<span class="number">7</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SpatialAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> kernel_size <span class="keyword">in</span> (<span class="number">3</span>,<span class="number">7</span>), <span class="string">&quot;kernel size must be 3 or 7&quot;</span></span><br><span class="line">        padding = <span class="number">3</span> <span class="keyword">if</span> kernel_size == <span class="number">7</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(<span class="number">2</span>,<span class="number">1</span>,kernel_size, padding=padding, bias=<span class="literal">False</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avgout = torch.mean(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        maxout, _ = torch.<span class="built_in">max</span>(x, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        x = torch.cat([avgout, maxout], dim=<span class="number">1</span>)</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(x)</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChannelAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_planes, rotio=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ChannelAttention, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.sharedMLP = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_planes, in_planes // ratio, <span class="number">1</span>, bias=<span class="literal">False</span>), nn.ReLU(),</span><br><span class="line">            nn.Conv2d(in_planes // rotio, in_planes, <span class="number">1</span>, bias=<span class="literal">False</span>))</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        avgout = self.sharedMLP(self.avg_pool(x))</span><br><span class="line">        maxout = self.sharedMLP(self.max_pool(x))</span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(avgout + maxout)</span><br></pre></td></tr></table></figure>
<p>以上就是两个模块的代码，添加到<code>models.py</code>文件中。</p>
<h2 id="4-设计cfg文件"><a href="#4-设计cfg文件" class="headerlink" title="4. 设计cfg文件"></a>4. 设计cfg文件</h2><p>这里以<code>yolov3-tiny.cfg</code>为baseline，然后添加注意力机制模块。</p>
<p>CBAM与SE类似，所以以SE为例，添加到backbone之后的部分，进行信息重构(refinement)。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[net]</span><br><span class="line"># Testing</span><br><span class="line">batch=1</span><br><span class="line">subdivisions=1</span><br><span class="line"># Training</span><br><span class="line"># batch=64</span><br><span class="line"># subdivisions=2</span><br><span class="line">width=416</span><br><span class="line">height=416</span><br><span class="line">channels=3</span><br><span class="line">momentum=0.9</span><br><span class="line">decay=0.0005</span><br><span class="line">angle=0</span><br><span class="line">saturation = 1.5</span><br><span class="line">exposure = 1.5</span><br><span class="line">hue=.1</span><br><span class="line"></span><br><span class="line">learning_rate=0.001</span><br><span class="line">burn_in=1000</span><br><span class="line">max_batches = 500200</span><br><span class="line">policy=steps</span><br><span class="line">steps=400000,450000</span><br><span class="line">scales=.1,.1</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=16</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=32</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=64</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=256</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=512</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[maxpool]</span><br><span class="line">size=2</span><br><span class="line">stride=1</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=1024</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[se]</span><br><span class="line">reduction=16</span><br><span class="line"></span><br><span class="line"># 在backbone结束的地方添加se模块</span><br><span class="line">#####backbone######</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=256</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=512</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=18</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask = 3,4,5</span><br><span class="line">anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319</span><br><span class="line">classes=1</span><br><span class="line">num=6</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .7</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br><span class="line"></span><br><span class="line">[route]</span><br><span class="line">layers = -4</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[upsample]</span><br><span class="line">stride=2</span><br><span class="line"></span><br><span class="line">[route]</span><br><span class="line">layers = -1, 8</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=256</span><br><span class="line">size=3</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br><span class="line"></span><br><span class="line">[convolutional]</span><br><span class="line">size=1</span><br><span class="line">stride=1</span><br><span class="line">pad=1</span><br><span class="line">filters=18</span><br><span class="line">activation=linear</span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask = 0,1,2</span><br><span class="line">anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319</span><br><span class="line">classes=1</span><br><span class="line">num=6</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .7</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure>
<h2 id="5-模型构建"><a href="#5-模型构建" class="headerlink" title="5. 模型构建"></a>5. 模型构建</h2><p>以上都是准备工作，以SE为例，我们修改<code>model.py</code>文件中的模型加载部分，并修改forward函数部分的代码，让其正常发挥作用：</p>
<p>在<code>model.py</code>中的<code>create_modules</code>函数中进行添加：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;se&#x27;</span>:</span><br><span class="line">    modules.add_module(</span><br><span class="line">        <span class="string">&#x27;se_module&#x27;</span>,</span><br><span class="line">        SELayer(output_filters[-<span class="number">1</span>], reduction=<span class="built_in">int</span>(mdef[<span class="string">&#x27;reduction&#x27;</span>])))</span><br></pre></td></tr></table></figure>
<p>然后修改Darknet中的forward部分的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, var=<span class="literal">None</span></span>):</span></span><br><span class="line">    img_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">    layer_outputs = []</span><br><span class="line">    output = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (mdef,</span><br><span class="line">            module) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(self.module_defs, self.module_list)):</span><br><span class="line">        mtype = mdef[<span class="string">&#x27;type&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> mtype <span class="keyword">in</span> [<span class="string">&#x27;convolutional&#x27;</span>, <span class="string">&#x27;upsample&#x27;</span>, <span class="string">&#x27;maxpool&#x27;</span>]:</span><br><span class="line">            x = module(x)</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;route&#x27;</span>:</span><br><span class="line">            layers = [<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> mdef[<span class="string">&#x27;layers&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(layers) == <span class="number">1</span>:</span><br><span class="line">                x = layer_outputs[layers[<span class="number">0</span>]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    x = torch.cat([layer_outputs[i] <span class="keyword">for</span> i <span class="keyword">in</span> layers], <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">except</span>:  <span class="comment"># apply stride 2 for darknet reorg layer</span></span><br><span class="line">                    layer_outputs[layers[<span class="number">1</span>]] = F.interpolate(</span><br><span class="line">                        layer_outputs[layers[<span class="number">1</span>]], scale_factor=[<span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">                    x = torch.cat([layer_outputs[i] <span class="keyword">for</span> i <span class="keyword">in</span> layers], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;shortcut&#x27;</span>:</span><br><span class="line">            x = x + layer_outputs[<span class="built_in">int</span>(mdef[<span class="string">&#x27;from&#x27;</span>])]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;yolo&#x27;</span>:</span><br><span class="line">            output.append(module(x, img_size))</span><br><span class="line">        layer_outputs.append(x <span class="keyword">if</span> i <span class="keyword">in</span> self.routs <span class="keyword">else</span> [])</span><br></pre></td></tr></table></figure>
<p>在forward中加入SE模块，其实很简单。SE模块与卷积层，上采样，最大池化层地位是一样的，不需要更多操作，只需要将以上部分代码进行修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (mdef, module) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(self.module_defs, self.module_list)):</span><br><span class="line">       mtype = mdef[<span class="string">&#x27;type&#x27;</span>]</span><br><span class="line">       <span class="keyword">if</span> mtype <span class="keyword">in</span> [<span class="string">&#x27;convolutional&#x27;</span>, <span class="string">&#x27;upsample&#x27;</span>, <span class="string">&#x27;maxpool&#x27;</span>, <span class="string">&#x27;se&#x27;</span>]:</span><br><span class="line">           x = module(x)</span><br></pre></td></tr></table></figure>
<p>CBAM的整体过程类似，可以自己尝试一下，顺便熟悉一下YOLOv3的整体流程。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用PyTorch分布式训练</title>
    <url>/2022/01/11/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Pytorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h2 id="DDP"><a href="#DDP" class="headerlink" title="DDP"></a>DDP</h2><p>DDP是PyTorch中的一个库，它支持跨多个设备的梯度同步。这意味着您可以通过跨多个GPU并行处理，线性地加快模型训练。DDP的工作原理是为每个GPU创建一个单独的Python进程，每个进程都使用一个不重叠的数据子集。</p>
<p>比起DP来，DDP训练速度更快，显卡负载也更为均衡。目前官方开发者推荐使用DDP代替DP，DP很少维护了，导致有许多bug。比如：<code>nn.ParameterList</code>和<code>nn.ParameterDict</code>在DP中会存在其他卡无法复制，变成空值的Bug，而这在DDP中就正常。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>① 添加超参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span>():</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args</span><br></pre></td></tr></table></figure>
<ul>
<li>local_rank：进程内GPU编号，非显式参数，由 <code>torch.distributed.launch</code> 内部指定，默认为GPU可用列表中的第一个GPU，这个是必须加的。</li>
</ul>
<p>② 在主函数添加：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;Distributed Training&#x27;</span>)</span><br><span class="line"><span class="comment"># 该参数由torch.distributed.launch自动传递，代表当前进程处理的GPU编号</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 所创建的进程数，也就是所使用的GPU数量</span></span><br><span class="line">num_gpus = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>]) <span class="keyword">if</span> <span class="string">&#x27;WORLD_SIZE&#x27;</span> <span class="keyword">in</span> os.environ <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">args.is_distributed = num_gpus &gt; <span class="number">1</span></span><br><span class="line">args.num_gpus = num_gpus</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.is_distributed:</span><br><span class="line">    torch.cuda.set_device(args.local_rank)</span><br><span class="line">    torch.distributed.init_process_group(backend=<span class="string">&#x27;nccl&#x27;</span>, init_method=<span class="string">&#x27;env://&#x27;</span>)</span><br><span class="line">    dist.barrier() <span class="comment"># 用dist.barrier()来同步不同进程间的快慢</span></span><br></pre></td></tr></table></figure>
<ul>
<li>world size：表示全局进程个数。</li>
</ul>
<p>③ 修改导入数据的接口：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = DAVIS2017(root, <span class="string">&#x27;training&#x27;</span>)</span><br><span class="line">num_workers = <span class="number">4</span> <span class="keyword">if</span> cuda <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 使用DistributedSampler来为各个进程分发数据，用于将数据集等分成不重叠的数个子集</span></span><br><span class="line">train_sampler  = torch.utils.data.distributed.DistributedSampler(dataset)</span><br><span class="line"><span class="comment"># 在Dataloader中指定sampler时，其中的shuffle必须为False，而DistributedSampler中的shuffle项默认为True，因此训练过程默认执行shuffle</span></span><br><span class="line">dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=<span class="literal">False</span>, num_workers=num_workers,pin_memory=cuda, drop_last=<span class="literal">True</span>, sampler=train_sampler)</span><br></pre></td></tr></table></figure>
<p>④ 准备模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = create_model()</span><br><span class="line"><span class="comment"># 创建CUDA设备</span></span><br><span class="line">device = device = torch.device(<span class="string">&#x27;cuda:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(args.local_rank))</span><br><span class="line"><span class="comment"># 把模型放到cuda上</span></span><br><span class="line">model = model.to(device)</span><br><span class="line"><span class="comment"># 将模型用DDP封装</span></span><br><span class="line">model = DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)</span><br></pre></td></tr></table></figure>
<p>⑤ 权重加载：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载模型前后用dist.barrier()来同步不同进程间的快慢</span></span><br><span class="line">dist.barrier()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;model.pth&#x27;</span>), map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">dist.barrier()</span><br></pre></td></tr></table></figure>
<p>⑥ 学习率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 学习率应扩大GPU数的倍数，因为DDP每张显卡分别跑batchsize</span></span><br><span class="line"><span class="comment"># 而DP是多张显卡跑一个batchsize</span></span><br><span class="line"><span class="comment"># 也可以将batchsize // args.num_gpus作为batchsize，lr不变</span></span><br><span class="line">lr *= args.num_gpus</span><br></pre></td></tr></table></figure>
<p>⑦ 迭代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    <span class="comment"># 在多GPU环境下，采样器必须知道哪个epoch</span></span><br><span class="line">    <span class="comment"># 因此，每次迭代开始需要为sampler设置当前epoch</span></span><br><span class="line">    train_sampler.set_epoch(epoch)</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>⑧ 输出loss：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_world_size</span>():</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dist.is_available():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dist.is_initialized():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> dist.get_world_size()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce_value</span>(<span class="params">value, average=<span class="literal">True</span></span>):</span></span><br><span class="line">    world_size = get_world_size()</span><br><span class="line">    <span class="keyword">if</span> world_size &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        dist.all_reduce(value)</span><br><span class="line">        <span class="keyword">if</span> average:</span><br><span class="line">            value /= world_size</span><br><span class="line">        <span class="keyword">return</span> value</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">epoch</span>):</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        ...</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        ...</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment"># loss为每个GPU上loss的累加，因此会很大</span></span><br><span class="line">        <span class="comment"># 如果想输出一个GPU上的loss，可对loss取平均</span></span><br><span class="line">        <span class="keyword">if</span> is_main_process():</span><br><span class="line">            reduced_loss = reduce_tensor(loss)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loss: %.3f&#x27;</span> % reduced_loss.item())</span><br></pre></td></tr></table></figure>
<p>⑨ 模型保存、日志输出、控制台打印等：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_rank</span>():</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dist.is_available():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> dist.is_initialized():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> dist.get_rank()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_main_process</span>():</span></span><br><span class="line">    <span class="keyword">return</span> get_rank() == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分布式训练会开启多个进程，因此模型的保存、日志输出、控制台打印等也会进行多次</span></span><br><span class="line"><span class="comment"># 因此直接保存会发生冲突</span></span><br><span class="line"><span class="comment"># 遇到此类操作都需要加判断，只在主进程时进行</span></span><br><span class="line"><span class="keyword">if</span> is_main_process():</span><br><span class="line">	torch.save(xxxx)</span><br></pre></td></tr></table></figure>
<p>⑩ 训练：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在原来基础上加上python -m torch.distributed.launch --nproc_per_node=GPU数量即可</span><br><span class="line">python -m torch.distributed.launch --nproc_per_node=GPU数量 train.py --arg1 --arg2 --arg3</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>如何给热点翻墙</title>
    <url>/2020/02/16/%E5%A6%82%E4%BD%95%E7%BB%99%E7%83%AD%E7%82%B9%E7%BF%BB%E5%A2%99/</url>
    <content><![CDATA[<h2 id="Netch简介"><a href="#Netch简介" class="headerlink" title="Netch简介"></a>Netch简介</h2><p>Netch是一款开源的网络游戏工具，支持Socks5、55R、V2等协议，UDP NAT  FullCone及指定进程加速（不需要麻烦的IP规则）。功能上和SSTAP差不多，不过听说加速效果比后者要更好，甚至堪比一些付费的加速器，当然前提需要你的线路给力，不然加速就没意义了。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-1.jpg" alt></p>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>下载 Netch 客户端，解压后以管理员身份运行 Netch.exe。若系统提示需要安装 .NET Framework，请<a href="https://www.microsoft.com/net/download/dotnet-framework-runtime">点此</a>访问微软官网下载安装。</p>
<p><strong>Github地址：</strong><a href="https://github.com/netchx/Netch">https://github.com/netchx/Netch</a></p>
<p><strong>下载地址：</strong><a href="https://github.com/netchx/Netch/releases">https://github.com/netchx/Netch/releases</a></p>
<p>打开程序后，选中 “订阅” &gt; “管理订阅链接”</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-2.jpg" alt></p>
<p>粘贴服务商提供的订阅链接到左下角的链接，备注随便填写，点击添加，然后点击保存</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-3.jpg" alt></p>
<p>也可以从剪切板添加节点</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2019-06-24_10-48-31.png" alt></p>
<p>选择<code>Bypass LAN and China #绕过局域网和大陆</code>，点击启动，即可</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_12-45-58.jpg" alt></p>
<p>模式中也可以选择相应的游戏进行加速，也支持给Xshell和Xftp连接国外服务器进行加速</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-7.jpg" alt></p>
<p>如果需要加速的游戏不在列表里面，那么就选中 “模式” &gt; “创建进程模式”</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-4.jpg" alt></p>
<p>点击 “扫描” 选取你游戏安装目录后选择确定即可添加，它将自动加载其中的exe文件，点击保存即可选择应用此模式</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/windows-netch-6.jpg" alt>                            </p>
<p>若需开启热点，给其他设备也翻墙，则需要Tap虚拟网卡的支持，自行查看自己电脑是否装有</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_12-58-05.jpg" alt></p>
<p>若未安装则去<a href="https://build.openvpn.net/downloads/releases/tap-windows-9.21.2.exe">TAP-Windows</a>下载安装，Clash、OpenVPN等软件中也提供了安装</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_12-57-35.jpg" alt></p>
<p>确认Tap网卡ip为自动获取</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_13-21-22.jpg" alt></p>
<p>选择<code>Bypass LAN and China (TUN/TAP)</code>，点击启动</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_12-52-59.jpg" alt></p>
<p>启动热点，会发现在网络适配器中多出一个本地连接</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_13-26-48.jpg" alt></p>
<p>右键Tap网卡，属性—共享，选择Internet连接共享，添加热点所对应的本地连接</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/Snipaste_2020-02-16_13-28-32.jpg" alt></p>
<p>此时，热点即可成功翻墙</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/netch/TIM%E5%9B%BE%E7%89%8720200216133203.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>如何减少卷积层计算量，使用宽卷积的好处及转置卷积中的棋盘效应</title>
    <url>/2020/03/04/%E5%A6%82%E4%BD%95%E5%87%8F%E5%B0%91%E5%8D%B7%E7%A7%AF%E5%B1%82%E8%AE%A1%E7%AE%97%E9%87%8F%EF%BC%8C%E4%BD%BF%E7%94%A8%E5%AE%BD%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%A5%BD%E5%A4%84%E5%8F%8A%E8%BD%AC%E7%BD%AE%E5%8D%B7%E7%A7%AF%E4%B8%AD%E7%9A%84%E6%A3%8B%E7%9B%98%E6%95%88%E5%BA%94/</url>
    <content><![CDATA[<h2 id="如何减少卷积层计算量？"><a href="#如何减少卷积层计算量？" class="headerlink" title="如何减少卷积层计算量？"></a>如何减少卷积层计算量？</h2><p>减少卷积层的计算量主要有以下几种方法：</p>
<ul>
<li>使用池化操作。在卷积层前使用池化操作降低特征图分辨率。</li>
<li><p>使用堆叠的小卷积核代替大卷积核。VGG16中使用2个3 x 3卷积代替一个5 x 5卷积。</p>
</li>
<li><p>使用深度可分离卷积。将原始的$K \times K \times C$的卷积核分成$K \times K \times 1$和$1 \times 1 \times C$两部分操作。</p>
</li>
<li><p>应用1 x 1卷积。将1 x 1卷积（假设通道数为$C_2$）直接应用在某个卷积层（假设维度为$K \times K \times C_{1}$）之前</p>
</li>
</ul>
<h2 id="使用宽卷积的好处？"><a href="#使用宽卷积的好处？" class="headerlink" title="使用宽卷积的好处？"></a>使用宽卷积的好处？</h2><p>所谓宽卷积就是指在卷积操作时填充方式为<code>same</code>方式。而与之对应的窄卷积就是指在卷积操作时填充方式为<code>valid</code>方式。<code>same</code>方式的填充通常使用0填充的方式对卷积核不满足整除条件的输入特征图进行补全，使得卷积层的输出维度和输入维度一致。<code>valid</code>方式的填充就是不进行任何填充，在输入特征边缘位置若不足以进行卷积操作，则对边缘信息进行舍弃，因此在步长为1的情况下该填充方式的卷积层输出特征维度可能会略小于输入特征的维度。我们可以发现宽卷积(<code>same</code>填充方式卷积)的好处就是通过补0操作可以有效的保留原始输入特征图的边界特征信息。</p>
<h2 id="转置卷积和棋盘效应？"><a href="#转置卷积和棋盘效应？" class="headerlink" title="转置卷积和棋盘效应？"></a>转置卷积和棋盘效应？</h2><p>当我们在用反卷积（转置卷积）做图像生成或者上采样的时候或许我们会观察到我们生成的图片会出现一些奇怪的棋盘图案或者说你感觉到你生成的图片有颗粒感。棋盘格效应趋向于出现在<strong>图像中最显著的地方 (颜色最强烈)</strong>，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/643.webp" alt></p>
<p>这种现象之所以会发生是因为在上采样使用反卷积的时候，卷积核的大小不能被步长整除导致的。先看一下没有棋盘效应的情况：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/644.webp" alt></p>
<p>再看一下出现棋盘效应的情况：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/645.webp" alt></p>
<p>即它很容易遇到一种叫做 <strong>“uneven overlap”(不均匀重叠)</strong> 的现象。具体来说, 当kernel_size 无法被 stride整除时, 反卷积就会出现这种不均匀重叠的现象。原则上，神经网络可以通过仔细学习权值来避免这种情况，但在实践中，神经网络很难完全避免这种情况.</p>
<p>并且在二维图片上棋盘效应会更加严重。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/20190809192609235.png" alt></p>
<p>因此为了避免棋盘效应的发生，一般有一下几种解决方案：</p>
<ul>
<li><p>方法1：现在，神经网络在创建图像时通常使用多层反卷积，从一系列较低分辨率的描述中迭代地构建较大的图像。虽然这些堆叠的反卷积可能会消除棋盘效应，但它们通常会复合，从而在各种尺度上产生棋盘效应。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/646.png" alt></p>
</li>
<li><p>方法2：在反卷积后面，再接一个步长为1的卷积，效果有限。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/647.webp" alt></p>
</li>
<li><p>方法3：调整卷积核的权重，适当加大重叠部分少的权重，虽然理论有效，但在实际操作中，不仅有困难也会减弱模型的表达力。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/648.webp" alt></p>
</li>
<li><p>方法4：使得卷积核大小能被步长整除，但卷积核权重的学习不均匀也会导致棋盘效应现象（下图为步长为2，核大小为4所产生的棋盘效应现象）<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/649.webp" alt></p>
</li>
<li><p>方法5：调整图像大小（使用最近邻插值或双线性插值），然后执行卷积操作。这似乎是一种自然的方法，大致相似的方法在图像超分辨率方面表现良好。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/convolution/650.png" alt></p>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>假设反卷积生成的图像中，包含1只黑猫，黑猫身体部分的像素颜色应该是平滑过渡的。或者极端的说，身体部分应该全部都是黑色的。而在实际生成的图像中，该部分却是由深深浅浅的近黑方块组成的，很像棋盘的网络。这就是所谓的棋盘效应。之所以会出现棋盘效应是因为插入的值为0，使得卷积的input feature map本身就是棋盘状，所以得到的大分辨率feature map也会产生棋盘格。反卷积产生的棋盘格，在stride和卷积核size是整数倍的时候能够有所缓解，因为二者整除关系使得卷积核每次滑动能用到的非零像素的个数是一样的或者中间区域向两边逐渐减少(而不是随着滑动反复变化产生棋盘格形状)，但是依然不能完全消除。</p>
<p>从原始英文博客上的实验结论来看，使用上采样+卷积层的图像放大方法有效的改善了棋盘效应，即不是将小分辨率的feature map的像素之间插0，而是采用插值的方法，所以要是图像生成的时候遇到了棋盘效应你知道怎么做了吗？Upsamping+Convolution来帮你。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决出现 unable to resolve host 问题</title>
    <url>/2019/12/21/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%87%BA%E7%8E%B0unable-to-resolve-host%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>Ubuntu环境，有时候执行sudo 就出现这个警告讯息: </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo: unable to resolve host abc </span><br></pre></td></tr></table></figure>
<p>虽然sudo 还是可以正常执行, 但是看到这样的通知还是会觉得烦，怎么去除这个警告呢？</p>
<p>这个警告是因为系统找不到一个叫做abc的hostname </p>
<p>通过 修改 /etc/hosts 设定, 可以解决<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nano /etc/hostname</span><br></pre></td></tr></table></figure></p>
<p>在127.0.0.1 localhost 后面加上主机名称(hostname) 即可:<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1 localhost abc</span><br></pre></td></tr></table></figure><br>问题解决！</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>图像分类算法优化技巧</title>
    <url>/2020/04/08/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这篇论文的全名是：<strong>Bag of Tricks for Image Classification with Convolutional Neural Networks</strong>。这篇论文是亚马逊团队对CNN网络调优的经验总结，实验基本是在分类网络实验上做的。目前，论文的复现结果都可以在GluonCV找到，地址为：<a href="https://github.com/dmlc/gluon-cv。">https://github.com/dmlc/gluon-cv。</a></p>
<h2 id="成果"><a href="#成果" class="headerlink" title="成果"></a>成果</h2><p>下面的Table1展示了本文的一系列Tricks被用在ResNet50网络做分类任务上获得的结果。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/640.png" alt></p>
<p>可以看到使用本文的技巧，Top1准确率从75.3%提升到了79.29%。所以这一系列技巧还是非常给力的，接下来我们就一起来探索探索。</p>
<h2 id="BaseLine"><a href="#BaseLine" class="headerlink" title="BaseLine"></a>BaseLine</h2><p>既然涉及到调参，那么第一步就得有一个BaseLine的结果作为参考，这一BaseLine并非直接截取之前对应的论文的结果，而是作者基于GluonCV复现的。关于复现的细节作者在论文2.1节中说的很清楚，包括数据预处理的方式和顺序，网络层的初始化方法，迭代次数，学习率变化策略等等。</p>
<p>下面的Table2展示了作者复现的ResNet-50，Inception-V3，MobileNet三个BaseLine。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/641.jpg" alt></p>
<h2 id="训练调参经验"><a href="#训练调参经验" class="headerlink" title="训练调参经验"></a>训练调参经验</h2><p>介绍完BaseLine，接下来就来看看作者的优化方法。论文从加快模型训练，网络结构优化以及训练参数调优三个部分分别介绍如何提升模型的效果。</p>
<h3 id="模型训练加速"><a href="#模型训练加速" class="headerlink" title="模型训练加速"></a>模型训练加速</h3><p>关于模型训练加速，论文提到了2点，一是<strong>使用更大的Batch Size</strong>，二是<strong>使用低精度(如FP16)进行训练</strong>（也是我们常说的混合精度训练）。关于使用更大的Batch Size进行训练加速，作者指出一般只增加Batch Size的话，效果不会太理想，例如FaceBook这篇大名鼎鼎的论文有证明：</p>
<p><strong>Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</strong></p>
<p>然后本文总结了几个重要要的调参方案，如下：</p>
<ul>
<li><strong>增大学习率</strong>。因为更大的Batch Size意味着每个Batch数据计算得到的梯度更加贴近整个数据集，从数学上来说就是方差更小，因此当更新方向更加准确之后，迈的步子也可以更大，一般来说Batch Size变成原始几倍，学习率就增加几倍。</li>
<li><p><strong>Warm up</strong>。Warm  up指的是用一个小的学习率先训练几个epoch，这是因为网络的参数是随机初始化的，假如一开始就采用较大的学习率容易出现数值不稳定，这也是为什么要使用Warm up。然后等到训练过程基本上稳定了就可以使用原始的初始学习率进行训练了。作者在使用Warm  up的过程中使用线性增加的策略。举个例子假如Warm  up阶段的初始学习率是0，warmup阶段共需要训练m个batch的数据（论文实现中m个batch共5个epoch），假设训练阶段的初始学习率是L，那么在第i个batch的学习率就设置为$i \times L / m$。</p>
</li>
<li><p><strong>每一个残差块后的最后一个BN层的$\gamma$参数初始化为0</strong>。我们知道BN层的$\gamma$，$\beta$参数是用来对标准化后的数据做线性变换的，公式表示为：$y=\gamma x+\beta$，其中我们一般会把$\gamma$设为1，而这篇论文提出初始化为0则更容易训练。</p>
</li>
<li><p><strong>不对Bias参数做权重惩罚</strong>。但是对权重还是要做的。。</p>
</li>
</ul>
<p>接下来作者提到了使用低精度(16-Bit浮点型)来做训练加速，也即是我们常说的混合精度训练。但不是所有的NVIDIA GPU都支持FP16，我大概只知道V100和2080 Ti是支持混合精度训练的。</p>
<p>作者将上面的Tricks结合在一起进行训练，<strong>下面的Table3展示了使用更大的Batch Size和16位浮点型进行训练的结果，可以看到这俩Tricks相比于BaseLine训练速度提升了许多，并且精度也更好了。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/642.png" alt></p>
<p>而下面的Table4则进一步展示了这些Tricks的消融实验，证明确实是有效的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/643.png" alt></p>
<h3 id="网络结构调优"><a href="#网络结构调优" class="headerlink" title="网络结构调优"></a>网络结构调优</h3><p>这一小节以ResNet-50为例子展开，下面的Figure1表示ResNet网络的原始结构图，简单来说就是一个输入流加4个stage和一个输出流。其中输入流和每个stage的详细结构在Figure1中间那一列显示，而残差结构则在Figure1中最右边进行显示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/644.png" alt></p>
<p>论文在网络结构部分进行改进获得的3种结构如<code>Figure2(a)，(b)，(c)</code>所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/645.jpg" alt></p>
<ul>
<li><p><strong>ResNet-B</strong>。ResNet-B改进的地方就是将4个Stage中做下采样的残差模块的下采样操作从第一个卷积层换到第三个卷积层，如果下采样操作放在的卷积层，那么会丢失比较多的特征信息(通道缩减默认是$\frac{1}{4}$，所以会丢失$\frac{3}{4}$)，而将下采样操作放在第3个卷积层则可以减少这种损失，因为即便stride=2，但是卷积核尺寸更大，保留有效信息更多。</p>
</li>
<li><p><strong>ResNet-C</strong>。ResNet-C改进的地方是将Figure1中的输入流部分的7 x 7卷积用两个3 x 3卷积来替换，这部分借鉴了Inception V2的思想，主要是为了减少运算量。但很遗憾，从后面的Table5可以看出3个3 x 3卷积的FLOPS比原始的7 x 7 + 5 x 5卷积的FLOPS还多。。</p>
</li>
<li><p><strong>ResNet-D</strong>。ResNet-D改进的地方是将Stage部分做下采样的残差模块的支路从stride=2的1 x 1卷积层换成stride=1的卷积层，并在前面添加一个p平均池化层来做下采样。个人猜测这可以减少信息损失？</p>
</li>
</ul>
<p>最终关于这些改进的网络结构的效果如Table5所示，可以看到效果提升还是有的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/646.png" alt></p>
<h3 id="模型训练调参"><a href="#模型训练调参" class="headerlink" title="模型训练调参"></a>模型训练调参</h3><p>这部分作者提到了4个调参技巧：</p>
<ul>
<li><p><strong>学习率衰减策略采用cosine函数</strong>。这部分的实验结果可以看Figure3，其中Figure3(a)表示<strong>cosine decay</strong>和<strong>step decay</strong>的示意图，而cosine衰减的公式为：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/647.png" alt><br>而Figure3(b)则表示2种学习率衰减策略在效果上的对比。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/648.png" alt></p>
</li>
<li><p><strong>使用标签平滑(label smooth)</strong>。这部分是把原始的one-hot类型标签做软化，这样可以在计算损失时一定程度的减小过拟合。从交叉熵损失函数可以看出，只有真实标签对应的类别概率才会对损失值计算有所帮助，因此标签平滑相当于减少真实标签的类别概率在计算损失值时的权重，同时增加其他类别的预测概率在最终损失函数中的权重。<strong>这样真实类别概率和其他类别的概率均值之间的gap（倍数）就会下降一些</strong>，Lable Smooth实际的公式如下：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/649.png" alt><br>代码实现可以简单表示为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">new_labels = (<span class="number">1.0</span> - label_smoothing) * one_hot_labels +  label_smoothing / num_classes</span><br></pre></td></tr></table></figure>
<p>完整的Pytorch代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    NLL loss with label smoothing.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, smoothing=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Constructor for the LabelSmoothing module.</span></span><br><span class="line"><span class="string">        :param smoothing: label smoothing factor</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(LabelSmoothing, self).__init__()</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, target</span>):</span></span><br><span class="line">        logprobs = torch.nn.functional.log_softmax(x, dim=-<span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">        nll_loss = -logprobs.gather(dim=-<span class="number">1</span>, index=target.unsqueeze(<span class="number">1</span>))</span><br><span class="line">        nll_loss = nll_loss.squeeze(<span class="number">1</span>)</span><br><span class="line">        smooth_loss = -logprobs.mean(dim=-<span class="number">1</span>)</span><br><span class="line">        loss = self.confidence * nll_loss + self.smoothing * smooth_loss</span><br><span class="line">        <span class="keyword">return</span> loss.mean()</span><br></pre></td></tr></table></figure>
<p>具体细节和公式可以再阅读原文，这里展示一下Lable Smooth的效果。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/650.png" alt><br>总结就一句话，one-hot编码会自驱的向正类和负类的差值扩大的方向学习(过度的信任标签为1的为正类)，在训练数据不足的情况容易过拟合，所以使用Label Smooth来软化一下，使得没那么容易过拟合。</p>
</li>
<li><p><strong>知识蒸馏(knowledge distillation)</strong>。知识蒸馏时模型压缩领域的一个重要分支，即采用一个效果更好的<strong>teacher model</strong>训练<strong>student model</strong>，使得<strong>student model</strong>在模型结构不改变的情况下提升效果。这篇论文使用ResNet-152作为<strong>teacher model</strong>，用ResNet-50作<strong>student model</strong>。代码实现细节上，通过在ResNet网络后添加一个蒸馏损失函数实现，这个损失函数用来评价<strong>teacher model</strong>输出和<strong>student model</strong>输出的差异，因此整体的损失函数原损失函数和蒸馏损失函数的结合，如公式(6)所示：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/651.png" alt><br>注意，p代表真实概率，z和r表示studnet model和techer model的最后一个全连接层的输出，T是超参数，用来平滑softmax函数的输出。</p>
</li>
<li><p><strong>Mixup</strong>。论文还引入了Mixup这种数据增强方式，如果使用了Mixup数据增强来进行训练，那么每次需要读取2张输入图像，这里用$\left(x_{i}, y_{i}\right)$,$\left(x_{j}, y_{j}\right)$来表示，那么通过下面的公式就可以合成获得一张新的图像和标签$(\hat{x}, \hat{y})$，然后使用这张新图像和新标签进行训练，需要注意的是采用这种方式训练模型时要训更多<code>epoch</code>。式子中的$\lambda$是一个超参数，用来调节合成的比重，取值范围是[0,1]。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/652.png" alt><br>最终，在使用了这4个Tricks后的消融实验结果如Table6所示。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/653.jpg" alt></p>
</li>
</ul>
<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>当把上面的Tricks迁移到目标检测和语义分割任务同样是有效的，实验结果如Table8和Table9所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/image_optimize/654.webp" alt></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>总的来说，这篇论文给了我们非常多的炼丹技巧，我们可以将这些技巧放迁移到我们自己的数据集上获得效果提升，是非常实用的一篇论文了。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>最简单最易实现的SE模块</title>
    <url>/2020/02/19/%E6%9C%80%E7%AE%80%E5%8D%95%E6%9C%80%E6%98%93%E5%AE%9E%E7%8E%B0%E7%9A%84SE%E6%A8%A1%E5%9D%97/</url>
    <content><![CDATA[<h2 id="Squeeze-and-Excitation-Networks"><a href="#Squeeze-and-Excitation-Networks" class="headerlink" title="Squeeze-and-Excitation Networks"></a>Squeeze-and-Excitation Networks</h2><p>SENet是Squeeze-and-Excitation  Networks的简称，拿到了ImageNet2017分类比赛冠军，其效果得到了认可，其提出的SE模块思想简单，易于实现，并且很容易可以加载到现有的网络模型框架中。SENet主要是学习了channel之间的相关性，筛选出了针对通道的注意力，稍微增加了一点计算量，但是效果比较好。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/se/640.webp" alt></p>
<p>通过上图可以理解他的实现过程，通过对卷积的到的feature  map进行处理，得到一个和通道数一样的一维向量作为每个通道的评价分数，然后将修改的分数分别施加到对应的通道上，得到其结果，就在原有的基础上只添加了一个模块，下边我们用pytorch实现这个很简单的模块。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/se/641.webp" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SELayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, channel, reduction=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SELayer, self).__init__()</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="number">1</span>)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel, channel // reduction, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Linear(channel // reduction, channel, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.Sigmoid()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        y = self.avg_pool(x).view(b, c)</span><br><span class="line">        y = self.fc(y).view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x * y.expand_as(x)</span><br></pre></td></tr></table></figure>
<p>虽然核心就是以上的内容，不过不能简单地结束，我们需要看一下以下几个点：</p>
<ul>
<li><p>作为一个重要的attention机制的文章，这篇文章如何描述attention，related work如何组织？</p>
<p>attention机制当时已经有一定的研究和发展，也是集中于序列学习，image captioning, understanding in  images这些工作，也已经有很多出色的工作是探索了attention机制。senet这篇文章主要探索了通过对通道间关系进行建模来提升模型的表达能力。related work 主要从更深的网络架构，架构搜索，注意力机制三个角度进行了梳理，确实非常全面。</p>
</li>
<li><p>如何解释SE模块？</p>
<p><strong>Sequeeze</strong>：对$C \times H \times W$进行global average pooling，得到 $1 \times 1 \times C$大小的特征图，这个特征图可以理解为具有全局感受野。</p>
<p><strong>Excitation</strong>：使用一个全连接神经网络，对Sequeeze之后的结果做一个非线性变换。</p>
<p><strong>特征重标定</strong>：使用Excitation 得到的结果作为权重，乘到输入特征上。</p>
</li>
<li><p>SE模块如何加到分类网络，效果如何？</p>
<p>分类网络现在一般都是成一个block一个block，se模块就可以加到一个block结束的位置，进行一个信息refine。这里用了一些STOA的分类模型如：resnet50，resnext50，bn-inception等网络。通过添加SE模块，能使模型提升0.5-1.5%,效果还可以，增加的计算量也可以忽略不计。在轻量级网络MobileNet，ShuffleNet上也进行了实验，可以提升的点更多一点大概在1.5-2%。</p>
</li>
<li><p>SE模块如何加到目标检测网络，效果如何？</p>
<p>主要还是将SE模块添加到backbone部分，优化学习到的内容。目标检测数据集使用的是benchmark MSCOCO, 使用的Faster  R-CNN作为目标检测器，使用backbone从ResNet50替换为SE-ResNet50以后带了了两个点的AP提升，确实有效果。</p>
</li>
<li><p>这篇文章的实验部分是如何设置的？</p>
<p>这篇文章中也进行了消融实验，来证明SE模块的有效性，也说明了设置reduction=16的原因。</p>
<ul>
<li>squeeze方式：仅仅比较了max和avg，发现avg要好一点。</li>
<li>excitation方式：使用了ReLU，Tanh，Sigmoid，发现Sigmoid好。</li>
<li>stage: resnet50有不同的阶段，通过实验发现，将se施加到所有的阶段效果最好。</li>
<li>集成策略：将se放在残差单元的前部，后部还是平行于残差单元，最终发现，放到前部比较好。</li>
</ul>
</li>
<li><p>如何查看每个通道学到的attention信息并证明其有效性？</p>
<p>作者选取了ImageNet中的四个类别进行了一个实验，测试backbone最后一个SE层的内容，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/se/642.webp" alt></p>
<p>可以看出这两个类激活出来的内容有一定的差距，起到了一定的作用。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>Attention机制</tag>
      </tags>
  </entry>
  <entry>
    <title>如何配置SwitchyOmega插件</title>
    <url>/2020/02/16/%E5%A6%82%E4%BD%95%E9%85%8D%E7%BD%AESwitchyOmega%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>SwitchyOmega是 Chrome 和 Firefox 浏览器上的代理扩展程序,可以轻松快捷的管理和切换多个代理设置。接管浏览器代理方式，可瞬间切换代理和本地连接方式，配合socks5（等其他代理工具）可实现只代理部分国内无法访问的网站。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>进入插件选项界面</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_13-39-31.jpg" alt></p>
<p>选择新建情景模式—代理服务器，名称自取</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_13-41-23.jpg" alt></p>
<p>找到软件所提供的Socks端口号，这里以clash为例</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-51-02.jpg" alt></p>
<p>SSR、Netch等同理</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-52-44.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-53-32.jpg" alt></p>
<p>按以下格式配置：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-49-43.jpg" alt></p>
<p>接着新建情景模式—自动切换模式，名字自取</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-55-29.jpg" alt></p>
<p>规则列表格式为：AutoProxy</p>
<p>规则列表网址为：<code>https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt</code></p>
<p>然后点击立即更新情景模式，则会自动加载PAC列表</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_14-57-22.jpg" alt></p>
<p>切换规则按如下配置：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_15-01-34.jpg" alt></p>
<p>意思是，选择auto模式时，插件为根据PAC规则判断是否要走代理</p>
<p>现在软件在后台启动着，不需要开启代理，都可以通过浏览器的此插件进行切换，PAC模式选auto，全局选代理服务器，不代理选直连</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/switchyomega/Snipaste_2020-02-16_15-06-10.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>江南大学学位论文LaTeX模板</title>
    <url>/2021/12/06/%E6%B1%9F%E5%8D%97%E5%A4%A7%E5%AD%A6%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87Latex%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[<blockquote>
<p>本文由🐧从<a href="https://gitee.com/zhuangbo/jnthesis">zhuangbo</a>转载</p>
</blockquote>
<h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p>江南大学博士、硕士学位（毕业）论文 LaTeX 模板。<a href="https://pan.baidu.com/s/1Ps7f2OFsJX80w1wuZ57PnQ">点此下载</a>(提取码: 8ub7)</p>
<p>文档类 <code>jnthesis.cls</code> 基于 <code>ctex</code> 宏包定义了论文格式，包括字体，字号，行距，标题，页眉，页脚，目录，摘要，正文等各种格式。</p>
<p>文件 <code>jn.bst</code> 定义了参考文献格式。</p>
<p>推荐使用 TeXlive 发行版，不推荐使用 CTEX 发行版。</p>
<p>为便于编辑，通常将长文档分成若干文件。本论文模板还提供了以下文件：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>文件</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>root.tex</code></td>
<td>主文档，整个文档结构，用 XeLaTeX 编译此文档</td>
</tr>
<tr>
<td><code>main.tex</code></td>
<td>主要内容，包含主要章节内容</td>
</tr>
<tr>
<td><code>cover.doc</code></td>
<td>封面，DOC 文件，修改编辑后另存为 PDF</td>
</tr>
<tr>
<td><code>cover.pdf</code></td>
<td>封面，PDF 文件，插入文档</td>
</tr>
<tr>
<td><code>statement.doc</code></td>
<td>声明和授权，DOC 文件，修改编辑后另存为 PDF</td>
</tr>
<tr>
<td><code>statement.pdf</code></td>
<td>声明和授权，PDF 文件，插入文档</td>
</tr>
<tr>
<td><code>setup/settings.tex</code></td>
<td>用户设置，如：标题，作者，其他宏包和样式等</td>
</tr>
<tr>
<td><code>setup/userdefs.tex</code></td>
<td>用户自定义符号</td>
</tr>
<tr>
<td><code>preface/e_abstract.tex</code></td>
<td>英文摘要和英文关键词</td>
</tr>
<tr>
<td><code>preface/c_abstract.tex</code></td>
<td>中文摘要和中文关键词</td>
</tr>
<tr>
<td><code>body/*.tex</code></td>
<td>各章节内容，不需要时在 main.tex 中删除</td>
</tr>
<tr>
<td><code>appendix/acknowledgements.tex</code></td>
<td>致谢</td>
</tr>
<tr>
<td><code>appendix/publications.tex</code></td>
<td>发表论文</td>
</tr>
<tr>
<td><code>references.bib</code></td>
<td>参考文献数据库</td>
</tr>
<tr>
<td><code>figures/...</code></td>
<td>插图</td>
</tr>
</tbody>
</table>
</div>
<p>具体用法如下：</p>
<ol>
<li><p>打开 <code>root.tex</code> 文件，设置文档参数以指定博士 (<code>doctor</code>)，硕士 (<code>master</code>) 或毕业(<code>nodegree</code>) 论文。</p>
</li>
<li><p>打开 <code>main.tex</code> 文件，规划论文主要章节。不需要的章节可以删除或注释掉。</p>
</li>
<li><p>修改 <code>cover.doc</code> 文件生成封面 <code>cover.pdf</code>。</p>
</li>
<li><p>修改 (如有必要) statement.doc<code>生成</code>statement.pdf`。</p>
</li>
<li><p>修改 <code>setup/settings.tex</code> 设置标题，作者，包含其他宏包等其他设置。</p>
</li>
<li><p>修改 (如有必要) <code>setup/userdefs.tex</code> 添加用户自定义符号或命令。</p>
</li>
<li><p>修改 <code>preface/e_abstract.tex</code> 添加英文摘要和英文关键词。</p>
</li>
<li><p>修改 <code>preface/c_abstract.tex</code> 添加中文摘要和中文关键词。</p>
</li>
<li><p>修改 <code>body/ch01.tex</code> 等，撰写各章内容。</p>
</li>
<li><p>修改 <code>appendix/acknowledgements.tex</code> 添加致谢内容。</p>
</li>
<li><p>修改 <code>appendix/publications.tex</code> 添加发表论文。</p>
</li>
<li><p>修改任何内容后，用 XeLaTeX 编译 <code>root.tex</code> 文件得到最终论文 <code>root.pdf</code>。若参考文献不正确，首先执行 BibTeX，再多次 (三次以上) 执行 XeLaTeX，直到得到正确的参考文献.</p>
</li>
</ol>
<p>一次完整的编译过程为 XeLaTeX &gt; BibTeX &gt; XeLaTeX &gt; XeLaTeX &gt; XeLaTeX。 通常在引用参考文献没有发生变化时，仅需要执行一次 XeLaTeX。 由于已经把整个文档划分成多个文件，加快了编译速度。 当 bib 文献数据库或文献引用发生变化时，为确保最终内容正确，可以执行一遍完整的编译过程。</p>
<p>本模板采用 MIT 协议授权，如有不完善之处请自行修改代码。</p>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title>梅林固件安装Clash</title>
    <url>/2022/01/17/%E6%A2%85%E6%9E%97%E5%9B%BA%E4%BB%B6%E5%AE%89%E8%A3%85Clash/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Merlin Clash是一款运行在<a href="https://www.koolcenter.com">KoolCenter</a>软件中心(Arm版)上的Clash GUI插件。获取插件需加入Telegram群组-<a href="https://t.me/merlinclashcat">merlinclashcat</a>，相信能看懂这篇的，都有翻墙技能，这里不再叙述。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>路由器需要能支持刷固件，固件需要带软件中心，比如梅林固件。一般华硕、网件的路由器固件种类多，比较好刷。若是华硕路由器刷梅林固件可查看我之前写的-<a href="https://qiyuan-z.github.io/2020/02/03/华硕路由器刷固件/">华硕路由器刷固件</a>。其他型号的请自行查找是否有人对其开发相应的固件供刷机。</p>
<h2 id="插件下载"><a href="#插件下载" class="headerlink" title="插件下载"></a>插件下载</h2><p>进入群组下载对应版本：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117102613765.png" alt></p>
<p>比如我的路由器是AC86U就下载ARM v8 HND版本，若是不知道自己该下哪个版本，群组里也提供了辅助工具：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117102934363.png" alt></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>打开[软件中心]-[离线安装]，上传下载好的merlinclash的<code>tar</code>包并安装。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117103235782.png" alt></p>
<p>要是提示含非法关键词，安装失败的，可查看之前写的-<a href="https://qiyuan-z.github.io/2022/01/16/解决梅林新版软件中心禁止安装含非法关键词的插件/">解决梅林新版软件中心禁止安装含非法关键词的插件</a>。</p>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>详细的使用和更多的技巧可参考<a href="https://mcreadme.gitbook.io/mc/">官方WiKi</a>。</p>
<p>我这里讲下主要的配置。</p>
<h3 id="订阅"><a href="#订阅" class="headerlink" title="订阅"></a>订阅</h3><p>插件支持<code>SS</code>|<code>SSR</code>|<code>V2ray</code>|<code>Trojan</code>|<code>Clash</code>订阅链接及<code>ss://xxx</code>|<code>ssr://xxxx</code>|<code>vemss://xxx</code>|<code>trojan://xxx</code>分享链接。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117104109292.png" alt></p>
<ul>
<li>小白一键订阅助手：推荐使用，填入代理商提供的订阅链接，设置好配置名称即可，支持多订阅合并成一个配置，使用<code>|</code>分开即可，格式：<code>订阅链接1|订阅链接2</code> 。</li>
<li>SubConverter本地转换：高级订阅方式，在小白一键订阅助手的基础上增加了一些自定义项。</li>
<li>Clash-Yaml配置下载：填入代理商提供的Clash专用订阅链接，但机场默认Clash规则普遍不适用于路由器（废流量/国内网站打不开等），不建议新手使用此种订阅方式。</li>
</ul>
<p>填好订阅链接，设置好配置名称后，点击开始转换，即可完成订阅。当然也提供<code>导入Clash配置文件</code>(直接导入*.yaml文件)、<code>导入【科学上网】节点</code>(从路由器SS插件导入节点，生成Clash配置文件)，不过一般不建议，可能会有奇怪的问题。</p>
<p>订阅完成后，可按需要设置定时订阅等，这里就不再叙述了。</p>
<h3 id="附加功能"><a href="#附加功能" class="headerlink" title="附加功能"></a>附加功能</h3><p>附加功能中建议打开[自定规则]，其他按你需要自行开启：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117105252711.png" alt></p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>完成配置后，打开开关，保存并启动后即可开启：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117105444296.png" alt></p>
<p>图中，红框处显示绿色，则正常。</p>
<h3 id="管理面板"><a href="#管理面板" class="headerlink" title="管理面板"></a>管理面板</h3><p>插件提供两种网页端的管理面板：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117105626420.png" alt></p>
<p>可在网页端输入ip地址访问，默认密码<code>clash</code>，也可直接点击按钮进入，此时免密。</p>
<h3 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h3><p>进入管理面板，可查看默认代理模式为总模式，有相应选项进行选择：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117105931807.png" alt></p>
<p>可设置按<code>延迟最低</code>自动切换、按<code>负载均衡</code>自动切换、<code>故障</code>时自动切换、<code>手动</code>选择以及<code>直连</code>，一般推荐使用按<code>延迟最低</code>自动切换。</p>
<h3 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h3><p>默认按配置文件设定的规则进行代理，即规则中出现的网站走代理，大陆不走代理。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117110304371.png" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117110353903.png" alt></p>
<p>因此，如果有些网站规则里没有，但你想让它走代理，可在[自定规则]中设置。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/26.jpg" alt></p>
<p>简单说明一些两个较为常用的：</p>
<ul>
<li>DOMAIN-SUFFIX：目的域名后缀， 设定浏览器等访问包含相关的域名后缀如何走规则。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>DOMAIN-SUFFIX</th>
<th>包含</th>
</tr>
</thead>
<tbody>
<tr>
<td>abc.com</td>
<td><code>abc.com</code> <code>abc.com/*</code> <code>*.abc.com</code> <code>*.abc.com/*</code></td>
</tr>
<tr>
<td>123.abc.com</td>
<td><code>123.abc.com</code> <code>123.abc.com/*</code> <code>*.123.abc.com</code> <code>*.123.abc.com/*</code></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>DOMAIN：目的域名，设定浏览器等访问的域名如何走规则。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>DOMAIN</th>
<th>包含</th>
</tr>
</thead>
<tbody>
<tr>
<td>abc.com</td>
<td><code>abc.com</code> <code>abc.com/*</code></td>
</tr>
<tr>
<td>123.abc.com</td>
<td><code>123.abc.com</code> <code>123.abc.com/*</code></td>
</tr>
</tbody>
</table>
</div>
<p>剩下的请自行查看<a href="https://mcreadme.gitbook.io/mc/Advanced/Custom">自定义规则 - MerlinClash Wiki (gitbook.io)</a>。</p>
<h3 id="代理端口"><a href="#代理端口" class="headerlink" title="代理端口"></a>代理端口</h3><p>可在管理面板查看：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117114252109.png" alt></p>
<p>因此，如果浏览器有使用SwitchyOmega插件(具体使用可参照之前写的-<a href="https://qiyuan-z.github.io/2020/02/16/如何配置SwitchyOmega插件/">如何配置SwitchyOmega插件</a>)，需按照图中设定的端口设置：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117114450798.png" alt></p>
<p>同理，若需要下载些国外资源，下载器的代理服务器设置，也需与设定的端口对应：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/image-20220117114733242.png" alt></p>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p>起飞🚀：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/Snipaste_2022-01-17_11-54-57.jpg" alt></p>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
      <tags>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title>对目录/var/lib/apt/lists/加锁问题解决方法</title>
    <url>/2020/01/19/%E5%AF%B9%E7%9B%AE%E5%BD%95varlibaptlists%E5%8A%A0%E9%94%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo rm /var/lib/apt/lists/lock</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>盘点不同类型的池化层、1x1卷积的作用和卷积核是否一定越大越好？</title>
    <url>/2020/03/03/%E7%9B%98%E7%82%B9%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%B1%A0%E5%8C%96%E5%B1%82%E3%80%811x1%E5%8D%B7%E7%A7%AF%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%8D%B7%E7%A7%AF%E6%A0%B8%E6%98%AF%E5%90%A6%E4%B8%80%E5%AE%9A%E8%B6%8A%E5%A4%A7%E8%B6%8A%E5%A5%BD%EF%BC%9F/</url>
    <content><![CDATA[<h2 id="池化层的不同类型"><a href="#池化层的不同类型" class="headerlink" title="池化层的不同类型"></a>池化层的不同类型</h2><p>池化通常也被称为下采样(Downsampling)，一般是用在卷积层之后，通过池化来降低卷积层输出特征图的维度，有效减少网络参数的同时还可以防止过拟合现象。池化层实际上真正起作用的地方在于他的非线性映射能力和可以保持一定量的平移不变性的能力。这个能力是因为在一个图像区域有用的特征很有可能在另一个区域同样有用。因此，为了描述一个大分辨率的图像特征，一个直观的方法就是对大分辨率图像中的不同位置的特征进行聚合统计。具体来说，常见池化的方法有以下几种：</p>
<ul>
<li>标准池化</li>
<li>重叠池化</li>
<li>空间金字塔池化</li>
</ul>
<p>接下来我们就仔细介绍一下每种池化。</p>
<h2 id="标准池化"><a href="#标准池化" class="headerlink" title="标准池化"></a>标准池化</h2><p>通常包括最大池化(MaxPooling)和平均池化(AveragePooling)。以最大池化为例，池化核尺寸为2 x 2，池化步长为2，可以看到特征图中的每一个像素点只会参与一次特征提取工作。这个过程可以用下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pooling/640.webp" alt></p>
<h2 id="重叠池化"><a href="#重叠池化" class="headerlink" title="重叠池化"></a>重叠池化</h2><p>操作和标准池化相同，但唯一不同地方在于滑动步长stride小于池化核的尺寸k，可以想象到这样的话特征图中的某些区域会参与到多次特征提取工作，最后得到的特征表达能力更强。这个过程可以表示为下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pooling/641.webp" alt></p>
<h2 id="空间金字塔池化"><a href="#空间金字塔池化" class="headerlink" title="空间金字塔池化"></a>空间金字塔池化</h2><p>这种池化是在进行多尺度训练的时候，第一次看到这种操作的时候是读目标检测算法之Fast RCNN算法的时候。对不同输出尺度采用不同的滑窗大小和步长以确保输出尺度相同($w i n_{s i z e}=\left\lceil\frac{i n}{o u t}\right\rceil$;$stride =\left\lfloor\frac{i n}{o u t}\right\rfloor$)，同时用如金字塔式叠加的多种池化尺度组合，以提取更加丰富的图像特征。常用于多尺度训练和目标检测中的区域提议网络(Region Proposal Network)的兴趣区域(Region of Interest)提取。空间金字塔池化可以用下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pooling/642.gif" alt></p>
<h2 id="1-1卷积的作用"><a href="#1-1卷积的作用" class="headerlink" title="1*1卷积的作用"></a>1*1卷积的作用</h2><p>我最开始接触到1 x 1卷积应该是在阅读经典论文GoogleNet的时候，当然我说的是我第一次接触，并不代表GoogleNet(包含了InceptionV1-V4)是第一个使用卷积的。在InceptionV1网络中，Inception模块长下面这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pooling/643.webp" alt></p>
<p>可以看到这个Inception模块中，由于每一层网络采用了更多的卷积核，大大增加了模型的参数量。这时候为了减少模型参数量，在每一个较大卷积核的卷积层前引入1 x 1卷积，将宽高和通道方向的卷积进行了分离。修改后的Inception模块表示为下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pooling/644.webp" alt></p>
<p>这样就实现了在不影响模型的特征表达能力条件下大大减少了模型的参数量。我们定量计算一下上下两个Inception模块的参数量，假设输入$C_1$输出$C_2$通道数都是16，则原始的Inception模块的参数量是：$(1 \times 1+3 \times 3+5 \times 5+0) \times C_{1} \times C_{2}=8960$，而使用了1 x 1卷积的Inception模块的参数量为：$\left(1 \times 1 \times\left(3 C_{1}+C_{2}\right)+3 \times 3 \times C_{2}+5 \times 5 \times C_{2}\right) \times C_{1}=5248$，可以看到计算量减少了接近一半。</p>
<p>因此，1 x 1卷积的作用可以总结为可以实现信息的通道整合和交互，以及具有升维/降维的能力。</p>
<h2 id="卷积核是否越大越好？"><a href="#卷积核是否越大越好？" class="headerlink" title="卷积核是否越大越好？"></a>卷积核是否越大越好？</h2><p>这是本文的最后一个问题，显然这个问题我们肯定会回答否。但你是否真的认真思考过其中的原因？在早期的一些经典网络中如Lenet-5和AlexNet，用到了一些大的卷积核例如11 x 11，5 x 5，受限于当时的计算资源，无法将网络堆叠得很深，因此需要将卷积核设得比较大以获得更大的感受野。但这种大卷积核导致计算量大幅增加，训练过程缓慢，更不利于训练深层模型。后来VGGNet，GoogleNet时代发现通过堆叠2个3 x 3卷积核可以获得和5 x 5卷积核相同的感受野，同时参数量也会减少，如$2 \times 3 \times 3&lt;5 \times 5$。因此，3 x 3卷积核被广泛应用在许多卷积神经网络中。所以基本可以认为在大多数情况下通过堆叠较小的卷积核比直接采用单个更大的卷积核更加有效并且能获得计算资源节约。因此我们可以认为，CV领域小卷积核堆叠是好于大卷积核的。</p>
<p>那么是不是其他领域也是这样呢？并不是。在NLP领域，由于文本内容不像图像数据一样可以对特征进行很深层的抽象，因此该领域的特征提取网络都是比较浅的。这个时候为了获得较大的感受野，就需要使用大的卷积核。因此，我们可以认为在NLP领域大卷积是好于小卷积核的。</p>
<p>总结一下，卷积核是否越大越好呢？这个要具体问题具体分析，在不同的领域大卷积核和小卷积核分别能取得不错的效果。并且在设置卷积核的时候一个常识是不能设得过大也不能过小，1 x 1卷积只适合做分离卷积任务而不能对输入的原始特征做有效的特征抽取，而极大的卷积核通常会组合过多无用的特征浪费大量的计算资源。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习中的batch大小对学习效果的影响</title>
    <url>/2020/03/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84batch%E5%A4%A7%E5%B0%8F%E5%AF%B9%E5%AD%A6%E4%B9%A0%E6%95%88%E6%9E%9C%E6%9C%89%E4%BD%95%E5%BD%B1%E5%93%8D%EF%BC%9F/</url>
    <content><![CDATA[<h2 id="谈谈深度学习中的Batch-Size"><a href="#谈谈深度学习中的Batch-Size" class="headerlink" title="谈谈深度学习中的Batch_Size"></a>谈谈深度学习中的Batch_Size</h2><p>Batch_Size（批尺寸）是机器学习中一个重要参数，涉及诸多矛盾，下面逐一展开。</p>
<h2 id="首先，为什么需要有-Batch-Size-这个参数？"><a href="#首先，为什么需要有-Batch-Size-这个参数？" class="headerlink" title="首先，为什么需要有 Batch_Size 这个参数？"></a>首先，为什么需要有 Batch_Size 这个参数？</h2><p>Batch 的选择，<strong>首先决定的是下降的方向</strong>。如果数据集比较小，完全可以采用<strong>全数据集 （ Full Batch Learning ）</strong>的形式，这样做至少有 2 个好处：其一，由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。其二，由于不同权重的梯度值差别巨大，因此选取一个全局的学习率很困难。 Full Batch Learning 可以使用 <strong>Rprop</strong> 只基于梯度符号并且针对性单独更新各权值。</p>
<p>对于更大的数据集，以上 2 个好处又变成了 2 个坏处：其一，随着数据集的海量增长和内存限制，一次性载入所有的数据进来变得越来越不可行。其二，以 Rprop 的方式迭代，会由于各个 Batch 之间的采样差异性，各次梯度修正值相互抵消，无法修正。这才有了后来 <strong>RMSProp</strong> 的妥协方案。</p>
<h2 id="既然-Full-Batch-Learning-并不适用大数据集，那么走向另一个极端怎么样？"><a href="#既然-Full-Batch-Learning-并不适用大数据集，那么走向另一个极端怎么样？" class="headerlink" title="既然 Full Batch Learning 并不适用大数据集，那么走向另一个极端怎么样？"></a>既然 Full Batch Learning 并不适用大数据集，那么走向另一个极端怎么样？</h2><p>所谓另一个极端，就是每次只训练一个样本，即 Batch_Size = 1。这就是<strong>在线学习（Online Learning）</strong>。线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是椭圆。对于多层神经元、非线性网络，在局部依然近似是抛物面。使用在线学习，每次修正方向以各自样本的梯度方向修正，横冲直撞各自为政，<strong>难以达到收敛</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Batch/640.jpg" alt></p>
<h2 id="可不可以选择一个适中的-Batch-Size-值呢？"><a href="#可不可以选择一个适中的-Batch-Size-值呢？" class="headerlink" title="可不可以选择一个适中的 Batch_Size 值呢？"></a>可不可以选择一个适中的 Batch_Size 值呢？</h2><p>当然可以，这就是<strong>批梯度下降法（Mini-batches Learning）</strong>。因为如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。</p>
<h2 id="在合理范围内，增大-Batch-Size-有何好处？"><a href="#在合理范围内，增大-Batch-Size-有何好处？" class="headerlink" title="在合理范围内，增大 Batch_Size 有何好处？"></a>在合理范围内，增大 Batch_Size 有何好处？</h2><ul>
<li>内存利用率提高了，大矩阵乘法的并行化效率提高。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ul>
<h2 id="盲目增大-Batch-Size-有何坏处？"><a href="#盲目增大-Batch-Size-有何坏处？" class="headerlink" title="盲目增大 Batch_Size 有何坏处？"></a>盲目增大 Batch_Size 有何坏处？</h2><ul>
<li>内存利用率提高了，但是内存容量可能撑不住了。</li>
<li>跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</li>
</ul>
<h2 id="调节-Batch-Size-对训练效果影响到底如何？"><a href="#调节-Batch-Size-对训练效果影响到底如何？" class="headerlink" title="调节 Batch_Size 对训练效果影响到底如何？"></a>调节 Batch_Size 对训练效果影响到底如何？</h2><p>这里是一个 LeNet 在 MNIST 数据集上的效果。MNIST 是一个手写体标准库，使用的是 Theano 框架。这是一个 Python  的深度学习库。安装方便（几行命令而已），调试简单（自带 Profile），GPU / CPU  通吃，官方教程相当完备，支持模块十分丰富（除了 CNNs，更是支持 RBM / DBN / LSTM / RBM-RNN / SdA / MLPs）。在其上层有 Keras 封装，支持 GRU / JZS1,  JZS2, JZS3 等较新结构，支持 Adagrad / Adadelta / RMSprop / Adam 等优化算法。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Batch/641.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/Batch/642.jpg" alt></p>
<p>运行结果如上图所示，其中绝对时间做了标幺化处理。运行结果与上文分析相印证：</p>
<ul>
<li>Batch_Size 太小，算法在 200 epoches 内不收敛。</li>
<li>随着 Batch_Size 增大，处理相同数据量的速度越快。</li>
<li>随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。</li>
<li>由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到<strong>时间上</strong>的最优。</li>
<li>由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛<strong>精度上</strong>的最优。</li>
</ul>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测算法之常见评价指标(mAP)的详细计算方法及代码解析</title>
    <url>/2020/02/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E4%B9%8B%E5%B8%B8%E8%A7%81%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87(mAP)%E7%9A%84%E8%AF%A6%E7%BB%86%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E5%8F%8A%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>定义一些评价标准：</p>
<ul>
<li><p>准确率(Acc)：准确率(Acc)的计算公式为$A c c=\frac{T P+T N}{N}$，即预测正确的样本比例，$N$代表测试的样本数。在检测任务中没有预测正确的负样本的概念，所以Acc自然用不到了。</p>
</li>
<li><p>查准率(Precision)：查准率是针对某一个具体类别而言的，公式为：Precision $=\frac{T P}{T P+F P}=\frac{T P}{N}$，其中$N$代表所有检测到的某个具体类的目标框个数。</p>
</li>
<li><p>召回率(Recall)：召回率仍然是针对某一个具体类别而言的，公式为：Recall$=\frac{T P}{T P+F N}$，即预测正确的目标框和所有Ground Truth框的比值。</p>
</li>
<li><p>F1 Score：定位查准率和召回率的调和平均，公式如下：</p>
<script type="math/tex; mode=display">
F_{1}=2 \times \frac{\text {Precision} * \text {Recall}}{\text {Precision}+\text {Recall}}=\frac{2 T P}{2 T P+F N+F P}</script></li>
<li><p>IOU：先为计算mAP值做一个铺垫，即IOU阈值是如何影响Precision和Recall值的？比如在PASCAL  VOC竞赛中采用的IoU阈值为0.5，而COCO竞赛中在计算mAP较复杂，其计算了一系列IoU阈值（0.05至0.95）下的mAP当成最后的mAP值。</p>
</li>
<li><p>mAP：全称为Average Precision，AP值是Precision-Recall曲线下方的面积。那么问题来了，目标检测中PR曲线怎么来的？可以在这篇论文找到答案，截图如下：</p>
</li>
</ul>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/map%20code/640.webp" alt></p>
<p>我来解释一下，要得到Precision-Recall曲线(以下简称PR)曲线，首先要对检测模型的预测结果按照目标置信度降序排列。然后给定一个<code>rank</code>值，Recall和Precision仅在置信度高于该<code>rank</code>值的预测结果中计算，改变<code>rank</code>值会相应的改变Recall值和Precision值。这里选择了11个不同的<code>rank</code>值，也就得到了11组Precision和Recall值，然后AP值即定义为在这11个Recall下Precision值的平均值，其可以表征整个PR曲线下方的面积。即：</p>
<script type="math/tex; mode=display">
A P=\frac{1}{11} \sum_{r \in\{0,0.1, \ldots, 1\}} p_{i n t e r p}(r)</script><p>还有另外一种插值的计算方法，即对于某个Recall值<code>r</code>，Precision取所有Recall值大于<code>r</code>中的最大值，这样保证了PR曲线是单调递减的，避免曲线出现摇摆。另外需要注意的一点是在2010年后计算AP值时是取了所有的数据点，而不仅仅只是11个Recall值。我们在计算出AP之后，对所有类别求平均之后就是mAP值了，也是当前目标检测用的最多的评判标准。</p>
<ul>
<li>AP50，AP60，AP70等等代表什么意思？代表IOU阈值分别取0.5，0.6，0.7等对应的AP值。</li>
</ul>
<h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>下面解析一下Faster-RCNN中对VOC数据集计算每个类别AP值的代码，mAP就是所有类的AP值平均值。代码来自py-faster-rcnn项目。代码解析如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Fast/er R-CNN</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Bharath Hariharan</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET <span class="comment">#读取xml文件</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cPickle <span class="comment">#序列化存储模块</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_rec</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Parse a PASCAL VOC xml file &quot;&quot;&quot;</span></span><br><span class="line">    tree = ET.parse(filename)</span><br><span class="line">    objects = []</span><br><span class="line">    <span class="comment"># 解析xml文件，将GT框信息放入一个列表</span></span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> tree.findall(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">        obj_struct = &#123;&#125;</span><br><span class="line">        obj_struct[<span class="string">&#x27;name&#x27;</span>] = obj.find(<span class="string">&#x27;name&#x27;</span>).text</span><br><span class="line">        obj_struct[<span class="string">&#x27;pose&#x27;</span>] = obj.find(<span class="string">&#x27;pose&#x27;</span>).text</span><br><span class="line">        obj_struct[<span class="string">&#x27;truncated&#x27;</span>] = <span class="built_in">int</span>(obj.find(<span class="string">&#x27;truncated&#x27;</span>).text)</span><br><span class="line">        obj_struct[<span class="string">&#x27;difficult&#x27;</span>] = <span class="built_in">int</span>(obj.find(<span class="string">&#x27;difficult&#x27;</span>).text)</span><br><span class="line">        bbox = obj.find(<span class="string">&#x27;bndbox&#x27;</span>)</span><br><span class="line">        obj_struct[<span class="string">&#x27;bbox&#x27;</span>] = [<span class="built_in">int</span>(bbox.find(<span class="string">&#x27;xmin&#x27;</span>).text),</span><br><span class="line">                              <span class="built_in">int</span>(bbox.find(<span class="string">&#x27;ymin&#x27;</span>).text),</span><br><span class="line">                              <span class="built_in">int</span>(bbox.find(<span class="string">&#x27;xmax&#x27;</span>).text),</span><br><span class="line">                              <span class="built_in">int</span>(bbox.find(<span class="string">&#x27;ymax&#x27;</span>).text)]</span><br><span class="line">        objects.append(obj_struct)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> objects</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单个计算AP的函数，输入参数为精确率和召回率，原理见上面</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_ap</span>(<span class="params">rec, prec, use_07_metric=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; ap = voc_ap(rec, prec, [use_07_metric])</span></span><br><span class="line"><span class="string">    Compute VOC AP given precision and recall.</span></span><br><span class="line"><span class="string">    If use_07_metric is true, uses the</span></span><br><span class="line"><span class="string">    VOC 07 11 point method (default:False).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 如果使用2007年的计算AP的方式(插值的方式)</span></span><br><span class="line">    <span class="keyword">if</span> use_07_metric:</span><br><span class="line">        <span class="comment"># 11 point metric</span></span><br><span class="line">        ap = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(<span class="number">0.</span>, <span class="number">1.1</span>, <span class="number">0.1</span>):</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">sum</span>(rec &gt;= t) == <span class="number">0</span>:</span><br><span class="line">                p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p = np.<span class="built_in">max</span>(prec[rec &gt;= t])</span><br><span class="line">            ap = ap + p / <span class="number">11.</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">       <span class="comment"># 使用2010年后的计算AP值的方式</span></span><br><span class="line">        <span class="comment"># 这里是新增一个(0,0)，方便计算</span></span><br><span class="line">        mrec = np.concatenate(([<span class="number">0.</span>], rec, [<span class="number">1.</span>]))</span><br><span class="line">        mpre = np.concatenate(([<span class="number">0.</span>], prec, [<span class="number">0.</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the precision envelope</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(mpre.size - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># to calculate area under PR curve, look for points</span></span><br><span class="line">        <span class="comment"># where X axis (recall) changes value</span></span><br><span class="line">        i = np.where(mrec[<span class="number">1</span>:] != mrec[:-<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># and sum (\Delta recall) * prec</span></span><br><span class="line">        ap = np.<span class="built_in">sum</span>((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_eval</span>(<span class="params">detpath,</span></span></span><br><span class="line"><span class="params"><span class="function">             annopath,</span></span></span><br><span class="line"><span class="params"><span class="function">             imagesetfile,</span></span></span><br><span class="line"><span class="params"><span class="function">             classname,</span></span></span><br><span class="line"><span class="params"><span class="function">             cachedir,</span></span></span><br><span class="line"><span class="params"><span class="function">             ovthresh=<span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">             use_07_metric=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;rec, prec, ap = voc_eval(detpath,</span></span><br><span class="line"><span class="string">                                annopath,</span></span><br><span class="line"><span class="string">                                imagesetfile,</span></span><br><span class="line"><span class="string">                                classname,</span></span><br><span class="line"><span class="string">                                [ovthresh],</span></span><br><span class="line"><span class="string">                                [use_07_metric])</span></span><br><span class="line"><span class="string">    Top level function that does the PASCAL VOC evaluation.</span></span><br><span class="line"><span class="string">    detpath: 产生的txt文件，里面是一张图片的各个检测框结果。</span></span><br><span class="line"><span class="string">    annopath: xml 文件与对应的图像相呼应。</span></span><br><span class="line"><span class="string">    imagesetfile: 一个txt文件，里面是每个图片的地址，每行一个地址。</span></span><br><span class="line"><span class="string">    classname: 种类的名字，即类别。</span></span><br><span class="line"><span class="string">    cachedir: 缓存标注的目录。</span></span><br><span class="line"><span class="string">    [ovthresh]: IOU阈值，默认为0.5，即mAP50。</span></span><br><span class="line"><span class="string">    [use_07_metric]: 是否使用2007的计算AP的方法，默认为Fasle</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># assumes detections are in detpath.format(classname)</span></span><br><span class="line">    <span class="comment"># assumes annotations are in annopath.format(imagename)</span></span><br><span class="line">    <span class="comment"># assumes imagesetfile is a text file with each line an image name</span></span><br><span class="line">    <span class="comment"># cachedir caches the annotations in a pickle file</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先加载Ground Truth标注信息。</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(cachedir):</span><br><span class="line">        os.mkdir(cachedir)</span><br><span class="line">    <span class="comment"># 即将新建文件的路径</span></span><br><span class="line">    cachefile = os.path.join(cachedir, <span class="string">&#x27;annots.pkl&#x27;</span>)</span><br><span class="line">    <span class="comment"># 读取文本里的所有图片路径</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(imagesetfile, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">    <span class="comment"># 获取文件名，strip用来去除头尾字符、空白符(包括\n、\r、\t、&#x27; &#x27;，即：换行、回车、制表符、空格)</span></span><br><span class="line">    imagenames = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> lines]</span><br><span class="line">    <span class="comment">#如果cachefile文件不存在，则写入</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(cachefile):</span><br><span class="line">        <span class="comment"># load annots</span></span><br><span class="line">        recs = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i, imagename <span class="keyword">in</span> <span class="built_in">enumerate</span>(imagenames):</span><br><span class="line">            <span class="comment">#annopath.format(imagename): label的xml文件所在的路径</span></span><br><span class="line">            recs[imagename] = parse_rec(annopath.<span class="built_in">format</span>(imagename))</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span> <span class="string">&#x27;Reading annotation for &#123;:d&#125;/&#123;:d&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                    i + <span class="number">1</span>, <span class="built_in">len</span>(imagenames))</span><br><span class="line">        <span class="comment"># save</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Saving cached annotations to &#123;:s&#125;&#x27;</span>.<span class="built_in">format</span>(cachefile)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cachefile, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment">#写入cPickle文件里面。写入的是一个字典，左侧为xml文件名，右侧为文件里面个各个参数。</span></span><br><span class="line">            cPickle.dump(recs, f)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># load</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(cachefile, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            recs = cPickle.load(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对每张图片的xml获取函数指定类的bbox等</span></span><br><span class="line">    class_recs = &#123;&#125;<span class="comment"># 保存的是 Ground Truth的数据</span></span><br><span class="line">    npos = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> imagename <span class="keyword">in</span> imagenames:</span><br><span class="line">        <span class="comment"># 获取Ground Truth每个文件中某种类别的物体</span></span><br><span class="line">        R = [obj <span class="keyword">for</span> obj <span class="keyword">in</span> recs[imagename] <span class="keyword">if</span> obj[<span class="string">&#x27;name&#x27;</span>] == classname]</span><br><span class="line">        bbox = np.array([x[<span class="string">&#x27;bbox&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> R])</span><br><span class="line">        <span class="comment">#  different基本都为0/False</span></span><br><span class="line">        difficult = np.array([x[<span class="string">&#x27;difficult&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> R]).astype(np.<span class="built_in">bool</span>)</span><br><span class="line">        det = [<span class="literal">False</span>] * <span class="built_in">len</span>(R)</span><br><span class="line">        npos = npos + <span class="built_in">sum</span>(~difficult) <span class="comment">#自增，~difficult取反,统计样本个数</span></span><br><span class="line">        <span class="comment"># # 记录Ground Truth的内容</span></span><br><span class="line">        class_recs[imagename] = &#123;<span class="string">&#x27;bbox&#x27;</span>: bbox,</span><br><span class="line">                                 <span class="string">&#x27;difficult&#x27;</span>: difficult,</span><br><span class="line">                                 <span class="string">&#x27;det&#x27;</span>: det&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read dets 读取某类别预测输出</span></span><br><span class="line">    detfile = detpath.<span class="built_in">format</span>(classname)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(detfile, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line"></span><br><span class="line">    splitlines = [x.strip().split(<span class="string">&#x27; &#x27;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> lines]</span><br><span class="line">    image_ids = [x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> splitlines] <span class="comment"># 图片ID</span></span><br><span class="line">    confidence = np.array([<span class="built_in">float</span>(x[<span class="number">1</span>]) <span class="keyword">for</span> x <span class="keyword">in</span> splitlines]) <span class="comment"># IOU值</span></span><br><span class="line">    BB = np.array([[<span class="built_in">float</span>(z) <span class="keyword">for</span> z <span class="keyword">in</span> x[<span class="number">2</span>:]] <span class="keyword">for</span> x <span class="keyword">in</span> splitlines]) <span class="comment"># bounding box数值</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对confidence的index根据值大小进行降序排列。</span></span><br><span class="line">    sorted_ind = np.argsort(-confidence)</span><br><span class="line">    sorted_scores = np.sort(-confidence)</span><br><span class="line">    <span class="comment">#重排bbox，由大概率到小概率。</span></span><br><span class="line">    BB = BB[sorted_ind, :]</span><br><span class="line">    <span class="comment"># 图片重排，由大概率到小概率。</span></span><br><span class="line">    image_ids = [image_ids[x] <span class="keyword">for</span> x <span class="keyword">in</span> sorted_ind]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># go down dets and mark TPs and FPs</span></span><br><span class="line">    nd = <span class="built_in">len</span>(image_ids)</span><br><span class="line">    tp = np.zeros(nd)</span><br><span class="line">    fp = np.zeros(nd)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(nd):</span><br><span class="line">        R = class_recs[image_ids[d]]</span><br><span class="line">        bb = BB[d, :].astype(<span class="built_in">float</span>)</span><br><span class="line">        ovmax = -np.inf</span><br><span class="line">        BBGT = R[<span class="string">&#x27;bbox&#x27;</span>].astype(<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> BBGT.size &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># compute overlaps</span></span><br><span class="line">            <span class="comment"># intersection</span></span><br><span class="line">            ixmin = np.maximum(BBGT[:, <span class="number">0</span>], bb[<span class="number">0</span>])</span><br><span class="line">            iymin = np.maximum(BBGT[:, <span class="number">1</span>], bb[<span class="number">1</span>])</span><br><span class="line">            ixmax = np.minimum(BBGT[:, <span class="number">2</span>], bb[<span class="number">2</span>])</span><br><span class="line">            iymax = np.minimum(BBGT[:, <span class="number">3</span>], bb[<span class="number">3</span>])</span><br><span class="line">            iw = np.maximum(ixmax - ixmin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">            ih = np.maximum(iymax - iymin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">            inters = iw * ih</span><br><span class="line"></span><br><span class="line">            <span class="comment"># union</span></span><br><span class="line">            uni = ((bb[<span class="number">2</span>] - bb[<span class="number">0</span>] + <span class="number">1.</span>) * (bb[<span class="number">3</span>] - bb[<span class="number">1</span>] + <span class="number">1.</span>) +</span><br><span class="line">                   (BBGT[:, <span class="number">2</span>] - BBGT[:, <span class="number">0</span>] + <span class="number">1.</span>) *</span><br><span class="line">                   (BBGT[:, <span class="number">3</span>] - BBGT[:, <span class="number">1</span>] + <span class="number">1.</span>) - inters)</span><br><span class="line"></span><br><span class="line">            overlaps = inters / uni</span><br><span class="line">            ovmax = np.<span class="built_in">max</span>(overlaps)</span><br><span class="line">            jmax = np.argmax(overlaps)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ovmax &gt; ovthresh:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> R[<span class="string">&#x27;difficult&#x27;</span>][jmax]:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> R[<span class="string">&#x27;det&#x27;</span>][jmax]:</span><br><span class="line">                    tp[d] = <span class="number">1.</span></span><br><span class="line">                    R[<span class="string">&#x27;det&#x27;</span>][jmax] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    fp[d] = <span class="number">1.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fp[d] = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute precision recall</span></span><br><span class="line">    fp = np.cumsum(fp)</span><br><span class="line">    tp = np.cumsum(tp)</span><br><span class="line">    rec = tp / <span class="built_in">float</span>(npos)</span><br><span class="line">    <span class="comment"># avoid divide by zero in case the first detection matches a difficult</span></span><br><span class="line">    <span class="comment"># ground truth</span></span><br><span class="line">    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)</span><br><span class="line">    ap = voc_ap(rec, prec, use_07_metric)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> rec, prec, ap</span><br></pre></td></tr></table></figure>
<p>这个脚本可以直接调用来计算mAP值，具体例子可以看这个：<a href="https://blog.csdn.net/amusi1994/article/details/81564504">在Darknet中调用上面的脚本来计算mAP值</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测算法优化技巧</title>
    <url>/2020/04/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>目标检测模型相比于分类模型的研究相比，更缺少普遍性，并且网络结构和优化目标更加复杂。</p>
<p>本文主要是基于Faster R-CNN和YOLOv3来探索目标检测网络的调整策略。这些策略不会改变模型的结构，也不会引入额外的计算代价。通过使用这些trick，可以比SOTA提高最多5个百分点。</p>
<p>19年由亚马逊团队发表的《Bag of Freebies for Training Object Detection Neural  Networks》。在使用了trick后，Faster R-CNN能提高1-2个百分点，而YOLOv3则提高了5个百分点。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/640.png" alt></p>
<h2 id="Trick"><a href="#Trick" class="headerlink" title="Trick"></a>Trick</h2><h3 id="mixup"><a href="#mixup" class="headerlink" title="mixup"></a>mixup</h3><p>mixup也是图片分类中的一个非常有效的trick, 具体流程如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/641.jpg" alt></p>
<p>简单来讲就是将两张图片通过不同的比例进行融合，同时图片对应的one-hot编码也以相同的比例相乘，从而构造出新的数据集。本质上，mixup在成对样本及其标签的凸组合（convex combinations）上训练神经网络，可以规范神经网络，增强训练样本之间的线性表达。其优点是：</p>
<ul>
<li>改善了网络模型的泛化能力</li>
<li>减少对错误标签的记忆</li>
<li>增加对抗样本的鲁棒性</li>
<li>稳定训练过程</li>
</ul>
<p>本文提出了针对目标检测的<strong>视觉连贯的mixup</strong>方法（Visually Coherent Image Mixup for Object Detection），操作流程如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/642.jpg" alt></p>
<p>通过上图也很容易理解，但在这里要引入一篇有意思的工作，指出了当时SOTA的目标检测器的缺陷，论文名称为：“<strong>Elephant in the room</strong>”。注意两张图结合的方式是直接叠加， 取最大的宽高，不进行resize。</p>
<p>大象通常都出现在自然场景下，数据集中是不存在背景是室内的图片的，Elephant in the room就是作者将大象图片抠出，然后直接放在室内场景下，并使用SOTA目标检测器进行检测，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/643.jpg" alt></p>
<p>可以看到使用SOTA(faster rcnn nas coco)检测大象的效果并不是很好，而且大象位置不同，也会给其他目标检测的效果带来影响，比如说上图中（d）和（f）图中cup这个对象没有被检测出来。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/644.jpg" alt></p>
<p>上图是一个猫在不同的背景下的检测结果，可以看到虽然ROI中内容大体不变，但是结果却有比较大的变化，这叫做特征干扰，同一个目标在不同背景被检测为不同的物体，在ROI之外的特征对最终结果会产生影响，这代表特征干扰对检测过程产生干扰，对检测结果产生不利影响。</p>
<p>针对以上问题，本文提出的是视觉连贯的mixup方法可以比较好的解决，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/645.jpg" alt></p>
<p>可以看到，上图中使用了视觉连贯的mixup方法之后，“Elephant in the room”也可以很有效的被检测出来，可以比较好的解决“Elephant in the room”这个问题。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/646.png" alt></p>
<p>作者也用实验证明了使用这种mixup可以让大象的召回率大幅度提升，并且对其他目标影响降低到了1.27%</p>
<h3 id="Classfication-Head-Label-Smoothing"><a href="#Classfication-Head-Label-Smoothing" class="headerlink" title="Classfication Head Label Smoothing"></a>Classfication Head Label Smoothing</h3><p>Label Smoothing也是分类中使用到的trick, 在目标检测问题中也一样适用。Label Smoothing  原理简单来说就是：在分类的时候，比如二分类把原先的标签(0,1) (称为hard target） 转成 soft target，具体方法就是  y‘ = y (1 − α) + α/K 这里α 是个超参数常量，K就是类别的个数 。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>在图像分类问题中，一般都会使用随机扰乱图片的空间特征的方法来进行数据增强， 比如随机翻转、旋转、抠图等。这些方法都可以提高模型的准确率、避免过拟合。</p>
<p>这部分主要对以下几种增强方法进行试验：</p>
<ul>
<li>随机几何变换：随机抠图、随机膨胀、随机水平翻转和随机resize。</li>
<li>随机颜色抖动：亮度、色调、饱和度、对比度。</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><p>训练策略：使用余弦学习率+warmup的方法。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/647.png" alt><br>上图是step方法和cosine方法的对比，预先的方法上升更快，不过最终结果比较接近，差的也不是很多。</p>
</li>
<li><p>跨卡同步Batch Normalization。</p>
</li>
<li>多尺度训练，和YOLOv3中的训练方式一样。从{320,352,384,416,448,480,512,544,576,608 }中选择一个尺度进行训练。</li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/648.jpg" alt></p>
<p>上图分别展示了在YOLOv3和Faster-RCNN上使用以上trick后的效果。其他实验结果就不一一列举了，感兴趣可以仔细读一下paper。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>ASFF这篇论文被很多人认为是YOLO中最强的改进版本，不仅仅是他提出的ASFF模块，更因为他有一个非常强的、融合了很多trick的baseline。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/649.png" alt></p>
<p>上表中的BoF代表的就是以上解读的这篇：《Bag of Freebies for Training Object Detection  Neural Networks》，可以通过对比看到提高了大约4个百分点。IoU代表的是使用了IoU loss，GA代表Guided  Anchoring,  GA主要是用于解决特征不对齐和anchor设置的问题（这也是一阶段检测方法的弱点），如下图所示，具体讲解可以看：<a href="https://zhuanlan.zhihu.com/p/55854246">https://zhuanlan.zhihu.com/p/55854246</a></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/object_optimize/650.jpg" alt></p>
<p>实际上ASFF模型带来的提升只有1个百分点左右，而以上结合了各种trick的强大的baseline是ASFF出彩的一个强有力的保证。</p>
<p>以上涉及到的trick的具体实现应该可以在ASFF官方实现中找到：<a href="https://github.com/ruinmessi/ASFF">https://github.com/ruinmessi/ASFF</a></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测算法的评价标准和常见数据集</title>
    <url>/2020/02/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86%E5%92%8C%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="1-准确率-Accuracy"><a href="#1-准确率-Accuracy" class="headerlink" title="1.准确率(Accuracy)"></a>1.准确率(Accuracy)</h3><p>检测时分对的样本数除以所有的样本数。准确率一般被用来评估检测模型的全局准确程度，包含的信息有限，不能完全评价一个模型性能。</p>
<h3 id="2-混淆矩阵-Confusion-Matrix"><a href="#2-混淆矩阵-Confusion-Matrix" class="headerlink" title="2.混淆矩阵(Confusion Matrix)"></a>2.混淆矩阵(Confusion Matrix)</h3><p>混淆矩阵是以模型预测的类别数量统计信息为横轴，真实标签的数量统计信息为纵轴画出的矩阵。对角线代表了模型预测和数据标签一致的数目，所以准确率也可以用<strong>混淆矩阵对角线之和除以测试集图片数量</strong>来计算。对角线上的数字越大越好，在混淆矩阵可视化结果中颜色越深，代表模型在该类的预测结果更好。其他地方自然是预测错误的地方，自然值越小，颜色越浅说明模型预测的更好。</p>
<h3 id="3-精确率-Precision-和召回率-Recall-和PR曲线"><a href="#3-精确率-Precision-和召回率-Recall-和PR曲线" class="headerlink" title="3.精确率(Precision)和召回率(Recall)和PR曲线"></a>3.精确率(Precision)和召回率(Recall)和PR曲线</h3><p>一个经典例子是存在一个测试集合，测试集合只有大雁和飞机两种图片组成，假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片。然后就可以定义：</p>
<ul>
<li>True positives: 简称为TP，即正样本被正确识别为正样本，飞机的图片被正确的识别成了飞机。</li>
<li>True negatives: 简称为TN，即负样本被正确识别为负样本，大雁的图片没有被识别出来，系统正确地认为它们是大雁。</li>
<li>False Positives: 简称为FP，即负样本被错误识别为正样本，大雁的图片被错误地识别成了飞机。</li>
<li>False negatives: 简称为FN，即正样本被错误识别为负样本，飞机的图片没有被识别出来，系统错误地认为它们是大雁。</li>
</ul>
<p><strong>精确率</strong>就是在识别出来的图片中，True positives所占的比率。也就是本假设中，所有被识别出来的飞机中，真正的飞机所占的比例，公式如下：Precision $=\frac{T P}{T P+F P}=\frac{T P}{N}$ ，其中N代表测试集样本数。</p>
<p><strong>召回率</strong>是测试集中所有正样本样例中，被正确识别为正样本的比例。也就是本假设中，被正确识别出来的飞机个数与测试集中所有真实飞机的个数的比值，公式如下： Recall$=\frac{T P}{T P+F N}$</p>
<p>所谓<strong>PR曲线</strong>就是改变识别阈值，使得系统依次能够识别前K张图片，阈值的变化同时会导致Precision与Recall值发生变化，从而得到曲线。曲线图大概如下，这里有3条PR曲线，周志华机器学习的解释如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/metrics/640.webp" alt></p>
<h3 id="4-平均精度-Average-Precision，AP-和mAP"><a href="#4-平均精度-Average-Precision，AP-和mAP" class="headerlink" title="4.平均精度(Average-Precision，AP)和mAP"></a>4.平均精度(Average-Precision，AP)和mAP</h3><p><strong>AP</strong>就是Precision-recall 曲线下面的面积，通常来说一个越好的分类器，AP值越高。<strong>mAP</strong>是多个类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值，mAP的大小一定在[0,1]区间，越大越好。该指标是目标检测算法中最重要的一个。</p>
<h3 id="5-ROC曲线"><a href="#5-ROC曲线" class="headerlink" title="5.ROC曲线"></a>5.ROC曲线</h3><p>如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/metrics/641.webp" alt></p>
<p>ROC的横轴是假正率(False positive rate， FPR)，FPR = FP / [ FP + TN]  ，代表所有负样本中错误预测为正样本的概率，假警报率。ROC的纵轴是真正率(True positive rate， TPR)，TPR  = TP / [ TP + FN]  ，代表所有正样本中预测正确的概率，命中率。ROC曲线的对角线坐标对应于随即猜测，而坐标点(0,1)也即是左上角坐标对应理想模型。曲线越接近左上角代表检测模型的效果越好。</p>
<p>即：从 (0, 0) 到 (1,1) 的对角线将ROC空间划分为左上／右下两个区域，在这条线的以上的点代表了一个好的分类结果（胜过随机分类），而在这条线以下的点代表了差的分类结果（劣于随机分类）。</p>
<p>完美的预测是一个在左上角的点，在ROC空间座标 (0,1)点，X=0 代表着没有伪阳性，Y=1  代表着没有伪阴性（所有的阳性都是真阳性）；也就是说，不管分类器输出结果是阳性或阴性，都是100%正确。一个随机的预测会得到位于从 (0, 0) 到 (1, 1) 对角线（也叫无识别率线）上的一个点；最直观的随机预测的例子就是抛硬币。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/metrics/v2-fc750883be72300fa2373d1c5b81ee9e_hd.jpg" alt></p>
<p>那么ROC曲线是怎么绘制的呢？有如下几个步骤：</p>
<ul>
<li>根据每个测试样本属于正样本的概率值从大到小排序。</li>
<li>从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。</li>
<li>每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。</li>
</ul>
<h3 id="6-AUC-Area-Uner-Curve"><a href="#6-AUC-Area-Uner-Curve" class="headerlink" title="6.AUC(Area Uner Curve)"></a>6.AUC(Area Uner Curve)</h3><p>即为ROC曲线下的面积。AUC越接近于1，分类器性能越好。AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。AUC的计算公式如下：</p>
<script type="math/tex; mode=display">
A U C=\frac{\sum p r e d_{p o s}>p r e d_{n e g}}{p o s i t i v e N u m * n e g a t i v e N  u m}</script><p>即：分别随机从样本集中抽取一个正负样本，正样本的预测值大于负样本的概率。</p>
<h3 id="PR曲线和ROC曲线选用时机"><a href="#PR曲线和ROC曲线选用时机" class="headerlink" title="PR曲线和ROC曲线选用时机"></a>PR曲线和ROC曲线选用时机</h3><p>目标检测中用的最多的是MAP值，但我们最好再了解一下PR曲线和ROC曲线的应用场景，在不同的数据集中选择合适的评价标准更好的判断我们的模型是否训好了。</p>
<h3 id="PR曲线"><a href="#PR曲线" class="headerlink" title="PR曲线"></a>PR曲线</h3><p>从PR的计算公式可以看出，PR曲线聚焦于正例。类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被广泛认为优于ROC曲线。</p>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p>当测试集中的正负样本的分布发生变化时，ROC曲线可以保持不变。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法。但是在关心正例的预测准确性的场景，ROC曲线就不能更好的反应模型的性能了，因为ROC曲线的横轴采用FPR，根据FPR公式 ，当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。</p>
<p>因此，PR曲线和ROC曲线的选用时机可以总结如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/metrics/642.webp" alt></p>
<p>从目标检测任务来讲，一般关心MAP值即可。</p>
<h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>刚才介绍了目标检测算法的常见评价标准，这里再介绍一下目标检测常用的数据集。以下介绍来自于github工程整理：DeepLearning-500-questions</p>
<h3 id="PASCAL-VOC数据集"><a href="#PASCAL-VOC数据集" class="headerlink" title="PASCAL VOC数据集"></a>PASCAL VOC数据集</h3><p>VOC数据集是目标检测经常用的一个数据集，自2005年起每年举办一次比赛，最开始只有4类，到2007年扩充为20个类，共有两个常用的版本：2007和2012。学术界常用5k的train/val 2007和16k的train/val 2012作为训练集，test 2007作为测试集，用10k的train/val 2007+test  2007和16k的train/val 2012作为训练集，test2012作为测试集，分别汇报结果。</p>
<h3 id="MSCOCO数据集"><a href="#MSCOCO数据集" class="headerlink" title="MSCOCO数据集"></a>MSCOCO数据集</h3><p>COCO数据集是微软团队发布的一个可以用来图像recognition+segmentation+captioning的数据集，该数据集收集了大量包含常见物体的日常场景图片，并提供像素级的实例标注以更精确地评估检测和分割算法的效果，致力于推动场景理解的研究进展。依托这一数据集，每年举办一次比赛，现已涵盖检测、分割、关键点识别、注释等机器视觉的中心任务，是继ImageNet Chanllenge以来最有影响力的学术竞赛之一。相比ImageNet，COCO更加偏好目标与其场景共同出现的图片，即non-iconic  images。这样的图片能够反映视觉上的语义，更符合图像理解的任务要求。而相对的iconic  images则更适合浅语义的图像分类等任务。COCO的检测任务共含有80个类，在2014年发布的数据规模分train/val/test分别为80k/40k/40k，学术界较为通用的划分是使用train和35k的val子集作为训练集（trainval35k），使用剩余的val作为测试集（minival），同时向官方的evaluation server提交结果（test-dev）。除此之外，COCO官方也保留一部分test数据作为比赛的评测集。</p>
<h3 id="Google-Open-Image数据集"><a href="#Google-Open-Image数据集" class="headerlink" title="Google Open Image数据集"></a>Google Open Image数据集</h3><p>pen Image是谷歌团队发布的数据集。最新发布的Open Images  V4包含190万图像、600个种类，1540万个bounding-box标注，是当前最大的带物体位置标注信息的数据集。这些边界框大部分都是由专业注释人员手动绘制的，确保了它们的准确性和一致性。另外，这些图像是非常多样化的，并且通常包含有多个对象的复杂场景（平均每个图像 8 个）。</p>
<h3 id="ImageNet数据集"><a href="#ImageNet数据集" class="headerlink" title="ImageNet数据集"></a>ImageNet数据集</h3><p>ImageNet是一个计算机视觉系统识别项目，  是目前世界上图像识别最大的数据库。ImageNet是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片识别物体。Imagenet数据集文档详细，有专门的团队维护，使用非常方便，在计算机视觉领域研究论文中应用非常广，几乎成为了目前深度学习图像领域算法性能检验的“标准”数据集。Imagenet数据集有1400多万幅图片，涵盖2万多个类别；其中有超过百万的图片有明确的类别标注和图像中物体位置的标注。</p>
<h3 id="DOTA数据集"><a href="#DOTA数据集" class="headerlink" title="DOTA数据集"></a>DOTA数据集</h3><p>DOTA是遥感航空图像检测的常用数据集，包含2806张航空图像，尺寸大约为4k x 4k，包含15个类别共计188282个实例，其中14个主类，small vehicle 和 large  vehicle都是vehicle的子类。其标注方式为四点确定的任意形状和方向的四边形。航空图像区别于传统数据集，有其自己的特点，如：尺度变化性更大；密集的小物体检测；检测目标的不确定性。数据划分为1/6验证集，1/3测试集，1/2训练集。目前发布了训练集和验证集，图像尺寸从800 x 800到4000 x 4000不等。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>自适应空间特征融合 (ASFF)</title>
    <url>/2020/04/20/%E8%87%AA%E9%80%82%E5%BA%94%E7%A9%BA%E9%97%B4%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-(ASFF)/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这是2019年的一篇论文 <strong>《Learning Spatial Fusion for Single-Shot Object Detection》</strong>，这篇论文主要是因为其提出的 <strong>自适应空间特征融合</strong>  (ASFF)被大家所熟知。金字塔特征表示法(FPN)是解决目标检测尺度变化挑战的常用方法。但是，对于基于FPN的单级检测器来说，不同特征尺度之间的不一致是其主要限制。因此这篇论文提出了一种新的数据驱动的金字塔特征融合方式，称之为自适应空间特征融合（ASFF）。它学习了在空间上过滤冲突信息以抑制梯度反传的时候不一致的方法，从而改善了特征的比例不变性，并且推理开销降低。借助ASFF策略和可靠的YOLOV3 BaseLine，在COCO数据集上实现了45FPS/42.4%AP以及29FPS/43.9%AP。下面先放一张论文的结果图。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/640.png" alt></p>
<h2 id="一个更强的YOLOV3基准"><a href="#一个更强的YOLOV3基准" class="headerlink" title="一个更强的YOLOV3基准"></a>一个更强的YOLOV3基准</h2><p>这篇文章之所以取得这么好的效果不仅仅是因为它提出的ASFF这种特征自适应融合方式，论文在YOLOV3的基础上集百家之长，构建了一个非常强的YOLOV3  BaseLine，这个BaseLine在MSCOCO上的mAP就达到了38.8%。相比于原始的YOLOV3的33%，提升了接近6个点。。论文使用的技巧包括：</p>
<ul>
<li>Guided Anchoring</li>
<li>Bag of Tricks</li>
<li>Additional IoU Loss</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/641.png" alt></p>
<h2 id="自适应特征融合-ASFF"><a href="#自适应特征融合-ASFF" class="headerlink" title="自适应特征融合(ASFF)"></a>自适应特征融合(ASFF)</h2><p>为了更加充分的利用高层特征的语义信息和底层特征的细粒度特征，很多网络都会采用FPN的方式输出多层特征，但是无论是类似于YOLOv3还是RetinaNet，它们都多用concatenation或者element-wise这种直接衔接或者相加的方式，论文认为这样并不能充分的利用不同尺度的特征，所以提出了<strong>Adaptively Spatial Feature Fusion</strong>（自适应特征融合方式）。以ASFF-3为例，其结构可以表示为Figure2。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/642.jpg" alt></p>
<p>在Figure2中，绿色框描述了如何将特征进行融合，其中$X^{1}$，$X^{2}$，$X^{3}$分别为来自level1，level2，level3这三个层的特征。然后level1，level2，level3这三个层的特征分别乘上权重参数并求和，就可以得到新的融合后的特征ASFF-3。这个过程可以用公式(1)来表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/643.png" alt></p>
<p>因此这里是相加的操作，所以需要加的时候必须保证leve1，level2，level3输出的特征相同，且通道数也要相同，所以需要对不同的特征层做上采样或者下采样并调整通道数来满足条件。对于需要上采样的层，如想得到ASFF3，需要将level1的特征图调整到和level3的特征图尺寸一致，采用的方式是先通过1 x 1卷积调整到和level3通道数一致，再用插值的方式将尺寸调整到一致。而对于需要下采样的层，比如想得到ASFF1，对于level2的特征图到level1的特征图只需要用一个3 x 3并且stride=2的卷积就OK了，如果是level3的特征图到level1的特征图则需要在3 x 3卷积的基础上再加上一个stride=2的最大池化层。</p>
<p>对于权重参数$\alpha$，$\beta$，$\gamma$，则是通过resize后的level1~level3特征图经过1 x 1卷积获得的。并且参数$\alpha$，$\beta$，$\gamma$经过concat之后通过<code>softmax</code>使得它们的范围都在<code>[0,1]</code>并且和为<code>1</code>。</p>
<h2 id="ASFF的可解释性"><a href="#ASFF的可解释性" class="headerlink" title="ASFF的可解释性"></a>ASFF的可解释性</h2><p>论文通过梯度和反向传播来解释为什么ASFF会有效。论文以YOLOv3为例，加入FPN后通过链式法则我们可以知道在反向传播的时候梯度计算如公式(3)所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/644.png" alt></p>
<p>稍微解释一下，左边的第一项$\frac{\partial L}{\partial x_{i j}^{1}}$代表的是损失函数对level1的特征图的某个像素求导，在YOLOV3中不同尺度的层之间的尺度变化一般就是下采样和上采样，因此这一项$\frac{\partial x_{i j}^{1-&gt;l}}{\partial x_{i j}^{1}}$通常为固定值，为了简化表示我们可以设置为1，即：$\frac{\partial x_{i j}^{1-&gt;l}}{\partial x_{i j}^{1}} \approx 1$，那么公式(3)可以简化为公式(4)：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/645.png" alt></p>
<p>进一步，这一项$\frac{\partial y_{i j}^{1}}{\partial x_{i j}^{1}}$相当于对输出特征的activation操作，导数也将为固定值，$\frac{\partial y_{i j}^{l}}{\partial x_{i j}^{1-&gt;l}}$，所以我们可以将它的值同样简化为1，则表达式进一步简化成了公式(5)：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/646.png" alt></p>
<p>假设$\operatorname{level} 1(i, j)$对应特征图位置刚好有物体并且为正样本，那其他上对应的位置上就可能刚好为负样本，这样反向传播的梯度中既包含了正样本又包含了负样本，这种不连续性会对梯度结果造成干扰，并且降低训练的效率。而通过ASFF的方式，反向传播的梯度表达式就变成了(6)：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/647.png" alt></p>
<p>因此，如果出现刚才的情况我们可以通过将$\alpha^{2}$和$\alpha^{3}$设置为0来解决，因为这样负样本的梯度不会结果造成干扰。</p>
<p><strong>同时这也解释了为什么特征融合的权重参数来源于输出特征+卷积，因为融合的权重参数和特征是息息相关的。</strong></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>下面的Table3展示了ASFF相比于concat和sum的方式的结果，可以看到加入了ASFF在BaseLine的基础上提升了2个多个mAP。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/648.png" alt></p>
<p>接着作者又对ASFF做了可视化分析，如Figure3所示。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ASFF/649.jpg" alt></p>
<p>可视化的结果进一步解释了ASFF的有效性。比如对于斑马的检测，可以看到斑马实际上是在level1这个特征图上被检测到的（响应越大，heatmap越红），并且观察level1这一层的$\alpha$，$\beta$，$\gamma$的权重可以发现，对于图中斑马这种大目标更容易被高层的特征捕捉到，因为对于大物体我们需要更大的感受野和高级语义特征。而对于下面的羊群的检测来讲，可以看到羊更多的是被level2和level3检测到，这也说明了对于小物体，我们更需要底层特征中的细粒度特征来辨别。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>这篇论文将YOLOv3的结果做得非常好，不仅仅是因为它的精度非常强，而且从数学角度来简洁的说明这个方法的有效性也是棒的。是具有很大的工程实践意义的，论文具体是如何做出的Stronger YOLOv3  BaseLine，这个可以去源码一探究竟了。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>矩阵分析（刘丁酉）课后答案及历年试卷</title>
    <url>/2019/12/20/%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%EF%BC%88%E5%88%98%E4%B8%81%E9%85%89%EF%BC%89%E8%AF%BE%E5%90%8E%E7%AD%94%E6%A1%88%E5%8F%8A%E5%8E%86%E5%B9%B4%E8%AF%95%E5%8D%B7/</url>
    <content><![CDATA[<p>考虑到刘丁酉版本只有部分习题的解答，还不够详细，于是我在学习过程中，将每道习题做了一遍，并记录了下来，希望能对学习矩阵分析的同学给予一定的参考。由于本人仍在学习阶段，难免答案会有做错的地方，希望大家不要尽信答案，只当作一个思路上的参考来看。顺便附赠历年的卷子与答案（看了一遍历年的卷子，答案有错!@-@）</p>
<p>下载地址：<a href="https://www.jianguoyun.com/p/DQe8_9kQlZ_3Bhid4LYC">点击下载</a></p>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title>解决Pycharm大量占用C盘问题</title>
    <url>/2020/05/05/%E8%A7%A3%E5%86%B3Pycharm%E5%A4%A7%E9%87%8F%E5%8D%A0%E7%94%A8C%E7%9B%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在使用 PyCharm 时会在 C:\Users\<username>.PyCharm&lt;版本号&gt; 下创建一大堆文件，里边包括了配置信息，项目缓存信息等。随着pycharm的使用，这个文件夹越来越大，占用着系统内存，好不霸道！要为了解决Pycharm大量占用C盘问题，需要把一些配置信息搬迁到指定位置。</username></p>
<h2 id="通过-PyCharm-修改"><a href="#通过-PyCharm-修改" class="headerlink" title="通过 PyCharm 修改"></a>通过 PyCharm 修改</h2><p>在启动 PyCharm 后选择 Help -&gt; Edit Custom Properties 的选项，弹出：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/1.png" alt></p>
<p>选择 Create ，之后在文件中添加以下内容，即你需要迁移到的路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">idea.config.path=D:/Program Files/.PyCharm&lt;版本号&gt;/config</span><br><span class="line">idea.system.path=D:/Program Files/.PyCharm&lt;版本号&gt;/system</span><br><span class="line">idea.plugins.path=D:/Program Files/.PyCharm&lt;版本号&gt;/config/plugins</span><br></pre></td></tr></table></figure>
<p>保存并关闭 PyCharm 之后，将原文件夹下的 C:\Users\<username>.PyCharm&lt;版本号&gt; 复制到目标搬迁文件夹下，然后将原文件夹下的 C:\Users\<username>.PyCharm&lt;版本号&gt;只保留 config 目录下的一个 idea.properties 文件，其余文件删除即可。</username></username></p>
<h2 id="修改程序配置"><a href="#修改程序配置" class="headerlink" title="修改程序配置"></a>修改程序配置</h2><p>打开 Pycharm 安装目录（bin），找到 idea.properties 文件：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/2.png" alt></p>
<p>然后，打开使用txt文本打开这个文件，并相应的写出红线标出的部分</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pycharm/3.png" alt></p>
<p>最后，打开pycharm就可以了。这时不会再在C盘创建.pycharm2019.3目录了。问题解决</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>解决nvidia-smi和nvcc显示信息与所安装CUDA版本不一致问题</title>
    <url>/2022/01/06/%E8%A7%A3%E5%86%B3nvidia-smi%E5%92%8Cnvcc%E6%98%BE%E7%A4%BA%E4%BF%A1%E6%81%AF%E4%B8%8E%E6%89%80%E5%AE%89%E8%A3%85CUDA%E7%89%88%E6%9C%AC%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h2 id="nvidia-smi-amp-nvcc-V"><a href="#nvidia-smi-amp-nvcc-V" class="headerlink" title="nvidia-smi &amp; nvcc -V"></a>nvidia-smi &amp; nvcc -V</h2><p>首先需明白CUDA有runtime api和driver api，两者都有对应的CUDA版本，<code>nvcc -V</code>显示前者对应的CUDA版本，而<code>nvidia-smi</code>显示后者对应的CUDA版本。</p>
<p>通常，driver api版本能向下兼容runtime api的版本，即<code>nvidia-smi</code>显示的版本大于<code>nvcc -V</code>的版本通常不会出现大问题。因此<code>nvidia-smi</code>显示的版本与所安装CUDA版本不一致是正常的。</p>
<p>而平常我们做深度学习所用的是CUDA的runtime api版本，因此以<code>nvcc -V</code>为准，这里版本如果不一致就容易发生问题。其原因主要是本机存在多个CUDA，没有正确映射造成。</p>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>查询现在的映射关系，可通过如下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">stat /usr/bin/nvcc</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/cuda/image-20220106101722613.png" alt></p>
<p>要是映射错误，需重新建立映射：</p>
<p>① 删除原来映射</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /usr/bin/nvcc</span><br></pre></td></tr></table></figure>
<p>② 建立新的软链接指向安装的CUDA版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ln -s /usr/local/cuda/bin/nvcc /usr/bin/nvcc</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
        <tag>cuDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>解决梅林新版软件中心禁止安装含非法关键词的插件</title>
    <url>/2022/01/16/%E8%A7%A3%E5%86%B3%E6%A2%85%E6%9E%97%E6%96%B0%E7%89%88%E8%BD%AF%E4%BB%B6%E4%B8%AD%E5%BF%83%E7%A6%81%E6%AD%A2%E5%AE%89%E8%A3%85%E5%90%AB%E9%9D%9E%E6%B3%95%E5%85%B3%E9%94%AE%E8%AF%8D%E7%9A%84%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>因为某些不可抗力的原因，梅林新版的软件中心离线安装科学插件的时候会出现下面的提示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/a415b7142f88f7d6d14de00c77684110923cde50.png@progressive.webp" alt></p>
<p>因此，为了安装插件，我们需要手动修改路由的安装脚本来跳过软件中心的检测。</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>① 进入路由[系统管理]-[系统设置]页面，更改[启用ssh]的选项为[LAN only]，[允许使用密码登录]为是，开启路由器的SSH功能。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/8f51831b741479132a152653e9519567bc757d2b.png@progressive.webp" alt></p>
<p>② 使用ssh客户端连接路由器，用账号密码登录。不会的请自行百度，也可参照我之前的<a href="https://qiyuan-z.github.io/2020/01/26/Ubuntu%E9%85%8D%E7%BD%AESSH%E5%92%8CXshell%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%95%99%E7%A8%8B/">教程</a>，下载Xshell之类的软件，登录服务器IP即为路由器的网关，华硕路由器默认(192.168.50.1)，SSH端口如图，默认为22。这里就不再细讲了。</p>
<p>③ 输入如下命令执行，即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sed -i &#x27;s/\tdetect_package/\t# detect_package/g&#x27; /koolshare/scripts/ks_tar_install.sh</span><br></pre></td></tr></table></figure>
<p>其原理就是编辑<code>/koolshare/scripts/ks_tar_install.sh</code>安装脚本文件，找到 <code>detect_package()</code>函数，把<code>ILLEGAL_KEYWORDS</code>这一行引号里面的内容删除。</p>
<p>因此，你也可以远程用记事本或<code>vim</code>之类的命令，对该文件进行编辑，手动删除保存即可。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/merlin/e4035d6254dd910f011d3e2a959c3f604fb3bd49.png@progressive.webp" alt></p>
<p>执行完该命令后，就跳过了软件中心的检测机制，可以自由的安装科学插件了。 </p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title>解决远程screen后，虚拟环境中的包丢了(如torch, tensorflow)</title>
    <url>/2020/05/04/%E8%A7%A3%E5%86%B3%E8%BF%9C%E7%A8%8Bscreen%E5%90%8E%EF%BC%8C%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E5%8C%85%E4%B8%A2%E4%BA%86%EF%BC%88%E5%A6%82torch,tensorflow%EF%BC%89/</url>
    <content><![CDATA[<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>1、在进入screen之前不要激活虚拟环境，待进入screen后再激活所需的虚拟环境。</p>
<p>2、出现如下错误时：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: libcudart.so.10.0: cannot open shared object file...</span><br></pre></td></tr></table></figure><br>解决方式：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo ldconfig /usr/local/cuda-10.0/lib64</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>设置Pycharm plots不在tool window显示</title>
    <url>/2020/01/26/%E8%AE%BE%E7%BD%AEPycharm-plots%E4%B8%8D%E5%9C%A8tool-window%E6%98%BE%E7%A4%BA/</url>
    <content><![CDATA[<p>Pycharm画图默认在tool windows显示，对于观看、操作其极不方便，特别是画动态图时，还会把每帧都输出，因此最好设置让它单独窗口显示。<br>如下图，把勾去掉即可。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/plot/Snipaste_2020-01-26_14-14-13.jpg" alt></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title>远程使用tensorboard等可视化工具</title>
    <url>/2020/05/27/%E8%BF%9C%E7%A8%8B%E4%BD%BF%E7%94%A8tensorboard%E7%AD%89%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/</url>
    <content><![CDATA[<p>有两种设置方法，一种代码设置，一种xshell界面设置</p>
<h2 id="连接SSH"><a href="#连接SSH" class="headerlink" title="连接SSH"></a>连接SSH</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh -L 16006:127.0.0.1:6006 -p 31017 username@remote_server_ip</span><br></pre></td></tr></table></figure>
<p><strong>16006:127.0.0.1:6006</strong> 代表本机6006端口映射为16006号端口，这两个端口号可以自己设置，不要与其他端口号冲突即可</p>
<p><strong>-p 31017</strong> 代表所连远程服务器的端口号，即SSH所用端口号</p>
<p><strong>username@remote_server_ip</strong> 代表你的用户名和SSH所连ip地址</p>
<p>在服务器上使用6006端口正常启动tensorboard：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=xxx --port=6006</span><br></pre></td></tr></table></figure>
<p><strong>—port=6006</strong> 代表将端口号指定为6006</p>
<p>由于上一步我们将端口号6006映射到16006，因此在本地浏览器输入地址：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">127.0.0.1:16006</span><br></pre></td></tr></table></figure>
<p>即可远程访问tensorboard</p>
<h2 id="使用Xshell"><a href="#使用Xshell" class="headerlink" title="使用Xshell"></a>使用Xshell</h2><p>在Windows系统装一个Xshell，在文件-&gt;属性-&gt;ssh-&gt;隧道-&gt;添加，类型local，源主机填127.0.0.1或者localhost（意思是本机），倾听端口为16006，表示把目标主机的目标端口转发到本地的侦听端口16006  （可自己设置），目标主机：服务器，填写服务器的ip，目标端口一般是6006（可自己设置）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/SSH/1.png" alt></p>
<p>在服务器上运行 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=xxx --port=6006</span><br></pre></td></tr></table></figure>
<p>在本机打开网页127.0.0.1:16006 ，即可查看远程的tensorboard</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet加载数据进行训练</title>
    <url>/2020/02/21/AlexeyAB-DarkNet%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前讲了DarkNet的底层数据结构，并且将网络配置文件进行了解析存放到了一个<code>network</code>结构体中，那么我们就要来看一下Darknet是如何加载数据进行训练的。</p>
<h2 id="加载训练数据"><a href="#加载训练数据" class="headerlink" title="加载训练数据"></a>加载训练数据</h2><p>DarkNet的数据加载函数<code>load_data()</code>在<code>src/data.c</code>中实现（<code>src/detector.c</code>函数中的<code>train_detector</code>直接调用这个函数加载数据）。<code>load_data()</code>函数调用流程如下：<code>load_data(args)-&gt;load_threads()-&gt;load_data_in_threads()-&gt;load_thread()-&gt;load_data_detection()</code>，前四个函数都是在对线程的调用进行封装。最底层的数据加载任务由<code>load_data_detection()</code>函数完成。所有的数据(图片数据和标注信息数据)加载完成之后再拼接到一个大的数组中。在DarkNet中，图片的存储形式是一个行向量，向量长度为<code>h*w*3</code>。同时图片被归一化到<code>[0, 1]</code>之间。</p>
<h2 id="load-threads-完成线程分配和数据拼接"><a href="#load-threads-完成线程分配和数据拼接" class="headerlink" title="load_threads()完成线程分配和数据拼接"></a>load_threads()完成线程分配和数据拼接</h2><p><code>load_threads</code>在<code>src/data.c</code>中实现，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// copy from https://github.com/hgpvision/darknet/blob/master/src/data.c#L355</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 开辟多个线程读入图片数据，读入数据存储至ptr.d中（主要调用load_in_thread()函数完成）</span></span><br><span class="line"><span class="comment">** 输入：ptr    包含所有线程要读入图片数据的信息（读入多少张，开几个线程读入，读入图片最终的宽高，图片路径等等）</span></span><br><span class="line"><span class="comment">** 返回：void*  万能指针（实际上不需要返回什么）</span></span><br><span class="line"><span class="comment">** 说明：1) load_threads()是一个指针函数，只是一个返回变量为void*的普通函数，不是函数指针</span></span><br><span class="line"><span class="comment">**       2) 输入ptr是一个void*指针（万能指针），使用时需要强转为具体类型的指针</span></span><br><span class="line"><span class="comment">**       3) 函数中涉及四个用来存储读入数据的变量：ptr, args, out, buffers，除args外都是data*类型，所有这些变量的</span></span><br><span class="line"><span class="comment">**          指针变量其实都指向同一块内存（当然函数中间有些动态变化），因此读入的数据都是互通的。</span></span><br><span class="line"><span class="comment">** 流程：本函数首先会获取要读入图片的张数、要开启线程的个数，而后计算每个线程应该读入的图片张数（尽可能的均匀分配），</span></span><br><span class="line"><span class="comment">**       并创建所有的线程，并行读入数据，最后合并每个线程读入的数据至一个大data中，这个data的指针变量与ptr的指针变量</span></span><br><span class="line"><span class="comment">**       指向的是统一块内存，因此也就最终将数据读入到ptr.d中（所以其实没有返回值）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">load_threads</span><span class="params">(<span class="keyword">void</span> *ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//srand(time(0));</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 先使用(load_args*)强转void*指针，而后取ptr所指内容赋值给args</span></span><br><span class="line">    <span class="comment">// 虽然args不是指针，args是深拷贝了ptr中的内容，但是要知道ptr（也就是load_args数据类型），有很多的</span></span><br><span class="line">    <span class="comment">// 指针变量，args深拷贝将拷贝这些指针变量到args中（这些指针变量本身对ptr来说就是内容，</span></span><br><span class="line">    <span class="comment">// 而args所指的值是args的内容，不是ptr的，不要混为一谈），因此，args与ptr将会共享所有指针变量所指的内容</span></span><br><span class="line">    load_args args = *(load_args *)ptr;</span><br><span class="line">    <span class="keyword">if</span> (args.threads == <span class="number">0</span>) args.threads = <span class="number">1</span>;</span><br><span class="line">	<span class="comment">// 另指针变量out=args.d，使得out与args.d指向统一块内存，之后，args.d所指的内存块会变（反正也没什么用了，变就变吧），</span></span><br><span class="line">    <span class="comment">// 但out不会变，这样可以保证out与最原始的ptr指向同一块存储读入图片数据的内存块，因此最终将图片读到out中，</span></span><br><span class="line">    <span class="comment">// 实际就是读到了最原始的ptr中，比如train_detector()函数中定义的args.d中</span></span><br><span class="line">    data *out = args.d;</span><br><span class="line">	<span class="comment">// 读入图片的总张数= batch * subdivision * ngpus，可参见train_detector()函数中的赋值</span></span><br><span class="line">    <span class="keyword">int</span> total = args.n;</span><br><span class="line">	<span class="comment">// 释放ptr：ptr是传入的指针变量，传入的指针变量本身也是按值传递的，即传入函数之后，指针变量得到复制，函数内的形参ptr</span></span><br><span class="line">    <span class="comment">// 获取外部实参的值之后，二者本身没有关系，但是由于是指针变量，二者之间又存在一丝关系，那就是函数内形参与函数外实参指向</span></span><br><span class="line">    <span class="comment">// 同一块内存。又由于函数外实参内存是动态分配的，因此函数内的形参可以使用free()函数进行内存释放，但一般不推荐这么做，因为函数内释放内存，</span></span><br><span class="line">    <span class="comment">// 会影响函数外实参的使用，可能使之成为野指针，那为什么这里可以用free()释放ptr呢，不会出现问题吗？</span></span><br><span class="line">    <span class="comment">// 其一，因为ptr是一个结构体，是一个包含众多的指针变量的结构体，如data* d等（当然还有其他非指针变量如int h等），</span></span><br><span class="line">    <span class="comment">// 直接free(ptr)将会导致函数外实参无法再访问非指针变量int h等（实际经过测试，在gcc编译器下，能访问但是值被重新初始化为0），</span></span><br><span class="line">    <span class="comment">// 因为函数内形参和函数外实参共享一块堆内存，而这些非指针变量都是存在这块堆内存上的，内存一释放，就无法访问了；</span></span><br><span class="line">    <span class="comment">// 但是对于指针变量，free(ptr)将无作为（这个结论也是经过测试的，也是用的gcc编译器），不会释放或者擦写掉ptr指针变量本身的值，</span></span><br><span class="line">    <span class="comment">// 当然也不会影响函数外实参，更不会牵扯到这些指针变量所指的内存块，总的来说，</span></span><br><span class="line">    <span class="comment">// free(ptr)将使得ptr不能再访问指针变量（如int h等，实际经过测试，在gcc编译器下，能访问但是值被重新初始化为0），</span></span><br><span class="line">    <span class="comment">// 但其指针变量本身没有受影响，依旧可以访问；对于函数外实参，同样不能访问非指针变量，而指针变量不受影响，依旧可以访问。</span></span><br><span class="line">    <span class="comment">// 其二，darknet数据读取的实现一层套一层（似乎有点罗嗦，总感觉代码可以不用这么写的:)），具体调用过程如下：</span></span><br><span class="line">    <span class="comment">// load_data(load_args args)-&gt;load_threads(load_args* ptr)-&gt;load_data_in_thread(load_args args)-&gt;load_thread(load_args* ptr)，</span></span><br><span class="line">    <span class="comment">// 就在load_data()中，重新定义了ptr，并为之动态分配了内存，且深拷贝了传给load_data()函数的值args，也就是说在此之后load_data()函数中的args除了其中的指针变量指着同一块堆内存之外，</span></span><br><span class="line">    <span class="comment">// 二者的非指针变量再无瓜葛，不管之后经过多少个函数，对ptr的非指针变量做了什么改动，比如这里直接free(ptr)，使得非指针变量值为0,都不会影响load_data()中的args的非指针变量，也就不会影响更为顶层函数中定义的args的非指针变量的值，</span></span><br><span class="line">    <span class="comment">// 比如train_detector()函数中的args，train_detector()对args非指针变量赋的值都不会受影响，保持不变。综其两点，此处直接free(ptr)是安全的。</span></span><br><span class="line">    <span class="comment">// 说明：free(ptr)函数，确定会做的事是使得内存块可以重新分配，且不会影响指针变量ptr本身的值，也就是ptr还是指向那块地址， 虽然可以使用，但很危险，因为这块内存实际是无效的，</span></span><br><span class="line">    <span class="comment">//      系统已经认为这块内存是可分配的，会毫不考虑的将这块内存分给其他变量，这样，其值随时都可能会被其他变量改变，这种情况下的ptr指针就是所谓的野指针（所以经常可以看到free之后，置原指针为NULL）。</span></span><br><span class="line">    <span class="comment">//      而至于free(ptr)还不会做其他事情，比如会不会重新初始化这块内存为0（擦写掉），以及怎么擦写，这些操作，是不确定的，可能跟具体的编译器有关（个人猜测），</span></span><br><span class="line">    <span class="comment">//      经过测试，对于gcc编译器，free(ptr)之后，ptr中的非指针变量的地址不变，但其值全部擦写为0；ptr中的指针变量，丝毫不受影响，指针变量本身没有被擦写，</span></span><br><span class="line">    <span class="comment">//      存储的地址还是指向先前分配的内存块，所以ptr能够正常访问其指针变量所指的值。测试代码为darknet_test_struct_memory_free.c。</span></span><br><span class="line">    <span class="comment">//      不知道这段测试代码在VS中执行会怎样，还没经过测试，也不知道换用其他编译器（darknet的Makefile文件中，指定了编译器为gcc），darknet的编译会不会有什么问题？？</span></span><br><span class="line">    <span class="comment">//      关于free()，可以看看：http://blog.sina.com.cn/s/blog_615ec1630102uwle.html，文章最后有一个很有意思的比喻，但意思好像就和我这里说的有点不一样了（到底是不是编译器搞得鬼呢？？）。</span></span><br><span class="line">    <span class="built_in">free</span>(ptr);</span><br><span class="line">	<span class="comment">// 每一个线程都会读入一个data，定义并分配args.thread个data的内存</span></span><br><span class="line">    data* buffers = (data*)<span class="built_in">xcalloc</span>(args.threads, <span class="built_in"><span class="keyword">sizeof</span></span>(data));</span><br><span class="line">    <span class="keyword">pthread_t</span>* threads = (<span class="keyword">pthread_t</span>*)<span class="built_in">xcalloc</span>(args.threads, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">pthread_t</span>));</span><br><span class="line">	<span class="comment">// 此处定义了多个线程，并为每个线程动态分配内存</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; args.threads; ++i)&#123;</span><br><span class="line">		<span class="comment">// 此处就承应了上面的注释，args.d指针变量本身发生了改动，使得本函数的args.d与out不再指向同一块内存，</span></span><br><span class="line">        <span class="comment">// 改为指向buffers指向的某一段内存，因为下面的load_data_in_thread()函数统一了结口，需要输入一个load_args类型参数，</span></span><br><span class="line">        <span class="comment">// 实际是想把图片数据读入到buffers[i]中，只能令args.d与buffers[i]指向同一块内存</span></span><br><span class="line">        args.d = buffers + i;</span><br><span class="line">		 <span class="comment">// 下面这句很有意思，因为有多个线程，所有线程读入的总图片张数为total，需要将total均匀的分到各个线程上，</span></span><br><span class="line">        <span class="comment">// 但很可能会遇到total不能整除的args.threads的情况，比如total = 61, args.threads =8,显然不能做到</span></span><br><span class="line">        <span class="comment">// 完全均匀的分配，但又要保证读入图片的总张数一定等于total，用下面的语句刚好在尽量均匀的情况下，</span></span><br><span class="line">        <span class="comment">// 保证总和为total，比如61,那么8个线程各自读入的照片张数分别为：7, 8, 7, 8, 8, 7, 8, 8</span></span><br><span class="line">        args.n = (i+<span class="number">1</span>) * total/args.threads - i * total/args.threads;</span><br><span class="line">		<span class="comment">// 开启线程，读入数据到args.d中（也就读入到buffers[i]中）</span></span><br><span class="line">        <span class="comment">// load_data_in_thread()函数返回所开启的线程，并存储之前已经动态分配内存用来存储所有线程的threads中，</span></span><br><span class="line">        <span class="comment">// 方便下面使用pthread_join()函数控制相应线程</span></span><br><span class="line">        threads[i] = <span class="built_in">load_data_in_thread</span>(args);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; args.threads; ++i)&#123;</span><br><span class="line">		<span class="comment">// 以阻塞的方式等待线程threads[i]结束：阻塞是指阻塞启动该子线程的母线程（此处应为主线程），</span></span><br><span class="line">        <span class="comment">// 是母线程处于阻塞状态，一直等待所有子线程执行完（读完所有数据）才会继续执行下面的语句</span></span><br><span class="line">        <span class="comment">// 关于多线程的使用，进行过代码测试，测试代码对应：darknet_test_pthread_join.c</span></span><br><span class="line">        <span class="built_in">pthread_join</span>(threads[i], <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 多个线程读入所有数据之后，分别存储到buffers[0],buffers[1]...中，接着使用concat_datas()函数将buffers中的数据全部合并成一个大数组得到out</span></span><br><span class="line">    *out = <span class="built_in">concat_datas</span>(buffers, args.threads);</span><br><span class="line">	 <span class="comment">// 也就只有out的shallow敢置为0了，为什么呢？因为out是此次迭代读入的最终数据，该数据参与训练（用完）之后，当然可以深层释放了，而此前的都是中间变量，</span></span><br><span class="line">    <span class="comment">// 还处于读入数据阶段，万不可设置shallow=0</span></span><br><span class="line">    out-&gt;shallow = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 释放buffers，buffers也是个中间变量，切记shallow设置为1,如果设置为0,那就连out中的数据也没了</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; args.threads; ++i)&#123;</span><br><span class="line">        buffers[i].shallow = <span class="number">1</span>;</span><br><span class="line">        <span class="built_in">free_data</span>(buffers[i]);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 最终直接释放buffers,threads，注意buffers是一个存储data的一维数组，上面循环中的内存释放，实际是释放每一个data的部分内存</span></span><br><span class="line">    <span class="comment">// （这部分内存对data而言是非主要内存，不是存储读入数据的内存块，而是存储指向这些内存块的指针变量，可以释放的）</span></span><br><span class="line">    <span class="built_in">free</span>(buffers);</span><br><span class="line">    <span class="built_in">free</span>(threads);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="load-data-in-thread-分配线程"><a href="#load-data-in-thread-分配线程" class="headerlink" title="load_data_in_thread()分配线程"></a>load_data_in_thread()分配线程</h2><p><code>load_data_in_thread()</code>函数仍然在<code>src/data.c</code>中，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 创建一个线程，读入相应图片数据（此时args.n不再是一次迭代读入的所有图片的张数，而是经过load_threads()均匀分配给每个线程的图片张数）</span></span><br><span class="line"><span class="comment">** 输入：args    包含该线程要读入图片数据的信息（读入多少张，读入图片最终的宽高，图片路径等等）</span></span><br><span class="line"><span class="comment">** 返回：phtread_t   线程id</span></span><br><span class="line"><span class="comment">** 说明：本函数实际没有做什么，就是深拷贝了args给ptr,然后创建了一个调用load_thread()函数的线程并返回线程id</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">pthread_t</span> <span class="title">load_data_in_thread</span><span class="params">(load_args args)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">pthread_t</span> thread;</span><br><span class="line">	<span class="comment">// 同样第一件事深拷贝了args给ptr</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">load_args</span>* <span class="title">ptr</span> =</span> (load_args*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(struct load_args));</span><br><span class="line">    *ptr = args;</span><br><span class="line">	<span class="comment">// 创建一个线程，读入相应数据，绑定load_thread()函数到该线程上，第四个参数是load_thread()的输入参数，第二个参数表示线程属性，设置为0（即NULL）</span></span><br><span class="line">	<span class="comment">//当创建线程成功时，函数返回0，若不为0则说明创建线程失败</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">pthread_create</span>(&amp;thread, <span class="number">0</span>, load_thread, ptr)) <span class="built_in">error</span>(<span class="string">&quot;Thread creation failed&quot;</span>); </span><br><span class="line">    <span class="keyword">return</span> thread;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="load-data-detection-完成底层的数据加载任务"><a href="#load-data-detection-完成底层的数据加载任务" class="headerlink" title="load_data_detection()完成底层的数据加载任务"></a>load_data_detection()完成底层的数据加载任务</h2><p><code>load_data_detection()</code>函数也定义在<code>src/data.c</code>中，带注释的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 可以参考，看一下对图像进行jitter处理的各种效果:</span></span><br><span class="line"><span class="comment">** https://github.com/vxy10/ImageAugmentation</span></span><br><span class="line"><span class="comment">** 从所有训练图片中，随机读取n张，并对这n张图片进行数据增强，同时矫正增强后的数据标签信息。最终得到的图片的宽高为w,h（原始训练集中的图片尺寸不定），也就是网络能够处理的图片尺寸，</span></span><br><span class="line"><span class="comment">** 数据增强包括：对原始图片进行宽高方向上的插值缩放（两方向上缩放系数不一定相同），下面称之为缩放抖动；随机抠取或者平移图片（位置抖动）；</span></span><br><span class="line"><span class="comment">** 在hsv颜色空间增加噪声（颜色抖动）；左右水平翻转，不含旋转抖动。</span></span><br><span class="line"><span class="comment">** 输入： n         一个线程读入的图片张数（详见函数内部注释）</span></span><br><span class="line"><span class="comment">**       paths     所有训练图片所在路径集合，是一个二维数组，每一行对应一张图片的路径（将在其中随机取n个）</span></span><br><span class="line"><span class="comment">**       m         paths的行数，也即训练图片总数</span></span><br><span class="line"><span class="comment">**       w         网络能够处理的图的宽度（也就是输入图片经过一系列数据增强、变换之后最终输入到网络的图的宽度）</span></span><br><span class="line"><span class="comment">**       h         网络能够处理的图的高度（也就是输入图片经过一系列数据增强、变换之后最终输入到网络的图的高度）</span></span><br><span class="line"><span class="comment">**       c         用来指定训练图片的通道数（默认为3，即RGB图）</span></span><br><span class="line"><span class="comment">**       boxes     每张训练图片最大处理的矩形框数（图片内可能含有更多的物体，即更多的矩形框，那么就在其中随机选择boxes个参与训练，具体执行在fill_truth_detection()函数中）</span></span><br><span class="line"><span class="comment">**       classes   类别总数，本函数并未用到（fill_truth_detection函数其实并没有用这个参数）</span></span><br><span class="line"><span class="comment">**       use_flip  是否使用水平翻转</span></span><br><span class="line"><span class="comment">**       use_mixup 是否使用mixup数据增强</span></span><br><span class="line"><span class="comment">**       jitter    这个参数为缩放抖动系数，就是图片缩放抖动的剧烈程度，越大，允许的抖动范围越大（所谓缩放抖动，就是在宽高上插值缩放图片，宽高两方向上缩放的系数不一定相同）</span></span><br><span class="line"><span class="comment">**       hue       颜色（hsv颜色空间）数据增强参数：色调（取值0度到360度）偏差最大值，实际色调偏差为-hue~hue之间的随机值</span></span><br><span class="line"><span class="comment">**       saturation 颜色（hsv颜色空间）数据增强参数：色彩饱和度（取值范围0~1）缩放最大值，实际为范围内的随机值</span></span><br><span class="line"><span class="comment">**       exposure  颜色（hsv颜色空间）数据增强参数：明度（色彩明亮程度，0~1）缩放最大值，实际为范围内的随机值</span></span><br><span class="line"><span class="comment">**       mini_batch      和目标跟踪有关，这里不关注</span></span><br><span class="line"><span class="comment">**       track           和目标跟踪有关，这里不关注</span></span><br><span class="line"><span class="comment">**       augment_speed   和目标跟踪有关，这里不关注</span></span><br><span class="line"><span class="comment">**       letter_box 是否进行letter_box变换</span></span><br><span class="line"><span class="comment">**       show_imgs</span></span><br><span class="line"><span class="comment">** 返回：data类型数据，包含一个线程读入的所有图片数据（含有n张图片）</span></span><br><span class="line"><span class="comment">** 说明：最后四个参数用于数据增强，主要对原图进行缩放抖动，位置抖动（平移）以及颜色抖动（颜色值增加一定噪声），抖动一定程度上可以理解成对图像增加噪声。</span></span><br><span class="line"><span class="comment">**       通过对原始图像进行抖动，实现数据增强。最后三个参数具体用法参考本函数内调用的random_distort_image()函数</span></span><br><span class="line"><span class="comment">** 说明2：从此函数可以看出，darknet对训练集中图片的尺寸没有要求，可以是任意尺寸的图片，因为经该函数处理（缩放/裁剪）之后，</span></span><br><span class="line"><span class="comment">**       不管是什么尺寸的照片，都会统一为网络训练使用的尺寸</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="function">data <span class="title">load_data_detection</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">char</span> **paths, <span class="keyword">int</span> m, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> c, <span class="keyword">int</span> boxes, <span class="keyword">int</span> classes, <span class="keyword">int</span> use_flip, <span class="keyword">int</span> use_blur, <span class="keyword">int</span> use_mixup, <span class="keyword">float</span> jitter,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">float</span> hue, <span class="keyword">float</span> saturation, <span class="keyword">float</span> exposure, <span class="keyword">int</span> mini_batch, <span class="keyword">int</span> track, <span class="keyword">int</span> augment_speed, <span class="keyword">int</span> letter_box, <span class="keyword">int</span> show_imgs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> random_index = <span class="built_in">random_gen</span>();</span><br><span class="line">    c = c ? c : <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">char</span> **random_paths;</span><br><span class="line">    <span class="keyword">char</span> **mixup_random_paths = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="comment">// paths包含所有训练图片的路径，get_random_paths函数从中随机提出n条，即为此次读入的n张图片的路径</span></span><br><span class="line">    <span class="keyword">if</span>(track) random_paths = <span class="built_in">get_sequential_paths</span>(paths, n, m, mini_batch, augment_speed);</span><br><span class="line">    <span class="keyword">else</span> random_paths = <span class="built_in">get_random_paths</span>(paths, n, m);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">assert</span>(use_mixup &lt; <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">int</span> mixup = use_mixup ? <span class="built_in">random_gen</span>() % <span class="number">2</span> : <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//printf(&quot;\n mixup = %d \n&quot;, mixup);</span></span><br><span class="line">	<span class="comment">// 如果使用mixup策略，需要再随机取出n条数据，即n张图片</span></span><br><span class="line">    <span class="keyword">if</span> (mixup) &#123;</span><br><span class="line">        <span class="keyword">if</span> (track) mixup_random_paths = <span class="built_in">get_sequential_paths</span>(paths, n, m, mini_batch, augment_speed);</span><br><span class="line">        <span class="keyword">else</span> mixup_random_paths = <span class="built_in">get_random_paths</span>(paths, n, m);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 初始化为0,清空内存中之前的旧值</span></span><br><span class="line">    data d = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    d.shallow = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 一次读入的图片张数：d.X中每行就是一张图片的数据，因此d.X.cols等于h*w*3</span></span><br><span class="line">    <span class="comment">// n = net.batch * net.subdivisions * ngpus</span></span><br><span class="line">    <span class="comment">// 从parse_net_option()函数可知，net.batch = net.batch / net.subdivision</span></span><br><span class="line">    <span class="comment">// net.batch * net.subdivisions就得到了在网络配置文件中设定的batch值，即网络配置文件.cfg中设置的每个batch的图片数量, 然后乘以ngpus，是考虑多个GPU实现数据并行，</span></span><br><span class="line">    <span class="comment">// 一次读入多个batch的数据，分配到不同GPU上进行训练。在load_threads()函数中，又将整个的n仅可能均匀的划分到每个线程上，</span></span><br><span class="line">    <span class="comment">// 也就是总的读入图片张数为n = net.batch * net.subdivisions * ngpus，但这些图片不是一个线程读完的，而是分配到多个线程并行读入，</span></span><br><span class="line">    <span class="comment">// 因此本函数中的n实际不是总的n，而是分配到该线程上的n，比如总共要读入128张图片，共开启8个线程读数据，那么本函数中的n为16,而不是总数128</span></span><br><span class="line">    d.X.rows = n;</span><br><span class="line">	<span class="comment">//d.X为一个matrix类型数据，其中d.X.vals是其具体数据，是指针的指针（即为二维数组），此处先为第一维动态分配内存</span></span><br><span class="line">    d.X.vals = (<span class="keyword">float</span>**)<span class="built_in">xcalloc</span>(d.X.rows, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>*));</span><br><span class="line">    d.X.cols = h*w*c;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> r1 = <span class="number">0</span>, r2 = <span class="number">0</span>, r3 = <span class="number">0</span>, r4 = <span class="number">0</span>, r_scale;</span><br><span class="line">    <span class="keyword">float</span> dhue = <span class="number">0</span>, dsat = <span class="number">0</span>, dexp = <span class="number">0</span>, flip = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> augmentation_calculated = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// d.y存储了所有读入照片的标签信息，每条标签包含5条信息：类别，以及矩形框的x,y,w,h</span></span><br><span class="line">    <span class="comment">// boxes为一张图片最多能够处理（参与训练）的矩形框的数（如果图片中的矩形框数多于这个数，那么随机挑选boxes个，这个参数仅在parse_region以及parse_detection中出现</span></span><br><span class="line">    <span class="comment">// 在其他网络解析函数中并没有出现。同样，d.y是一个matrix，make_matrix会指定y的行数和列数，同时会为其第一维动态分配内存</span></span><br><span class="line">    d.y = <span class="built_in">make_matrix</span>(n, <span class="number">5</span> * boxes);</span><br><span class="line">    <span class="keyword">int</span> i_mixup = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i_mixup = <span class="number">0</span>; i_mixup &lt;= mixup; i_mixup++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i_mixup) augmentation_calculated = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">			</span><br><span class="line">            <span class="keyword">float</span> *truth = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(<span class="number">5</span> * boxes, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">            <span class="keyword">char</span> *filename = (i_mixup) ? mixup_random_paths[i] : random_paths[i];</span><br><span class="line">			<span class="comment">//读入原始的图片</span></span><br><span class="line">            image orig = <span class="built_in">load_image</span>(filename, <span class="number">0</span>, <span class="number">0</span>, c);</span><br><span class="line">			<span class="comment">// 原始图像长宽</span></span><br><span class="line">            <span class="keyword">int</span> oh = orig.h;</span><br><span class="line">            <span class="keyword">int</span> ow = orig.w;</span><br><span class="line">			<span class="comment">// 缩放抖动大小：缩放抖动系数乘以原始图宽高即得像素单位意义上的缩放抖动</span></span><br><span class="line">            <span class="keyword">int</span> dw = (ow*jitter);</span><br><span class="line">            <span class="keyword">int</span> dh = (oh*jitter);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!augmentation_calculated || !track)</span><br><span class="line">            &#123;</span><br><span class="line">                augmentation_calculated = <span class="number">1</span>;</span><br><span class="line">                r1 = <span class="built_in">random_float</span>();</span><br><span class="line">                r2 = <span class="built_in">random_float</span>();</span><br><span class="line">                r3 = <span class="built_in">random_float</span>();</span><br><span class="line">                r4 = <span class="built_in">random_float</span>();</span><br><span class="line"></span><br><span class="line">                r_scale = <span class="built_in">random_float</span>();</span><br><span class="line"></span><br><span class="line">                dhue = <span class="built_in">rand_uniform_strong</span>(-hue, hue);</span><br><span class="line">                dsat = <span class="built_in">rand_scale</span>(saturation);</span><br><span class="line">                dexp = <span class="built_in">rand_scale</span>(exposure);</span><br><span class="line"></span><br><span class="line">                flip = use_flip ? <span class="built_in">random_gen</span>() % <span class="number">2</span> : <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> pleft = <span class="built_in">rand_precalc_random</span>(-dw, dw, r1);</span><br><span class="line">            <span class="keyword">int</span> pright = <span class="built_in">rand_precalc_random</span>(-dw, dw, r2);</span><br><span class="line">            <span class="keyword">int</span> ptop = <span class="built_in">rand_precalc_random</span>(-dh, dh, r3);</span><br><span class="line">            <span class="keyword">int</span> pbot = <span class="built_in">rand_precalc_random</span>(-dh, dh, r4);</span><br><span class="line">			<span class="comment">// 这个系数没用到</span></span><br><span class="line">            <span class="keyword">float</span> scale = <span class="built_in">rand_precalc_random</span>(<span class="number">.25</span>, <span class="number">2</span>, r_scale); <span class="comment">// unused currently</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (letter_box)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">float</span> img_ar = (<span class="keyword">float</span>)ow / (<span class="keyword">float</span>)oh; <span class="comment">//原始图像宽高比</span></span><br><span class="line">                <span class="keyword">float</span> net_ar = (<span class="keyword">float</span>)w / (<span class="keyword">float</span>)h; <span class="comment">//输入到网络要求的图像宽高比</span></span><br><span class="line">                <span class="keyword">float</span> result_ar = img_ar / net_ar; <span class="comment">//两者求比值来判断如何进行letter_box缩放</span></span><br><span class="line">                <span class="comment">//printf(&quot; ow = %d, oh = %d, w = %d, h = %d, img_ar = %f, net_ar = %f, result_ar = %f \n&quot;, ow, oh, w, h, img_ar, net_ar, result_ar);</span></span><br><span class="line">                <span class="keyword">if</span> (result_ar &gt; <span class="number">1</span>)  <span class="comment">// sheight - should be increased</span></span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">float</span> oh_tmp = ow / net_ar;</span><br><span class="line">                    <span class="keyword">float</span> delta_h = (oh_tmp - oh) / <span class="number">2</span>;</span><br><span class="line">                    ptop = ptop - delta_h;</span><br><span class="line">                    pbot = pbot - delta_h;</span><br><span class="line">                    <span class="comment">//printf(&quot; result_ar = %f, oh_tmp = %f, delta_h = %d, ptop = %f, pbot = %f \n&quot;, result_ar, oh_tmp, delta_h, ptop, pbot);</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>  <span class="comment">// swidth - should be increased</span></span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">float</span> ow_tmp = oh * net_ar;</span><br><span class="line">                    <span class="keyword">float</span> delta_w = (ow_tmp - ow) / <span class="number">2</span>;</span><br><span class="line">                    pleft = pleft - delta_w;</span><br><span class="line">                    pright = pright - delta_w;</span><br><span class="line">                    <span class="comment">//printf(&quot; result_ar = %f, ow_tmp = %f, delta_w = %d, pleft = %f, pright = %f \n&quot;, result_ar, ow_tmp, delta_w, pleft, pright);</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">			<span class="comment">// 以下步骤就是执行了letter_box变换</span></span><br><span class="line">            <span class="keyword">int</span> swidth = ow - pleft - pright;</span><br><span class="line">            <span class="keyword">int</span> sheight = oh - ptop - pbot;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">float</span> sx = (<span class="keyword">float</span>)swidth / ow;</span><br><span class="line">            <span class="keyword">float</span> sy = (<span class="keyword">float</span>)sheight / oh;</span><br><span class="line"></span><br><span class="line">            image cropped = <span class="built_in">crop_image</span>(orig, pleft, ptop, swidth, sheight);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">float</span> dx = ((<span class="keyword">float</span>)pleft / ow) / sx;</span><br><span class="line">            <span class="keyword">float</span> dy = ((<span class="keyword">float</span>)ptop / oh) / sy;</span><br><span class="line">			<span class="comment">// resize到指定大小</span></span><br><span class="line">            image sized = <span class="built_in">resize_image</span>(cropped, w, h);</span><br><span class="line">            <span class="comment">// 翻转</span></span><br><span class="line">			<span class="keyword">if</span> (flip) <span class="built_in">flip_image</span>(sized);</span><br><span class="line">			<span class="comment">//随机对图像jitter（在hsv三个通道上添加扰动），实现数据增强</span></span><br><span class="line">            <span class="built_in">distort_image</span>(sized, dhue, dsat, dexp);</span><br><span class="line">            <span class="comment">//random_distort_image(sized, hue, saturation, exposure);</span></span><br><span class="line">			<span class="comment">// truth包含所有图像的标签信息（包括真实类别与位置</span></span><br><span class="line">            <span class="comment">// 因为对原始图片进行了数据增强，其中的平移抖动势必会改动每个物体的矩形框标签信息（主要是矩形框的像素坐标信息），需要根据具体的数据增强方式进行相应矫正</span></span><br><span class="line">            <span class="comment">// 后面的参数就是用于数据增强后的矩形框信息矫正</span></span><br><span class="line">            <span class="built_in">fill_truth_detection</span>(filename, boxes, truth, classes, flip, dx, dy, <span class="number">1.</span> / sx, <span class="number">1.</span> / sy, w, h);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (i_mixup) &#123;</span><br><span class="line">                image old_img = sized;</span><br><span class="line">                old_img.data = d.X.vals[i];</span><br><span class="line">                <span class="comment">//show_image(sized, &quot;new&quot;);</span></span><br><span class="line">                <span class="comment">//show_image(old_img, &quot;old&quot;);</span></span><br><span class="line">                <span class="comment">//wait_until_press_key_cv();</span></span><br><span class="line">				<span class="comment">// 做mixup，混合系数为0.5</span></span><br><span class="line">                <span class="built_in">blend_images</span>(sized, <span class="number">0.5</span>, old_img, <span class="number">0.5</span>);</span><br><span class="line">				<span class="comment">// 标签也要对应改变</span></span><br><span class="line">                <span class="built_in">blend_truth</span>(truth, boxes, d.y.vals[i]);</span><br><span class="line">                <span class="built_in">free_image</span>(old_img);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            d.X.vals[i] = sized.data;</span><br><span class="line">            <span class="built_in">memcpy</span>(d.y.vals[i], truth, <span class="number">5</span> * boxes * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (show_imgs)<span class="comment">// &amp;&amp; i_mixup)</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">char</span> buff[<span class="number">1000</span>];</span><br><span class="line">                <span class="built_in">sprintf</span>(buff, <span class="string">&quot;aug_%d_%d_%s_%d&quot;</span>, random_index, i, <span class="built_in">basecfg</span>(filename), <span class="built_in">random_gen</span>());</span><br><span class="line"></span><br><span class="line">                <span class="keyword">int</span> t;</span><br><span class="line">                <span class="keyword">for</span> (t = <span class="number">0</span>; t &lt; boxes; ++t) &#123;</span><br><span class="line">                    box b = <span class="built_in">float_to_box_stride</span>(d.y.vals[i] + t*(<span class="number">4</span> + <span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line">                    <span class="keyword">if</span> (!b.x) <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">int</span> left = (b.x - b.w / <span class="number">2.</span>)*sized.w;</span><br><span class="line">                    <span class="keyword">int</span> right = (b.x + b.w / <span class="number">2.</span>)*sized.w;</span><br><span class="line">                    <span class="keyword">int</span> top = (b.y - b.h / <span class="number">2.</span>)*sized.h;</span><br><span class="line">                    <span class="keyword">int</span> bot = (b.y + b.h / <span class="number">2.</span>)*sized.h;</span><br><span class="line">                    <span class="built_in">draw_box_width</span>(sized, left, top, right, bot, <span class="number">1</span>, <span class="number">150</span>, <span class="number">100</span>, <span class="number">50</span>); <span class="comment">// 3 channels RGB</span></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="built_in">save_image</span>(sized, buff);</span><br><span class="line">                <span class="keyword">if</span> (show_imgs == <span class="number">1</span>) &#123;</span><br><span class="line">                    <span class="built_in">show_image</span>(sized, buff);</span><br><span class="line">                    <span class="built_in">wait_until_press_key_cv</span>();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;\nYou use flag -show_imgs, so will be saved aug_...jpg images. Press Enter: \n&quot;</span>);</span><br><span class="line">                <span class="comment">//getchar();</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="built_in">free_image</span>(orig);</span><br><span class="line">            <span class="built_in">free_image</span>(cropped);</span><br><span class="line">            <span class="built_in">free</span>(truth);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(random_paths);</span><br><span class="line">    <span class="keyword">if</span> (mixup_random_paths) <span class="built_in">free</span>(mixup_random_paths);</span><br><span class="line">    <span class="keyword">return</span> d;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>    <span class="comment">// OPENCV</span></span></span><br></pre></td></tr></table></figure>
<h2 id="load-data-args-使用方法"><a href="#load-data-args-使用方法" class="headerlink" title="load_data(args)使用方法"></a>load_data(args)使用方法</h2><p>在<code>src/detector.c</code>中的的<code>train_detector()</code>函数共有<code>3</code>次调用<code>load_data(args)</code>，第一次调用是为训练阶段做好数据准备工作，充分利用这段时间来加载数据。第二次调用是在<code>resize</code>操作中，可以看到这里只有<code>random</code>和<code>count</code>同时满足条件的情况下会做<code>resize</code>操作，也就是说<code>resize</code>加载的数据是未进行<code>resize</code>过的，因此，需要调整<code>args</code>中的图像宽高之后再重新调用<code>load_data(args)</code>加载数据。反之，不做任何处理，之前加载的数据仍然可用。第三次调用就是在数据加载完成后，将加载好的数据保存起来<code>train=buffer</code>; 然后开始下一次的加载工作。这一次的数据就会进行这一次的训练操作(调用<code>train_network</code>函数)。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet BN层代码详解(batchnorm_layer.c)</title>
    <url>/2020/03/01/AlexeyAB-DarkNet-BN%E5%B1%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(batchnorm_layer.c)/</url>
    <content><![CDATA[<h2 id="BatchNorm原理"><a href="#BatchNorm原理" class="headerlink" title="BatchNorm原理"></a>BatchNorm原理</h2><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/667.png" alt></p>
<p>这是论文中给出的对BatchNorm的算法流程解释，这篇推文的目的主要是推导和从源码角度解读BatchNorm的前向传播和反向传播，就不关注具体的原理了（实际上是因为BN层的原理非常复杂），我们暂时知道BN层是用来调整数据分布，降低过拟合的就够了。</p>
<h2 id="前向传播推导"><a href="#前向传播推导" class="headerlink" title="前向传播推导"></a>前向传播推导</h2><p>前向传播实际就是将Algorithm1的4个公式转化为编程语言，这里先贴一段CS231N官方提供的代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">batchnorm_forward</span><span class="params">(x, gamma, beta, bn_param)</span>:</span></span><br><span class="line"><span class="function">  <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span></span><br><span class="line"><span class="string"><span class="function">  Input:</span></span></span><br><span class="line"><span class="string"><span class="function">  - x: (N, D)维输入数据</span></span></span><br><span class="line"><span class="string"><span class="function">  - gamma: (D,)维尺度变化参数</span></span></span><br><span class="line"><span class="string"><span class="function">  - beta: (D,)维尺度变化参数</span></span></span><br><span class="line"><span class="string"><span class="function">  - bn_param: Dictionary with the following keys:</span></span></span><br><span class="line"><span class="string"><span class="function">    - mode: &#x27;train&#x27; 或者 &#x27;test&#x27;</span></span></span><br><span class="line"><span class="string"><span class="function">    - eps: 一般取1e-8~1e-4</span></span></span><br><span class="line"><span class="string"><span class="function">    - momentum: 计算均值、方差的更新参数</span></span></span><br><span class="line"><span class="string"><span class="function">    - running_mean: (D,)动态变化array存储训练集的均值</span></span></span><br><span class="line"><span class="string"><span class="function">    - running_var：(D,)动态变化array存储训练集的方差</span></span></span><br><span class="line"><span class="string"><span class="function"></span></span></span><br><span class="line"><span class="string"><span class="function">  Returns a tuple of:</span></span></span><br><span class="line"><span class="string"><span class="function">  - out: 输出y_i（N，D）维</span></span></span><br><span class="line"><span class="string"><span class="function">  - cache: 存储反向传播所需数据</span></span></span><br><span class="line"><span class="string"><span class="function">  &quot;</span><span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="function">  mode =</span> bn_param[<span class="string">&#x27;mode&#x27;</span>]</span><br><span class="line">  eps = bn_param.<span class="built_in">get</span>(<span class="string">&#x27;eps&#x27;</span>, <span class="number">1e-5</span>)</span><br><span class="line">  momentum = bn_param.<span class="built_in">get</span>(<span class="string">&#x27;momentum&#x27;</span>, <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">  N, D = x.shape</span><br><span class="line">  # 动态变量，存储训练集的均值方差</span><br><span class="line">  running_mean = bn_param.<span class="built_in">get</span>(<span class="string">&#x27;running_mean&#x27;</span>, np.<span class="built_in">zeros</span>(D, dtype=x.dtype))</span><br><span class="line">  running_var = bn_param.<span class="built_in">get</span>(<span class="string">&#x27;running_var&#x27;</span>, np.<span class="built_in">zeros</span>(D, dtype=x.dtype))</span><br><span class="line"></span><br><span class="line">  out, cache = None, None</span><br><span class="line">  # TRAIN 对每个batch操作</span><br><span class="line">  <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">    sample_mean = np.<span class="built_in">mean</span>(x, axis = <span class="number">0</span>)</span><br><span class="line">    sample_var = np.<span class="built_in">var</span>(x, axis = <span class="number">0</span>)</span><br><span class="line">    x_hat = (x - sample_mean) / np.<span class="built_in">sqrt</span>(sample_var + eps)</span><br><span class="line">    out = gamma * x_hat + beta</span><br><span class="line">    cache = (x, gamma, beta, x_hat, sample_mean, sample_var, eps)</span><br><span class="line">    running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * sample_mean</span><br><span class="line">    running_var = momentum * running_var + (<span class="number">1</span> - momentum) * sample_var</span><br><span class="line">  # TEST：要用整个训练集的均值、方差</span><br><span class="line">  elif mode == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">    x_hat = (x - running_mean) / np.<span class="built_in">sqrt</span>(running_var + eps)</span><br><span class="line">    out = gamma * x_hat + beta</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    raise <span class="built_in">ValueError</span>(<span class="string">&#x27;Invalid forward batchnorm mode &quot;%s&quot;&#x27;</span> % mode)</span><br><span class="line"></span><br><span class="line">  bn_param[<span class="string">&#x27;running_mean&#x27;</span>] = running_mean</span><br><span class="line">  bn_param[<span class="string">&#x27;running_var&#x27;</span>] = running_var</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> out, cache</span><br></pre></td></tr></table></figure>
<p>就是一个公式带入的问题，这里倒是没啥好说的，不过了为了和下面反向传播对比理解，这里我们明确每一个张量的维度：</p>
<ul>
<li><strong>x</strong> shape为(N,D)，可以将N看成batch size,D看成特征图展开为1列的元素个数</li>
<li><strong>gamma</strong> shape为(D,)</li>
<li><strong>beta</strong> shape为(D,)</li>
<li><strong>running_mean</strong> shape为(D,)</li>
<li><strong>running_var</strong> shape为(D,)</li>
</ul>
<p>请特别注意滑动平均(影子变量)这种Trick的引入，目的是为了控制变量更新的速度，防止变量的突然变化对变量的整体影响，这能提高模型的鲁棒性。</p>
<h2 id="反向传播推导"><a href="#反向传播推导" class="headerlink" title="反向传播推导"></a>反向传播推导</h2><p>这才是重点，现在做一些约定：</p>
<ul>
<li>$\delta$为一个Batch所有样本的方差</li>
<li>$\mu$为样本均值</li>
<li>$\hat{x}$为归一化后的样本数据</li>
<li>$y_{i}$为输入样本$x_{i}$经过尺度变化的输出量</li>
<li>$\gamma$和$\beta$为尺度变化系数</li>
<li>$\frac{\partial L}{\partial y}$是上一层的梯度，并假设$x$和$y$都是$(\mathrm{N}, \mathrm{D})$维，即有N个维度为D的样本在BN层的前向传播中$x_{i}$通过$\gamma, \beta, \hat{x}$将$x_{i}$变换为$y_{i}$，那么反向传播则是根据$\frac{\partial L}{\partial y_{i}}$求得$\frac{\partial L}{\partial \gamma}, \frac{\partial L}{\partial \beta}, \frac{\partial L}{\partial x_{i}}$</li>
<li>求解$\frac{\partial L}{\partial \gamma}$  $\frac{\partial L}{\partial \gamma}=\sum_{i} \frac{\partial L}{\partial y_{i}} \frac{\partial y_{i}}{\partial \gamma}=\sum_{i} \frac{\partial L}{\partial y_{i}} \hat{x}$</li>
<li>求解$\frac{\partial L}{\partial \beta}$  $\frac{\partial L}{\partial \beta}=\sum_{i} \frac{\partial L}{\partial y_{i}} \frac{\partial y_{i}}{\partial \beta}=\sum_{i} \frac{\partial L}{\partial y_{i}}$</li>
<li>求解$\frac{\partial L}{\partial x_{i}}$根据论文的公式和链式法则可得下面的等式: $\frac{\partial L}{\partial x_{i}}=\frac{\partial L}{\partial \widehat{x}_{i}} \frac{\partial \widehat{x}_{i}}{\partial x_{i}}+\frac{\partial L}{\partial \sigma} \frac{\partial \sigma}{\partial x_{i}}+\frac{\partial L}{\partial \mu} \frac{\partial \mu}{\partial x_{i}}$我们这里又可以先求$\frac{\partial L}{\partial \hat{x}}$</li>
<li>$\frac{\partial L}{\partial \hat{x}}=\frac{\partial L}{\partial y} \frac{\partial y}{\partial \hat{x}}=\frac{\partial L}{\partial y} \gamma$    (1)</li>
<li>$\frac{\partial L}{\partial \sigma}=\sum_{i} \frac{\partial L}{\partial y_{i}} \frac{\partial y_{i}}{\partial \hat{x}_{i}} \frac{\partial \hat{x}_{i}}{\partial \sigma}=-\frac{1}{2} \sum_{i} \frac{\partial L}{\partial \widehat{x}_{i}}\left(x_{i}-\mu\right)(\sigma+\varepsilon)^{-1.5}$    (2)</li>
<li>$\frac{\partial L}{\partial \mu}=\frac{\partial L}{\partial \hat{x}} \frac{\partial \hat{x}}{\partial \mu}+\frac{\partial L}{\partial \sigma} \frac{\partial \sigma}{\partial \mu}=\sum_{i} \frac{\partial L}{\partial \hat{x}_{i}} \frac{-1}{\sqrt{\sigma+\varepsilon}}+\frac{\partial L}{\partial \sigma} \frac{-2 \Sigma_{i}\left(x_{i}-\mu\right)}{N}$    (3)</li>
<li>有了(1) (2) (3)就可以求出$\frac{\partial L}{\partial x_{i}}$<br>$\frac{\partial L}{\partial x_{i}}=\frac{\partial L}{\partial \widehat{x}_{i}} \frac{\partial \widehat{x}_{i}}{\partial x_{i}}+\frac{\partial L}{\partial \sigma} \frac{\partial \sigma}{\partial x_{i}}+\frac{\partial L}{\partial \mu} \frac{\partial \mu}{\partial x_{i}}=\frac{\partial L}{\partial \hat{x}_{i}} \frac{1}{\sqrt{\sigma+\varepsilon}}+\frac{\partial L}{\partial \sigma} \frac{2\left(x_{i}-\mu\right)}{N}+\frac{\partial L}{\partial \mu} \frac{1}{N}$</li>
</ul>
<p>到这里就推到出了BN层的反向传播公式了，和论文中一样，截取一下论文中的结果图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/668.webp" alt></p>
<p>贴一份CS231N反向传播代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">def <span class="title">batchnorm_backward</span><span class="params">(dout, cache)</span>:</span></span><br><span class="line"><span class="function">  <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span></span><br><span class="line"><span class="string"><span class="function">  Inputs:</span></span></span><br><span class="line"><span class="string"><span class="function">  - dout: 上一层的梯度，维度(N, D)，即 dL/dy</span></span></span><br><span class="line"><span class="string"><span class="function">  - cache: 所需的中间变量，来自于前向传播</span></span></span><br><span class="line"><span class="string"><span class="function"></span></span></span><br><span class="line"><span class="string"><span class="function">  Returns a tuple of:</span></span></span><br><span class="line"><span class="string"><span class="function">  - dx: (N, D)维的 dL/dx</span></span></span><br><span class="line"><span class="string"><span class="function">  - dgamma: (D,)维的dL/dgamma</span></span></span><br><span class="line"><span class="string"><span class="function">  - dbeta: (D,)维的dL/dbeta</span></span></span><br><span class="line"><span class="string"><span class="function">  &quot;</span><span class="string">&quot;&quot;</span></span></span><br><span class="line"><span class="function">    x, gamma, beta, x_hat, sample_mean, sample_var, eps =</span> cache</span><br><span class="line">  N = x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  dgamma = np.<span class="built_in">sum</span>(dout * x_hat, axis = <span class="number">0</span>)</span><br><span class="line">  dbeta = np.<span class="built_in">sum</span>(dout, axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">  dx_hat = dout * gamma</span><br><span class="line">  dsigma = <span class="number">-0.5</span> * np.<span class="built_in">sum</span>(dx_hat * (x - sample_mean), axis=<span class="number">0</span>) * np.<span class="built_in">power</span>(sample_var + eps, <span class="number">-1.5</span>)</span><br><span class="line">  dmu = -np.<span class="built_in">sum</span>(dx_hat / np.<span class="built_in">sqrt</span>(sample_var + eps), axis=<span class="number">0</span>) - <span class="number">2</span> * dsigma*np.<span class="built_in">sum</span>(x-sample_mean, axis=<span class="number">0</span>)/ N</span><br><span class="line">  dx = dx_hat /np.<span class="built_in">sqrt</span>(sample_var + eps) + <span class="number">2.0</span> * dsigma * (x - sample_mean) / N + dmu / N</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure>
<h2 id="DarkNet代码详解"><a href="#DarkNet代码详解" class="headerlink" title="DarkNet代码详解"></a>DarkNet代码详解</h2><h3 id="1-构造BN层"><a href="#1-构造BN层" class="headerlink" title="1. 构造BN层"></a>1. 构造BN层</h3><p>构造BN层的代码在<code>src/batchnorm_layer.c</code>中实现，详细代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">layer <span class="title">make_batchnorm_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> c, <span class="keyword">int</span> train)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Batch Normalization Layer: %d x %d x %d image\n&quot;</span>, w,h,c);</span><br><span class="line">    layer layer = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    layer.type = BATCHNORM; <span class="comment">// 网络层的名字</span></span><br><span class="line">    layer.batch = batch; <span class="comment">//一个batch中包含的图片数</span></span><br><span class="line">    layer.train = train;</span><br><span class="line">    layer.h = layer.out_h = h;  <span class="comment">// 当前层的输出高度等于输入高度h</span></span><br><span class="line">    layer.w = layer.out_w = w; <span class="comment">// 当前层的输出宽度等于输入宽度w</span></span><br><span class="line">    layer.c = layer.out_c = c; <span class="comment">// 当前层的输出通道数等于输入通道数</span></span><br><span class="line"></span><br><span class="line">    layer.n = layer.c;</span><br><span class="line">    layer.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(h * w * c * batch, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// layer.output为该层所有的输出（包括mini-batch所有输入图片的输出）</span></span><br><span class="line">    layer.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(h * w * c * batch, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//layer.delta 是该层的敏感度图，和输出的维度想同</span></span><br><span class="line">    layer.inputs = w*h*c; <span class="comment">//mini-batch中每张输入图片的像素元素个数</span></span><br><span class="line">    layer.outputs = layer.inputs; <span class="comment">// 对应每张输入图片的所有输出特征图的总元素个数（每张输入图片会得到n也即layer.out_c张特征图）</span></span><br><span class="line"></span><br><span class="line">    layer.biases = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// BN层特有参数，缩放系数</span></span><br><span class="line">    layer.bias_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// 缩放系数的敏感度图</span></span><br><span class="line"></span><br><span class="line">    layer.scales = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// BN层特有参数，偏置系数</span></span><br><span class="line">    layer.scale_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// 偏置系数的敏感度图</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; c; ++i)&#123;</span><br><span class="line">        layer.scales[i] = <span class="number">1</span>; <span class="comment">// 将缩放系数初始化为1</span></span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    layer.mean = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// mean 一个batch中所有图片的均值，分通道求取</span></span><br><span class="line">    layer.variance = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));  <span class="comment">// variance 一个batch中所有图片的方差，分通道求取</span></span><br><span class="line"></span><br><span class="line">    layer.rolling_mean = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// 均值的滑动平均，影子变量</span></span><br><span class="line">    layer.rolling_variance = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(c, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// 方差的滑动平均，影子变量</span></span><br><span class="line"></span><br><span class="line">    layer.forward = forward_batchnorm_layer; <span class="comment">// 前向传播函数</span></span><br><span class="line">    layer.backward = backward_batchnorm_layer; <span class="comment">// 反向传播函数</span></span><br><span class="line">    layer.update = update_batchnorm_layer;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> layer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-前向传播公式实现"><a href="#2-前向传播公式实现" class="headerlink" title="2.前向传播公式实现"></a>2.前向传播公式实现</h3><p>DarkNet中在<code>src/blas.h</code>中实现了前向传播的几个公式：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 计算输入数据x的平均值，输出的mean是一个矢量，比如如果x是多张三通道的图片，那么mean的维度就为通道3</span></span><br><span class="line"><span class="comment">** 由于每次训练输入的都是一个batch的图片，因此最终会输出batch张三通道的图片，mean中的第一个元素就是第</span></span><br><span class="line"><span class="comment">** 一个通道上全部batch张输出特征图所有元素的平均值，本函数的用处之一就是batch normalization的第一步了</span></span><br><span class="line"><span class="comment">** x: 包含所有数据，比如l.output，其包含的元素个数为l.batch*l.outputs</span></span><br><span class="line"><span class="comment">** batch: 一个batch中包含的图片张数，即l.batch</span></span><br><span class="line"><span class="comment">** filters: 该层神经网络的滤波器个数，也即该层网络输出图片的通道数（比如对卷积网络来说，就是核的个数了）</span></span><br><span class="line"><span class="comment">** spatial: 该层神经网络每张输出特征图的尺寸，也即等于l.out_w*l.out_h</span></span><br><span class="line"><span class="comment">** mean: 求得的平均值，维度为filters，也即每个滤波器对应有一个均值（每个滤波器会处理所有图片）</span></span><br><span class="line"><span class="comment">** x的内存排布？此处还是结合batchnorm_layer.c中的forward_batch_norm_layer()函数的调用来解释，其中x为l.output，其包含的元素个数为l</span></span><br><span class="line"><span class="comment">** 有l.batch行，每行有l.out_c*l.out_w*l.out_h个元素，每一行又可以分成l.out_c行，l.out_w*l.out_h列，</span></span><br><span class="line"><span class="comment">** 那么l.mean中的每一个元素，是某一个通道上所有batch的输出的平均值</span></span><br><span class="line"><span class="comment">** （比如卷积层，有3个核，那么输出通道有3个，每张输入图片都会输出3张特征图，可以理解每张输出图片是3通道的，</span></span><br><span class="line"><span class="comment">** 若每次输入batch=64张图片，那么将会输出64张3通道的图片，而mean中的每个元素就是某个通道上所有64张图片</span></span><br><span class="line"><span class="comment">** 所有元素的平均值，比如第1个通道上，所有64张图片像素平均值）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mean_cpu</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial, <span class="keyword">float</span> *mean)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// scale即是均值中的分母项</span></span><br><span class="line">    <span class="keyword">float</span> scale = <span class="number">1.</span>/(batch * spatial);</span><br><span class="line">    <span class="keyword">int</span> i,j,k;</span><br><span class="line">    <span class="comment">// 外循环次数为filters，也即mean的维度，每次循环将得到一个平均值</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; filters; ++i)&#123;</span><br><span class="line">        mean[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 中间循环次数为batch，也即叠加每张输入图片对应的某一通道上的输出</span></span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; batch; ++j)&#123;</span><br><span class="line">            <span class="comment">// 内层循环即叠加一张输出特征图的所有像素值</span></span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>; k &lt; spatial; ++k)&#123;</span><br><span class="line">                <span class="comment">// 计算偏移</span></span><br><span class="line">                <span class="keyword">int</span> index = j*filters*spatial + i*spatial + k;</span><br><span class="line">                mean[i] += x[index];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mean[i] *= scale;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 计算输入x中每个元素的方差</span></span><br><span class="line"><span class="comment">** 本函数的主要用处应该就是batch normalization的第二步了</span></span><br><span class="line"><span class="comment">** x: 包含所有数据，比如l.output，其包含的元素个数为l.batch*l.outputs</span></span><br><span class="line"><span class="comment">** batch: 一个batch中包含的图片张数，即l.batch</span></span><br><span class="line"><span class="comment">** filters: 该层神经网络的滤波器个数，也即是该网络层输出图片的通道数</span></span><br><span class="line"><span class="comment">** spatial: 该层神经网络每张特征图的尺寸，也即等于l.out_w*l.out_h</span></span><br><span class="line"><span class="comment">** mean: 求得的平均值，维度为filters，也即每个滤波器对应有一个均值（每个滤波器会处理所有图片）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">variance_cpu</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *mean, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial, <span class="keyword">float</span> *variance)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 这里计算方差分母要减去1的原因是无偏估计，可以看：https://www.zhihu.com/question/20983193</span></span><br><span class="line">    <span class="comment">// 事实上，在统计学中，往往采用的方差计算公式都会让分母减1,这时因为所有数据的方差是基于均值这个固定点来计算的，</span></span><br><span class="line">    <span class="comment">// 对于有n个数据的样本，在均值固定的情况下，其采样自由度为n-1（只要n-1个数据固定，第n个可以由均值推出）</span></span><br><span class="line">    <span class="keyword">float</span> scale = <span class="number">1.</span>/(batch * spatial - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; filters; ++i)&#123;</span><br><span class="line">        variance[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; batch; ++j)&#123;</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>; k &lt; spatial; ++k)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = j*filters*spatial + i*spatial + k;</span><br><span class="line">                <span class="comment">// 每个元素减去均值求平方</span></span><br><span class="line">                variance[i] += <span class="built_in">pow</span>((x[index] - mean[i]), <span class="number">2</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        variance[i] *= scale;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">normalize_cpu</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *mean, <span class="keyword">float</span> *variance, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> b, f, i;</span><br><span class="line">    <span class="keyword">for</span>(b = <span class="number">0</span>; b &lt; batch; ++b)&#123;</span><br><span class="line">        <span class="keyword">for</span>(f = <span class="number">0</span>; f &lt; filters; ++f)&#123;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; spatial; ++i)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = b*filters*spatial + f*spatial + i;</span><br><span class="line">                x[index] = (x[index] - mean[f])/(<span class="built_in">sqrt</span>(variance[f]) + <span class="number">.000001</span>f);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** axpy 是线性代数中的一种基本操作(仿射变换)完成y= alpha*x + y操作，其中x,y为矢量，alpha为实数系数，</span></span><br><span class="line"><span class="comment">** 请看: https://www.jianshu.com/p/e3f386771c51</span></span><br><span class="line"><span class="comment">** N: X中包含的有效元素个数</span></span><br><span class="line"><span class="comment">** ALPHA: 系数alpha</span></span><br><span class="line"><span class="comment">** X: 参与运算的矢量X</span></span><br><span class="line"><span class="comment">** INCX: 步长(倍数步长)，即x中凡是INCX倍数编号的参与运算</span></span><br><span class="line"><span class="comment">** Y: 参与运算的矢量，也相当于是输出</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">axpy_cpu</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span> ALPHA, <span class="keyword">float</span> *X, <span class="keyword">int</span> INCX, <span class="keyword">float</span> *Y, <span class="keyword">int</span> INCY)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; N; ++i) Y[i*INCY] += ALPHA*X[i*INCX];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">scal_cpu</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span> ALPHA, <span class="keyword">float</span> *X, <span class="keyword">int</span> INCX)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; N; ++i) X[i*INCX] *= ALPHA;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-前向传播和反向传播接口函数"><a href="#3-前向传播和反向传播接口函数" class="headerlink" title="3. 前向传播和反向传播接口函数"></a>3. 前向传播和反向传播接口函数</h3><p>DarkNet在<code>src/batchnorm_layer.c</code>中实现了前向传播和反向传播的接口函数：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// BN层的前向传播函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_batchnorm_layer</span><span class="params">(layer l, network net)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l.type == BATCHNORM) <span class="built_in">copy_cpu</span>(l.outputs*l.batch, net.input, <span class="number">1</span>, l.output, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">copy_cpu</span>(l.outputs*l.batch, l.output, <span class="number">1</span>, l.x, <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 训练阶段</span></span><br><span class="line">    <span class="keyword">if</span>(net.train)&#123;</span><br><span class="line">        <span class="comment">// blas.c中有详细注释，计算输入数据的均值，保存为l.mean</span></span><br><span class="line">        <span class="built_in">mean_cpu</span>(l.output, l.batch, l.out_c, l.out_h*l.out_w, l.mean);</span><br><span class="line">        <span class="comment">// blas.c中有详细注释，计算输入数据的方差，保存为l.variance</span></span><br><span class="line">        <span class="built_in">variance_cpu</span>(l.output, l.mean, l.batch, l.out_c, l.out_h*l.out_w, l.variance);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 计算滑动平均和方差，影子变量，可以参考https://blog.csdn.net/just_sort/article/details/100039418</span></span><br><span class="line">        <span class="built_in">scal_cpu</span>(l.out_c, <span class="number">.99</span>, l.rolling_mean, <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">axpy_cpu</span>(l.out_c, <span class="number">.01</span>, l.mean, <span class="number">1</span>, l.rolling_mean, <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">scal_cpu</span>(l.out_c, <span class="number">.99</span>, l.rolling_variance, <span class="number">1</span>);</span><br><span class="line">        <span class="built_in">axpy_cpu</span>(l.out_c, <span class="number">.01</span>, l.variance, <span class="number">1</span>, l.rolling_variance, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 减去均值，除以方差得到x^，论文中的第3个公式</span></span><br><span class="line">        <span class="built_in">normalize_cpu</span>(l.output, l.mean, l.variance, l.batch, l.out_c, l.out_h*l.out_w);</span><br><span class="line">        <span class="comment">// BN层的输出</span></span><br><span class="line">        <span class="built_in">copy_cpu</span>(l.outputs*l.batch, l.output, <span class="number">1</span>, l.x_norm, <span class="number">1</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 测试阶段，直接用滑动变量来计算输出</span></span><br><span class="line">        <span class="built_in">normalize_cpu</span>(l.output, l.rolling_mean, l.rolling_variance, l.batch, l.out_c, l.out_h*l.out_w);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 最后一个公式，对输出进行移位和偏置</span></span><br><span class="line">    <span class="built_in">scale_bias</span>(l.output, l.scales, l.batch, l.out_c, l.out_h*l.out_w);</span><br><span class="line">    <span class="built_in">add_bias</span>(l.output, l.biases, l.batch, l.out_c, l.out_h*l.out_w);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// BN层的反向传播函数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_batchnorm_layer</span><span class="params">(layer l, network net)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 如果在测试阶段，均值和方差都可以直接用滑动变量来赋值</span></span><br><span class="line">    <span class="keyword">if</span>(!net.train)&#123;</span><br><span class="line">        l.mean = l.rolling_mean;</span><br><span class="line">        l.variance = l.rolling_variance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 在卷积层中定义了backward_bias，并有详细注释</span></span><br><span class="line">    <span class="built_in">backward_bias</span>(l.bias_updates, l.delta, l.batch, l.out_c, l.out_w*l.out_h);</span><br><span class="line">    <span class="comment">// 这里是对论文中最后一个公式的缩放系数求梯度更新值</span></span><br><span class="line">    <span class="built_in">backward_scale_cpu</span>(l.x_norm, l.delta, l.batch, l.out_c, l.out_w*l.out_h, l.scale_updates);</span><br><span class="line">    <span class="comment">// 也是在convlution_layer.c中定义的函数，先将敏感度图乘以l.scales</span></span><br><span class="line">    <span class="built_in">scale_bias</span>(l.delta, l.scales, l.batch, l.out_c, l.out_h*l.out_w);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 对应了https://blog.csdn.net/just_sort/article/details/100039418 中对均值求导数</span></span><br><span class="line">    <span class="built_in">mean_delta_cpu</span>(l.delta, l.variance, l.batch, l.out_c, l.out_w*l.out_h, l.mean_delta);</span><br><span class="line">    <span class="comment">// 对应了https://blog.csdn.net/just_sort/article/details/100039418 中对方差求导数</span></span><br><span class="line">    <span class="built_in">variance_delta_cpu</span>(l.x, l.delta, l.mean, l.variance, l.batch, l.out_c, l.out_w*l.out_h, l.variance_delta);</span><br><span class="line">    <span class="comment">// 计算敏感度图，对应了论文中的最后一部分</span></span><br><span class="line">    <span class="built_in">normalize_delta_cpu</span>(l.x, l.mean, l.variance, l.mean_delta, l.variance_delta, l.batch, l.out_c, l.out_w*l.out_h, l.delta);</span><br><span class="line">    <span class="keyword">if</span>(l.type == BATCHNORM) <span class="built_in">copy_cpu</span>(l.outputs*l.batch, l.delta, <span class="number">1</span>, net.delta, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-反向传播函数公式实现"><a href="#4-反向传播函数公式实现" class="headerlink" title="4.反向传播函数公式实现"></a>4.反向传播函数公式实现</h3><p>其中反向传播的函数如下，就是利用推导出的公式来计算：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里是对论文中最后一个公式的缩放系数求梯度更新值</span></span><br><span class="line"><span class="comment">// x_norm 代表BN层前向传播的输出值</span></span><br><span class="line"><span class="comment">// delta 代表上一层的梯度图</span></span><br><span class="line"><span class="comment">// batch 为l.batch，即一个batch的图片数</span></span><br><span class="line"><span class="comment">// n代表输出通道数，也即是输入通道数</span></span><br><span class="line"><span class="comment">// size 代表w * h</span></span><br><span class="line"><span class="comment">// scale_updates 代表scale的梯度更新值</span></span><br><span class="line"><span class="comment">// y = gamma * x + beta</span></span><br><span class="line"><span class="comment">// dy / d(gamma) = x</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_scale_cpu</span><span class="params">(<span class="keyword">float</span> *x_norm, <span class="keyword">float</span> *delta, <span class="keyword">int</span> batch, <span class="keyword">int</span> n, <span class="keyword">int</span> size, <span class="keyword">float</span> *scale_updates)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,b,f;</span><br><span class="line">    <span class="keyword">for</span>(f = <span class="number">0</span>; f &lt; n; ++f)&#123;</span><br><span class="line">        <span class="keyword">float</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(b = <span class="number">0</span>; b &lt; batch; ++b)&#123;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; size; ++i)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = i + size*(f + n*b);</span><br><span class="line">                sum += delta[index] * x_norm[index];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        scale_updates[f] += sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对均值求导</span></span><br><span class="line"><span class="comment">// 对应了论文中的求导公式3，不过Darknet特殊的点在于是先计算均值的梯度</span></span><br><span class="line"><span class="comment">// 这个时候方差是没有梯度的，所以公式3的后半部分为0，也就只保留了公式3的前半部分</span></span><br><span class="line"><span class="comment">// 不过我从理论上无法解释这种操作会带来什么影响，但从目标检测来看应该是没有影响的</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mean_delta_cpu</span><span class="params">(<span class="keyword">float</span> *delta, <span class="keyword">float</span> *variance, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial, <span class="keyword">float</span> *mean_delta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; filters; ++i)&#123;</span><br><span class="line">        mean_delta[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; batch; ++j) &#123;</span><br><span class="line">            <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; spatial; ++k) &#123;</span><br><span class="line">                <span class="keyword">int</span> index = j*filters*spatial + i*spatial + k;</span><br><span class="line">                mean_delta[i] += delta[index];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mean_delta[i] *= (<span class="number">-1.</span>/<span class="built_in">sqrt</span>(variance[i] + <span class="number">.00001</span>f));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 对方差求导</span></span><br><span class="line"><span class="comment">// 对应了论文中的求导公式2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span>  <span class="title">variance_delta_cpu</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *delta, <span class="keyword">float</span> *mean, <span class="keyword">float</span> *variance, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial, <span class="keyword">float</span> *variance_delta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; filters; ++i)&#123;</span><br><span class="line">        variance_delta[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; batch; ++j)&#123;</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>; k &lt; spatial; ++k)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = j*filters*spatial + i*spatial + k;</span><br><span class="line">                variance_delta[i] += delta[index]*(x[index] - mean[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        variance_delta[i] *= <span class="number">-.5</span> * <span class="built_in">pow</span>(variance[i] + <span class="number">.00001</span>f, (<span class="keyword">float</span>)(<span class="number">-3.</span>/<span class="number">2.</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 求出BN层的梯度敏感度图</span></span><br><span class="line"><span class="comment">// 对应了论文中的求导公式4，即是对x_i求导</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">normalize_delta_cpu</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *mean, <span class="keyword">float</span> *variance, <span class="keyword">float</span> *mean_delta, <span class="keyword">float</span> *variance_delta, <span class="keyword">int</span> batch, <span class="keyword">int</span> filters, <span class="keyword">int</span> spatial, <span class="keyword">float</span> *delta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> f, j, k;</span><br><span class="line">    <span class="keyword">for</span>(j = <span class="number">0</span>; j &lt; batch; ++j)&#123;</span><br><span class="line">        <span class="keyword">for</span>(f = <span class="number">0</span>; f &lt; filters; ++f)&#123;</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>; k &lt; spatial; ++k)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = j*filters*spatial + f*spatial + k;</span><br><span class="line">                delta[index] = delta[index] * <span class="number">1.</span>/(<span class="built_in">sqrt</span>(variance[f] + <span class="number">.00001</span>f)) + variance_delta[f] * <span class="number">2.</span> * (x[index] - mean[f]) / (spatial * batch) + mean_delta[f]/(spatial*batch);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet池化层代码详解(maxpool_layer.c)</title>
    <url>/2020/02/29/AlexeyAB-DarkNet%E6%B1%A0%E5%8C%96%E5%B1%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(maxpool_layer.c)/</url>
    <content><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>为了图文并茂的解释这个层，我们首先来说一下池化层的原理，池化层分为最大池化以及平均池化。最大池化可以用下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/666.png" alt></p>
<p>可以看到最大池化层需要记录池化输出特征图的每个值是由原始特征图中哪个值得来的，也就是需要额外记录一个最大值在原图的中的索引。而平均池化只需要将上面的求最大值的操作换成求平均的操作即可，因为是平均操作所以就没必要记录索引了。</p>
<h2 id="池化层的构造"><a href="#池化层的构造" class="headerlink" title="池化层的构造"></a>池化层的构造</h2><p>池化层的构造由<code>make_maxpool_layer</code>函数实现，虽然名字是构造<code>maxpool_layer</code>，但其实现也考虑了平均池化，也就是说通过参数设置可以将池化层变成平均池化。这一函数的详细讲解请看如下代码，为了美观，我去掉了一些无关代码，完整代码请到github查看。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 构建最大/平均池化层</span></span><br><span class="line"><span class="comment">** batch: 该层输入中一个batch所含有的图片张数，等于net.batch</span></span><br><span class="line"><span class="comment">** h,w,c: 该层输入图片的高度，宽度与通道数</span></span><br><span class="line"><span class="comment">** size: 池化核的大小</span></span><br><span class="line"><span class="comment">** stride: 滑动步长</span></span><br><span class="line"><span class="comment">** padding: 四周补0长度</span></span><br><span class="line"><span class="comment">返回: 最大/平均池化层l</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">maxpool_layer <span class="title">make_maxpool_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> h, <span class="keyword">int</span> w, <span class="keyword">int</span> c, <span class="keyword">int</span> size, <span class="keyword">int</span> stride_x, <span class="keyword">int</span> stride_y, <span class="keyword">int</span> padding, <span class="keyword">int</span> maxpool_depth, <span class="keyword">int</span> out_channels, <span class="keyword">int</span> antialiasing, <span class="keyword">int</span> avgpool, <span class="keyword">int</span> train)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    maxpool_layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">	<span class="comment">//层类别</span></span><br><span class="line">    l.avgpool = avgpool;</span><br><span class="line">    <span class="keyword">if</span> (avgpool) l.type = LOCAL_AVGPOOL;</span><br><span class="line">    <span class="keyword">else</span> l.type = MAXPOOL;</span><br><span class="line">    l.train = train;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> blur_stride_x = stride_x;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> blur_stride_y = stride_y;</span><br><span class="line">    l.antialiasing = antialiasing;</span><br><span class="line">    <span class="keyword">if</span> (antialiasing) &#123;</span><br><span class="line">        stride_x = stride_y = l.stride = l.stride_x = l.stride_y = <span class="number">1</span>; <span class="comment">// use stride=1 in host-layer</span></span><br><span class="line">    &#125;</span><br><span class="line">    l.batch = batch;<span class="comment">//一个batch中包含的图片数</span></span><br><span class="line">    l.h = h; <span class="comment">//输入图片的高度</span></span><br><span class="line">    l.w = w; <span class="comment">//输入图片的宽度</span></span><br><span class="line">    l.c = c; <span class="comment">//输入图片的通道数</span></span><br><span class="line">    l.pad = padding; <span class="comment">// 补0的个数</span></span><br><span class="line">    l.maxpool_depth = maxpool_depth; <span class="comment">//池化层每隔l.maxpool_depth执行一次pool操作</span></span><br><span class="line">    l.out_channels = out_channels; <span class="comment">//输出图片的通道数</span></span><br><span class="line">    <span class="keyword">if</span> (maxpool_depth) &#123;</span><br><span class="line">        l.out_c = out_channels;</span><br><span class="line">        l.out_w = l.w;</span><br><span class="line">        l.out_h = l.h;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        l.out_w = (w + padding - size) / stride_x + <span class="number">1</span>; <span class="comment">//输出图片的宽度</span></span><br><span class="line">        l.out_h = (h + padding - size) / stride_y + <span class="number">1</span>; <span class="comment">//输出图片的高度</span></span><br><span class="line">        l.out_c = c; <span class="comment">//输出图片的通道数</span></span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//</span></span><br><span class="line">    l.outputs = l.out_h * l.out_w * l.out_c; <span class="comment">//池化化层对应一张输入图片的输出元素个数</span></span><br><span class="line">    l.inputs = h*w*c; <span class="comment">//池化层</span></span><br><span class="line">    l.size = size; <span class="comment">//池化层池化窗口大小</span></span><br><span class="line">    l.stride = stride_x; <span class="comment">//池化层步幅</span></span><br><span class="line">    l.stride_x = stride_x; <span class="comment">//在x方向上的池化层步幅</span></span><br><span class="line">    l.stride_y = stride_y; <span class="comment">//在y方向上的池化层步幅</span></span><br><span class="line">    <span class="keyword">int</span> output_size = l.out_h * l.out_w * l.out_c * batch; <span class="comment">// 池化层所有输出的元素个数（包含整个batch的）</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (train) &#123;</span><br><span class="line">		<span class="comment">// 训练的时候，用于保存每个最大池化窗口内的最大值对应的索引，方便之后的反向传播</span></span><br><span class="line">		<span class="comment">// 如果是平均池化层就不用了</span></span><br><span class="line">        <span class="keyword">if</span> (!avgpool) l.indexes = (<span class="keyword">int</span>*)<span class="built_in">xcalloc</span>(output_size, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">		<span class="comment">//池化层的误差项</span></span><br><span class="line">        l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(output_size, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//池化层的所有输出(包含整个batch的)</span></span><br><span class="line">    l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(output_size, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="keyword">if</span> (avgpool) &#123;</span><br><span class="line">		<span class="comment">//平均池化层的前向传播和反向传播</span></span><br><span class="line">        l.forward = forward_local_avgpool_layer;</span><br><span class="line">        l.backward = backward_local_avgpool_layer;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">//最大池化层的前向传播和反向传播</span></span><br><span class="line">        l.forward = forward_maxpool_layer;</span><br><span class="line">        l.backward = backward_maxpool_layer;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// GPU上和CPU上的操作类似</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="keyword">if</span> (avgpool) &#123;</span><br><span class="line">        l.forward_gpu = forward_local_avgpool_layer_gpu;</span><br><span class="line">        l.backward_gpu = backward_local_avgpool_layer_gpu;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        l.forward_gpu = forward_maxpool_layer_gpu;</span><br><span class="line">        l.backward_gpu = backward_maxpool_layer_gpu;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (train) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!avgpool) l.indexes_gpu = <span class="built_in">cuda_make_int_array</span>(output_size);</span><br><span class="line">        l.delta_gpu = <span class="built_in">cuda_make_array</span>(l.delta, output_size);</span><br><span class="line">    &#125;</span><br><span class="line">    l.output_gpu  = <span class="built_in">cuda_make_array</span>(l.output, output_size);</span><br><span class="line">    <span class="built_in">create_maxpool_cudnn_tensors</span>(&amp;l);</span><br><span class="line">    <span class="keyword">if</span> (avgpool) <span class="built_in">cudnn_local_avgpool_setup</span>(&amp;l);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">cudnn_maxpool_setup</span>(&amp;l);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// GPU</span></span></span><br><span class="line">    <span class="comment">//计算池化层的参数量，以BFLOPs为单位，这是AlexeyAB DarkNet新增的</span></span><br><span class="line">	l.bflops = (l.size*l.size*l.c * l.out_h*l.out_w) / <span class="number">1000000000.</span>;</span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最大池化层的前向传播"><a href="#最大池化层的前向传播" class="headerlink" title="最大池化层的前向传播"></a>最大池化层的前向传播</h2><p>AlexeyAB DarkNet的池化层和原始的DarkNet的池化层最大的不同在于新增了一个<code>l.maxpool_depth</code>参数，如果这个参数不为0，那么池化层需要每隔<code>l.out_channels</code>个特征图执行最大池化，注意这个参数只对最大池化有效。池化层的前向传播函数为<code>forward_maxpool_layer</code>，详细解释如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 池化层的前向传播函数</span></span><br><span class="line"><span class="comment">** l: 当前层(最大池化层/平均池化层)</span></span><br><span class="line"><span class="comment">** net: 整个网络结构</span></span><br><span class="line"><span class="comment">** 最大池化层处理图像的方式与卷积层类似，也是将最大池化核在图像</span></span><br><span class="line"><span class="comment">** 平面上按照指定的跨度移动，并取对应池化核区域中最大元素值为对应输出元素。</span></span><br><span class="line"><span class="comment">** 最大池化层没有训练参数（没有权重以及偏置），因此，相对与卷积来说，</span></span><br><span class="line"><span class="comment">** 其前向（以及下面的反向）过程比较简单，实现上也是非常直接，不需要什么技巧。</span></span><br><span class="line"><span class="comment">** 但需要注意AlexeyAB DarkNet在原始的代码上改动比较多，具体注释如下。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_maxpool_layer</span><span class="params">(<span class="keyword">const</span> maxpool_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//如果l.maxpool_depth参数生效，执行下面的前向传播过程</span></span><br><span class="line">    <span class="keyword">if</span> (l.maxpool_depth)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> b, i, j, k, g;</span><br><span class="line">		<span class="comment">// 遍历batch中每一张输入图片，计算得到与每一张输入图片具有l.maxpool_depth个通道的输出图</span></span><br><span class="line">        <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">			<span class="comment">//openmp优化</span></span><br><span class="line">			<span class="comment">//外层循环遍历特征图的长</span></span><br><span class="line">            <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.h; ++i) &#123;</span><br><span class="line">				<span class="comment">//中层循环遍历特征图的宽</span></span><br><span class="line">                <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.w; ++j) &#123;</span><br><span class="line">					<span class="comment">//内层循环遍历特征图的输出通道</span></span><br><span class="line">                    <span class="keyword">for</span> (g = <span class="number">0</span>; g &lt; l.out_c; ++g)</span><br><span class="line">                    &#123;</span><br><span class="line">						<span class="comment">//out_index为输出图中的索引</span></span><br><span class="line">                        <span class="keyword">int</span> out_index = j + l.w*(i + l.h*(g + l.out_c*b));</span><br><span class="line">                        <span class="keyword">float</span> max = -FLT_MAX;</span><br><span class="line">                        <span class="keyword">int</span> max_i = <span class="number">-1</span>;</span><br><span class="line">						<span class="comment">//如上所述，每隔l.out_c个通道执行一次最大池化操作</span></span><br><span class="line">                        <span class="keyword">for</span> (k = g; k &lt; l.c; k += l.out_c)</span><br><span class="line">                        &#123;</span><br><span class="line">                            <span class="keyword">int</span> in_index = j + l.w*(i + l.h*(k + l.c*b));</span><br><span class="line">                            <span class="keyword">float</span> val = state.input[in_index];</span><br><span class="line">                            <span class="comment">//记录最大池化的索引</span></span><br><span class="line">                            max_i = (val &gt; max) ? in_index : max_i;</span><br><span class="line">                            max = (val &gt; max) ? val : max;</span><br><span class="line">                        &#125;</span><br><span class="line">                        l.output[out_index] = max;</span><br><span class="line">                        <span class="keyword">if</span> (l.indexes) l.indexes[out_index] = max_i;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!state.train &amp;&amp; l.stride_x == l.stride_y) &#123;</span><br><span class="line">		<span class="comment">//前向推理并且x和y方向的步幅相同的情况下，使用avx指令集优化Pool层的前向传播</span></span><br><span class="line">        forward_maxpool_layer_avx(state.input, l.output, l.indexes, l.size, l.w, l.h, l.out_w, l.out_h, l.c, l.pad, l.stride, l.batch);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> b, i, j, k, m, n;</span><br><span class="line">		<span class="comment">// 初始偏移设定为四周补0长度的负值</span></span><br><span class="line">        <span class="keyword">int</span> w_offset = -l.pad / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> h_offset = -l.pad / <span class="number">2</span>;</span><br><span class="line">		<span class="comment">// 获取当前层的输出尺寸</span></span><br><span class="line">        <span class="keyword">int</span> h = l.out_h;</span><br><span class="line">        <span class="keyword">int</span> w = l.out_w;</span><br><span class="line">		<span class="comment">// 获取当前层输入图像的通道数，为什么是输入通道数？不应该为输出通道数吗？</span></span><br><span class="line">        <span class="comment">// 实际二者没有区别，对于最大池化层来说，输入有多少通道，输出就有多少通道！</span></span><br><span class="line">		<span class="comment">// 注意上面如果maxpool_depth有值，那么输出通道数就和输入通道数不一样了。</span></span><br><span class="line">        <span class="keyword">int</span> c = l.c;</span><br><span class="line">		<span class="comment">// 遍历batch中每一张输入图片，计算得到与每一张输入图片具有相同通道的输出图</span></span><br><span class="line">        <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">			<span class="comment">// 对于每张输入图片，将得到通道数一样的输出图，以输出图为基准，按输出图通道，行，列依次遍历</span></span><br><span class="line">			<span class="comment">// （这对应图像在l.output的存储方式，每张图片按行铺排成一大行，然后图片与图片之间再并成一行）。</span></span><br><span class="line">			<span class="comment">// 以输出图为基准进行遍历，最终循环的总次数刚好覆盖池化核在输入图片不同位置进行池化操作。</span></span><br><span class="line">            <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; c; ++k) &#123;</span><br><span class="line">                <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; h; ++i) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; w; ++j) &#123;</span><br><span class="line">						<span class="comment">// out_index为输出图中的索引：out_index = b * c * w * h + k * w * h + h * w + w，展开写可能更为清晰些</span></span><br><span class="line">                        <span class="keyword">int</span> out_index = j + w*(i + h*(k + c*b));</span><br><span class="line">                        <span class="keyword">float</span> max = -FLT_MAX;</span><br><span class="line">                        <span class="keyword">int</span> max_i = <span class="number">-1</span>;</span><br><span class="line">						<span class="comment">// 下面两个循环回到了输入图片，计算得到的cur_h以及cur_w都是在当前层所有输入元素的索引，内外循环的目的是</span></span><br><span class="line">                        <span class="comment">// 找寻输入图像中，以(h_offset + i*l.stride, w_offset + j*l.stride)为左上起点，尺寸为l.size池化区域中的</span></span><br><span class="line">                        <span class="comment">//最大元素值max及其在所有输入元素中的索引max_i</span></span><br><span class="line">                        <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.size; ++n) &#123;</span><br><span class="line">                            <span class="keyword">for</span> (m = <span class="number">0</span>; m &lt; l.size; ++m) &#123;</span><br><span class="line">								<span class="comment">//cur_h, cur_w是在所有输入图像的第k通道的cur_h行与cur_w列，index是在所有输入图像元素中的总索引</span></span><br><span class="line">                                <span class="keyword">int</span> cur_h = h_offset + i*l.stride_y + n;</span><br><span class="line">                                <span class="keyword">int</span> cur_w = w_offset + j*l.stride_x + m;</span><br><span class="line">                                <span class="keyword">int</span> index = cur_w + l.w*(cur_h + l.h*(k + b*l.c));</span><br><span class="line">								<span class="comment">// 边界检查：正常情况下，是不会越界的，但是如果有补0操作，就会越界了，这里的处理方式是直接让这些元素值为-FLT_MAX</span></span><br><span class="line">                                <span class="keyword">int</span> valid = (cur_h &gt;= <span class="number">0</span> &amp;&amp; cur_h &lt; l.h &amp;&amp;</span><br><span class="line">                                    cur_w &gt;= <span class="number">0</span> &amp;&amp; cur_w &lt; l.w);</span><br><span class="line">								<span class="comment">// 记录这个池化区域中最大的元素及其在所有输入元素中的总索引</span></span><br><span class="line">                                <span class="keyword">float</span> val = (valid != <span class="number">0</span>) ? state.input[index] : -FLT_MAX;</span><br><span class="line">                                max_i = (val &gt; max) ? index : max_i;</span><br><span class="line">                                max = (val &gt; max) ? val : max;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">						<span class="comment">// 由此得到最大池化层每一个输出元素值及其在所有输入元素中的总索引。</span></span><br><span class="line">						<span class="comment">// 为什么需要记录每个输出元素值对应在输入元素中的总索引呢？因为在下面的反向过程中需要用到，在计算当前最大池化层上一层网络的敏感度时，</span></span><br><span class="line">						<span class="comment">// 需要该索引明确当前层的每个元素究竟是取上一层输出（也即上前层输入）的哪一个元素的值，具体见下面backward_maxpool_layer()函数的注释。</span></span><br><span class="line">                        l.output[out_index] = max;</span><br><span class="line">                        <span class="keyword">if</span> (l.indexes) l.indexes[out_index] = max_i;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (l.antialiasing) &#123;</span><br><span class="line">        network_state s = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">        s.train = state.train;</span><br><span class="line">        s.workspace = state.workspace;</span><br><span class="line">        s.net = state.net;</span><br><span class="line">        s.input = l.output;</span><br><span class="line">        forward_convolutional_layer(*(l.input_layer), s);</span><br><span class="line">        <span class="comment">//simple_copy_ongpu(l.outputs*l.batch, l.output, l.input_antialiasing);</span></span><br><span class="line">        <span class="built_in">memcpy</span>(l.output, l.input_layer-&gt;output, l.input_layer-&gt;outputs * l.input_layer-&gt;batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最大池化层的反向传播"><a href="#最大池化层的反向传播" class="headerlink" title="最大池化层的反向传播"></a>最大池化层的反向传播</h2><p>池化层的反向传播由<code>backward_maxpool_layer</code>实现，反向传播实际上比前向传播更加简单，你可以停下来想想为什么，再看我下面的详细解释。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 最大池化层反向传播函数</span></span><br><span class="line"><span class="comment">** l: 当前最大池化层</span></span><br><span class="line"><span class="comment">** state: 整个网络</span></span><br><span class="line"><span class="comment">** 说明：这个函数看上去很简单，比起backward_convolutional_layer()少了很多，这都是有原因的。实际上，在darknet中，不管是什么层，</span></span><br><span class="line"><span class="comment">**      其反向传播函数都会先后做两件事：1）计算当前层的敏感度图l.delta、权重更新值以及偏置更新值；2）计算上一层的敏感度图net.delta（部分计算，</span></span><br><span class="line"><span class="comment">**      要完成计算得等到真正到了这一层再说）。而这里，显然没有第一步，只有第二步，而且很简单，这是为什么呢？首先回答为什么没有第一步。注意当前层l是最大池化层，</span></span><br><span class="line"><span class="comment">**      最大池化层没有训练参数，说的再直白一点就是没有激活函数，或者认为激活函数就是f(x)=x，所以激活函数对于加权输入的导数其实就是1,</span></span><br><span class="line"><span class="comment">**      正如在backward_convolutional_layer()注释的那样，每一层的反向传播函数的第一步是将之前（就是下一层计算得到的，注意过程是反向的）</span></span><br><span class="line"><span class="comment">**      未计算完得到的l.delta乘以激活函数对加权输入的导数，以最终得到当前层的敏感度图，而对于最大池化层来说，每一个输出对于加权输入的导数值都是1,</span></span><br><span class="line"><span class="comment">**      同时并没有权重及偏置这些需要训练的参数，自然不再需要第一步；对于第二步为什么会如此简单。请看代码注释。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_maxpool_layer</span><span class="params">(<span class="keyword">const</span> maxpool_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">//获取当前最大池化层l的输出尺寸h,w</span></span><br><span class="line">    <span class="keyword">int</span> h = l.out_h;</span><br><span class="line">    <span class="keyword">int</span> w = l.out_w;</span><br><span class="line">	<span class="comment">//获取当前层输入/输出通道数</span></span><br><span class="line">    <span class="keyword">int</span> c = l.out_c;</span><br><span class="line">	<span class="comment">// 计算上一层的敏感度图（未计算完全，还差一个环节，这个环节等真正反向到了那层再执行，但是其实已经完全计算了，因为池化层无参数）</span></span><br><span class="line">    <span class="comment">// 循环总次数为当前层输出总元素个数（包含所有输入图片的输出，即维度为l.out_h * l.out_w * l.c * l.batch，注意此处l.c==l.out_c）</span></span><br><span class="line">    <span class="comment">// 对于上一层输出中的很多元素的导数值为0,而对最大值元素，其导数值为1；再乘以当前层的敏感度图，导数值为0的还是为0,导数值为1则就等于当前层的敏感度值。</span></span><br><span class="line">    <span class="comment">// 以输出图总元素个数进行遍历，刚好可以找出上一层输出中所有真正起作用（在某个池化区域中充当了最大元素值）也即敏感度值不为0的元素，而那些没有起作用的元素，</span></span><br><span class="line">    <span class="comment">// 可以不用理会，保持其初始值0就可以了。</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for <span class="comment">//openmp优化</span></span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; h*w*c*l.batch; ++i)&#123;</span><br><span class="line">        <span class="keyword">int</span> index = l.indexes[i];</span><br><span class="line">		<span class="comment">// 遍历的基准是以当前层的输出元素为基准的，l.indexes记录了当前层每一个输出元素与上一层哪一个输出元素有真正联系（也即上一层对应池化核区域中最大值元素的索引），</span></span><br><span class="line">        <span class="comment">// 所以index是上一层中所有输出元素的索引，且该元素在当前层某个池化域中充当了最大值元素，这个元素的敏感度值将直接传承当前层对应元素的敏感度值。</span></span><br><span class="line">        <span class="comment">// 而net.delta中，剩下没有被index按索引访问到的元素，就是那些没有真正起到作用的元素，这些元素的敏感度值为0（net.delta已经在前向时将所有元素值初始化为0）</span></span><br><span class="line">        <span class="comment">// 至于为什么要用+=运算符，原因有两个，和卷积类似：一是池化核由于跨度较小，导致有重叠区域；二是batch中有多张图片，需要将所有图片的影响加起来。</span></span><br><span class="line">        state.delta[index] += l.delta[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="平均池化层的前向传播和反向传播"><a href="#平均池化层的前向传播和反向传播" class="headerlink" title="平均池化层的前向传播和反向传播"></a>平均池化层的前向传播和反向传播</h2><p>刚才已经讲到了，最大池化以及平均池化整理是非常类似的，只是把最大的算术操作换成平均，然后平均池化层的反向传播就完成了，具体的代码可以去github项目中查看。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet网络的前向和反向传播介绍以及layer的详细解析</title>
    <url>/2020/02/22/AlexeyAB-DarkNet%E7%BD%91%E7%BB%9C%E7%9A%84%E5%89%8D%E5%90%91%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%BB%8B%E7%BB%8D%E4%BB%A5%E5%8F%8Alayer%E7%9A%84%E8%AF%A6%E7%BB%86%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面我们已经成功的获取了目标检测的网络结构(<code>cfg</code>文件的内容)，并将网络保存在了一个<code>network</code>结构体中，然后我们还分析了数据加载方式。现在数据和网络结构都有了，接下来就是开始训练/测试的过程了，这个过程主要调用的是<code>network</code>的前向传播和反向传播函数，而<code>network</code>的前向传播和反向传播又可以细分为每一个<code>layer</code>的前向传播和反向传播，今天我们来看一下网络的前向传播和反向传播以及<code>layer</code>是如何定义的。</p>
<h2 id="网络的前向传播和反向传播"><a href="#网络的前向传播和反向传播" class="headerlink" title="网络的前向传播和反向传播"></a>网络的前向传播和反向传播</h2><p>网络的前向传播函数在<code>src/network.c</code>中实现，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 前向计算网络net每一层的输出</span></span><br><span class="line"><span class="comment">** state用来标记当前网络的状态，</span></span><br><span class="line"><span class="comment">** 遍历net的每一层网络，从第0层到最后一层，逐层计算每层的输出</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_network</span><span class="params">(network net, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 网络的工作空间, 指的是所有层中占用运算空间最大的那个层的 workspace_size,</span></span><br><span class="line">    <span class="comment">// 因为实际上在 GPU 或 CPU 中某个时刻只有一个层在做前向或反向运算</span></span><br><span class="line">    state.workspace = net.workspace;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 遍历所有层，从第一层到最后一层，逐层进行前向传播，网络共有net.n层</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; net.n; ++i)&#123;</span><br><span class="line">		<span class="comment">// 当前正在进行第i层的处理</span></span><br><span class="line">        state.index = i;</span><br><span class="line">		<span class="comment">// 获取当前层</span></span><br><span class="line">        layer l = net.layers[i];</span><br><span class="line">		<span class="comment">// 如果当前层的l.delta已经动态分配了内存，则调用fill_cpu()函数将其所有元素初始化为0</span></span><br><span class="line">        <span class="keyword">if</span>(l.delta &amp;&amp; state.train)&#123;</span><br><span class="line">			<span class="comment">// 第一个参数为l.delta的元素个数，第二个参数为初始化值，为0</span></span><br><span class="line">            <span class="built_in">scal_cpu</span>(l.outputs * l.batch, <span class="number">0</span>, l.delta, <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//double time = get_time_point();</span></span><br><span class="line">		<span class="comment">// 前向传播: 完成当前层前向推理</span></span><br><span class="line">        l.forward(l, state);</span><br><span class="line">		<span class="comment">// 完成某一层的推理时，置网络的输入为当前层的输出（这将成为下一层网络的输入），注意此处更改的是state，而非原始的net</span></span><br><span class="line">        <span class="comment">//printf(&quot;%d - Predicted in %lf milli-seconds.\n&quot;, i, ((double)get_time_point() - time) / 1000);</span></span><br><span class="line">        state.input = l.output;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>网络的反向传播函数也在<code>src/network.c</code>中实现，代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 反向计算网络net每一层的梯度图，并进而计算每一层的权重、偏置更新值，最后完成每一层权重与偏置更新</span></span><br><span class="line"><span class="comment">** 流程: 遍历net的每一层网络，从最后一层到第一层(此处所指的第一层不是指输入层，而是与输入层直接相连的第一层隐含层)进行反向传播</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_network</span><span class="params">(network net, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">// 在进行反向传播之前先保存一下原来的net信息</span></span><br><span class="line">    <span class="keyword">float</span> *original_input = state.input;</span><br><span class="line">    <span class="keyword">float</span> *original_delta = state.delta;</span><br><span class="line">    state.workspace = net.workspace;</span><br><span class="line">    <span class="keyword">for</span>(i = net.n<span class="number">-1</span>; i &gt;= <span class="number">0</span>; --i)&#123;</span><br><span class="line">		<span class="comment">// 标志参数，当前网络的活跃层</span></span><br><span class="line">        state.index = i;</span><br><span class="line">		<span class="comment">// i = 0时，也即已经到了网络的第1层（或者说第0层，看个人习惯了～）了，</span></span><br><span class="line">        <span class="comment">// 就是直接与输入层相连的第一层隐含层（注意不是输入层，我理解的输入层就是指输入的图像数据，</span></span><br><span class="line">        <span class="comment">// 严格来说，输入层不算一层网络，因为输入层没有训练参数，也没有激活函数），这个时候，不需要else中的赋值，1）对于第1层来说，其前面已经没有网络层了（输入层不算），</span></span><br><span class="line">        <span class="comment">// 因此没有必要再计算前一层的参数，故没有必要在获取上一层；2）第一层的输入就是图像输入，也即整个net最原始的输入，在开始进行反向传播之前，已经用original_*变量保存了</span></span><br><span class="line">        <span class="comment">// 最为原始的net，所以net.input就是第一层的输入，不需要获取上一层的输出作为当前层的输入；3）同1），第一层之前已经没有层了，</span></span><br><span class="line">        <span class="comment">// 也就不需要计算上一层的delta，即不需要再将net.delta链接到prev.delta，此时进入到l.backward()中后，net.delta就是NULL（可以参看darknet.h中关于delta</span></span><br><span class="line">        <span class="comment">// 的注释），也就不会再计算上一层的敏感度了（比如卷积神经网络中的backward_convolutional_layer()函数）</span></span><br><span class="line">        <span class="comment">// 这几行代码就是给net.input和net.delta赋值</span></span><br><span class="line">        <span class="keyword">if</span>(i == <span class="number">0</span>)&#123;</span><br><span class="line">            state.input = original_input;</span><br><span class="line">            state.delta = original_delta;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            layer prev = net.layers[i<span class="number">-1</span>];</span><br><span class="line">            state.input = prev.output;</span><br><span class="line">            state.delta = prev.delta;</span><br><span class="line">        &#125;</span><br><span class="line">        layer l = net.layers[i];</span><br><span class="line">        <span class="keyword">if</span> (l.stopbackward) <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> (l.onlyforward) <span class="keyword">continue</span>;</span><br><span class="line">		<span class="comment">// 反向计算第i层的敏感度图、权重及偏置更新值，并更新权重、偏置（同时会计算上一层的敏感度图，</span></span><br><span class="line">        <span class="comment">// 存储在net.delta中，但是还差一个环节：乘上上一层输出对加权输入的导数，也即上一层激活函数对加权输入的导数）</span></span><br><span class="line">        l.<span class="built_in">backward</span>(l, state);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="layer的解释"><a href="#layer的解释" class="headerlink" title="layer的解释"></a>layer的解释</h2><p>在将具体某个层如卷积层的前向传播和反向传播之前，需要先来看一下<code>layer</code>是怎么定义的，因为网络的前向传播和反向传播实际上就是各个网络层(<code>layer</code>)的前向传播和反向传播，这部分加好注释的代码（在<code>src/darknet.h</code>中）如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义layer</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">layer</span> &#123;</span></span><br><span class="line">    LAYER_TYPE type; <span class="comment">// 网络层的类型，枚举类型，取值比如DROPOUT,CONVOLUTIONAL,MAXPOOL分别表示dropout层，卷积层，最大池化层，可参见LAYER_TYPE枚举类型的定义</span></span><br><span class="line">    ACTIVATION activation; <span class="comment">//激活函数类型，枚举类型</span></span><br><span class="line">    COST_TYPE cost_type; <span class="comment">//损失函数类型，枚举类型</span></span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*forward)   (struct layer, struct network_state);</span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*backward)  (struct layer, struct network_state);</span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*update)    (struct layer, <span class="keyword">int</span>, <span class="keyword">float</span>, <span class="keyword">float</span>, <span class="keyword">float</span>);</span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*forward_gpu)   (struct layer, struct network_state);</span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*backward_gpu)  (struct layer, struct network_state);</span><br><span class="line">    <span class="built_in"><span class="keyword">void</span></span>(*update_gpu)    (struct layer, <span class="keyword">int</span>, <span class="keyword">float</span>, <span class="keyword">float</span>, <span class="keyword">float</span>);</span><br><span class="line">    layer *share_layer;</span><br><span class="line">    <span class="keyword">int</span> train;</span><br><span class="line">    <span class="keyword">int</span> avgpool;</span><br><span class="line">    <span class="keyword">int</span> batch_normalize; <span class="comment">// 是否进行BN，如果进行BN，则值为1</span></span><br><span class="line">    <span class="keyword">int</span> shortcut;</span><br><span class="line">    <span class="keyword">int</span> batch; <span class="comment">// 一个batch中含有的图片张数，等于net.batch，详细可以参考network.h中的注释，一般在构建具体网络层时赋值（比如make_maxpool_layer()中）</span></span><br><span class="line">    <span class="keyword">int</span> forced;</span><br><span class="line">    <span class="keyword">int</span> flipped;</span><br><span class="line">    <span class="keyword">int</span> inputs; <span class="comment">// 一张输入图片所含的元素个数（一般在各网络层构建函数中赋值，比如make_connected_layer()），第一层的值等于l.h*l.w*l.c，</span></span><br><span class="line">                <span class="comment">// 之后的每一层都是由上一层的输出自动推算得到的（参见parse_network_cfg()，在构建每一层后，会更新params.inputs为上一层的l.outputs）</span></span><br><span class="line">    <span class="keyword">int</span> outputs; <span class="comment">// 该层对应一张输入图片的输出元素个数（一般在各网络层构建函数中赋值，比如make_connected_layer()）</span></span><br><span class="line">                 <span class="comment">// 对于一些网络，可由输入图片的尺寸及相关参数计算出，比如卷积层，可以通过输入尺寸以及步长、核大小计算出；</span></span><br><span class="line">                 <span class="comment">// 对于另一些尺寸，则需要通过网络配置文件指定，如未指定，取默认值1，比如全连接层（见parse_connected()函数）</span></span><br><span class="line">    <span class="keyword">int</span> nweights;</span><br><span class="line">    <span class="keyword">int</span> nbiases;</span><br><span class="line">    <span class="keyword">int</span> extra;</span><br><span class="line">    <span class="keyword">int</span> truths;  <span class="comment">// &lt; 根据region_layer.c判断，这个变量表示一张图片含有的真实值的个数，对于检测模型来说，一个真实的标签含有5个值，</span></span><br><span class="line">                <span class="comment">// 包括类型对应的编号以及定位矩形框用到的w,h,x,y四个参数，且在darknet中固定每张图片最大处理30个矩形框，（可查看max_boxes参数），</span></span><br><span class="line">                <span class="comment">// 因此，在region_layer.c的make_region_layer()函数中赋值为30*5.</span></span><br><span class="line">    <span class="keyword">int</span> h, w, c;  <span class="comment">// 该层输入的图片的宽，高，通道数（一般在各网络层构建函数中赋值，比如make_connected_layer()）</span></span><br><span class="line">    <span class="keyword">int</span> out_h, out_w, out_c;<span class="comment">// 该层输出图片的高、宽、通道数（一般在各网络层构建函数中赋值，比如make_connected_layer()）</span></span><br><span class="line">    <span class="keyword">int</span> n; <span class="comment">// 对于卷积层，该参数表示卷积核个数，等于out_c，其值由网络配置文件指定；对于region_layer层，该参数等于配置文件中的num值</span></span><br><span class="line">           <span class="comment">// (该参数通过make_region_layer()函数赋值，在parser.c中调用的make_region_layer()函数)，</span></span><br><span class="line">           <span class="comment">// 可以在darknet/cfg文件夹下执行命令：grep num *.cfg便可以搜索出所有设置了num参数的网络，这里面包括yolo.cfg等，其值有</span></span><br><span class="line">           <span class="comment">// 设定为3,5,2的，该参数就是Yolo论文中的B，也就是一个cell中预测多少个box。</span></span><br><span class="line">    <span class="keyword">int</span> max_boxes; <span class="comment">// 每张图片最多含有的标签矩形框数（参看：data.c中的load_data_detection()，其输入参数boxes就是指这个参数），</span></span><br><span class="line">                   <span class="comment">// 什么意思呢？就是每张图片中最多打了max_boxes个标签物体，模型预测过程中，可能会预测出很多的物体，但实际上，</span></span><br><span class="line">                   <span class="comment">// 图片中打上标签的真正存在的物体最多就max_boxes个，预测多出来的肯定存在false positive，需要滤出与筛选，</span></span><br><span class="line">                   <span class="comment">// 可参看region_layer.c中forward_region_layer()函数的第二个for循环中的注释</span></span><br><span class="line">    <span class="keyword">int</span> groups; <span class="comment">// 应该是控制组卷积的组数，类似于caffe的group参数</span></span><br><span class="line">    <span class="keyword">int</span> group_id;</span><br><span class="line">    <span class="keyword">int</span> size; <span class="comment">// 核尺寸（比如卷积核，池化核等）</span></span><br><span class="line">    <span class="keyword">int</span> side;</span><br><span class="line">    <span class="keyword">int</span> stride; <span class="comment">// 滑动步长，如卷积核的滑动步长</span></span><br><span class="line">    <span class="keyword">int</span> stride_x;</span><br><span class="line">    <span class="keyword">int</span> stride_y;</span><br><span class="line">    <span class="keyword">int</span> dilation; <span class="comment">//空洞卷积参数</span></span><br><span class="line">    <span class="keyword">int</span> antialiasing;</span><br><span class="line">    <span class="keyword">int</span> maxpool_depth;</span><br><span class="line">    <span class="keyword">int</span> out_channels; <span class="comment">// 输出通道数</span></span><br><span class="line">    <span class="keyword">int</span> reverse;</span><br><span class="line">    <span class="keyword">int</span> flatten;</span><br><span class="line">    <span class="keyword">int</span> spatial;</span><br><span class="line">    <span class="keyword">int</span> pad; <span class="comment">// 该层对输入数据四周的补0长度（现在发现在卷积层，最大池化层中有用到该参数），一般在构建具体网络层时赋值（比如make_maxpool_layer()中）</span></span><br><span class="line">    <span class="keyword">int</span> sqrt;</span><br><span class="line">    <span class="keyword">int</span> flip;</span><br><span class="line">    <span class="keyword">int</span> index;</span><br><span class="line">    <span class="keyword">int</span> scale_wh;</span><br><span class="line">    <span class="keyword">int</span> binary;</span><br><span class="line">    <span class="keyword">int</span> xnor;</span><br><span class="line">    <span class="keyword">int</span> peephole;</span><br><span class="line">    <span class="keyword">int</span> use_bin_output;</span><br><span class="line">    <span class="keyword">int</span> keep_delta_gpu;</span><br><span class="line">    <span class="keyword">int</span> optimized_memory;</span><br><span class="line">    <span class="keyword">int</span> steps;</span><br><span class="line">    <span class="keyword">int</span> state_constrain;</span><br><span class="line">    <span class="keyword">int</span> hidden;</span><br><span class="line">    <span class="keyword">int</span> truth;</span><br><span class="line">    <span class="keyword">float</span> smooth;</span><br><span class="line">    <span class="keyword">float</span> dot;</span><br><span class="line">    <span class="keyword">int</span> deform;</span><br><span class="line">    <span class="keyword">int</span> sway;</span><br><span class="line">    <span class="keyword">int</span> rotate;</span><br><span class="line">    <span class="keyword">int</span> stretch;</span><br><span class="line">    <span class="keyword">int</span> stretch_sway;</span><br><span class="line">    <span class="keyword">float</span> angle;</span><br><span class="line">    <span class="keyword">float</span> jitter;</span><br><span class="line">    <span class="keyword">float</span> saturation;</span><br><span class="line">    <span class="keyword">float</span> exposure;</span><br><span class="line">    <span class="keyword">float</span> shift;</span><br><span class="line">    <span class="keyword">float</span> ratio;</span><br><span class="line">    <span class="keyword">float</span> learning_rate_scale;</span><br><span class="line">    <span class="keyword">float</span> clip;</span><br><span class="line">    <span class="keyword">int</span> focal_loss;</span><br><span class="line">    <span class="keyword">float</span> *classes_multipliers;</span><br><span class="line">    <span class="keyword">float</span> label_smooth_eps;</span><br><span class="line">    <span class="keyword">int</span> noloss;</span><br><span class="line">    <span class="keyword">int</span> softmax;</span><br><span class="line">    <span class="keyword">int</span> classes; <span class="comment">// 物体类别种数，一个训练好的网络，只能检测指定所有物体类别中的物体，比如yolo9000.cfg，设置该值为9418，</span></span><br><span class="line">                 <span class="comment">// 也就是该网络训练好了之后可以检测9418种物体。该参数由网络配置文件指定。目前在作者给的例子中,</span></span><br><span class="line">                 <span class="comment">// 有设置该值的配置文件大都是检测模型，纯识别的网络模型没有设置该值，我想是因为检测模型输出的一般会为各个类别的概率，</span></span><br><span class="line">                 <span class="comment">// 所以需要知道这个种类数目，而识别的话，不需要知道某个物体属于这些所有类的具体概率，因此可以不知道。</span></span><br><span class="line">    <span class="keyword">int</span> coords; <span class="comment">// 这个参数一般用在检测模型中，且不是所有层都有这个参数，一般在检测模型最后一层有，比如region_layer层，该参数的含义</span></span><br><span class="line">                <span class="comment">// 是定位一个物体所需的参数个数，一般为4个，包括物体所在矩形框中心坐标x,y两个参数以及矩形框长宽w,h两个参数，</span></span><br><span class="line">                <span class="comment">// 可以在darknet/cfg文件夹下，执行grep coords *.cfg，会搜索出所有使用该参数的模型，并可看到该值都设置为4</span></span><br><span class="line">    <span class="keyword">int</span> background;</span><br><span class="line">    <span class="keyword">int</span> rescore;</span><br><span class="line">    <span class="keyword">int</span> objectness;</span><br><span class="line">    <span class="keyword">int</span> does_cost;</span><br><span class="line">    <span class="keyword">int</span> joint;</span><br><span class="line">    <span class="keyword">int</span> noadjust;</span><br><span class="line">    <span class="keyword">int</span> reorg;</span><br><span class="line">    <span class="keyword">int</span> log;</span><br><span class="line">    <span class="keyword">int</span> tanh;</span><br><span class="line">    <span class="keyword">int</span> *mask;</span><br><span class="line">    <span class="keyword">int</span> total;</span><br><span class="line">    <span class="keyword">float</span> bflops;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> adam;</span><br><span class="line">    <span class="keyword">float</span> B1;</span><br><span class="line">    <span class="keyword">float</span> B2;</span><br><span class="line">    <span class="keyword">float</span> eps;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> t;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> alpha;</span><br><span class="line">    <span class="keyword">float</span> beta;</span><br><span class="line">    <span class="keyword">float</span> kappa;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> coord_scale;</span><br><span class="line">    <span class="keyword">float</span> object_scale;</span><br><span class="line">    <span class="keyword">float</span> noobject_scale;</span><br><span class="line">    <span class="keyword">float</span> mask_scale;</span><br><span class="line">    <span class="keyword">float</span> class_scale;</span><br><span class="line">    <span class="keyword">int</span> bias_match;</span><br><span class="line">    <span class="keyword">float</span> random;</span><br><span class="line">    <span class="keyword">float</span> ignore_thresh;</span><br><span class="line">    <span class="keyword">float</span> truth_thresh;</span><br><span class="line">    <span class="keyword">float</span> iou_thresh;</span><br><span class="line">    <span class="keyword">float</span> thresh;</span><br><span class="line">    <span class="keyword">float</span> focus;</span><br><span class="line">    <span class="keyword">int</span> classfix;</span><br><span class="line">    <span class="keyword">int</span> absolute;</span><br><span class="line">    <span class="keyword">int</span> assisted_excitation;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> onlyforward; <span class="comment">// 标志参数，当值为1那么当前层只执行前向传播</span></span><br><span class="line">    <span class="keyword">int</span> stopbackward;  <span class="comment">// 标志参数，用来强制停止反向传播过程（值为1则停止反向传播），参看network.c中的backward_network()函数</span></span><br><span class="line">    <span class="keyword">int</span> dontload;</span><br><span class="line">    <span class="keyword">int</span> dontsave;</span><br><span class="line">    <span class="keyword">int</span> dontloadscales;</span><br><span class="line">    <span class="keyword">int</span> numload;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> temperature; <span class="comment">// 温度参数，softmax层特有参数，在parse_softmax()函数中赋值，由网络配置文件指定，如果未指定，则使用默认值1（见parse_softmax()）</span></span><br><span class="line">    <span class="keyword">float</span> probability; <span class="comment">// dropout概率，即舍弃概率，相应的1-probability为保留概率（具体的使用可参见forward_dropout_layer()），在make_dropout_layer()中赋值，</span></span><br><span class="line">						<span class="comment">// 其值由网络配置文件指定，如果网络配置文件未指定，则取默认值0.5（见parse_dropout()）</span></span><br><span class="line">    <span class="keyword">float</span> dropblock_size_rel;</span><br><span class="line">    <span class="keyword">int</span> dropblock_size_abs;</span><br><span class="line">    <span class="keyword">int</span> dropblock;</span><br><span class="line">    <span class="keyword">float</span> scale; <span class="comment">// 在dropout层中，该变量是一个比例因子，取值为保留概率的倒数（darknet实现用的是inverted dropout），用于缩放输入元素的值</span></span><br><span class="line">                       <span class="comment">// （在网上随便搜索关于dropout的博客，都会提到inverted dropout），在make_dropout_layer()函数中赋值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span>  * cweights;</span><br><span class="line">    <span class="keyword">int</span>   * indexes; <span class="comment">// 维度为l.out_h * l.out_w * l.out_c * l.batch，可知包含整个batch输入图片的输出，一般在构建具体网络层时动态分配内存（比如make_maxpool_layer()中）。</span></span><br><span class="line">                     <span class="comment">// 目前仅发现其用在在最大池化层中。该变量存储的是索引值，并与当前层所有输出元素一一对应，表示当前层每个输出元素的值是上一层输出中的哪一个元素值（存储的索引值是</span></span><br><span class="line">                     <span class="comment">// 在上一层所有输出元素（包含整个batch）中的索引），因为对于最大池化层，每一个输出元素的值实际是上一层输出（也即当前层输入）某个池化区域中的最大元素值，indexes就是记录</span></span><br><span class="line">                     <span class="comment">// 这些局部最大元素值在上一层所有输出元素中的总索引。记录这些值有什么用吗？当然有，用于反向传播过程计算上一层敏感度值，详见backward_maxpool_layer()以及forward_maxpool_layer()函数。</span></span><br><span class="line">    <span class="keyword">int</span>   * input_layers; <span class="comment">//这个层有哪些输入层</span></span><br><span class="line">    <span class="keyword">int</span>   * input_sizes; <span class="comment">// 输入层的尺寸</span></span><br><span class="line">    <span class="keyword">float</span> **layers_output; <span class="comment">//产生的一系列输出层</span></span><br><span class="line">    <span class="keyword">float</span> **layers_delta;</span><br><span class="line">    WEIGHTS_TYPE_T weights_type;</span><br><span class="line">    WEIGHTS_NORMALIZATION_T weights_normalizion;</span><br><span class="line">	<span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 这个参数用的不多，仅在region_layer.c中使用，该参数的作用是用于不同数据集间类别编号的转换，更为具体的，</span></span><br><span class="line"><span class="comment">     * 是coco数据集中80类物体编号与联合数据集中9000+物体类别编号之间的转换，可以对比查看data/coco.names与</span></span><br><span class="line"><span class="comment">     * data/9k.names以及data/coco9k.map三个文件（旧版的darknet可能没有，新版的darknet才有coco9k.map这个文件），</span></span><br><span class="line"><span class="comment">     * 可以发现，coco.names中每一个物体类别都可以在9k.names中找到,且coco.names中每个物体类别名称在9k.names</span></span><br><span class="line"><span class="comment">     * 中所在的行数就是coco9k.map中的编号值（减了1,因为在程序数组中编号从0开始），也就是这个map将coco数据集中</span></span><br><span class="line"><span class="comment">     * 的类别编号映射到联和数据集9k中的类别编号（这个9k数据集是一个联和多个数据集的大数集，其名称分类被层级划分，</span></span><br><span class="line"><span class="comment">     * ）（注意两个文件中物体的类别名称大部分都相同，有小部分存在小差异，虽然有差异，但只是两个数据集中使用的名称有所差异而已，</span></span><br><span class="line"><span class="comment">     * 对应的物体是一样的，比如在coco.names中摩托车的名称为motorbike，在联合数据集9k.names，其名称为motorcycle）.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">int</span>   * map;</span><br><span class="line">    <span class="keyword">int</span>   * counts;</span><br><span class="line">    <span class="keyword">float</span> ** sums;</span><br><span class="line">	<span class="comment">// 这个参数目前只发现用在dropout层，用于存储一些列的随机数，这些随机数与dropout层的输入元素一一对应，维度为l.batch*l.inputs（包含整个batch的），在make_dropout_layer()函数中用calloc动态分配内存，</span></span><br><span class="line">    <span class="comment">// 并在前向传播函数forward_dropout_layer()函数中逐元素赋值。里面存储的随机数满足0~1均匀分布，干什么用呢？用于决定该输入元素的去留，</span></span><br><span class="line">    <span class="comment">// 我们知道dropout层就完成一个事：按照一定概率舍弃输入神经元（所谓舍弃就是置该输入的值为0），rand中存储的值就是如果小于l.probability，则舍弃该输入神经元（详见：forward_dropout_layer()）。</span></span><br><span class="line">    <span class="comment">// 为什么要保留这些随机数呢？和最大池化层中的l.indexes类似，在反向传播函数backward_dropout_layer()中用来指示计算上一层的敏感度值，因为dropout舍弃了一些输入，</span></span><br><span class="line">    <span class="comment">// 这些输入（dropout层的输入，上一层的输出）对应的敏感度值可以置为0，而那些没有舍弃的输入，才有必要由当前dropout层反向传播过去。</span></span><br><span class="line">    <span class="keyword">float</span> * rand;</span><br><span class="line">    <span class="keyword">float</span> * cost;</span><br><span class="line">    <span class="keyword">float</span> * state;</span><br><span class="line">    <span class="keyword">float</span> * prev_state;</span><br><span class="line">    <span class="keyword">float</span> * forgot_state;</span><br><span class="line">    <span class="keyword">float</span> * forgot_delta;</span><br><span class="line">    <span class="keyword">float</span> * state_delta;</span><br><span class="line">    <span class="keyword">float</span> * combine_cpu;</span><br><span class="line">    <span class="keyword">float</span> * combine_delta_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *concat;</span><br><span class="line">    <span class="keyword">float</span> *concat_delta;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *binary_weights;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *biases;  <span class="comment">// 当前层所有偏置，对于卷积层，维度l.n，每个卷积核有一个偏置；对于全连接层，维度等于单张输入图片对应的元素个数即outputs，一般在各网络构建函数中动态分配内存（比如make_connected_layer()</span></span><br><span class="line">    <span class="keyword">float</span> *bias_updates; <span class="comment">// 当前层所有偏置更新值，对于卷积层，维度l.n，每个卷积核有一个偏置；对于全连接层，维度为outputs。所谓权重系数更新值，就是梯度下降中与步长相乘的那项，也即误差对偏置的导数，</span></span><br><span class="line">                          <span class="comment">// 一般在各网络构建函数中动态分配内存（比如make_connected_layer())</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *scales;</span><br><span class="line">    <span class="keyword">float</span> *scale_updates;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *weights; <span class="comment">//当前层所有权重系数（连接当前层和上一层的系数，但记在当前层上），对于卷积层，维度为l.n*l.c*l.size*l.size，即卷积核个数乘以卷积核尺寸再乘以输入通道数（各个通道上的权重系数独立不一样）；</span></span><br><span class="line">                     <span class="comment">// 对于全连接层，维度为单张图片输入与输出元素个数之积inputs*outputs，一般在各网络构建函数中动态分配内存（比如make_connected_layer()）</span></span><br><span class="line">    <span class="keyword">float</span> *weight_updates;<span class="comment">// 当前层所有权重系数更新值，对于卷积层维度为l.n*l.c*l.size*l.size；对于全连接层，维度为单张图片输入与输出元素个数之积inputs*outputs，</span></span><br><span class="line">                            <span class="comment">// 所谓权重系数更新值，就是梯度下降中与步长相乘的那项，也即误差对权重的导数，一般在各网络构建函数中动态分配内存（比如make_connected_layer()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> scale_x_y;</span><br><span class="line">    <span class="keyword">float</span> max_delta;</span><br><span class="line">    <span class="keyword">float</span> uc_normalizer;</span><br><span class="line">    <span class="keyword">float</span> iou_normalizer;</span><br><span class="line">    <span class="keyword">float</span> cls_normalizer;</span><br><span class="line">    IOU_LOSS iou_loss;</span><br><span class="line">    NMS_KIND nms_kind;</span><br><span class="line">    <span class="keyword">float</span> beta_nms;</span><br><span class="line">    YOLO_POINT yolo_point;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *align_bit_weights_gpu;</span><br><span class="line">    <span class="keyword">float</span> *mean_arr_gpu;</span><br><span class="line">    <span class="keyword">float</span> *align_workspace_gpu;</span><br><span class="line">    <span class="keyword">float</span> *transposed_align_workspace_gpu;</span><br><span class="line">    <span class="keyword">int</span> align_workspace_size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *align_bit_weights;</span><br><span class="line">    <span class="keyword">float</span> *mean_arr;</span><br><span class="line">    <span class="keyword">int</span> align_bit_weights_size;</span><br><span class="line">    <span class="keyword">int</span> lda_align;</span><br><span class="line">    <span class="keyword">int</span> new_lda;</span><br><span class="line">    <span class="keyword">int</span> bit_align;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *col_image;</span><br><span class="line">    <span class="keyword">float</span> * delta; <span class="comment">// 存储每一层的敏感度图：包含所有输出元素的敏感度值（整个batch所有图片）。所谓敏感度，即误差函数关于当前层每个加权输入的导数值，</span></span><br><span class="line">                   <span class="comment">// 关于敏感度图这个名称，其实就是梯度，可以参考https://www.zybuluo.com/hanbingtao/note/485480。</span></span><br><span class="line">                   <span class="comment">// 元素个数为l.batch * l.outputs（其中l.outputs = l.out_h * l.out_w * l.out_c），</span></span><br><span class="line">                   <span class="comment">// 对于卷积神经网络，在make_convolutional_layer()动态分配内存，按行存储，可视为l.batch行，l.outputs列，</span></span><br><span class="line">                   <span class="comment">// 即batch中每一张图片，对应l.delta中的一行，而这一行，又可以视作有l.out_c行，l.out_h*l.out_c列，</span></span><br><span class="line">                   <span class="comment">// 其中每小行对应一张输入图片的一张输出特征图的敏感度。一般在构建具体网络层时动态分配内存（比如make_maxpool_layer()中）。</span></span><br><span class="line">    <span class="keyword">float</span> * output; <span class="comment">// 存储该层所有的输出，维度为l.out_h * l.out_w * l.out_c * l.batch，可知包含整个batch输入图片的输出，一般在构建具体网络层时动态分配内存（比如make_maxpool_layer()中）。</span></span><br><span class="line">                    <span class="comment">// 按行存储：每张图片按行铺排成一大行，图片间再并成一行。</span></span><br><span class="line">    <span class="keyword">float</span> * activation_input;</span><br><span class="line">    <span class="keyword">int</span> delta_pinned;</span><br><span class="line">    <span class="keyword">int</span> output_pinned;</span><br><span class="line">    <span class="keyword">float</span> * loss;</span><br><span class="line">    <span class="keyword">float</span> * squared;</span><br><span class="line">    <span class="keyword">float</span> * norms;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * spatial_mean;</span><br><span class="line">    <span class="keyword">float</span> * mean;</span><br><span class="line">    <span class="keyword">float</span> * variance;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * mean_delta;</span><br><span class="line">    <span class="keyword">float</span> * variance_delta;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * rolling_mean;</span><br><span class="line">    <span class="keyword">float</span> * rolling_variance;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * x;</span><br><span class="line">    <span class="keyword">float</span> * x_norm;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * m;</span><br><span class="line">    <span class="keyword">float</span> * v;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * bias_m;</span><br><span class="line">    <span class="keyword">float</span> * bias_v;</span><br><span class="line">    <span class="keyword">float</span> * scale_m;</span><br><span class="line">    <span class="keyword">float</span> * scale_v;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *z_cpu;</span><br><span class="line">    <span class="keyword">float</span> *r_cpu;</span><br><span class="line">    <span class="keyword">float</span> *h_cpu;</span><br><span class="line">    <span class="keyword">float</span> *stored_h_cpu;</span><br><span class="line">    <span class="keyword">float</span> * prev_state_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *temp_cpu;</span><br><span class="line">    <span class="keyword">float</span> *temp2_cpu;</span><br><span class="line">    <span class="keyword">float</span> *temp3_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *dh_cpu;</span><br><span class="line">    <span class="keyword">float</span> *hh_cpu;</span><br><span class="line">    <span class="keyword">float</span> *prev_cell_cpu;</span><br><span class="line">    <span class="keyword">float</span> *cell_cpu;</span><br><span class="line">    <span class="keyword">float</span> *f_cpu;</span><br><span class="line">    <span class="keyword">float</span> *i_cpu;</span><br><span class="line">    <span class="keyword">float</span> *g_cpu;</span><br><span class="line">    <span class="keyword">float</span> *o_cpu;</span><br><span class="line">    <span class="keyword">float</span> *c_cpu;</span><br><span class="line">    <span class="keyword">float</span> *stored_c_cpu;</span><br><span class="line">    <span class="keyword">float</span> *dc_cpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *binary_input;</span><br><span class="line">    <span class="keyword">uint32_t</span> *bin_re_packed_input;</span><br><span class="line">    <span class="keyword">char</span> *t_bit_input;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">self_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">output_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">reset_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">update_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_gate_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_gate_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_save_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_save_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_state_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_state_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_z_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_z_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_r_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_r_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">input_h_layer</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">state_h_layer</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wz</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">uz</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wr</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">ur</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wh</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">uh</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">uo</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wo</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">vo</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">uf</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wf</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">vf</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">ui</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wi</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">vi</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">ug</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">layer</span> *<span class="title">wg</span>;</span></span><br><span class="line"> </span><br><span class="line">    tree *softmax_tree; <span class="comment">// softmax层用到的一个参数，不过这个参数似乎并不常见，很多用到softmax层的网络并没用使用这个参数，目前仅发现darknet9000.cfg中使用了该参数，如果未用到该参数，其值为NULL，如果用到了则会在parse_softmax()中赋值，</span></span><br><span class="line">                       <span class="comment">// 目前个人的初步猜测是利用该参数来组织标签数据，以方便访问</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">size_t</span> workspace_size; <span class="comment">// net.workspace的元素个数，为所有层中最大的l.out_h*l.out_w*l.size*l.size*l.c，（在make_convolutional_layer()计算得到workspace_size的大小，在parse_network_cfg()中动态分配内存，此值对应未使用gpu时的情况</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="keyword">int</span> *indexes_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *z_gpu;</span><br><span class="line">    <span class="keyword">float</span> *r_gpu;</span><br><span class="line">    <span class="keyword">float</span> *h_gpu;</span><br><span class="line">    <span class="keyword">float</span> *stored_h_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *temp_gpu;</span><br><span class="line">    <span class="keyword">float</span> *temp2_gpu;</span><br><span class="line">    <span class="keyword">float</span> *temp3_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *dh_gpu;</span><br><span class="line">    <span class="keyword">float</span> *hh_gpu;</span><br><span class="line">    <span class="keyword">float</span> *prev_cell_gpu;</span><br><span class="line">    <span class="keyword">float</span> *prev_state_gpu;</span><br><span class="line">    <span class="keyword">float</span> *last_prev_state_gpu;</span><br><span class="line">    <span class="keyword">float</span> *last_prev_cell_gpu;</span><br><span class="line">    <span class="keyword">float</span> *cell_gpu;</span><br><span class="line">    <span class="keyword">float</span> *f_gpu;</span><br><span class="line">    <span class="keyword">float</span> *i_gpu;</span><br><span class="line">    <span class="keyword">float</span> *g_gpu;</span><br><span class="line">    <span class="keyword">float</span> *o_gpu;</span><br><span class="line">    <span class="keyword">float</span> *c_gpu;</span><br><span class="line">    <span class="keyword">float</span> *stored_c_gpu;</span><br><span class="line">    <span class="keyword">float</span> *dc_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// adam</span></span><br><span class="line">    <span class="keyword">float</span> *m_gpu;</span><br><span class="line">    <span class="keyword">float</span> *v_gpu;</span><br><span class="line">    <span class="keyword">float</span> *bias_m_gpu;</span><br><span class="line">    <span class="keyword">float</span> *scale_m_gpu;</span><br><span class="line">    <span class="keyword">float</span> *bias_v_gpu;</span><br><span class="line">    <span class="keyword">float</span> *scale_v_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * combine_gpu;</span><br><span class="line">    <span class="keyword">float</span> * combine_delta_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * forgot_state_gpu;</span><br><span class="line">    <span class="keyword">float</span> * forgot_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * state_gpu;</span><br><span class="line">    <span class="keyword">float</span> * state_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * gate_gpu;</span><br><span class="line">    <span class="keyword">float</span> * gate_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * save_gpu;</span><br><span class="line">    <span class="keyword">float</span> * save_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * concat_gpu;</span><br><span class="line">    <span class="keyword">float</span> * concat_delta_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *binary_input_gpu;</span><br><span class="line">    <span class="keyword">float</span> *binary_weights_gpu;</span><br><span class="line">    <span class="keyword">float</span> *bin_conv_shortcut_in_gpu;</span><br><span class="line">    <span class="keyword">float</span> *bin_conv_shortcut_out_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * mean_gpu;</span><br><span class="line">    <span class="keyword">float</span> * variance_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * rolling_mean_gpu;</span><br><span class="line">    <span class="keyword">float</span> * rolling_variance_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * variance_delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * mean_delta_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * col_image_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * x_gpu;</span><br><span class="line">    <span class="keyword">float</span> * x_norm_gpu;</span><br><span class="line">    <span class="keyword">float</span> * weights_gpu;</span><br><span class="line">    <span class="keyword">float</span> * weight_updates_gpu;</span><br><span class="line">    <span class="keyword">float</span> * weight_deform_gpu;</span><br><span class="line">    <span class="keyword">float</span> * weight_change_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * weights_gpu16;</span><br><span class="line">    <span class="keyword">float</span> * weight_updates_gpu16;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * biases_gpu;</span><br><span class="line">    <span class="keyword">float</span> * bias_updates_gpu;</span><br><span class="line">    <span class="keyword">float</span> * bias_change_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * scales_gpu;</span><br><span class="line">    <span class="keyword">float</span> * scale_updates_gpu;</span><br><span class="line">    <span class="keyword">float</span> * scale_change_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> * input_antialiasing_gpu;</span><br><span class="line">    <span class="keyword">float</span> * output_gpu;</span><br><span class="line">    <span class="keyword">float</span> * activation_input_gpu;</span><br><span class="line">    <span class="keyword">float</span> * loss_gpu;</span><br><span class="line">    <span class="keyword">float</span> * delta_gpu;</span><br><span class="line">    <span class="keyword">float</span> * rand_gpu;</span><br><span class="line">    <span class="keyword">float</span> * squared_gpu;</span><br><span class="line">    <span class="keyword">float</span> * norms_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *gt_gpu;</span><br><span class="line">    <span class="keyword">float</span> *a_avg_gpu;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> *input_sizes_gpu;</span><br><span class="line">    <span class="keyword">float</span> **layers_output_gpu;</span><br><span class="line">    <span class="keyword">float</span> **layers_delta_gpu;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CUDNN</span></span><br><span class="line">    cudnnTensorDescriptor_t srcTensorDesc, dstTensorDesc;</span><br><span class="line">    cudnnTensorDescriptor_t srcTensorDesc16, dstTensorDesc16;</span><br><span class="line">    cudnnTensorDescriptor_t dsrcTensorDesc, ddstTensorDesc;</span><br><span class="line">    cudnnTensorDescriptor_t dsrcTensorDesc16, ddstTensorDesc16;</span><br><span class="line">    cudnnTensorDescriptor_t normTensorDesc, normDstTensorDesc, normDstTensorDescF16;</span><br><span class="line">    cudnnFilterDescriptor_t weightDesc, weightDesc16;</span><br><span class="line">    cudnnFilterDescriptor_t dweightDesc, dweightDesc16;</span><br><span class="line">    cudnnConvolutionDescriptor_t convDesc;</span><br><span class="line">    cudnnConvolutionFwdAlgo_t fw_algo, fw_algo16;</span><br><span class="line">    cudnnConvolutionBwdDataAlgo_t bd_algo, bd_algo16;</span><br><span class="line">    cudnnConvolutionBwdFilterAlgo_t bf_algo, bf_algo16;</span><br><span class="line">    cudnnPoolingDescriptor_t poolingDesc;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// CUDNN</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// GPU</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>PyQt5的安装与使用</title>
    <url>/2022/01/19/PyQt5%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>PyQt是Qt框架的Python语言实现，由Riverbank Computing开发，是最强大的GUI库之一。PyQt提供了一个设计良好的窗口控件集合，每一个PyQt控件都对应一个Qt控件，因此PyQt的API接口与Qt的API接口很接近，但不再使用QMake系统和Q_OBJECT宏。</p>
<p>PyQt5有超过620个类，6000个函数和方法，主要模块如下：</p>
<ul>
<li>QtCore：包含了核心的非 GUI 的功能。主要和时间、文件与文件夹、各种数据、流、URLs、mime 类文件、进程与线程一起使用。</li>
<li>QtGui：包含了窗口系统、事件处理、2D 图像、基本绘画、字体和文字类。</li>
<li>QtWidgets：包含了一系列创建桌面应用的 UI 元素。</li>
<li>QtMultimedia：包含了处理多媒体的内容和调用摄像头 API 的类。</li>
<li>QtBluetooth：包含了查找和连接蓝牙的类。</li>
<li>QtNetwork：包含了网络编程的类，这些工具能让 TCP/IP 和 UDP 开发变得更加方便和可靠。</li>
<li>QtPositioning：包含了定位的类，可以使用卫星、WiFi 甚至文本。</li>
<li>Enginio：包含了通过客户端进入和管理 Qt Cloud 的类。</li>
<li>QtWebSockets：包含了 WebSocket 协议的类。</li>
<li>QtWebKit：包含了一个基 WebKit2 的 web 浏览器。</li>
<li>QtWebKitWidgets：包含了基于 QtWidgets 的 WebKit1 的类。</li>
<li>QtXml：包含了处理 xml 的类，提供了 SAX 和 DOM API 的工具。</li>
<li>QtSvg：提供了显示 SVG 内容的类，Scalable Vector Graphics (SVG) 是一种是一种基于可扩展标记语言 (XML)，用于描述二维矢量图形的图形格式（这句话来自于维基百科）。</li>
<li>QtSql：提供了处理数据库的工具。</li>
<li>QtTest：提供了测试 PyQt5 应用的工具。</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装PyQt5"><a href="#安装PyQt5" class="headerlink" title="安装PyQt5"></a><strong>安装PyQt5</strong></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install pyqt5</span><br><span class="line">pip install pyqt5-tools</span><br></pre></td></tr></table></figure>
<p>其中pyqt5-tools为Qt Designer拖拽式的界面设计工具。安装过程中可能会报如下错误：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">qt5-tools 5.15.2.1.2 has requirement click~=7.0, but you&#x27;ll have click 8.0.1 which is incompatible.</span><br></pre></td></tr></table></figure>
<p>解决方案：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install click~=7.0</span><br></pre></td></tr></table></figure>
<h3 id="Qt-Designer介绍"><a href="#Qt-Designer介绍" class="headerlink" title="Qt Designer介绍"></a>Qt Designer介绍</h3><p>Qt Designer是通过拖拽的方式放置控件，并实时查看控件效果进行快速UI设计。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-cf82bbfb6ce4e9cf168b9aebd62c3c1e_r.jpg" alt></p>
<p>整个画面的构成：</p>
<ul>
<li>左侧的“Widget Box”就是各种可以自由拖动的组件</li>
<li>中间的“MainWindow – untitled”窗体就是画布</li>
<li>右上方的“Object Inspector”可以查看当前ui的结构</li>
<li>右侧中部的“Property Editor”可以设置当前选中组件的属性</li>
<li>右下方的“Resource Browser”可以添加各种素材，比如图片，背景等等</li>
</ul>
<p>最终生成.ui文件（实质上是XML格式的文件），可直接使用，也可以通过pyuic5工具转换成.py文件。</p>
<h3 id="Qt-Disigner配置"><a href="#Qt-Disigner配置" class="headerlink" title="Qt Disigner配置"></a>Qt Disigner配置</h3><p>在Pycharm中，依次打开 File – Settings – Tools – External Tools，点击 + Create Tool，配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Name: QtDisigner</span><br><span class="line"></span><br><span class="line">Program : D:\Program Files\Python36\Lib\site-packages\qt5_applications\Qt\bin\designer.exe # 请根据实际修改</span><br><span class="line"></span><br><span class="line">Working directory: $FileDir$</span><br></pre></td></tr></table></figure>
<h3 id="PyUIC配置"><a href="#PyUIC配置" class="headerlink" title="PyUIC配置"></a>PyUIC配置</h3><p>PyUIC主要是把Qt Designer生成的.ui文件换成.py文件。</p>
<p>在Pycharm中，依次打开 File – Settings – Tools – External Tools，点击 + Create Tool，配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Name: PyUIC</span><br><span class="line"></span><br><span class="line">Program : D:\Program Files\Python36\python.exe # 当前Python目录，请根据实际修改</span><br><span class="line"></span><br><span class="line">Arguments: -m PyQt5.uic.pyuic $FileName$ -o $FileNameWithoutExtension$.py</span><br><span class="line"></span><br><span class="line">Working directory: $FileDir$</span><br></pre></td></tr></table></figure>
<h3 id="PyRCC配置"><a href="#PyRCC配置" class="headerlink" title="PyRCC配置"></a>PyRCC配置</h3><p>PyRCC主要是把编写的.qrc资源文件换成.py文件。</p>
<p>在Pycharm中，依次打开 File – Settings – Tools – External Tools，点击 + Create Tool，配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Name: PyRCC</span><br><span class="line"></span><br><span class="line">Program: D:\Program Files\Python36\pyrcc5.exe # 当前rcc工具目录，请根据实际修改</span><br><span class="line"></span><br><span class="line">Arguments: $FileName$ -o $FileNameWithoutExtension$_rc.py</span><br><span class="line"></span><br><span class="line">Working directory: $FileDir$</span><br></pre></td></tr></table></figure>
<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p>创建一个空白的界面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QMainWindow, QLabel</span><br><span class="line"></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line">win = QMainWindow()</span><br><span class="line">win.setGeometry(<span class="number">400</span>, <span class="number">400</span>, <span class="number">400</span>, <span class="number">300</span>)</span><br><span class="line">win.setWindowTitle(<span class="string">&quot;Pyqt5 Tutorial&quot;</span>)</span><br><span class="line">win.show()</span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-789ca14e93078a3d118458b4c4c51ed0_720w.jpg" alt></p>
<p>其中：</p>
<ul>
<li>Qapplication()：每个GUI都必须包含一个Qapplication，argv表示获取命令行参数，如果不用获取，则可以使用[]代替。</li>
<li>QMainWindow()：类似一个容器（窗口）用来包含按钮、文本、输入框等widgets。arg标识可以获取命令行执行时的参数。</li>
<li>setGeometry是用来定义 QMainWindow() 窗口的尺寸， 语法：setGeometry(x, y, width, height )，其中x,y为屏幕上的坐标点。</li>
<li>show()：用来显示窗口</li>
<li>exit(app.exec_())：设置窗口一直运行指导使用关闭按钮进行关闭</li>
</ul>
<p>PyQt5支持的常见Widgets有：QLabel、QComboBox、QCheckBox、QRadioButton、QPushButton、QTableWidget、QLineEdit、QSlider、QProgressBar等。</p>
<p>对于使用Pyqt5设置文本内容，使用Qlabel：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QMainWindow, QLabel</span><br><span class="line"></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line">win = QMainWindow()</span><br><span class="line">win.setGeometry(<span class="number">400</span>, <span class="number">400</span>, <span class="number">400</span>, <span class="number">300</span>)</span><br><span class="line">win.setWindowTitle(<span class="string">&quot;Pyqt5 Tutorial&quot;</span>)</span><br><span class="line"><span class="comment"># Label Text</span></span><br><span class="line">label = QLabel(win)</span><br><span class="line">label.resize(<span class="number">200</span>, <span class="number">100</span>)</span><br><span class="line">label.setText(<span class="string">&quot;Hi this is Pyqt5&quot;</span>)</span><br><span class="line">label.move(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">win.show()</span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-e0f7a0c8b5b49ae37ff4c7cebfee5d37_720w.jpg" alt></p>
<p>按钮与事件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QMainWindow, QPushButton</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">click</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Hy Button is clicked!&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = QApplication(sys.argv)</span><br><span class="line">win = QMainWindow()</span><br><span class="line">win.setGeometry(<span class="number">400</span>, <span class="number">400</span>, <span class="number">400</span>, <span class="number">300</span>)</span><br><span class="line">win.setWindowTitle(<span class="string">&quot;Pyqt5 Tutorial&quot;</span>)</span><br><span class="line"><span class="comment"># Button</span></span><br><span class="line">button = QPushButton(win)</span><br><span class="line">button.resize(<span class="number">200</span>, <span class="number">100</span>)</span><br><span class="line">button.setText(<span class="string">&quot;Hi! Click Me&quot;</span>)</span><br><span class="line">button.move(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">button.clicked.connect(click)</span><br><span class="line">win.show()</span><br><span class="line">sys.exit(app.exec_())</span><br></pre></td></tr></table></figure>
<ul>
<li>button.clicked.connect() 在按钮点击后执行特定的事件。</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-79eef493a6c53929ee1c104a161ff0a0_720w.jpg" alt></p>
<h2 id="常见Widgets介绍"><a href="#常见Widgets介绍" class="headerlink" title="常见Widgets介绍"></a>常见Widgets介绍</h2><h3 id="QLabel"><a href="#QLabel" class="headerlink" title="QLabel"></a>QLabel</h3><p>用于显示文本或图像。没有提供用户交互功能，标签的外观可以通过各种方式进行配置。</p>
<p>QLabel可以包含以下任何内容类型：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>内容</th>
<th>设置</th>
</tr>
</thead>
<tbody>
<tr>
<td>纯文本</td>
<td>将字符串传递给setText()</td>
</tr>
<tr>
<td>富文本</td>
<td>将富文本传递给setText()</td>
</tr>
<tr>
<td>图像</td>
<td>将QPixmap对象传递给setPixmap()</td>
</tr>
<tr>
<td>动画</td>
<td>将QMovie对象传递给setMovie()</td>
</tr>
<tr>
<td>数字</td>
<td>将int或double数字传递给setNum()，将数字转换为纯文本</td>
</tr>
<tr>
<td>空</td>
<td>与纯文本相同。这是默认的，由clear()设置</td>
</tr>
</tbody>
</table>
</div>
<h3 id="QComboBox"><a href="#QComboBox" class="headerlink" title="QComboBox"></a>QComboBox</h3><p>组合框(也就是下拉框)是一个显示当前项目的选择小部件，可以弹出可选项目列表。组合框可以是可编辑的，允许用户修改列表中的每个项目。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/5b89284b0001e2e002460326.jpg" alt></p>
<h3 id="QCheckBox"><a href="#QCheckBox" class="headerlink" title="QCheckBox"></a>QCheckBox</h3><p>这是一个复选框，具有两种状态的小部件：打开和关闭。通常用于表示可以启用或禁用的应用程序中的功能。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/aHR0cDovL3pldGNvZGUuY29tL2ltZy9ndWkvcHlxdDUvcWNoZWNrYm94LnBuZw.png" alt></p>
<h3 id="QRadioButton"><a href="#QRadioButton" class="headerlink" title="QRadioButton"></a>QRadioButton</h3><p>单选按钮为用户提供多选一的选择，是一种开关按钮。是否选择状态通过isChecked()方法判断。isChecked()方法返回值True表示选中，False表示未选中。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/1600711-20190818142147945-613402618.png" alt></p>
<h3 id="QLineEdit"><a href="#QLineEdit" class="headerlink" title="QLineEdit"></a>QLineEdit</h3><p>是一个单行文本框控件，可以输入单行字符串，无法换行输入。多行可用<code>QTextEdit</code>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/2019080312455368.png" alt></p>
<h3 id="QPushButton"><a href="#QPushButton" class="headerlink" title="QPushButton"></a>QPushButton</h3><p>这是一个切换按钮，有两种状态：按下和未按下。通过点击它们在这两种状态之间切换。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/aHR0cDovL3pldGNvZGUuY29tL2ltZy9ndWkvcHlxdDUvdG9nZ2xlYnV0dG9uLnBuZw.png" alt></p>
<h3 id="QTableWidget"><a href="#QTableWidget" class="headerlink" title="QTableWidget"></a>QTableWidget</h3><p>是Qt中常用显示数据的表格。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/1499671-20181206174313071-1960046355.png" alt></p>
<h3 id="QSlider"><a href="#QSlider" class="headerlink" title="QSlider"></a>QSlider</h3><p>这是一个滚动条，具有简单句柄的小部件，可以来回拉动。这样就可以为特定任务选择一个值。有时使用滑块比输入数字或使用旋转框更自然。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/aHR0cDovL3pldGNvZGUuY29tL2ltZy9ndWkvcHlxdDUvcXNsaWRlci5wbmc.png" alt></p>
<h3 id="QProgressBar"><a href="#QProgressBar" class="headerlink" title="QProgressBar"></a>QProgressBar</h3><p>这是一个进度条，是处理冗长任务时使用的小部件，以便用户知道任务正在进行中。可以设置进度条的最小值和最大值。默认值为0和99。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/aHR0cDovL3pldGNvZGUuY29tL2ltZy9ndWkvcHlxdDUvcXByb2dyZXNzYmFyLnBuZw.png" alt></p>
<h3 id="QCalendarWidget"><a href="#QCalendarWidget" class="headerlink" title="QCalendarWidget"></a>QCalendarWidget</h3><p>提供基于月度的日历小部件。它允许用户以简单直观的方式选择日期。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/cleanlooks-calendarwidget.png" alt></p>
<h2 id="对话框类控件"><a href="#对话框类控件" class="headerlink" title="对话框类控件"></a>对话框类控件</h2><p>一些提示框，如选择字体、颜色等，所有对话框的父类是<code>QDialog</code>，子类如下。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">控件</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>QMessageBox</code></td>
<td style="text-align:left">用于提示信息, 如警告、询问和严重出错等。</td>
</tr>
<tr>
<td style="text-align:left"><code>QFileDialog</code></td>
<td style="text-align:left">用于打开文件和保存文件，可以设置过滤器限制文件后缀名。</td>
</tr>
<tr>
<td style="text-align:left"><code>QFontDialog</code></td>
<td style="text-align:left">用于设置字体。</td>
</tr>
<tr>
<td style="text-align:left"><code>QInputDialog</code></td>
<td style="text-align:left">用于控件的标准输入，如<code>getInt</code>只能获得整数输入。</td>
</tr>
<tr>
<td style="text-align:left"><code>QColorDialog</code></td>
<td style="text-align:left">用于设置颜色。</td>
</tr>
</tbody>
</table>
</div>
<h2 id="日期类控件"><a href="#日期类控件" class="headerlink" title="日期类控件"></a>日期类控件</h2><p>用日期类的控件输入，可以避免用户的输入不规范。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">控件</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>QCalendar</code></td>
<td style="text-align:left">以网格日历的形式输入日期，可以获取日期，日期改变后发射信号</td>
</tr>
<tr>
<td style="text-align:left"><code>QDateTimeEdit</code></td>
<td style="text-align:left">可编辑日期，感觉不好用，可以设置为弹出日历。</td>
</tr>
<tr>
<td style="text-align:left"><code>QCalendar</code></td>
<td style="text-align:left">以日历的形式输入日期</td>
</tr>
<tr>
<td style="text-align:left"><code>QCalendar</code></td>
<td style="text-align:left">以日历的形式输入日期</td>
</tr>
</tbody>
</table>
</div>
<h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>所开发的程序包含太多控件，一个窗口装载不下或者装载太多控件而不美观，应该使用容器装载更多的控件。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">控件</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>QTabWidget</code></td>
<td style="text-align:left">一个选项卡，一个页面区域，单击选项卡查看各个页面。</td>
</tr>
<tr>
<td style="text-align:left"><code>QDockWidgetWidget</code></td>
<td style="text-align:left">浮动窗口，类似与Dev C++ 中的底层Debug窗口，保持浮动状态或者在制定位置附加到主窗口。</td>
</tr>
<tr>
<td style="text-align:left"><code>QScrollBar</code></td>
<td style="text-align:left">提供水平或者垂直的滚动条，扩大窗口的有效装载面积。</td>
</tr>
<tr>
<td style="text-align:left"><code>QGroupBox</code></td>
<td style="text-align:left">下拉框，就是，一个页面内一直向下拖动</td>
</tr>
</tbody>
</table>
</div>
<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>简易的天气查询软件：</p>
<h3 id="使用Qt-Designer设计一个界面"><a href="#使用Qt-Designer设计一个界面" class="headerlink" title="使用Qt Designer设计一个界面"></a>使用Qt Designer设计一个界面</h3><p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-c4c600882e69d9c649f6785b64fe469a_r.jpg" alt></p>
<p>用到的控件有Button，GroupBox，Label，ComboBox，TextEdit，同时定义了两个按钮queryBtn及clearBtn，分别用来查询及清空天气数据。需要绑定槽函数，方法如下：</p>
<ul>
<li>在Qt Designer右下角选择[信号/槽编辑器]，点击+号新增</li>
<li>分别选择queryBtn及clearBtn，选择信号clicked()，接收者Dialog及槽accept()，（槽函数这里不知道如何定义，后期在代码里再进行修改）</li>
</ul>
<p>以上完成后保存为Weather.ui文件。</p>
<h3 id="转换-ui文件为-py文件"><a href="#转换-ui文件为-py文件" class="headerlink" title="转换.ui文件为.py文件"></a>转换.ui文件为.py文件</h3><p>PyQt5支持直接使用.ui文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtWidgets, uic</span><br><span class="line"></span><br><span class="line">app = QtWidgets.QApplication(sys.argv)</span><br><span class="line">window = uic.loadUi(<span class="string">&quot;mainwindow.ui&quot;</span>)</span><br><span class="line">window.show()</span><br><span class="line">app.<span class="built_in">exec</span>()</span><br></pre></td></tr></table></figure>
<p>但是为了更好的自定义及修改上面的槽函数，可以使用External Tools – PyUIC，即可生成Weather.py，实际运行命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m PyQt5.uic.pyuic Weather.ui -o Weather.py</span><br></pre></td></tr></table></figure>
<p>其中，需要把两个按钮绑定的槽函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># self.queryBtn.clicked.connect(Dialog.accept)</span></span><br><span class="line"><span class="comment"># self.clearBtn.clicked.connect(Dialog.accept)</span></span><br><span class="line"><span class="comment"># 修改为：</span></span><br><span class="line">self.queryBtn.clicked.connect(Dialog.queryWeather)</span><br><span class="line">self.clearBtn.clicked.connect(Dialog.clearText)</span><br></pre></td></tr></table></figure>
<p>最终的Weather.py内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># Form implementation generated from reading ui file &#x27;Weather.ui&#x27;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Created by: PyQt5 UI code generator 5.15.4</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># WARNING: Any manual changes made to this file will be lost when pyuic5 is</span></span><br><span class="line"><span class="comment"># run again.  Do not edit this file unless you know what you are doing.</span></span><br><span class="line"><span class="keyword">from</span> PyQt5 <span class="keyword">import</span> QtCore, QtGui, QtWidgets</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ui_Dialog</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setupUi</span>(<span class="params">self, Dialog</span>):</span></span><br><span class="line">        Dialog.setObjectName(<span class="string">&quot;Dialog&quot;</span>)</span><br><span class="line">        Dialog.resize(<span class="number">600</span>, <span class="number">600</span>)</span><br><span class="line">        self.groupBox = QtWidgets.QGroupBox(Dialog)</span><br><span class="line">        self.groupBox.setGeometry(QtCore.QRect(<span class="number">30</span>, <span class="number">20</span>, <span class="number">551</span>, <span class="number">511</span>))</span><br><span class="line">        self.groupBox.setObjectName(<span class="string">&quot;groupBox&quot;</span>)</span><br><span class="line">        self.label_2 = QtWidgets.QLabel(self.groupBox)</span><br><span class="line">        self.label_2.setGeometry(QtCore.QRect(<span class="number">20</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">16</span>))</span><br><span class="line">        self.label_2.setObjectName(<span class="string">&quot;label_2&quot;</span>)</span><br><span class="line">        self.comboBox = QtWidgets.QComboBox(self.groupBox)</span><br><span class="line">        self.comboBox.setGeometry(QtCore.QRect(<span class="number">70</span>, <span class="number">30</span>, <span class="number">87</span>, <span class="number">22</span>))</span><br><span class="line">        self.comboBox.setObjectName(<span class="string">&quot;comboBox&quot;</span>)</span><br><span class="line">        self.comboBox.addItem(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        self.comboBox.addItem(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        self.comboBox.addItem(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        self.textEdit = QtWidgets.QTextEdit(self.groupBox)</span><br><span class="line">        self.textEdit.setGeometry(QtCore.QRect(<span class="number">20</span>, <span class="number">70</span>, <span class="number">491</span>, <span class="number">411</span>))</span><br><span class="line">        self.textEdit.setObjectName(<span class="string">&quot;textEdit&quot;</span>)</span><br><span class="line">        self.queryBtn = QtWidgets.QPushButton(Dialog)</span><br><span class="line">        self.queryBtn.setGeometry(QtCore.QRect(<span class="number">490</span>, <span class="number">560</span>, <span class="number">93</span>, <span class="number">28</span>))</span><br><span class="line">        self.queryBtn.setObjectName(<span class="string">&quot;queryBtn&quot;</span>)</span><br><span class="line">        self.clearBtn = QtWidgets.QPushButton(Dialog)</span><br><span class="line">        self.clearBtn.setGeometry(QtCore.QRect(<span class="number">30</span>, <span class="number">560</span>, <span class="number">93</span>, <span class="number">28</span>))</span><br><span class="line">        self.clearBtn.setObjectName(<span class="string">&quot;clearBtn&quot;</span>)</span><br><span class="line">        self.retranslateUi(Dialog)</span><br><span class="line">        self.clearBtn.clicked.connect(Dialog.clearText)</span><br><span class="line">        self.queryBtn.clicked.connect(Dialog.queryWeather)</span><br><span class="line">        QtCore.QMetaObject.connectSlotsByName(Dialog)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">retranslateUi</span>(<span class="params">self, Dialog</span>):</span></span><br><span class="line">        _translate = QtCore.QCoreApplication.translate</span><br><span class="line">        Dialog.setWindowTitle(_translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;Dialog&quot;</span>))</span><br><span class="line">        self.groupBox.setTitle(_translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;城市天气预报&quot;</span>))</span><br><span class="line">        self.label_2.setText(_translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;城市&quot;</span>))</span><br><span class="line">        self.comboBox.setItemText(<span class="number">0</span>, _translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;北京&quot;</span>))</span><br><span class="line">        self.comboBox.setItemText(<span class="number">1</span>, _translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;苏州&quot;</span>))</span><br><span class="line">        self.comboBox.setItemText(<span class="number">2</span>, _translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;上海&quot;</span>))</span><br><span class="line">        self.queryBtn.setText(_translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;查询&quot;</span>))</span><br><span class="line">        self.clearBtn.setText(_translate(<span class="string">&quot;Dialog&quot;</span>, <span class="string">&quot;清空&quot;</span>))</span><br></pre></td></tr></table></figure>
<h3 id="调用MainDialog"><a href="#调用MainDialog" class="headerlink" title="调用MainDialog"></a>调用MainDialog</h3><p>在MainDialog中调用界面类Ui_Dialog，然后在其中中添加查询天气的业务逻辑代码，这样就做到了界面显示和业务逻辑的分离。新增demo.py文件， 在MainDialog类中定义了两个槽函数queryWeather()和clearText()，以便在界面文件Weather.ui中定义的两个按钮(queryBtn和clearBtn) 触发clicked信号与这两个槽函数进行绑定。</p>
<p>完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> Weather</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> QApplication, QDialog</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MainDialog</span>(<span class="params">QDialog</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, parent=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(QDialog, self).__init__(parent)</span><br><span class="line">        self.ui = Weather.Ui_Dialog()</span><br><span class="line">        self.ui.setupUi(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">queryWeather</span>(<span class="params">self</span>):</span></span><br><span class="line">        cityName = self.ui.comboBox.currentText()</span><br><span class="line">        cityCode = self.getCode(cityName)</span><br><span class="line">        r = requests.get(</span><br><span class="line">            <span class="string">&quot;https://restapi.amap.com/v3/weather/weatherInfo?key=f4fd5b287b6d7d51a3c60fee24e42002&amp;city=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(cityCode))</span><br><span class="line">        <span class="keyword">if</span> r.status_code == <span class="number">200</span>:</span><br><span class="line">            data = r.json()[<span class="string">&#x27;lives&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">            weatherMsg = <span class="string">&#x27;城市：&#123;&#125;\n天气：&#123;&#125;\n温度：&#123;&#125;\n风向：&#123;&#125;\n风力：&#123;&#125;\n湿度：&#123;&#125;\n发布时间：&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                data[<span class="string">&#x27;city&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;weather&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;temperature&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;winddirection&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;windpower&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;humidity&#x27;</span>],</span><br><span class="line">                data[<span class="string">&#x27;reporttime&#x27;</span>],</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            weatherMsg = <span class="string">&#x27;天气查询失败，请稍后再试！&#x27;</span></span><br><span class="line">        self.ui.textEdit.setText(weatherMsg)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getCode</span>(<span class="params">self, cityName</span>):</span></span><br><span class="line">        cityDict = &#123;<span class="string">&quot;北京&quot;</span>: <span class="string">&quot;110000&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;苏州&quot;</span>: <span class="string">&quot;320500&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;上海&quot;</span>: <span class="string">&quot;310000&quot;</span>&#125;</span><br><span class="line">        **<span class="keyword">return</span>** cityDict.get(cityName, <span class="string">&#x27;101010100&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clearText</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.ui.textEdit.clear()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    myapp = QApplication(sys.argv)</span><br><span class="line">    myDlg = MainDialog()</span><br><span class="line">    myDlg.show()</span><br><span class="line">    sys.exit(myapp.exec_())</span><br></pre></td></tr></table></figure>
<p>运行demo.py并执行查询后的效果：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-9bd67aa165f2c7f316814677f8188d69_720w.jpg" alt></p>
<h3 id="将代码打包成exe文件"><a href="#将代码打包成exe文件" class="headerlink" title="将代码打包成exe文件"></a>将代码打包成exe文件</h3><p>将.py文件打包成可执行的exe在Python中称为freezing，常用的工具有：PyInstaller，py2exe，cx_Freeze，bbfreze，py2app等。</p>
<ul>
<li>py2exe：软件更新已经不活跃。</li>
<li>pyinstaller：明确支持win8、win10、理论上支持win7,，支持macOS，linux。可以打包成文件夹形式内含exe入口执行文件的形式，也可以是一个单独的exe文件。</li>
<li>fbs：基于PyInstaller，使用起来更加方便</li>
</ul>
<p>这里以fbs为例。</p>
<p>fbs的安装方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install fbs</span><br></pre></td></tr></table></figure>
<p>在命令行中输入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fbs startproject</span><br></pre></td></tr></table></figure>
<p>执行完成后需要输入一些APP的名称等。完成后会生成如下目录：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/qt/v2-737356572bfd6968ef6c90ebd8252244_720w.jpg" alt></p>
<p>将刚才编写的PyQt5的代码（demo.py和Weather.py）拖到<code>src/main/python</code>文件夹下，删除原有的main.py，并将demo.py修改为main.py。然后打开 main.py，在文件头部添加如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fbs_runtime.application_context.PyQt5 <span class="keyword">import</span> ApplicationContext</span><br></pre></td></tr></table></figure>
<p>完成后执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fbs freeze</span><br></pre></td></tr></table></figure>
<p>即可实现打包，生成的exe可执行文件在<code>\target\MyApp</code>文件下。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/457972006">Python GUI 开发必备！PyQt5 学习指南 - 知乎 (zhihu.com)</a></p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3的数据加载机制和增强方法</title>
    <url>/2020/02/15/YOLOv3%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%92%8C%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<h2 id="1-标注格式"><a href="#1-标注格式" class="headerlink" title="1. 标注格式"></a>1. 标注格式</h2><p><code>voc_label.py</code>，其作用是将xml文件转成txt文件格式，具体文件如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># class id, x, y, w, h</span><br><span class="line">0 0.8604166666666666 0.5403899721448469 0.058333333333333334 0.055710306406685235</span><br></pre></td></tr></table></figure>
<p>其中的x,y 的意义是归一化以后的框的中心坐标，w,h是归一化后的框的宽和高。</p>
<p>具体的归一化方式为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span>(<span class="params">size, box</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    size是图片的长和宽</span></span><br><span class="line"><span class="string">    box是xmin,xmax,ymin,ymax坐标值</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dw = <span class="number">1.</span> / (size[<span class="number">0</span>])</span><br><span class="line">    dh = <span class="number">1.</span> / (size[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 得到长和宽的缩放比</span></span><br><span class="line">    x = (box[<span class="number">0</span>] + box[<span class="number">1</span>])/<span class="number">2.0</span>  </span><br><span class="line">    y = (box[<span class="number">2</span>] + box[<span class="number">3</span>])/<span class="number">2.0</span>  </span><br><span class="line">    w = box[<span class="number">1</span>] - box[<span class="number">0</span>]</span><br><span class="line">    h = box[<span class="number">3</span>] - box[<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># 分别计算中心点坐标，框的宽和高</span></span><br><span class="line">    x = x * dw</span><br><span class="line">    w = w * dw</span><br><span class="line">    y = y * dh</span><br><span class="line">    h = h * dh</span><br><span class="line">    <span class="comment"># 按照图片长和宽进行归一化</span></span><br><span class="line">    <span class="keyword">return</span> (x,y,w,h)</span><br></pre></td></tr></table></figure>
<p>可以看出，归一化都是相对于图片的宽和高进行归一化的。</p>
<h2 id="2-调用"><a href="#2-调用" class="headerlink" title="2. 调用"></a>2. 调用</h2><p>下边是train.py文件中的有关数据的调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Dataset</span></span><br><span class="line">dataset = LoadImagesAndLabels(train_path, img_size, batch_size,</span><br><span class="line">                              augment=<span class="literal">True</span>,</span><br><span class="line">                              hyp=hyp,  <span class="comment"># augmentation hyperparameters</span></span><br><span class="line">                              rect=opt.rect,  <span class="comment"># rectangular training</span></span><br><span class="line">                              cache_labels=<span class="literal">True</span>,</span><br><span class="line">                              cache_images=opt.cache_images)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="built_in">min</span>(batch_size, <span class="built_in">len</span>(dataset))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用多少个线程加载数据集</span></span><br><span class="line">nw = <span class="built_in">min</span>([os.cpu_count(), batch_size <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset,</span><br><span class="line">                        batch_size=batch_size,</span><br><span class="line">                        num_workers=nw,</span><br><span class="line">                        shuffle=<span class="keyword">not</span> opt.rect,</span><br><span class="line">                        <span class="comment"># Shuffle=True</span></span><br><span class="line">                        <span class="comment"># unless rectangular training is used</span></span><br><span class="line">                        pin_memory=<span class="literal">True</span>,</span><br><span class="line">                        collate_fn=dataset.collate_fn)</span><br></pre></td></tr></table></figure>
<p>在pytorch中，数据集加载主要是重构datasets类，然后再使用dataloader中加载dataset，就构建好了数据部分。</p>
<p>下面是一个简单的使用模板：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据自己的数据集格式进行重构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment">#下载数据、初始化数据，都可以在这里完成</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&#x27;label.txt&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        <span class="comment"># 使用numpy读取数据</span></span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, <span class="number">0</span>:-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="comment"># dataloader中使用该方法，通过index进行访问</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 查询数据集中数量，可以通过len(mydataset)得到</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化这个类，然后我们就得到了Dataset类型的数据，记下来就将这个类传给DataLoader，就可以了。</span></span><br><span class="line">myDataset = MyDataset()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建dataloader</span></span><br><span class="line">train_loader = DataLoader(dataset=myDataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># 将数据从 train_loader 中读出来,一次读取的样本数是32个</span></span><br><span class="line">        inputs, labels = data</span><br><span class="line">        <span class="comment"># 将这些数据转换成Variable类型</span></span><br><span class="line">        inputs, labels = Variable(inputs), Variable(labels)</span><br><span class="line">		<span class="comment"># 模型训练...</span></span><br></pre></td></tr></table></figure>
<p>通过以上模板就能大致了解pytorch中的数据加载机制，下面开始介绍YOLOv3中的数据加载。</p>
<h2 id="3-YOLOv3中的数据加载"><a href="#3-YOLOv3中的数据加载" class="headerlink" title="3. YOLOv3中的数据加载"></a>3. YOLOv3中的数据加载</h2><p>下面解析的是LoadImagesAndLabels类中的几个主要的函数：</p>
<h3 id="3-1-init函数"><a href="#3-1-init函数" class="headerlink" title="3.1 init函数"></a>3.1 init函数</h3><p>init函数中包含了大部分需要处理的数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LoadImagesAndLabels</span>(<span class="params">Dataset</span>):</span>  <span class="comment"># for training/testing</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 path,</span></span></span><br><span class="line"><span class="params"><span class="function">                 img_size=<span class="number">416</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 batch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 augment=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 hyp=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 rect=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 image_weights=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 cache_labels=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 cache_images=<span class="literal">False</span></span>):</span></span><br><span class="line">        path = <span class="built_in">str</span>(Path(path))  <span class="comment"># os-agnostic</span></span><br><span class="line">        <span class="keyword">assert</span> os.path.isfile(path), <span class="string">&#x27;File not found %s. See %s&#x27;</span> % (path,</span><br><span class="line">                                                                    help_url)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.img_files = [</span><br><span class="line">                x.replace(<span class="string">&#x27;/&#x27;</span>, os.sep)</span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> f.read().splitlines()  <span class="comment"># os-agnostic</span></span><br><span class="line">                <span class="keyword">if</span> os.path.splitext(x)[-<span class="number">1</span>].lower() <span class="keyword">in</span> img_formats</span><br><span class="line">            ]</span><br><span class="line">        <span class="comment"># img_files是一个list，保存的是图片的路径</span></span><br><span class="line"></span><br><span class="line">        n = <span class="built_in">len</span>(self.img_files)</span><br><span class="line">        <span class="keyword">assert</span> n &gt; <span class="number">0</span>, <span class="string">&#x27;No images found in %s. See %s&#x27;</span> % (path, help_url)</span><br><span class="line">        bi = np.floor(np.arange(n) / batch_size).astype(np.<span class="built_in">int</span>)  <span class="comment"># batch index</span></span><br><span class="line">        <span class="comment"># 如果n=10, batch=2, bi=[0,0,1,1,2,2,3,3,4,4]</span></span><br><span class="line">        nb = bi[-<span class="number">1</span>] + <span class="number">1</span>  <span class="comment"># 最多有多少个batch</span></span><br><span class="line"></span><br><span class="line">        self.n = n</span><br><span class="line">        self.batch = bi  <span class="comment"># 图片的batch索引，代表第几个batch的图片</span></span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.augment = augment</span><br><span class="line">        self.hyp = hyp</span><br><span class="line">        self.image_weights = image_weights <span class="comment"># 是否选择根据权重进行采样</span></span><br><span class="line">        self.rect = <span class="literal">False</span> <span class="keyword">if</span> image_weights <span class="keyword">else</span> rect</span><br><span class="line">        <span class="comment"># 如果选择根据权重进行采样，将无法使用矩形训练：</span></span><br><span class="line">        <span class="comment"># 具体内容见下文</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 标签文件是通过images替换为labels, .jpg替换为.txt得到的。</span></span><br><span class="line">        self.label_files = [</span><br><span class="line">            x.replace(<span class="string">&#x27;images&#x27;</span>,</span><br><span class="line">                      <span class="string">&#x27;labels&#x27;</span>).replace(os.path.splitext(x)[-<span class="number">1</span>], <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> self.img_files</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 矩形训练具体内容见下文解析</span></span><br><span class="line">        <span class="keyword">if</span> self.rect:</span><br><span class="line">            <span class="comment"># 获取图片的长和宽 (wh)</span></span><br><span class="line">            sp = path.replace(<span class="string">&#x27;.txt&#x27;</span>, <span class="string">&#x27;.shapes&#x27;</span>)</span><br><span class="line">            <span class="comment"># 字符串替换</span></span><br><span class="line">            <span class="comment"># shapefile path</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(sp, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:  <span class="comment"># 读取shape文件</span></span><br><span class="line">                    s = [x.split() <span class="keyword">for</span> x <span class="keyword">in</span> f.read().splitlines()]</span><br><span class="line">                    <span class="keyword">assert</span> <span class="built_in">len</span>(s) == n, <span class="string">&#x27;Shapefile out of sync&#x27;</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                s = [</span><br><span class="line">                    exif_size(Image.<span class="built_in">open</span>(f))</span><br><span class="line">                    <span class="keyword">for</span> f <span class="keyword">in</span> tqdm(self.img_files, desc=<span class="string">&#x27;Reading image shapes&#x27;</span>)</span><br><span class="line">                ]</span><br><span class="line">                np.savetxt(sp, s, fmt=<span class="string">&#x27;%g&#x27;</span>)  <span class="comment"># overwrites existing (if any)</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据长宽比进行排序</span></span><br><span class="line">            s = np.array(s, dtype=np.float64)</span><br><span class="line">            ar = s[:, <span class="number">1</span>] / s[:, <span class="number">0</span>]  <span class="comment"># aspect ratio</span></span><br><span class="line">            i = ar.argsort()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 根据顺序重排顺序</span></span><br><span class="line">            self.img_files = [self.img_files[i] <span class="keyword">for</span> i <span class="keyword">in</span> i]</span><br><span class="line">            self.label_files = [self.label_files[i] <span class="keyword">for</span> i <span class="keyword">in</span> i]</span><br><span class="line">            self.shapes = s[i]  <span class="comment"># wh</span></span><br><span class="line">            ar = ar[i]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 设置训练的图片形状</span></span><br><span class="line">            shapes = [[<span class="number">1</span>, <span class="number">1</span>]] * nb</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb):</span><br><span class="line">                ari = ar[bi == i]</span><br><span class="line">                mini, maxi = ari.<span class="built_in">min</span>(), ari.<span class="built_in">max</span>()</span><br><span class="line">                <span class="keyword">if</span> maxi &lt; <span class="number">1</span>:</span><br><span class="line">                    shapes[i] = [maxi, <span class="number">1</span>]</span><br><span class="line">                <span class="keyword">elif</span> mini &gt; <span class="number">1</span>:</span><br><span class="line">                    shapes[i] = [<span class="number">1</span>, <span class="number">1</span> / mini]</span><br><span class="line"></span><br><span class="line">            self.batch_shapes = np.ceil(</span><br><span class="line">                np.array(shapes) * img_size / <span class="number">32.</span>).astype(np.<span class="built_in">int</span>) * <span class="number">32</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 预载标签</span></span><br><span class="line">        <span class="comment"># weighted CE 训练时需要这个步骤</span></span><br><span class="line">        <span class="comment"># 否则无法按照权重进行采样</span></span><br><span class="line">        self.imgs = [<span class="literal">None</span>] * n</span><br><span class="line">        self.labels = [<span class="literal">None</span>] * n</span><br><span class="line">        <span class="keyword">if</span> cache_labels <span class="keyword">or</span> image_weights:  <span class="comment"># cache labels for faster training</span></span><br><span class="line">            self.labels = [np.zeros((<span class="number">0</span>, <span class="number">5</span>))] * n</span><br><span class="line">            extract_bounding_boxes = <span class="literal">False</span></span><br><span class="line">            create_datasubset = <span class="literal">False</span></span><br><span class="line">            pbar = tqdm(self.label_files, desc=<span class="string">&#x27;Caching labels&#x27;</span>)</span><br><span class="line">            nm, nf, ne, ns, nd = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>  <span class="comment"># number missing, found, empty, datasubset, duplicate</span></span><br><span class="line">            <span class="keyword">for</span> i, file <span class="keyword">in</span> <span class="built_in">enumerate</span>(pbar):</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 读取每个文件内容</span></span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        l = np.array(</span><br><span class="line">                            [x.split() <span class="keyword">for</span> x <span class="keyword">in</span> f.read().splitlines()],</span><br><span class="line">                            dtype=np.float32)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    nm += <span class="number">1</span>  <span class="comment"># print(&#x27;missing labels for image %s&#x27; % self.img_files[i])  # file missing</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> l.shape[<span class="number">0</span>]:</span><br><span class="line">                    <span class="comment"># 判断文件内容是否符合要求</span></span><br><span class="line">                    <span class="comment"># 所有的值需要&gt;0, &lt;1, 一共5列</span></span><br><span class="line">                    <span class="keyword">assert</span> l.shape[<span class="number">1</span>] == <span class="number">5</span>, <span class="string">&#x27;&gt; 5 label columns: %s&#x27;</span> % file</span><br><span class="line">                    <span class="keyword">assert</span> (l &gt;= <span class="number">0</span>).<span class="built_in">all</span>(), <span class="string">&#x27;negative labels: %s&#x27;</span> % file</span><br><span class="line">                    <span class="keyword">assert</span> (l[:, <span class="number">1</span>:] &lt;= <span class="number">1</span>).<span class="built_in">all</span>(</span><br><span class="line">                    ), <span class="string">&#x27;non-normalized or out of bounds coordinate labels: %s&#x27;</span> % file</span><br><span class="line">                    <span class="keyword">if</span> np.unique(</span><br><span class="line">                            l, axis=<span class="number">0</span>).shape[<span class="number">0</span>] &lt; l.shape[<span class="number">0</span>]:  <span class="comment"># duplicate rows</span></span><br><span class="line">                        nd += <span class="number">1</span>  <span class="comment"># print(&#x27;WARNING: duplicate rows in %s&#x27; % self.label_files[i])  # duplicate rows</span></span><br><span class="line"></span><br><span class="line">                    self.labels[i] = l</span><br><span class="line">                    nf += <span class="number">1</span>  <span class="comment"># file found</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 创建一个小型的数据集进行试验</span></span><br><span class="line">                    <span class="keyword">if</span> create_datasubset <span class="keyword">and</span> ns &lt; <span class="number">1E4</span>:</span><br><span class="line">                        <span class="keyword">if</span> ns == <span class="number">0</span>:</span><br><span class="line">                            create_folder(path=<span class="string">&#x27;./datasubset&#x27;</span>)</span><br><span class="line">                            os.makedirs(<span class="string">&#x27;./datasubset/images&#x27;</span>)</span><br><span class="line">                        exclude_classes = <span class="number">43</span></span><br><span class="line">                        <span class="keyword">if</span> exclude_classes <span class="keyword">not</span> <span class="keyword">in</span> l[:, <span class="number">0</span>]:</span><br><span class="line">                            ns += <span class="number">1</span></span><br><span class="line">                            <span class="comment"># shutil.copy(src=self.img_files[i], dst=&#x27;./datasubset/images/&#x27;)  # copy image</span></span><br><span class="line">                            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./datasubset/images.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                                f.write(self.img_files[i] + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 为两阶段分类器提取目标检测的检测框</span></span><br><span class="line">                    <span class="comment"># 默认开关是关掉的，不是很理解</span></span><br><span class="line">                    <span class="keyword">if</span> extract_bounding_boxes:</span><br><span class="line">                        p = Path(self.img_files[i])</span><br><span class="line">                        img = cv2.imread(<span class="built_in">str</span>(p))</span><br><span class="line">                        h, w = img.shape[:<span class="number">2</span>]</span><br><span class="line">                        <span class="keyword">for</span> j, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(l):</span><br><span class="line">                            f = <span class="string">&#x27;%s%sclassifier%s%g_%g_%s&#x27;</span> % (p.parent.parent,</span><br><span class="line">                                                              os.sep, os.sep,</span><br><span class="line">                                                              x[<span class="number">0</span>], j, p.name)</span><br><span class="line">                            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(Path(f).parent):</span><br><span class="line">                                os.makedirs(Path(f).parent)</span><br><span class="line">                                <span class="comment"># make new output folder</span></span><br><span class="line"></span><br><span class="line">                            b = x[<span class="number">1</span>:] * np.array([w, h, w, h])  <span class="comment"># box</span></span><br><span class="line">                            b[<span class="number">2</span>:] = b[<span class="number">2</span>:].<span class="built_in">max</span>()  <span class="comment"># rectangle to square</span></span><br><span class="line">                            b[<span class="number">2</span>:] = b[<span class="number">2</span>:] * <span class="number">1.3</span> + <span class="number">30</span>  <span class="comment"># pad</span></span><br><span class="line"></span><br><span class="line">                            b = xywh2xyxy(b.reshape(-<span class="number">1</span>,<span class="number">4</span>)).ravel().astype(np.<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">                            b[[<span class="number">0</span>,<span class="number">2</span>]] = np.clip(b[[<span class="number">0</span>, <span class="number">2</span>]], <span class="number">0</span>,w)  <span class="comment"># clip boxes outside of image</span></span><br><span class="line">                            b[[<span class="number">1</span>, <span class="number">3</span>]] = np.clip(b[[<span class="number">1</span>, <span class="number">3</span>]], <span class="number">0</span>, h)</span><br><span class="line">                            <span class="keyword">assert</span> cv2.imwrite(f, img[b[<span class="number">1</span>]:b[<span class="number">3</span>], b[<span class="number">0</span>]:b[<span class="number">2</span>]]), <span class="string">&#x27;Failure extracting classifier boxes&#x27;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    ne += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                pbar.desc = <span class="string">&#x27;Caching labels (%g found, %g missing, %g empty, %g duplicate, for %g images)&#x27;</span> </span><br><span class="line">                % (nf, nm, ne, nd, n) <span class="comment"># 统计发现，丢失，空，重复标签的数量。</span></span><br><span class="line">            <span class="keyword">assert</span> nf &gt; <span class="number">0</span>, <span class="string">&#x27;No labels found. See %s&#x27;</span> % help_url</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将图片加载到内存中，可以加速训练</span></span><br><span class="line">        <span class="comment"># 警告：如果在数据比较多的情况下可能会超出RAM</span></span><br><span class="line">        <span class="keyword">if</span> cache_images:  <span class="comment"># if training</span></span><br><span class="line">            gb = <span class="number">0</span>  <span class="comment"># 计算缓存到内存中的图片占用的空间GB为单位</span></span><br><span class="line">            pbar = tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(self.img_files)), desc=<span class="string">&#x27;Caching images&#x27;</span>)</span><br><span class="line">            self.img_hw0, self.img_hw = [<span class="literal">None</span>] * n, [<span class="literal">None</span>] * n</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> pbar:  <span class="comment"># max 10k images</span></span><br><span class="line">                self.imgs[i], self.img_hw0[i], self.img_hw[i] = load_image(</span><br><span class="line">                    self, i)  <span class="comment"># img, hw_original, hw_resized</span></span><br><span class="line">                gb += self.imgs[i].nbytes</span><br><span class="line">                pbar.desc = <span class="string">&#x27;Caching images (%.1fGB)&#x27;</span> % (gb / <span class="number">1E9</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 删除损坏的文件</span></span><br><span class="line">        <span class="comment"># 根据需要进行手动开关</span></span><br><span class="line">        detect_corrupted_images = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> detect_corrupted_images:</span><br><span class="line">            <span class="keyword">from</span> skimage <span class="keyword">import</span> io  <span class="comment"># conda install -c conda-forge scikit-image</span></span><br><span class="line">            <span class="keyword">for</span> file <span class="keyword">in</span> tqdm(self.img_files,</span><br><span class="line">                             desc=<span class="string">&#x27;Detecting corrupted images&#x27;</span>):</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    _ = io.imread(file)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;Corrupted image detected: %s&#x27;</span> % file)</span><br></pre></td></tr></table></figure>
<p><strong>Rectangular inference（矩形推理）</strong></p>
<ol>
<li>矩形推理是在detect.py，也就是测试过程中的实现，可以减少推理时间。YOLOv3中是下采样32倍，长宽也必须是32的倍数，所以在进入模型前，数据需要处理到416×416大小，这个过程称为仿射变换，如果用opencv实现可以用以下代码：</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 来自 https://zhuanlan.zhihu.com/p/93822508</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cv2_letterbox_image</span>(<span class="params">image, expected_size</span>):</span></span><br><span class="line">    ih, iw = image.shape[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">    ew, eh = expected_size</span><br><span class="line">    scale = <span class="built_in">min</span>(eh / ih, ew / iw)</span><br><span class="line">    nh = <span class="built_in">int</span>(ih * scale)</span><br><span class="line">    nw = <span class="built_in">int</span>(iw * scale)</span><br><span class="line">    image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    top = (eh - nh) // <span class="number">2</span></span><br><span class="line">    bottom = eh - nh - top</span><br><span class="line">    left = (ew - nw) // <span class="number">2</span></span><br><span class="line">    right = ew - nw - left</span><br><span class="line">    new_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)</span><br><span class="line">    <span class="keyword">return</span> new_img</span><br></pre></td></tr></table></figure>
<p>比如下图是一个h&gt;w，一个是w&gt;h的图片经过仿射变换后resize到416×416的示例：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/643.webp" alt></p>
<p>以上就是正方形推理，但是可以看出以上通过补充得到的结果会存在很多冗余信息，而Rectangular Training思路就是想要去掉这些冗余的部分。</p>
<p>具体过程为：求得较长边缩放到416的比例，然后对图片w:h按这个比例缩放，使得较长边达到416,再对较短边进行尽量少的填充使得较短边满足32的倍数。</p>
<p>示例如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/644.webp" alt></p>
<p><strong>Rectangular Training（矩形训练）</strong></p>
<p>很自然的，训练的过程也可以用到这个想法，减少冗余。不过训练的时候情况比较复杂，由于在训练过程中是一个batch的图片，而每个batch图片是有可能长宽比不同的，这就是与测试最大的区别。具体是实现是取这个batch中最大的场合宽，然后将整个batch中填充到max width和max  height,这样操作对小一些的图片来说也是比较浪费。这里的yolov3的实现主要就是优化了一下如何将比例相近的图片放在一个batch，这样显然填充的就更少一些了。作者在issue中提到，在coco数据集中使用这个策略进行训练，能够快1/3。</p>
<p>而如果选择开启矩形训练，必须要关闭dataloader中的shuffle参数，防止对数据的顺序进行调整。同时如果选择image_weights, 根据图片进行采样，也无法与矩阵训练同时使用。</p>
<h3 id="3-2-getitem函数"><a href="#3-2-getitem函数" class="headerlink" title="3.2 getitem函数"></a>3.2 getitem函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">    <span class="comment"># 新的下角标</span></span><br><span class="line">    <span class="keyword">if</span> self.image_weights:</span><br><span class="line">        index = self.indices[index]</span><br><span class="line"></span><br><span class="line">    img_path = self.img_files[index]</span><br><span class="line">    label_path = self.label_files[index]</span><br><span class="line"></span><br><span class="line">    hyp = self.hyp</span><br><span class="line">    mosaic = <span class="literal">True</span> <span class="keyword">and</span> self.augment</span><br><span class="line">    <span class="comment"># 如果开启组合变化、数据增强</span></span><br><span class="line">    <span class="comment"># 加载四张图片，作为一个拼图，具体看下文解析。</span></span><br><span class="line">    <span class="keyword">if</span> mosaic:</span><br><span class="line">        <span class="comment"># 加载拼图内容</span></span><br><span class="line">        img, labels = load_mosaic(self, index)</span><br><span class="line">        shapes = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 加载图片</span></span><br><span class="line">        img, (h0, w0), (h, w) = load_image(self, index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 仿射变换</span></span><br><span class="line">        shape = self.batch_shapes[self.batch[</span><br><span class="line">            index]] <span class="keyword">if</span> self.rect <span class="keyword">else</span> self.img_size</span><br><span class="line">        img, ratio, pad = letterbox(img,</span><br><span class="line">                                    shape,</span><br><span class="line">                                    auto=<span class="literal">False</span>,</span><br><span class="line">                                    scaleup=self.augment)</span><br><span class="line">        shapes = (h0, w0), (</span><br><span class="line">            (h / h0, w / w0), pad)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加载标注文件</span></span><br><span class="line">        labels = []</span><br><span class="line">        <span class="keyword">if</span> os.path.isfile(label_path):</span><br><span class="line">            x = self.labels[index]</span><br><span class="line">            <span class="keyword">if</span> x <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># 如果标签没有加载，读取label_path内容</span></span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(label_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    x = np.array(</span><br><span class="line">                        [x.split() <span class="keyword">for</span> x <span class="keyword">in</span> f.read().splitlines()],</span><br><span class="line">                        dtype=np.float32)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> x.size &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 将归一化后的xywh转化为左上角、右下角的表达形式</span></span><br><span class="line">                labels = x.copy()</span><br><span class="line">                labels[:, <span class="number">1</span>] = ratio[<span class="number">0</span>] * w * (</span><br><span class="line">                    x[:, <span class="number">1</span>] - x[:, <span class="number">3</span>] / <span class="number">2</span>) + pad[<span class="number">0</span>]  <span class="comment"># pad width</span></span><br><span class="line">                labels[:, <span class="number">2</span>] = ratio[<span class="number">1</span>] * h * (</span><br><span class="line">                    x[:, <span class="number">2</span>] - x[:, <span class="number">4</span>] / <span class="number">2</span>) + pad[<span class="number">1</span>]  <span class="comment"># pad height</span></span><br><span class="line">                labels[:, <span class="number">3</span>] = ratio[<span class="number">0</span>] * w * (x[:, <span class="number">1</span>] +</span><br><span class="line">                                               x[:, <span class="number">3</span>] / <span class="number">2</span>) + pad[<span class="number">0</span>]</span><br><span class="line">                labels[:, <span class="number">4</span>] = ratio[<span class="number">1</span>] * h * (x[:, <span class="number">2</span>] +</span><br><span class="line">                                               x[:, <span class="number">4</span>] / <span class="number">2</span>) + pad[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.augment:</span><br><span class="line">        <span class="comment"># 图片空间的数据增强</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mosaic:</span><br><span class="line">            <span class="comment"># 如果没有使用组合的方法，那么对图片进行随机放射</span></span><br><span class="line">            img, labels = random_affine(img,</span><br><span class="line">                                        labels,</span><br><span class="line">                                        degrees=hyp[<span class="string">&#x27;degrees&#x27;</span>],</span><br><span class="line">                                        translate=hyp[<span class="string">&#x27;translate&#x27;</span>],</span><br><span class="line">                                        scale=hyp[<span class="string">&#x27;scale&#x27;</span>],</span><br><span class="line">                                        shear=hyp[<span class="string">&#x27;shear&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 增强hsv空间</span></span><br><span class="line">        augment_hsv(img,</span><br><span class="line">                    hgain=hyp[<span class="string">&#x27;hsv_h&#x27;</span>],</span><br><span class="line">                    sgain=hyp[<span class="string">&#x27;hsv_s&#x27;</span>],</span><br><span class="line">                    vgain=hyp[<span class="string">&#x27;hsv_v&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    nL = <span class="built_in">len</span>(labels)  <span class="comment"># 标注文件个数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> nL:</span><br><span class="line">        <span class="comment"># 将 xyxy 格式转化为 xywh 格式</span></span><br><span class="line">        labels[:, <span class="number">1</span>:<span class="number">5</span>] = xyxy2xywh(labels[:, <span class="number">1</span>:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 归一化到0-1之间</span></span><br><span class="line">        labels[:, [<span class="number">2</span>, <span class="number">4</span>]] /= img.shape[<span class="number">0</span>]  <span class="comment"># height</span></span><br><span class="line">        labels[:, [<span class="number">1</span>, <span class="number">3</span>]] /= img.shape[<span class="number">1</span>]  <span class="comment"># width</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.augment:</span><br><span class="line">        <span class="comment"># 随机左右翻转</span></span><br><span class="line">        lr_flip = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> lr_flip <span class="keyword">and</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">            img = np.fliplr(img)</span><br><span class="line">            <span class="keyword">if</span> nL:</span><br><span class="line">                labels[:, <span class="number">1</span>] = <span class="number">1</span> - labels[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 随机上下翻转</span></span><br><span class="line">        ud_flip = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> ud_flip <span class="keyword">and</span> random.random() &lt; <span class="number">0.5</span>:</span><br><span class="line">            img = np.flipud(img)</span><br><span class="line">            <span class="keyword">if</span> nL:</span><br><span class="line">                labels[:, <span class="number">2</span>] = <span class="number">1</span> - labels[:, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    labels_out = torch.zeros((nL, <span class="number">6</span>))</span><br><span class="line">    <span class="keyword">if</span> nL:</span><br><span class="line">        labels_out[:, <span class="number">1</span>:] = torch.from_numpy(labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 图像维度转换</span></span><br><span class="line">    img = img[:, :, ::-<span class="number">1</span>].transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)  <span class="comment"># BGR to RGB, to 3x416x416</span></span><br><span class="line">    img = np.ascontiguousarray(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(img), labels_out, img_path, shapes</span><br></pre></td></tr></table></figure>
<p>下图是开启了组合和旋转以后的增强效果</p>
<p>这里理解组合就是将四张图片，以不同的比例，合成为一张图片。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/645.webp" alt></p>
<h3 id="3-3-collate-fn函数"><a href="#3-3-collate-fn函数" class="headerlink" title="3.3 collate_fn函数"></a>3.3 collate_fn函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span>(<span class="params">batch</span>):</span></span><br><span class="line">    img, label, path, shapes = <span class="built_in">zip</span>(*batch)  <span class="comment"># transposed</span></span><br><span class="line">    <span class="keyword">for</span> i, l <span class="keyword">in</span> <span class="built_in">enumerate</span>(label):</span><br><span class="line">        l[:, <span class="number">0</span>] = i  <span class="comment"># add target image index for build_targets()</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack(img, <span class="number">0</span>), torch.cat(label, <span class="number">0</span>), path, shapes</span><br></pre></td></tr></table></figure>
<p>还有最后一点内容，是关于pytorch的数据读取机制，在pytorch的dataloader中是会对通过getitem方法得到的结果（batch）进行包装，而这个包装可能与我们想要的有所不同。默认的方法可以看以下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">default_collate</span>(<span class="params">batch</span>):</span></span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Puts each data field into a tensor with outer dimension batch size&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    elem_type = <span class="built_in">type</span>(batch[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], torch.Tensor):</span><br><span class="line">        out = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> _use_shared_memory:</span><br><span class="line">            <span class="comment"># If we&#x27;re in a background process, concatenate directly into a</span></span><br><span class="line">            <span class="comment"># shared memory tensor to avoid an extra copy</span></span><br><span class="line">            numel = <span class="built_in">sum</span>([x.numel() <span class="keyword">for</span> x <span class="keyword">in</span> batch])</span><br><span class="line">            storage = batch[<span class="number">0</span>].storage()._new_shared(numel)</span><br><span class="line">            out = batch[<span class="number">0</span>].new(storage)</span><br><span class="line">        <span class="keyword">return</span> torch.stack(batch, <span class="number">0</span>, out=out)</span><br><span class="line">    <span class="keyword">elif</span> elem_type.__module__ == <span class="string">&#x27;numpy&#x27;</span> <span class="keyword">and</span> elem_type.__name__ != <span class="string">&#x27;str_&#x27;</span> \</span><br><span class="line">            <span class="keyword">and</span> elem_type.__name__ != <span class="string">&#x27;string_&#x27;</span>:</span><br><span class="line">        elem = batch[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> elem_type.__name__ == <span class="string">&#x27;ndarray&#x27;</span>:</span><br><span class="line">            <span class="comment"># array of string classes and object</span></span><br><span class="line">            <span class="keyword">if</span> np_str_obj_array_pattern.search(elem.dtype.<span class="built_in">str</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">raise</span> TypeError(error_msg_fmt.<span class="built_in">format</span>(elem.dtype))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> default_collate([torch.from_numpy(b) <span class="keyword">for</span> b <span class="keyword">in</span> batch])</span><br><span class="line">        <span class="keyword">if</span> elem.shape == ():  <span class="comment"># scalars</span></span><br><span class="line">            py_type = <span class="built_in">float</span> <span class="keyword">if</span> elem.dtype.name.startswith(<span class="string">&#x27;float&#x27;</span>) <span class="keyword">else</span> <span class="built_in">int</span></span><br><span class="line">            <span class="keyword">return</span> numpy_type_map[elem.dtype.name](<span class="built_in">list</span>(<span class="built_in">map</span>(py_type, batch)))</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], <span class="built_in">float</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.tensor(batch, dtype=torch.float64)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], int_classes):</span><br><span class="line">        <span class="keyword">return</span> torch.tensor(batch)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], string_classes):</span><br><span class="line">        <span class="keyword">return</span> batch</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], container_abcs.Mapping):</span><br><span class="line">        <span class="keyword">return</span> &#123;key: default_collate([d[key] <span class="keyword">for</span> d <span class="keyword">in</span> batch]) <span class="keyword">for</span> key <span class="keyword">in</span> batch[<span class="number">0</span>]&#125;</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], <span class="built_in">tuple</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(batch[<span class="number">0</span>], <span class="string">&#x27;_fields&#x27;</span>):  <span class="comment"># namedtuple</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">type</span>(batch[<span class="number">0</span>])(*(default_collate(samples) <span class="keyword">for</span> samples <span class="keyword">in</span> <span class="built_in">zip</span>(*batch)))</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(batch[<span class="number">0</span>], container_abcs.<span class="type">Sequence</span>):</span><br><span class="line">        transposed = <span class="built_in">zip</span>(*batch)</span><br><span class="line">        <span class="keyword">return</span> [default_collate(samples) <span class="keyword">for</span> samples <span class="keyword">in</span> transposed]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">raise</span> TypeError((error_msg_fmt.<span class="built_in">format</span>(<span class="built_in">type</span>(batch[<span class="number">0</span>]))))</span><br></pre></td></tr></table></figure>
<p>会根据你的数据类型进行相应的处理，但是这往往不是我们需要的，所以需要修改<code>collate_fn</code>,具体内容请看代码，比较简单，就不多赘述。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3网络模型的构建</title>
    <url>/2020/02/18/YOLOv3%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="1-cfg文件"><a href="#1-cfg文件" class="headerlink" title="1. cfg文件"></a>1. cfg文件</h2><p>在YOLOv3中，修改网络结构很容易，只需要修改cfg文件即可。目前，cfg文件支持convolutional, maxpool, unsample, route, shortcut, yolo这几个层。</p>
<p>而且作者也提供了多个cfg文件来进行网络构建，比如：yolov3.cfg、yolov3-tiny.cfg、yolov3-spp.cfg、csresnext50-panet-spp.cfg文件（提供的yolov3-spp-pan-scale.cfg文件，在代码级别还没有提供支持）。</p>
<p>如果想要添加自定义的模块也很方便，比如说注意力机制模块、空洞卷积等，都可以简单地得到添加或者修改。</p>
<p>为了更加方便的理解cfg文件网络是如何构建的，在这里推荐一个Github上的网络结构可视化软件：<code>Netron</code>，下图是可视化yolov3-tiny的结果：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/648.jpg" alt></p>
<h2 id="2-网络模型构建"><a href="#2-网络模型构建" class="headerlink" title="2. 网络模型构建"></a>2. 网络模型构建</h2><p>从<code>train.py</code>文件入手，其中涉及的网络构建的代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = Darknet(cfg, arc=opt.arc).to(device)</span><br></pre></td></tr></table></figure>
<p>然后沿着Darknet实现进行讲解：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Darknet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="comment"># YOLOv3 object detection model</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfg, img_size=(<span class="params"><span class="number">416</span>, <span class="number">416</span></span>), arc=<span class="string">&#x27;default&#x27;</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Darknet, self).__init__()</span><br><span class="line">        self.module_defs = parse_model_cfg(cfg)</span><br><span class="line">        self.module_list, self.routs = create_modules(self.module_defs, img_size, arc)</span><br><span class="line">        self.yolo_layers = get_yolo_layers(self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Darknet Header</span></span><br><span class="line">        self.version = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>], dtype=np.int32)</span><br><span class="line">        <span class="comment"># (int32) version info: major, minor, revision</span></span><br><span class="line">        self.seen = np.array([<span class="number">0</span>], dtype=np.int64)</span><br><span class="line">        <span class="comment"># (int64) number of images seen during training</span></span><br></pre></td></tr></table></figure>
<p>以上文件中，比较关键的就是成员函变量<code>module_defs</code>、<code>module_list</code>、<code>routs</code>、<code>yolo_layers</code>四个成员函数，先对这几个参数的意义进行解释：</p>
<h3 id="2-1-module-defs"><a href="#2-1-module-defs" class="headerlink" title="2.1 module_defs"></a>2.1 module_defs</h3><p>调用了<code>parse_model_cfg</code>函数，得到了<code>module_defs</code>对象。实际上该函数是通过解析cfg文件，得到一个list，list中包含多个字典，每个字典保存的内容就是一个模块内容，比如说：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">batch_normalize=1</span><br><span class="line">filters=128</span><br><span class="line">size=3</span><br><span class="line">stride=2</span><br><span class="line">pad=1</span><br><span class="line">activation=leaky</span><br></pre></td></tr></table></figure>
<p>函数代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_model_cfg</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="comment"># path参数为: cfg/yolov3-tiny.cfg</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> path.endswith(<span class="string">&#x27;.cfg&#x27;</span>):</span><br><span class="line">        path += <span class="string">&#x27;.cfg&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path) <span class="keyword">and</span> os.path.exists(<span class="string">&#x27;cfg&#x27;</span> + os.sep + path):</span><br><span class="line">        path = <span class="string">&#x27;cfg&#x27;</span> + os.sep + path</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.read().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 去除以#开头的，属于注释部分的内容</span></span><br><span class="line">    lines = [x <span class="keyword">for</span> x <span class="keyword">in</span> lines <span class="keyword">if</span> x <span class="keyword">and</span> <span class="keyword">not</span> x.startswith(<span class="string">&#x27;#&#x27;</span>)]</span><br><span class="line">    lines = [x.rstrip().lstrip() <span class="keyword">for</span> x <span class="keyword">in</span> lines]</span><br><span class="line">    mdefs = []  <span class="comment"># 模块的定义</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">&#x27;[&#x27;</span>):  <span class="comment"># 标志着一个模块的开始</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            比如:</span></span><br><span class="line"><span class="string">            [shortcut]</span></span><br><span class="line"><span class="string">            from=-3</span></span><br><span class="line"><span class="string">            activation=linear</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">            mdefs.append(&#123;&#125;)</span><br><span class="line">            mdefs[-<span class="number">1</span>][<span class="string">&#x27;type&#x27;</span>] = line[<span class="number">1</span>:-<span class="number">1</span>].rstrip()</span><br><span class="line">            <span class="keyword">if</span> mdefs[-<span class="number">1</span>][<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;convolutional&#x27;</span>:</span><br><span class="line">                mdefs[-<span class="number">1</span>][<span class="string">&#x27;batch_normalize&#x27;</span>] = <span class="number">0</span>  </span><br><span class="line">                <span class="comment"># pre-populate with zeros (may be overwritten later)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 将键和键值放入字典</span></span><br><span class="line">            key, val = line.split(<span class="string">&quot;=&quot;</span>)</span><br><span class="line">            key = key.rstrip()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;anchors&#x27;</span> <span class="keyword">in</span> key:</span><br><span class="line">                mdefs[-<span class="number">1</span>][key] = np.array([<span class="built_in">float</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> val.split(<span class="string">&#x27;,&#x27;</span>)]).reshape((-<span class="number">1</span>, <span class="number">2</span>))  <span class="comment"># np anchors</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mdefs[-<span class="number">1</span>][key] = val.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 支持的参数类型</span></span><br><span class="line">    supported = [<span class="string">&#x27;type&#x27;</span>, <span class="string">&#x27;batch_normalize&#x27;</span>, <span class="string">&#x27;filters&#x27;</span>, <span class="string">&#x27;size&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;stride&#x27;</span>, <span class="string">&#x27;pad&#x27;</span>, <span class="string">&#x27;activation&#x27;</span>, <span class="string">&#x27;layers&#x27;</span>, <span class="string">&#x27;groups&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;from&#x27;</span>, <span class="string">&#x27;mask&#x27;</span>, <span class="string">&#x27;anchors&#x27;</span>, <span class="string">&#x27;classes&#x27;</span>, <span class="string">&#x27;num&#x27;</span>, <span class="string">&#x27;jitter&#x27;</span>, \</span><br><span class="line">                 <span class="string">&#x27;ignore_thresh&#x27;</span>, <span class="string">&#x27;truth_thresh&#x27;</span>, <span class="string">&#x27;random&#x27;</span>,\</span><br><span class="line">                 <span class="string">&#x27;stride_x&#x27;</span>, <span class="string">&#x27;stride_y&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断所有参数中是否有不符合要求的key</span></span><br><span class="line">    f = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> mdefs[<span class="number">1</span>:]:</span><br><span class="line">        [f.append(k) <span class="keyword">for</span> k <span class="keyword">in</span> x <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> f]</span><br><span class="line">    u = [x <span class="keyword">for</span> x <span class="keyword">in</span> f <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> supported]  <span class="comment"># unsupported fields</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">not</span> <span class="built_in">any</span>(u), <span class="string">&quot;Unsupported fields %s in %s. See https://github.com/ultralytics/yolov3/issues/631&quot;</span> % (u, path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mdefs</span><br></pre></td></tr></table></figure>
<p>返回的内容通过debug模式进行查看：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/649.webp" alt></p>
<p>其中需要关注的就是anchor的组织：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/650.webp" alt></p>
<p>可以看出，anchor是按照每两个一对进行组织的，与我们的理解一致。</p>
<h3 id="2-2-module-list-amp-routs"><a href="#2-2-module-list-amp-routs" class="headerlink" title="2.2 module_list&amp;routs"></a>2.2 module_list&amp;routs</h3><p>这个部分是本文的核心，也是理解模型构建的关键。</p>
<p>在pytorch中，构建模型常见的有通过Sequential或者ModuleList进行构建。</p>
<p><strong>通过Sequential构建</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=nn.Sequential()</span><br><span class="line">model.add_module(<span class="string">&#x27;conv&#x27;</span>,nn.Conv2d(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">model.add_module(<span class="string">&#x27;batchnorm&#x27;</span>,nn.BatchNorm2d(<span class="number">3</span>))</span><br><span class="line">model.add_module(<span class="string">&#x27;activation_layer&#x27;</span>,nn.ReLU())</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=nn.Sequential(</span><br><span class="line">    nn.Conv2d(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">3</span>),</span><br><span class="line">    nn.ReLU()</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line">model=nn.Sequential(OrderedDict([</span><br><span class="line">    (<span class="string">&#x27;conv&#x27;</span>,nn.Conv2d(<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">    (<span class="string">&#x27;batchnorm&#x27;</span>,nn.BatchNorm2d(<span class="number">3</span>)),</span><br><span class="line">    (<span class="string">&#x27;activation_layer&#x27;</span>,nn.ReLU())</span><br><span class="line">]))</span><br></pre></td></tr></table></figure>
<p>通过sequential构建的模块内部<strong>实现了forward函数</strong>，可以直接传入参数，进行调用。</p>
<p><strong>通过ModuleList构建</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model=nn.ModuleList([nn.Linear(<span class="number">3</span>,<span class="number">4</span>),</span><br><span class="line">						 nn.ReLU(),</span><br><span class="line">						 nn.Linear(<span class="number">4</span>,<span class="number">2</span>)])</span><br></pre></td></tr></table></figure>
<p>ModuleList类似list，内部<strong>没有实现forward函数</strong>，使用的时候需要构建forward函数,构建自己模型常用ModuleList函数建立子模型,建立forward函数实现前向传播。</p>
<p>在YOLOv3中，灵活地结合了两种使用方式，通过解析以上得到的module_defs，进行构建一个ModuleList，然后再通过构建forward函数进行前向传播即可。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_modules</span>(<span class="params">module_defs, img_size, arc</span>):</span></span><br><span class="line">    <span class="comment"># 通过module_defs进行构建模型</span></span><br><span class="line">    hyperparams = module_defs.pop(<span class="number">0</span>)</span><br><span class="line">    output_filters = [<span class="built_in">int</span>(hyperparams[<span class="string">&#x27;channels&#x27;</span>])]</span><br><span class="line">    module_list = nn.ModuleList()</span><br><span class="line">    routs = []  <span class="comment"># 存储了所有的层，在route、shortcut会使用到。</span></span><br><span class="line">    yolo_index = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, mdef <span class="keyword">in</span> <span class="built_in">enumerate</span>(module_defs):</span><br><span class="line">        modules = nn.Sequential()</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        通过type字样不同的类型，来进行模型构建</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;convolutional&#x27;</span>:</span><br><span class="line">            bn = <span class="built_in">int</span>(mdef[<span class="string">&#x27;batch_normalize&#x27;</span>])</span><br><span class="line">            filters = <span class="built_in">int</span>(mdef[<span class="string">&#x27;filters&#x27;</span>])</span><br><span class="line">            size = <span class="built_in">int</span>(mdef[<span class="string">&#x27;size&#x27;</span>])</span><br><span class="line">            stride = <span class="built_in">int</span>(mdef[<span class="string">&#x27;stride&#x27;</span>]) <span class="keyword">if</span> <span class="string">&#x27;stride&#x27;</span> <span class="keyword">in</span> mdef <span class="keyword">else</span> (<span class="built_in">int</span>(</span><br><span class="line">                mdef[<span class="string">&#x27;stride_y&#x27;</span>]), <span class="built_in">int</span>(mdef[<span class="string">&#x27;stride_x&#x27;</span>]))</span><br><span class="line">            pad = (size - <span class="number">1</span>) // <span class="number">2</span> <span class="keyword">if</span> <span class="built_in">int</span>(mdef[<span class="string">&#x27;pad&#x27;</span>]) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            modules.add_module(</span><br><span class="line">                <span class="string">&#x27;Conv2d&#x27;</span>,</span><br><span class="line">                nn.Conv2d(</span><br><span class="line">                    in_channels=output_filters[-<span class="number">1</span>],</span><br><span class="line">                    out_channels=filters,</span><br><span class="line">                    kernel_size=size,</span><br><span class="line">                    stride=stride,</span><br><span class="line">                    padding=pad,</span><br><span class="line">                    groups=<span class="built_in">int</span>(mdef[<span class="string">&#x27;groups&#x27;</span>]) <span class="keyword">if</span> <span class="string">&#x27;groups&#x27;</span> <span class="keyword">in</span> mdef <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">                    bias=<span class="keyword">not</span> bn))</span><br><span class="line">            <span class="keyword">if</span> bn:</span><br><span class="line">                modules.add_module(<span class="string">&#x27;BatchNorm2d&#x27;</span>,</span><br><span class="line">                                   nn.BatchNorm2d(filters, momentum=<span class="number">0.1</span>))</span><br><span class="line">            <span class="keyword">if</span> mdef[<span class="string">&#x27;activation&#x27;</span>] == <span class="string">&#x27;leaky&#x27;</span>:  <span class="comment"># <span class="doctag">TODO:</span> activation study https://github.com/ultralytics/yolov3/issues/441</span></span><br><span class="line">                modules.add_module(<span class="string">&#x27;activation&#x27;</span>, nn.LeakyReLU(<span class="number">0.1</span>,</span><br><span class="line">                                                              inplace=<span class="literal">True</span>))</span><br><span class="line">            <span class="keyword">elif</span> mdef[<span class="string">&#x27;activation&#x27;</span>] == <span class="string">&#x27;swish&#x27;</span>:</span><br><span class="line">                modules.add_module(<span class="string">&#x27;activation&#x27;</span>, Swish())</span><br><span class="line">            <span class="comment"># 在此处可以添加新的激活函数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;maxpool&#x27;</span>:</span><br><span class="line">            <span class="comment"># 最大池化操作</span></span><br><span class="line">            size = <span class="built_in">int</span>(mdef[<span class="string">&#x27;size&#x27;</span>])</span><br><span class="line">            stride = <span class="built_in">int</span>(mdef[<span class="string">&#x27;stride&#x27;</span>])</span><br><span class="line">            maxpool = nn.MaxPool2d(kernel_size=size,</span><br><span class="line">                                   stride=stride,</span><br><span class="line">                                   padding=<span class="built_in">int</span>((size - <span class="number">1</span>) // <span class="number">2</span>))</span><br><span class="line">            <span class="keyword">if</span> size == <span class="number">2</span> <span class="keyword">and</span> stride == <span class="number">1</span>:  <span class="comment"># yolov3-tiny</span></span><br><span class="line">                modules.add_module(<span class="string">&#x27;ZeroPad2d&#x27;</span>, nn.ZeroPad2d((<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>)))</span><br><span class="line">                modules.add_module(<span class="string">&#x27;MaxPool2d&#x27;</span>, maxpool)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                modules = maxpool</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;upsample&#x27;</span>:</span><br><span class="line">            <span class="comment"># 通过近邻插值完成上采样</span></span><br><span class="line">            modules = nn.Upsample(scale_factor=<span class="built_in">int</span>(mdef[<span class="string">&#x27;stride&#x27;</span>]),</span><br><span class="line">                                  mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;route&#x27;</span>:</span><br><span class="line">            <span class="comment"># nn.Sequential() placeholder for &#x27;route&#x27; layer</span></span><br><span class="line">            layers = [<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> mdef[<span class="string">&#x27;layers&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">            filters = <span class="built_in">sum</span>(</span><br><span class="line">                [output_filters[i + <span class="number">1</span> <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">else</span> i] <span class="keyword">for</span> i <span class="keyword">in</span> layers])</span><br><span class="line">            <span class="comment"># extend表示添加一系列对象</span></span><br><span class="line">            routs.extend([l <span class="keyword">if</span> l &gt; <span class="number">0</span> <span class="keyword">else</span> l + i <span class="keyword">for</span> l <span class="keyword">in</span> layers])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;shortcut&#x27;</span>:</span><br><span class="line">            <span class="comment"># nn.Sequential() placeholder for &#x27;shortcut&#x27; layer</span></span><br><span class="line">            filters = output_filters[<span class="built_in">int</span>(mdef[<span class="string">&#x27;from&#x27;</span>])]</span><br><span class="line">            layer = <span class="built_in">int</span>(mdef[<span class="string">&#x27;from&#x27;</span>])</span><br><span class="line">            routs.extend([i + layer <span class="keyword">if</span> layer &lt; <span class="number">0</span> <span class="keyword">else</span> layer])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mdef[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;yolo&#x27;</span>:</span><br><span class="line">            yolo_index += <span class="number">1</span></span><br><span class="line">            mask = [<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> mdef[<span class="string">&#x27;mask&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]  <span class="comment"># anchor mask</span></span><br><span class="line">            modules = YOLOLayer(</span><br><span class="line">                anchors=mdef[<span class="string">&#x27;anchors&#x27;</span>][mask],  <span class="comment"># anchor list</span></span><br><span class="line">                nc=<span class="built_in">int</span>(mdef[<span class="string">&#x27;classes&#x27;</span>]),  <span class="comment"># number of classes</span></span><br><span class="line">                img_size=img_size,  <span class="comment"># (416, 416)</span></span><br><span class="line">                yolo_index=yolo_index,  <span class="comment"># 0, 1 or 2</span></span><br><span class="line">                arc=arc)  <span class="comment"># yolo architecture</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 这是在focal loss文章中提到的为卷积层添加bias</span></span><br><span class="line">            <span class="comment"># 主要用于解决样本不平衡问题</span></span><br><span class="line">            <span class="comment"># (论文地址 https://arxiv.org/pdf/1708.02002.pdf section 3.3)</span></span><br><span class="line">            <span class="comment"># 具体讲解见下方</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> arc == <span class="string">&#x27;defaultpw&#x27;</span> <span class="keyword">or</span> arc == <span class="string">&#x27;Fdefaultpw&#x27;</span>:</span><br><span class="line">                    <span class="comment"># default with positive weights</span></span><br><span class="line">                    b = [-<span class="number">5.0</span>, -<span class="number">5.0</span>]  <span class="comment"># obj, cls</span></span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;default&#x27;</span>:</span><br><span class="line">                    <span class="comment"># default no pw (40 cls, 80 obj)</span></span><br><span class="line">                    b = [-<span class="number">5.0</span>, -<span class="number">5.0</span>]</span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;uBCE&#x27;</span>:</span><br><span class="line">                    <span class="comment"># unified BCE (80 classes)</span></span><br><span class="line">                    b = [<span class="number">0</span>, -<span class="number">9.0</span>]</span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;uCE&#x27;</span>:</span><br><span class="line">                    <span class="comment"># unified CE (1 background + 80 classes)</span></span><br><span class="line">                    b = [<span class="number">10</span>, -<span class="number">0.1</span>]</span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;Fdefault&#x27;</span>:</span><br><span class="line">                    <span class="comment"># Focal default no pw (28 cls, 21 obj, no pw)</span></span><br><span class="line">                    b = [-<span class="number">2.1</span>, -<span class="number">1.8</span>]</span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;uFBCE&#x27;</span> <span class="keyword">or</span> arc == <span class="string">&#x27;uFBCEpw&#x27;</span>:</span><br><span class="line">                    <span class="comment"># unified FocalBCE (5120 obj, 80 classes)</span></span><br><span class="line">                    b = [<span class="number">0</span>, -<span class="number">6.5</span>]</span><br><span class="line">                <span class="keyword">elif</span> arc == <span class="string">&#x27;uFCE&#x27;</span>:</span><br><span class="line">                    <span class="comment"># unified FocalCE (64 cls, 1 background + 80 classes)</span></span><br><span class="line">                    b = [<span class="number">7.7</span>, -<span class="number">1.1</span>]</span><br><span class="line"></span><br><span class="line">                bias = module_list[-<span class="number">1</span>][<span class="number">0</span>].bias.view(<span class="built_in">len</span>(mask), -<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 255 to 3x85</span></span><br><span class="line">                bias[:, <span class="number">4</span>] += b[<span class="number">0</span>] - bias[:, <span class="number">4</span>].mean()  <span class="comment"># obj</span></span><br><span class="line">                bias[:, <span class="number">5</span>:] += b[<span class="number">1</span>] - bias[:, <span class="number">5</span>:].mean()  <span class="comment"># cls</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 将新的偏移量赋值回模型中</span></span><br><span class="line">                module_list[-<span class="number">1</span>][<span class="number">0</span>].bias = torch.nn.Parameter(bias.view(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;WARNING: smart bias initialization failure.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Warning: Unrecognized Layer Type: &#x27;</span> + mdef[<span class="string">&#x27;type&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将module内容保存在module_list中。</span></span><br><span class="line">        module_list.append(modules)</span><br><span class="line">        <span class="comment"># 保存所有的filter个数</span></span><br><span class="line">        output_filters.append(filters)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> module_list, routs</span><br></pre></td></tr></table></figure>
<p><strong>bias部分讲解</strong></p>
<p>其中在YOLO Layer部分涉及到一个初始化的trick，来自Focal Loss中关于模型初始化的讨论，具体内容请阅读论文，<code>https://arxiv.org/pdf/1708.02002.pdf</code> 的第3.3节。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/651.webp" alt></p>
<p>这里涉及到一个非常insight的点，在第一篇中介绍了，YOLO层前一个卷积的filter个数计算公式如下：</p>
<script type="math/tex; mode=display">
filter=(c l a s s+5) \times 3</script><p>5代表x,y,w,h, score，score代表该格子中是否存在目标，3代表这个格子中会分配3个anchor进行匹配。在YOLOLayer中的forward函数中，有以下代码，需要通过sigmoid激活函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">&#x27;default&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># seperate obj and cls</span></span><br><span class="line">	torch.sigmoid_(io[..., <span class="number">4</span>])</span><br><span class="line"><span class="keyword">elif</span> <span class="string">&#x27;BCE&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># unified BCE (80 classes)</span></span><br><span class="line">	torch.sigmoid_(io[..., <span class="number">5</span>:])</span><br><span class="line">	io[..., <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> <span class="string">&#x27;CE&#x27;</span> <span class="keyword">in</span> self.arc:  <span class="comment"># unified CE (1 background + 80 classes)</span></span><br><span class="line">	io[..., <span class="number">4</span>:] = F.softmax(io[..., <span class="number">4</span>:], dim=<span class="number">4</span>)</span><br><span class="line">	io[..., <span class="number">4</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/pyyolov3/652.png" alt></p>
<p>可以观察到，Sigmoid梯度是有限的，在<code>[-5,5]</code>之间。</p>
<p>而pytorch中的卷积层默认的初始化是以0为中心点的正态分布，这样进行的初始化会导致很多gird中大约一半得到了激活，在计算loss的时候就会计算上所有的激活的点对应的坐标信息，这样计算loss就会变得很大。</p>
<p>根据这个现象，作者选择在YOLOLayer的前一个卷积层添加bias，来避免这种情况，实际操作就是在原有的bias上减去5，这样通过卷积得到的数值就不会被激活，可以防止在初始阶段的第一个batch中就进行过拟合。通过以上操作，能够让所有的神经元在前几个batch中输出空的检测。</p>
<p>经过作者的实验，通过使用bias的trick，可以提升mAP、F1、P、R等指标，还能让训练过程更加平滑。</p>
<h3 id="2-3-yolo-layers"><a href="#2-3-yolo-layers" class="headerlink" title="2.3 yolo_layers"></a>2.3 yolo_layers</h3><p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_yolo_layers</span>(<span class="params">model</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [i <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(model.module_defs) <span class="keyword">if</span> x[<span class="string">&#x27;type&#x27;</span>] == <span class="string">&#x27;yolo&#x27;</span>]</span><br><span class="line">    <span class="comment"># [82, 94, 106] for yolov3</span></span><br></pre></td></tr></table></figure>
<p>yolo layer的获取是通过解析module_defs这个存储cfg文件中的信息的变量得到的。以yolov3.cfg为例，最终返回的是yolo层在整个module的序号。比如：第83,94,106个层是YOLO层。</p>
<h2 id="3-forward函数"><a href="#3-forward函数" class="headerlink" title="3. forward函数"></a>3. forward函数</h2><p>在YOLO中，如果能理解前向传播的过程，那整个网络的构建也就很清楚明了了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, var=<span class="literal">None</span></span>):</span></span><br><span class="line">    img_size = x.shape[-<span class="number">2</span>:]</span><br><span class="line">    layer_outputs = []</span><br><span class="line">    output = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, (mdef,</span><br><span class="line">            module) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(self.module_defs, self.module_list)):</span><br><span class="line">        mtype = mdef[<span class="string">&#x27;type&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> mtype <span class="keyword">in</span> [<span class="string">&#x27;convolutional&#x27;</span>, <span class="string">&#x27;upsample&#x27;</span>, <span class="string">&#x27;maxpool&#x27;</span>]:</span><br><span class="line">            <span class="comment"># 卷积层，上采样，池化层只需要经过即可</span></span><br><span class="line">            x = module(x)</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;route&#x27;</span>:</span><br><span class="line">            <span class="comment"># route操作就是将几个层的内容拼接起来，具体可以看cfg文件解析</span></span><br><span class="line">            layers = [<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> mdef[<span class="string">&#x27;layers&#x27;</span>].split(<span class="string">&#x27;,&#x27;</span>)]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(layers) == <span class="number">1</span>:</span><br><span class="line">                x = layer_outputs[layers[<span class="number">0</span>]]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    x = torch.cat([layer_outputs[i] <span class="keyword">for</span> i <span class="keyword">in</span> layers], <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="comment"># apply stride 2 for darknet reorg layer</span></span><br><span class="line">                    layer_outputs[layers[<span class="number">1</span>]] = F.interpolate(</span><br><span class="line">                        layer_outputs[layers[<span class="number">1</span>]], scale_factor=[<span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">                    x = torch.cat([layer_outputs[i] <span class="keyword">for</span> i <span class="keyword">in</span> layers], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;shortcut&#x27;</span>:</span><br><span class="line">            x = x + layer_outputs[<span class="built_in">int</span>(mdef[<span class="string">&#x27;from&#x27;</span>])]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="string">&#x27;yolo&#x27;</span>:</span><br><span class="line">            output.append(module(x, img_size))</span><br><span class="line">        <span class="comment">#记录route对应的层</span></span><br><span class="line">        layer_outputs.append(x <span class="keyword">if</span> i <span class="keyword">in</span> self.routs <span class="keyword">else</span> [])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.training:</span><br><span class="line">        <span class="comment"># 如果训练，直接输出YOLO要求的Tensor</span></span><br><span class="line">        <span class="comment"># 3*(class+5)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> ONNX_EXPORT:<span class="comment"># 这个是对应的onnx导出的内容</span></span><br><span class="line">        x = [torch.cat(x, <span class="number">0</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">zip</span>(*output)]</span><br><span class="line">        <span class="keyword">return</span> x[<span class="number">0</span>], torch.cat(x[<span class="number">1</span>:<span class="number">3</span>], <span class="number">1</span>)  <span class="comment"># scores, boxes: 3780x80, 3780x4</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 对应测试阶段</span></span><br><span class="line">        io, p = <span class="built_in">list</span>(<span class="built_in">zip</span>(*output))  <span class="comment"># inference output, training output</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat(io, <span class="number">1</span>), p</span><br></pre></td></tr></table></figure>
<p>forward的过程也比较简单，通过得到的module_defs和module_list变量，通过for循环将整个module_list中的内容进行一遍串联，需要得到的最终结果是YOLO层的输出。</p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>快速入门Docker</title>
    <url>/2022/01/04/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8Docker/</url>
    <content><![CDATA[<h1 id="Docker是什么？"><a href="#Docker是什么？" class="headerlink" title="Docker是什么？"></a>Docker是什么？</h1><p>Docker是一个虚拟环境容器，可以将你的开发环境、代码、配置文件等一并打包到这个容器中，并发布和应用到任意平台中。</p>
<h1 id="Docker的三个概念"><a href="#Docker的三个概念" class="headerlink" title="Docker的三个概念"></a>Docker的三个概念</h1><p>① 镜像（Image）：是一个包含有文件系统的面向Docker引擎的只读模板。任何应用程序运行都需要环境，而镜像就是用来提供这种运行环境的。例如一个Ubuntu镜像就是一个包含Ubuntu操作系统环境的模板。</p>
<p>② 容器（Container）：类似于一个轻量级的沙盒，可以将其看作一个极简的Linux系统环境（包括root权限、进程空间、用户空间和网络空间等），以及运行在其中的应用程序。Docker引擎利用容器来运行、隔离各个应用。容器是镜像创建的应用实例，可以创建、启动、停止、删除容器，各个容器之间是是相互隔离的，互不影响。注意：镜像本身是只读的，容器从镜像启动时，Docker在镜像的上层创建一个可写层，镜像本身不变。</p>
<p>③ 仓库（Repository）：Docker用来集中存放镜像文件的地方。注意与注册服务器（Registry）的区别：注册服务器是存放仓库的地方，一般会有多个仓库；而仓库是存放镜像的地方，一般每个仓库存放一类镜像，每个镜像利用tag进行区分，比如Ubuntu仓库存放有多个版本（12.04、14.04等）的Ubuntu镜像。</p>
<h1 id="Docker的安装和卸载"><a href="#Docker的安装和卸载" class="headerlink" title="Docker的安装和卸载"></a>Docker的安装和卸载</h1><p>可查看<a href="https://docs.docker.com/engine/install/">官方教程</a>，这里以CentOS系统和Ubuntu系统为例。</p>
<h2 id="CentOS"><a href="#CentOS" class="headerlink" title="CentOS"></a>CentOS</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>① 安装所需软件包与驱动程序</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils device-mapper-persistent-data lvm2</span><br></pre></td></tr></table></figure>
<p>② 设置仓库源</p>
<ul>
<li><p>官方源（比较慢）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></li>
<li><p>阿里源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></li>
<li><p>清华大学源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager --add-repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>③ 安装Docker（默认安装最新版本）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>
<p>安装过程中会提示是否接受GPG密钥，请选是。</p>
<p>如果要安装指定版本，可使用如下命令查可用版本（按版本号从高到低对结果进行排序）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure>
<p>例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable</span><br></pre></td></tr></table></figure>
<p>并通过其版本号安装特定版本，即第二列第一个<code>:</code>一直到第一个<code>-</code>中间的字符。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce-18.09.1 docker-ce-cli-18.09.1 containerd.io</span><br></pre></td></tr></table></figure>
<p>注：Docker 安装完默认未启动。并且已经创建好 docker 用户组，但该用户组下没有用户。</p>
<p>④ 启动Docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl start docker</span><br></pre></td></tr></table></figure>
<p>⑤ 验证</p>
<p>通过运行 hello-world 映像来验证是否正确安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
<h3 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h3><p>删除安装包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum remove docker-ce</span><br></pre></td></tr></table></figure>
<p>删除镜像、容器、配置文件等内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure>
<p>卸载旧版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure>
<h2 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h2><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p><strong>自动安装：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>
<p>也可以使用国内 daocloud 一键安装命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -sSL https://get.daocloud.io/docker | sh</span><br></pre></td></tr></table></figure>
<p><strong>手动安装：</strong></p>
<p>① 更新apt包索引</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>② 安装apt依赖包，用于通过https来获取仓库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common</span><br></pre></td></tr></table></figure>
<p>③ 添加Docker的官方GPG密钥：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure>
<p>9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 通过搜索指纹的后8个字符，验证您现在是否拥有带有指纹的密钥。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-key fingerprint 0EBFCD88</span><br></pre></td></tr></table></figure>
<p>④ 设置稳定版仓库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository &quot;deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/ $(lsb_release -cs) stable&quot;</span><br></pre></td></tr></table></figure>
<p>⑤ 更新apt包索引</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>⑥ 安装Docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>
<p>如果要安装指定版本，可使用如下命令查可用版本（按版本号从高到低对结果进行排序）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apt-cache madison docker-ce</span><br></pre></td></tr></table></figure>
<p>例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker-ce | 5:18.09.1~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu  xenial/stable amd64 Packages</span><br><span class="line">docker-ce | 5:18.09.0~3-0~ubuntu-xenial | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu  xenial/stable amd64 Packages</span><br><span class="line">docker-ce | 18.06.1~ce~3-0~ubuntu       | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu  xenial/stable amd64 Packages</span><br><span class="line">docker-ce | 18.06.0~ce~3-0~ubuntu       | https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu  xenial/stable amd64 Packages</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>并通过其版本号安装特定版本，即第二列第一个<code>:</code>一直到第一个<code>-</code>中间的字符。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install docker-ce-18.09.1 docker-ce-cli-18.09.1 containerd.io</span><br></pre></td></tr></table></figure>
<p>注：Docker 安装完默认未启动。并且已经创建好 docker 用户组，但该用户组下没有用户。</p>
<p>⑦ 启动Docker</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service docker start</span><br></pre></td></tr></table></figure>
<p>⑧ 验证</p>
<p>通过运行 hello-world 映像来验证是否正确安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
<h3 id="卸载-1"><a href="#卸载-1" class="headerlink" title="卸载"></a>卸载</h3><p>删除安装包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get purge docker-ce</span><br></pre></td></tr></table></figure>
<p>删除镜像、容器、配置文件等内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure>
<p>卸载旧版本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get remove docker docker-engine docker.io containerd runc</span><br></pre></td></tr></table></figure>
<h1 id="加入用户组"><a href="#加入用户组" class="headerlink" title="加入用户组"></a>加入用户组</h1><p>Docker需要用户具有sudo权限，为了避免每次命令都输入sudo，建议将用户加入Docker用户组：</p>
<p>① 添加Docker分组</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo groupadd docker</span><br></pre></td></tr></table></figure>
<p>② 将当前用户添加到分组</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure>
<p>③ 重启服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure>
<p>④ 切换当前会话到新组</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">newgrp - docker</span><br></pre></td></tr></table></figure>
<h1 id="配置镜像加速"><a href="#配置镜像加速" class="headerlink" title="配置镜像加速"></a>配置镜像加速</h1><p>国内从DockerHub拉取镜像速度慢，此时可以配置镜像加速器。Docker官方和国内很多云服务商都提供了国内加速器服务。例如：</p>
<ul>
<li>科大镜像：<a href="https://docker.mirrors.ustc.edu.cn/">https://docker.mirrors.ustc.edu.cn/</a></li>
<li>网易：<a href="https://hub-mirror.c.163.com/">https://hub-mirror.c.163.com/</a></li>
<li>阿里云：https://&lt;你的ID&gt;.mirror.aliyuncs.com</li>
<li>七牛云加速器：<a href="https://reg-mirror.qiniu.com">https://reg-mirror.qiniu.com</a></li>
<li>中国科技大学<a href="https://docker.mirrors.ustc.edu.cn">https://docker.mirrors.ustc.edu.cn</a></li>
</ul>
<p>注：阿里云须<a href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors">登录</a>，从左侧菜单选中镜像加速器获取专属地址。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/docker/docker1.jpg" alt></p>
<p>这里以Ubuntu16.04+、Debian8+、CentOS7的配置为例，在 <code>/etc/docker/daemon.json</code>中写入如下内容（如果文件不存在请新建该文件）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">&quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;,</span><br><span class="line">&quot;http://hub-mirror.c.163.com&quot;,</span><br><span class="line">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>多个镜像源则以<code>,</code>分割。</p>
<p>之后重启服务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><h2 id="docker常用命令"><a href="#docker常用命令" class="headerlink" title="docker常用命令"></a>docker常用命令</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker --help #查看docker命令</span><br><span class="line">docker info #docker 详细信息，镜像和容器</span><br><span class="line">docker version #查看docker版本</span><br></pre></td></tr></table></figure>
<h2 id="常用镜像命令"><a href="#常用镜像命令" class="headerlink" title="常用镜像命令"></a>常用镜像命令</h2><h3 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker images #查看docker镜像</span><br><span class="line">docker images -a #列出本地所有的镜像</span><br><span class="line">docker images -q #只显示镜像ID</span><br><span class="line">docker images --digests #显示镜像的摘要信息</span><br><span class="line">docker images --no-trunc #显示完整的镜像信息</span><br></pre></td></tr></table></figure>
<p>具体列解释含义：</p>
<ul>
<li>REPOSITORY：镜像仓库源        </li>
<li>TAG：镜像的标签         </li>
<li>IMAGE ID：镜像id      </li>
<li>CREATED：创建时间       </li>
<li>SIZE：大小</li>
</ul>
<p>注：同一个仓库源可以有多个TAG，表示这个仓库源的不同版本，我们使用<code>REPOSITORY:TAG</code>来定义不同的镜像。如果不指定一个镜像的版本标签，例如只使用tomcat，docker将默认使用<code>tomcat:latest</code>镜像</p>
<h3 id="查找镜像"><a href="#查找镜像" class="headerlink" title="查找镜像"></a>查找镜像</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker search tomcat #从Docker Hub上查找tomcat镜像</span><br><span class="line">docker search --filter=stars=300 tomcat #从Docker Hub上查找关注度(stars)大于300的tomcat镜像</span><br></pre></td></tr></table></figure>
<h3 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker pull tomcat #下载tomcat镜像，相当于：docker pull tomcat:latest</span><br></pre></td></tr></table></figure>
<h3 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker rmi redis #单个镜像删除，相当于：docker rmi redis:latest</span><br><span class="line">docker rmi -f redis #强制删除(针对基于镜像有运行的容器进程)</span><br><span class="line">docker rmi -f redis tomcat nginx #多个镜像删除，不同镜像间以空格间隔</span><br><span class="line">docker rmi -f $(docker images -q) #删除本地全部镜像</span><br></pre></td></tr></table></figure>
<h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><p>只有在镜像的基础上才能运行容器命令</p>
<h3 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker ps -a #-a 是查看当前所有正在运行的容器</span><br><span class="line">docker ps -q #只显示容器ID</span><br></pre></td></tr></table></figure>
<h3 id="容器启动"><a href="#容器启动" class="headerlink" title="容器启动"></a>容器启动</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -i -t --name mycentos #新建并启动容器，参数：-i 以交互模式运行容器；-t 为容器重新分配一个伪输入终端；--name 为容器指定一个名称, 相当于: docker run -it mycentos</span><br><span class="line">docker run -d mycentos #后台启动容器，参数：-d 以守护进程方式启动容器</span><br><span class="line">docker start 容器id或容器名 #启动容器</span><br><span class="line">docker restart 容器id或容器名 #重启容器</span><br></pre></td></tr></table></figure>
<h3 id="容器停止"><a href="#容器停止" class="headerlink" title="容器停止"></a>容器停止</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker kill 容器id或容器名</span><br><span class="line">docker stop 容器id或容器名</span><br></pre></td></tr></table></figure>
<h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#放在镜像名后的是命令，这里我们希望有个交互式Shell，因此用的是/bin/bash</span><br><span class="line">docker attach 容器id或容器名 /bin/bash #进入容器正在执行的终端，不会启动新的终端进程</span><br><span class="line">docker run -it 容器id或容器名 /bin/bash #使用run方式在创建时进入</span><br><span class="line">docker exec -it 容器id或容器名 /bin/bash #进入容器后，开启一个新的终端，可以在里面操作</span><br></pre></td></tr></table></figure>
<h3 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">exit #关闭容器并退出</span><br><span class="line">快捷键：Ctrl + P + Q #仅退出容器，不关闭</span><br></pre></td></tr></table></figure>
<h3 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it -v /宿主机目录:/容器目录 镜像名 /bin/bash #-v 容器启动时会将宿主机目录挂载到容器里</span><br></pre></td></tr></table></figure>
<h3 id="容器内拷贝文件到主机"><a href="#容器内拷贝文件到主机" class="headerlink" title="容器内拷贝文件到主机"></a>容器内拷贝文件到主机</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker cp 容器id:容器内路径 目的主机路径</span><br></pre></td></tr></table></figure>
<h3 id="容器连接"><a href="#容器连接" class="headerlink" title="容器连接"></a>容器连接</h3><p>可以通过 <code>-P</code> 或 <code>-p</code>参数来指定端口映射，实现外部通过网络端口来访问运行在Docker容器内的服务，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -d -P training/webapp python app.py</span><br><span class="line">docker run -d -p 5000:5000 training/webapp python app.py</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-P</code> :是容器内部端口<strong>随机</strong>映射到主机的高端口。</li>
<li><code>-p</code>:是容器内部端口绑定到<strong>指定</strong>的主机端口。</li>
</ul>
<p>外部可通过SSH，使用ip+绑定的主机端口号进行容器访问。</p>
<h2 id="利用Dockerfile创建镜像"><a href="#利用Dockerfile创建镜像" class="headerlink" title="利用Dockerfile创建镜像"></a>利用Dockerfile创建镜像</h2><p>Dockerfile可以理解为一种配置文件，用来告诉docker build命令应该执行哪些操作。可参照<a href="https://docs.docker.com/engine/reference/builder/">官方</a>说明。</p>
<h3 id="Dockerfile组成"><a href="#Dockerfile组成" class="headerlink" title="Dockerfile组成"></a>Dockerfile组成</h3><p>Dockerfile是由一行行命令语句组成，并且支持已<code>#</code>开头的注释行。</p>
<p>一般来说，可以将Dockerfile分为四个部分：</p>
<ul>
<li>基础镜像(父镜像)信息指令<code>FROM</code></li>
<li>维护者信息指令<code>MAINTAINER</code></li>
<li>镜像操作指令<code>RUN</code>、<code>EVN</code>、<code>ADD</code>和<code>WORKDIR</code>等</li>
<li>容器启动指令<code>CMD</code>、<code>ENTRYPOINT</code>和<code>USER</code>等</li>
</ul>
<h3 id="Dockerfile示例"><a href="#Dockerfile示例" class="headerlink" title="Dockerfile示例"></a>Dockerfile示例</h3><p>下面是一段简单的Dockerfile的例子：</p>
<p>首先创建Dockerfile文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch Dockerfile</span><br></pre></td></tr></table></figure>
<p>然后编辑该文件，输入内容：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM python:3.6</span><br><span class="line">MAINTAINER zqy &lt;zqy@gmail.com&gt;</span><br><span class="line">COPY . /app</span><br><span class="line">WORKDIR /app</span><br><span class="line">RUN pip install -r requirements.txt</span><br><span class="line">EXPOSE 5000</span><br><span class="line">ENTRYPOINT [&quot;python&quot;]</span><br><span class="line">CMD [&quot;app.py&quot;]</span><br></pre></td></tr></table></figure></p>
<ul>
<li>1、从<code>Docker Hub</code>上<code>pull</code>下<code>python 3.6</code>的基础镜像</li>
<li>2、构建者的信息（自己定义）</li>
<li>3、<code>copy</code>当前目录<code>.</code>到容器中的<code>/app</code>目录下</li>
<li>4、指定工作路径为<code>/app</code></li>
<li>5、安装依赖包</li>
<li>6、暴露<code>5000</code>端口</li>
<li>7、执行<code>app.py</code></li>
</ul>
<p>最后在Dockerfile文件所在目录执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker build -t zqy/demo:v1 .</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-t</code>是为新镜像设置仓库和名称，其中<code>zqy</code>为仓库名，<code>demo</code>为镜像名，<code>:v1</code>为版本标签（不添加为默认 <code>latest</code> ），<code>.</code>为当前路径</li>
</ul>
<h3 id="常用指令集"><a href="#常用指令集" class="headerlink" title="常用指令集"></a>常用指令集</h3><h4 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h4><p>用于指定基础的<code>images</code>，一般格式为<code>FROM &lt;image&gt;</code>or<code>FORM &lt;image&gt;:&lt;tag&gt;</code>，所有的 Dockerfile都用该以<code>FROM</code>开头，<code>FROM</code>命令指明Dockerfile所创建的镜像文件以什么镜像为基础，<code>FROM</code>以后的所有指令都会在<code>FROM</code>的基础上进行创建镜像。</p>
<h4 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h4><p>MAINTAINER 是用于指定镜像创建者和联系方式，一般格式为<code>MAINTAINER &lt;name&gt;</code>。</p>
<h4 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h4><p>用于复制本地主机的<code>&lt;src&gt;</code>(为 Dockerfile 所在目录的相对路径)到容器中的 <code>&lt;dest&gt;</code>。当使用本地目录为源目录时，推荐使用<code>COPY</code>。一般格式为<code>COPY &lt;src&gt; &lt;dest&gt;</code>或<code>COPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</code>(特别适合路径中带有空格的情况)。</p>
<h4 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h4><p>不仅能够将构建命令所在的主机本地的文件或目录，而且能够将远程URL所对应的文件或目录，作为资源复制到镜像文件系统。可以认为是增强版的<code>COPY</code>，支持将远程URL的资源加入到镜像的文件系统。一般格式为<code>ADD &lt;src&gt; &lt;dest&gt;</code>或<code>ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</code>(特别适合路径中带有空格的情况)。</p>
<h4 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h4><p>设置环境变量，可以被后面的所有指令中使用，格式为<code>ENV &lt;key&gt; &lt;value&gt; ...</code>，如设置JAVA环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENV JAVA_HOME /opt/software/jdk1.8.0_161</span><br><span class="line">ENV PATH $JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<h4 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h4><p>用于配合<code>RUN</code>，<code>CMD</code>，<code>ENTRYPOINT</code>命令设置当前工作路径。可以设置多次，如果是相对路径，则相对前一个<code>WORKDIR</code>命令。默认路径为<code>/</code>。一般格式为<code>WORKDIR /path/to/work/dir</code>。</p>
<h4 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h4><p>用于容器内部执行命令。每个<code>RUN</code>命令相当于在原有的镜像基础上添加了一个改动层，原有的镜像不会有变化。一般格式为<code>RUN &lt;command&gt;</code> 。例如要安装<code>python</code>依赖包，做法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RUN pip install -r requirements.txt</span><br></pre></td></tr></table></figure>
<h4 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h4><p>用来指定对外开放的端口。一般格式为<code>EXPOSE &lt;port&gt; [&lt;port&gt;...]</code></p>
<h4 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h4><p>让容器表现得像一个可执行程序一样。一个Dockerfile中只能有一个<code>ENTRYPOINT</code>，如果有多个，则最后一个生效。</p>
<p><code>ENTRYPOINT</code> 命令有两种格式：</p>
<ul>
<li><code>ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</code> ：推荐使用的 <code>exec</code>形式</li>
<li><code>ENTRYPOINT command param1 param2</code> ：<code>shell</code> 形式</li>
</ul>
<p>例如要将<code>python</code>镜像变成可执行的程序，可以这样去做：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENTRYPOINT [&quot;python&quot;]</span><br></pre></td></tr></table></figure>
<h4 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h4><p>用于启动容器时默认执行的命令，<code>CMD</code>命令可以包含可执行文件，也可以不包含可执行文件。不包含可执行文件的情况下就要用<code>ENTRYPOINT</code>指定一个，然后<code>CMD</code>命令的参数就会作为<code>ENTRYPOINT</code>的参数。</p>
<p><code>CMD</code> 命令有三种格式：</p>
<ul>
<li><code>CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]</code>：推荐使用的 <code>exec</code> 形式。</li>
<li><code>CMD [&quot;param1&quot;,&quot;param2&quot;]</code>：无可执行程序形式</li>
<li><code>CMD command param1 param2</code>：shell 形式。</li>
</ul>
<p>一个Dockerfile中只能有一个<code>CMD</code>，如果有多个，则最后一个生效。而<code>CMD</code>的<code>shell</code>形式默认调用<code>/bin/sh -c</code>执行命令。</p>
<p><code>CMD</code>命令会被Docker命令行传入的参数覆盖：<code>docker run busybox /bin/echo Hello</code> <code>Docker</code>会把<code>CMD</code>里的命令覆盖。</p>
<h4 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h4><p>指定运行容器时的用户名或UID或GID，后续的操作都会使用指定用户。格式：<code>USER user</code>或<code>USER user:group</code>或<code>USER uid</code>或<code>USER uid:gid</code>或<code>USER user:gid</code>或<code>USER uid:group</code></p>
<p>例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">USER www #使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过docker run运行容器时，可以通过-u参数来覆盖所指定的用户。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet卷积层的前向传播解析</title>
    <url>/2020/02/23/AlexeyAB-DarkNet%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天来介绍一下DarkNet中卷积层的前向传播和反向传播的实现，卷积层是卷积神经网络中的核心组件，了解它的底层代码实现对我们理解卷积神经网络以及优化卷积神经网络都有一些帮助。</p>
<h2 id="卷积层的构造"><a href="#卷积层的构造" class="headerlink" title="卷积层的构造"></a>卷积层的构造</h2><p>卷积层的构造主要在<code>src/convolutional_layer.c</code>中的<code>make_convolutional_layer</code>中进行实现，下面给出部分核心代码。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** batch 每个batch含有的图片数</span></span><br><span class="line"><span class="comment">** step</span></span><br><span class="line"><span class="comment">** h 图像高度(行数)</span></span><br><span class="line"><span class="comment">** w 图像宽度(列数)</span></span><br><span class="line"><span class="comment">** c 输入图像通道数</span></span><br><span class="line"><span class="comment">** n 卷积核个数</span></span><br><span class="line"><span class="comment">** groups 分组数</span></span><br><span class="line"><span class="comment">** size 卷积核尺寸</span></span><br><span class="line"><span class="comment">** stride 步长</span></span><br><span class="line"><span class="comment">** dilation 空洞卷积空洞率</span></span><br><span class="line"><span class="comment">** padding 四周补0长度</span></span><br><span class="line"><span class="comment">** activation 激活函数类别</span></span><br><span class="line"><span class="comment">** batch_normalize 是否进行BN</span></span><br><span class="line"><span class="comment">** binary 是否对权重进行二值化</span></span><br><span class="line"><span class="comment">** xnor 是否对权重以及输入进行二值化</span></span><br><span class="line"><span class="comment">** adam 优化方式</span></span><br><span class="line"><span class="comment">** use_bin_output</span></span><br><span class="line"><span class="comment">** index 分组卷积的时候分组索引</span></span><br><span class="line"><span class="comment">** antialiasing 抗锯齿标志，如果为真强行设置所有的步长为1</span></span><br><span class="line"><span class="comment">** share_layer 标志参数，表示这一个卷积层是否和其它卷积层共享权重</span></span><br><span class="line"><span class="comment">** assisted_excitation</span></span><br><span class="line"><span class="comment">** deform 暂时不知道</span></span><br><span class="line"><span class="comment">** train 标志参数，是否在训练</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function">convolutional_layer <span class="title">make_convolutional_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> steps, <span class="keyword">int</span> h, <span class="keyword">int</span> w, <span class="keyword">int</span> c, <span class="keyword">int</span> n, <span class="keyword">int</span> groups, <span class="keyword">int</span> size, <span class="keyword">int</span> stride_x, <span class="keyword">int</span> stride_y, <span class="keyword">int</span> dilation, <span class="keyword">int</span> padding, ACTIVATION activation,</span></span></span><br><span class="line"><span class="params"><span class="function"> <span class="keyword">int</span> batch_normalize, <span class="keyword">int</span> binary, <span class="keyword">int</span> xnor, <span class="keyword">int</span> adam, <span class="keyword">int</span> use_bin_output, <span class="keyword">int</span> index, <span class="keyword">int</span> antialiasing, convolutional_layer *share_layer, <span class="keyword">int</span> assisted_excitation, <span class="keyword">int</span> deform, <span class="keyword">int</span> train)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> total_batch = batch*steps;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    convolutional_layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    l.type = CONVOLUTIONAL;</span><br><span class="line">    l.train = train;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (xnor) groups = <span class="number">1</span>;   <span class="comment">//对于二值网络，不能使用分组卷积</span></span><br><span class="line">    <span class="keyword">if</span> (groups &lt; <span class="number">1</span>) groups = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> blur_stride_x = stride_x;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> blur_stride_y = stride_y;</span><br><span class="line">    l.antialiasing = antialiasing;</span><br><span class="line">    <span class="keyword">if</span> (antialiasing) &#123;</span><br><span class="line">        stride_x = stride_y = l.stride = l.stride_x = l.stride_y = <span class="number">1</span>; <span class="comment">// use stride=1 in host-layer</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    l.deform = deform;</span><br><span class="line">    l.assisted_excitation = assisted_excitation;</span><br><span class="line">    l.share_layer = share_layer;</span><br><span class="line">    l.index = index;</span><br><span class="line">    l.h = h;</span><br><span class="line">    l.w = w;</span><br><span class="line">    l.c = c;</span><br><span class="line">    l.groups = groups;</span><br><span class="line">    l.n = n;</span><br><span class="line">    l.binary = binary;</span><br><span class="line">    l.xnor = xnor;</span><br><span class="line">    l.use_bin_output = use_bin_output;</span><br><span class="line">    l.batch = batch;</span><br><span class="line">    l.steps = steps;</span><br><span class="line">    l.stride = stride_x;</span><br><span class="line">    l.stride_x = stride_x;</span><br><span class="line">    l.stride_y = stride_y;</span><br><span class="line">    l.dilation = dilation;</span><br><span class="line">    l.size = size;</span><br><span class="line">    l.pad = padding;</span><br><span class="line">    l.batch_normalize = batch_normalize;</span><br><span class="line">    l.learning_rate_scale = <span class="number">1</span>;</span><br><span class="line">	<span class="comment">// 该卷积层总的权重元素个数（权重元素个数等于输入数据的通道数/分组数*卷积核个数*卷积核的二维尺寸，注意因为每一个卷积核是同时作用于输入数据</span></span><br><span class="line">    <span class="comment">// 的多个通道上的，因此实际上卷积核是三维的，包括两个维度的平面尺寸，以及输入数据通道数这个维度，每个通道上的卷积核参数都是独立的训练参数）</span></span><br><span class="line">    l.nweights = (c / groups) * n * size * size;</span><br><span class="line">	<span class="comment">// 如果是共享卷积层，可以直接用共享的卷积层来赋值（猜测是有预训练权重的时候可以直接赋值）</span></span><br><span class="line">    <span class="keyword">if</span> (l.share_layer) &#123;</span><br><span class="line">        <span class="keyword">if</span> (l.size != l.share_layer-&gt;size || l.nweights != l.share_layer-&gt;nweights || l.c != l.share_layer-&gt;c || l.n != l.share_layer-&gt;n) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Layer size, nweights, channels or filters don&#x27;t match for the share_layer&quot;</span>);</span><br><span class="line">            <span class="built_in">getchar</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        l.weights = l.share_layer-&gt;weights;</span><br><span class="line">        l.weight_updates = l.share_layer-&gt;weight_updates;</span><br><span class="line"></span><br><span class="line">        l.biases = l.share_layer-&gt;biases;</span><br><span class="line">        l.bias_updates = l.share_layer-&gt;bias_updates;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 该卷积层总的权重元素(卷积核元素)个数=输入图像通道数 / 分组数*卷积核个数*卷积核尺寸</span></span><br><span class="line">        l.weights = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(l.nweights, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">		<span class="comment">// bias就是Wx+b中的b（上面的weights就是W），有多少个卷积核，就有多少个b（与W的个数一一对应，每个W的元素个数为c*size*size）</span></span><br><span class="line">        l.biases = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(n, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">		<span class="comment">// 训练期间，需要执行反向传播</span></span><br><span class="line">        <span class="keyword">if</span> (train) &#123;</span><br><span class="line">			<span class="comment">// 敏感图和特征图的尺寸应该是一样的</span></span><br><span class="line">            l.weight_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(l.nweights, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">			<span class="comment">// bias的敏感图，维度和bias一致</span></span><br><span class="line">            l.bias_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(n, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// float scale = 1./sqrt(size*size*c);</span></span><br><span class="line">	<span class="comment">// 初始化权重：缩放因子*标准正态分布随机数，缩放因子等于sqrt(2./(size*size*c))，随机初始化</span></span><br><span class="line">    <span class="comment">// 此处初始化权重为正态分布，而在全连接层make_connected_layer()中初始化权重是均匀分布的。</span></span><br><span class="line">    <span class="comment">// TODO：个人感觉，这里应该加一个if条件语句：if(weightfile)，因为如果导入了预训练权重文件，就没有必要这样初始化了（事实上在detector.c的train_detector()函数中，</span></span><br><span class="line">    <span class="comment">// 紧接着parse_network_cfg()函数之后，就添加了if(weightfile)语句判断是否导入权重系数文件，如果导入了权重系数文件，也许这里初始化的值也会覆盖掉，</span></span><br><span class="line">    <span class="comment">// 总之这里的权重初始化的处理方式还是值得思考的，也许更好的方式是应该设置专门的函数进行权重的初始化，同时偏置也是，不过这里似乎没有考虑偏置的初始化，在make_connected_layer()中倒是有。。。）</span></span><br><span class="line">    <span class="keyword">float</span> scale = <span class="built_in">sqrt</span>(<span class="number">2.</span>/(size*size*c/groups));</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.nweights; ++i) l.weights[i] = scale*<span class="built_in">rand_uniform</span>(<span class="number">-1</span>, <span class="number">1</span>);   <span class="comment">// rand_normal();</span></span><br><span class="line">	<span class="comment">// 根据该层输入图像的尺寸、卷积核尺寸以及跨度计算输出特征图的宽度和高度</span></span><br><span class="line">    <span class="keyword">int</span> out_h = <span class="built_in">convolutional_out_height</span>(l);</span><br><span class="line">    <span class="keyword">int</span> out_w = <span class="built_in">convolutional_out_width</span>(l);</span><br><span class="line">	<span class="comment">// 输出图像高度</span></span><br><span class="line">    l.out_h = out_h;</span><br><span class="line">	<span class="comment">// 输出图像宽度	</span></span><br><span class="line">    l.out_w = out_w;</span><br><span class="line">	<span class="comment">// 输出图像通道数(等于卷积核个数,有多少个卷积核，最终就得到多少张特征图，每张特征图是一个通道)</span></span><br><span class="line">    l.out_c = n;</span><br><span class="line">    l.outputs = l.out_h * l.out_w * l.out_c; <span class="comment">// 对应每张输入图片的所有输出特征图的总元素个数（每张输入图片会得到n也即l.out_c张特征图）</span></span><br><span class="line">    l.inputs = l.w * l.h * l.c; <span class="comment">// mini-batch中每张输入图片的像素元素个数</span></span><br><span class="line">    l.activation = activation;</span><br><span class="line"></span><br><span class="line">    l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(total_batch*l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">// l.output为该层所有的输出（包括mini-batch所有输入图片的输出）</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> GPU</span></span><br><span class="line">    <span class="keyword">if</span> (train) l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(total_batch*l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));  <span class="comment">// l.delta 该层的敏感度图，和输出的维度想同</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// not GPU</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 卷积层三种指针函数，对应三种计算：前向，反向，更新</span></span><br><span class="line">    l.forward = forward_convolutional_layer;</span><br><span class="line">    l.backward = backward_convolutional_layer;</span><br><span class="line">    l.update = update_convolutional_layer;</span><br></pre></td></tr></table></figure>
<h2 id="卷积层前向传播的代码解析"><a href="#卷积层前向传播的代码解析" class="headerlink" title="卷积层前向传播的代码解析"></a>卷积层前向传播的代码解析</h2><p>代码在<code>src/convolutional_layer.c</code>中，注释如下。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 卷积层的前向传播核心代码</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_convolutional_layer</span><span class="params">(convolutional_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> out_h = <span class="built_in">convolutional_out_height</span>(l);</span><br><span class="line">    <span class="keyword">int</span> out_w = <span class="built_in">convolutional_out_width</span>(l);</span><br><span class="line">    <span class="keyword">int</span> i, j;</span><br><span class="line">	<span class="comment">// l.outputs = l.out_h * l.out_w * l.out_c在make各网络层函数中赋值（比如make_convolutional_layer()），</span></span><br><span class="line">    <span class="comment">// 对应每张输入图片的所有输出特征图的总元素个数（每张输入图片会得到n也即l.out_c张特征图）</span></span><br><span class="line">    <span class="comment">// 初始化输出l.output全为0.0；输入l.outputs*l.batch为输出的总元素个数，其中l.outputs为batch</span></span><br><span class="line">    <span class="comment">// 中一个输入对应的输出的所有元素的个数，l.batch为一个batch输入包含的图片张数；0表示初始化所有输出为0；</span></span><br><span class="line">    <span class="built_in">fill_cpu</span>(l.outputs*l.batch, <span class="number">0</span>, l.output, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 是否进行二值化操作</span></span><br><span class="line">    <span class="keyword">if</span> (l.xnor &amp;&amp; (!l.align_bit_weights || state.train)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!l.align_bit_weights || state.train) &#123;</span><br><span class="line">            <span class="built_in">binarize_weights</span>(l.weights, l.n, l.nweights, l.binary_weights);</span><br><span class="line">            <span class="comment">//printf(&quot;\n binarize_weights l.align_bit_weights = %p \n&quot;, l.align_bit_weights);</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">swap_binary</span>(&amp;l);</span><br><span class="line">        <span class="built_in">binarize_cpu</span>(state.input, l.c*l.h*l.w*l.batch, l.binary_input);</span><br><span class="line">        state.input = l.binary_input;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> m = l.n / l.groups; <span class="comment">// 该层的卷积核个数</span></span><br><span class="line">    <span class="keyword">int</span> k = l.size*l.size*l.c / l.groups; <span class="comment">// 该层每个卷积核的参数元素个数</span></span><br><span class="line">    <span class="keyword">int</span> n = out_h*out_w; <span class="comment">// 该层每个特征图的尺寸(元素个数)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> u = <span class="number">0</span>;</span><br><span class="line">    u++;</span><br><span class="line">    <span class="comment">// 该循环即为卷积计算核心代码：所有卷积核对batch中每张图片进行卷积运算</span></span><br><span class="line">    <span class="comment">// 每次循环处理一张输入图片（所有卷积核对batch中一张图片做卷积运算）</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.batch; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">		<span class="comment">// 该循环是为了处理分组卷积</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.groups; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">			<span class="comment">// 当前组卷积核(也即权重)，元素个数为l.n*l.c/l.groups*l.size*l.size,</span></span><br><span class="line">            <span class="comment">// 共有l.n行，l.c/l.gropus,l.c*l.size*l.size列</span></span><br><span class="line">            <span class="keyword">float</span> *a = l.weights +j*l.nweights / l.groups;</span><br><span class="line">			<span class="comment">// 对输入图像进行重排之后的图像数据，所以内存空间申请为网络中最大占用内存</span></span><br><span class="line">            <span class="keyword">float</span> *b = state.workspace;</span><br><span class="line">			<span class="comment">// 存储一张输入图片（多通道）当前组的输出特征图（输入图片是多通道的，输出</span></span><br><span class="line">            <span class="comment">// 图片也是多通道的，有多少组卷积核就有多少组通道，每个分组后的卷积核得到一张特征图即为一个通道）</span></span><br><span class="line">            <span class="comment">// 这里似乎有点拗口，可以看下分组卷积原理。</span></span><br><span class="line">            <span class="keyword">float</span> *c = l.output +(i*l.groups + j)*n*m;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//gemm(0,0,m,n,k,1,a,k,b,n,1,c,n);</span></span><br><span class="line">            <span class="comment">//gemm_nn_custom(m, n, k, 1, a, k, b, n, c, n);</span></span><br><span class="line">			<span class="comment">//二值网络，特殊处理，里面还有一些优化，细节很多，这里暂时不管二值网络这部分，把注意力先放在普通卷积层的计算上</span></span><br><span class="line">            <span class="keyword">if</span> (l.xnor &amp;&amp; l.align_bit_weights &amp;&amp; !state.train &amp;&amp; l.stride_x == l.stride_y)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">memset</span>(b, <span class="number">0</span>, l.bit_align*l.size*l.size*l.c * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (l.c % <span class="number">32</span> == <span class="number">0</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">//printf(&quot; l.index = %d - new XNOR \n&quot;, l.index);</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> ldb_align = l.lda_align;</span><br><span class="line">                    <span class="keyword">size_t</span> new_ldb = k + (ldb_align - k%ldb_align); <span class="comment">// (k / 8 + 1) * 8;</span></span><br><span class="line">                    <span class="comment">//size_t t_intput_size = new_ldb * l.bit_align;// n;</span></span><br><span class="line">                    <span class="comment">//size_t t_bit_input_size = t_intput_size / 8;// +1;</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> re_packed_input_size = l.c * l.w * l.h;</span><br><span class="line">                    <span class="built_in">memset</span>(state.workspace, <span class="number">0</span>, re_packed_input_size * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">const</span> <span class="keyword">size_t</span> new_c = l.c / <span class="number">32</span>;</span><br><span class="line">                    <span class="keyword">size_t</span> in_re_packed_input_size = new_c * l.w * l.h + <span class="number">1</span>;</span><br><span class="line">                    <span class="built_in">memset</span>(l.bin_re_packed_input, <span class="number">0</span>, in_re_packed_input_size * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">uint32_t</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">//float *re_packed_input = calloc(l.c * l.w * l.h, sizeof(float));</span></span><br><span class="line">                    <span class="comment">//uint32_t *bin_re_packed_input = calloc(new_c * l.w * l.h + 1, sizeof(uint32_t));</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// float32x4 by channel (as in cuDNN)</span></span><br><span class="line">                    <span class="built_in">repack_input</span>(state.input, state.workspace, l.w, l.h, l.c);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 32 x floats -&gt; 1 x uint32_t</span></span><br><span class="line">                    <span class="built_in">float_to_bit</span>(state.workspace, (<span class="keyword">unsigned</span> <span class="keyword">char</span> *)l.bin_re_packed_input, l.c * l.w * l.h);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">//free(re_packed_input);</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// slow - convolution the packed inputs and weights: float x 32 by channel (as in cuDNN)</span></span><br><span class="line">                    <span class="comment">//convolution_repacked((uint32_t *)bin_re_packed_input, (uint32_t *)l.align_bit_weights, l.output,</span></span><br><span class="line">                    <span class="comment">//    l.w, l.h, l.c, l.n, l.size, l.pad, l.new_lda, l.mean_arr);</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// // then exit from if()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">im2col_cpu_custom</span>((<span class="keyword">float</span> *)l.bin_re_packed_input, new_c, l.h, l.w, l.size, l.stride, l.pad, state.workspace);</span><br><span class="line">                    <span class="comment">//im2col_cpu((float *)bin_re_packed_input, new_c, l.h, l.w, l.size, l.stride, l.pad, b);</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//free(bin_re_packed_input);</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> new_k = l.size*l.size*l.c / <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// good for (l.c == 64)</span></span><br><span class="line">                    <span class="comment">//gemm_nn_bin_32bit_packed(m, n, new_k, 1,</span></span><br><span class="line">                    <span class="comment">//    l.align_bit_weights, l.new_lda/32,</span></span><br><span class="line">                    <span class="comment">//    b, n,</span></span><br><span class="line">                    <span class="comment">//    c, n, l.mean_arr);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// // then exit from if()</span></span><br><span class="line"></span><br><span class="line">                    <span class="built_in">transpose_uint32</span>((<span class="keyword">uint32_t</span> *)state.workspace, (<span class="keyword">uint32_t</span>*)l.t_bit_input, new_k, n, n, new_ldb);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// the main GEMM function</span></span><br><span class="line">                    <span class="built_in">gemm_nn_custom_bin_mean_transposed</span>(m, n, k, <span class="number">1</span>, (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)l.align_bit_weights, new_ldb, (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)l.t_bit_input, new_ldb, c, n, l.mean_arr);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// // alternative GEMM</span></span><br><span class="line">                    <span class="comment">//gemm_nn_bin_transposed_32bit_packed(m, n, new_k, 1,</span></span><br><span class="line">                    <span class="comment">//    l.align_bit_weights, l.new_lda/32,</span></span><br><span class="line">                    <span class="comment">//    t_bit_input, new_ldb / 32,</span></span><br><span class="line">                    <span class="comment">//    c, n, l.mean_arr);</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//free(t_bit_input);</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                &#123; <span class="comment">// else (l.c % 32 != 0)</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//--------------------------------------------------------</span></span><br><span class="line">                    <span class="comment">//printf(&quot; l.index = %d - old XNOR \n&quot;, l.index);</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//im2col_cpu_custom_align(state.input, l.c, l.h, l.w, l.size, l.stride, l.pad, b, l.bit_align);</span></span><br><span class="line">                    <span class="built_in">im2col_cpu_custom_bin</span>(state.input, l.c, l.h, l.w, l.size, l.stride, l.pad, state.workspace, l.bit_align);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">//size_t output_size = l.outputs;</span></span><br><span class="line">                    <span class="comment">//float *count_output = calloc(output_size, sizeof(float));</span></span><br><span class="line">                    <span class="comment">//size_t bit_output_size = output_size / 8 + 1;</span></span><br><span class="line">                    <span class="comment">//char *bit_output = calloc(bit_output_size, sizeof(char));</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//size_t intput_size = n * k; // (out_h*out_w) X (l.size*l.size*l.c) : after im2col()</span></span><br><span class="line">                    <span class="comment">//size_t bit_input_size = intput_size / 8 + 1;</span></span><br><span class="line">                    <span class="comment">//char *bit_input = calloc(bit_input_size, sizeof(char));</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//size_t weights_size = k * m; //l.size*l.size*l.c*l.n; // l.nweights</span></span><br><span class="line">                    <span class="comment">//size_t bit_weights_size = weights_size / 8 + 1;</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">//char *bit_weights = calloc(bit_weights_size, sizeof(char));</span></span><br><span class="line">                    <span class="comment">//float *mean_arr = calloc(l.n, sizeof(float));</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// transpose B from NxK to KxN (x-axis (ldb = l.size*l.size*l.c) - should be multiple of 8 bits)</span></span><br><span class="line">                    &#123;</span><br><span class="line">                        <span class="comment">//size_t ldb_align = 256; // 256 bit for AVX2</span></span><br><span class="line">                        <span class="keyword">int</span> ldb_align = l.lda_align;</span><br><span class="line">                        <span class="keyword">size_t</span> new_ldb = k + (ldb_align - k%ldb_align);</span><br><span class="line">                        <span class="keyword">size_t</span> t_intput_size = <span class="built_in">binary_transpose_align_input</span>(k, n, state.workspace, &amp;l.t_bit_input, ldb_align, l.bit_align);</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// 5x times faster than gemm()-float32</span></span><br><span class="line">                        <span class="built_in">gemm_nn_custom_bin_mean_transposed</span>(m, n, k, <span class="number">1</span>, (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)l.align_bit_weights, new_ldb, (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)l.t_bit_input, new_ldb, c, n, l.mean_arr);</span><br><span class="line"></span><br><span class="line">                        <span class="comment">//gemm_nn_custom_bin_mean_transposed(m, n, k, 1, bit_weights, k, t_bit_input, new_ldb, c, n, mean_arr);</span></span><br><span class="line"></span><br><span class="line">                        <span class="comment">//free(t_input);</span></span><br><span class="line">                        <span class="comment">//free(t_bit_input);</span></span><br><span class="line">                        <span class="comment">//&#125;</span></span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="built_in">add_bias</span>(l.output, l.biases, l.batch, l.n, out_h*out_w);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//activate_array(l.output, m*n*l.batch, l.activation);</span></span><br><span class="line">                <span class="keyword">if</span> (l.activation == SWISH) <span class="built_in">activate_array_swish</span>(l.output, l.outputs*l.batch, l.activation_input, l.output);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == MISH) <span class="built_in">activate_array_mish</span>(l.output, l.outputs*l.batch, l.activation_input, l.output);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN) <span class="built_in">activate_array_normalize_channels</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN_SOFTMAX) <span class="built_in">activate_array_normalize_channels_softmax</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, <span class="number">0</span>);</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN_SOFTMAX_MAXVAL) <span class="built_in">activate_array_normalize_channels_softmax</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, <span class="number">1</span>);</span><br><span class="line">                <span class="keyword">else</span> <span class="built_in">activate_array_cpu_custom</span>(l.output, m*n*l.batch, l.activation);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//printf(&quot; l.index = %d - FP32 \n&quot;, l.index);</span></span><br><span class="line">				<span class="comment">// 由于有分组卷积，所以获取属于当前组的输入im并按一定存储规则排列的数组b，</span></span><br><span class="line">				<span class="comment">// 以方便、高效地进行矩阵（卷积）计算，详细查看该函数注释（比较复杂）</span></span><br><span class="line">				<span class="comment">// 这里的im实际上只加载了一张图片的数据</span></span><br><span class="line">				<span class="comment">// 关于im2col的原理我会讲</span></span><br><span class="line">                <span class="keyword">float</span> *im = state.input + (i*l.groups + j)*(l.c / l.groups)*l.h*l.w;</span><br><span class="line">				<span class="comment">// 如果这里卷积核尺寸为1，是不需要改变内存排布方式</span></span><br><span class="line">                <span class="keyword">if</span> (l.size == <span class="number">1</span>) &#123;</span><br><span class="line">                    b = im;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">//im2col_cpu(im, l.c / l.groups, l.h, l.w, l.size, l.stride, l.pad, b);</span></span><br><span class="line">					<span class="comment">// 将多通道二维图像im变成按一定存储规则排列的数组b，</span></span><br><span class="line">					<span class="comment">// 以方便、高效地进行矩阵（卷积）计算，详细查看该函数注释（比较复杂）</span></span><br><span class="line">					<span class="comment">// 进行重排，l.c/groups为每张图片的通道数分组，l.h为每张图片的高度，l.w为每张图片的宽度，l.size为卷积核尺寸，l.stride为步长</span></span><br><span class="line">					<span class="comment">// 得到的b为一张图片重排后的结果，也是按行存储的一维数组（共有l.c/l.groups*l.size*l.size行，l.out_w*l.out_h列）</span></span><br><span class="line">                    <span class="built_in">im2col_cpu_ext</span>(im,   <span class="comment">// input</span></span><br><span class="line">                        l.c / l.groups,     <span class="comment">// input channels</span></span><br><span class="line">                        l.h, l.w,           <span class="comment">// input size (h, w)</span></span><br><span class="line">                        l.size, l.size,     <span class="comment">// kernel size (h, w)</span></span><br><span class="line">                        l.pad, l.pad,       <span class="comment">// padding (h, w)</span></span><br><span class="line">                        l.stride_y, l.stride_x, <span class="comment">// stride (h, w)</span></span><br><span class="line">                        l.dilation, l.dilation, <span class="comment">// dilation (h, w)</span></span><br><span class="line">                        b);                 <span class="comment">// output</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line">				<span class="comment">// 此处在im2col_cpu操作基础上，利用矩阵乘法c=alpha*a*b+beta*c完成对图像卷积的操作</span></span><br><span class="line">				<span class="comment">// 0,0表示不对输入a,b进行转置，</span></span><br><span class="line">				<span class="comment">// m是输入a,c的行数，具体含义为每个卷积核的个数，</span></span><br><span class="line">				<span class="comment">// n是输入b,c的列数，具体含义为每个输出特征图的元素个数(out_h*out_w)，</span></span><br><span class="line">				<span class="comment">// k是输入a的列数也是b的行数，具体含义为卷积核元素个数乘以输入图像的通道数除以分组数（l.size*l.size*l.c/l.groups），</span></span><br><span class="line">				<span class="comment">// a,b,c即为三个参与运算的矩阵（用一维数组存储）,alpha=beta=1为常系数，</span></span><br><span class="line">				<span class="comment">// a为所有卷积核集合,元素个数为l.n*l.c/l.groups*l.size*l.size，按行存储，共有l*n行，l.c/l.groups*l.size*l.size列，</span></span><br><span class="line">				<span class="comment">// 即a中每行代表一个可以作用在3通道上的卷积核，</span></span><br><span class="line">				<span class="comment">// b为一张输入图像经过im2col_cpu重排后的图像数据（共有l.c/l.group*l.size*l.size行，l.out_w*l.out_h列），</span></span><br><span class="line">				<span class="comment">// c为gemm()计算得到的值，包含一张输入图片得到的所有输出特征图（每个卷积核得到一张特征图），c中一行代表一张特征图，</span></span><br><span class="line">				<span class="comment">// 各特征图铺排开成一行后，再将所有特征图并成一大行，存储在c中，因此c可视作有l.n行，l.out_h*l.out_w列。</span></span><br><span class="line">				<span class="comment">// 详细查看该函数注释（比较复杂）</span></span><br><span class="line">                <span class="built_in">gemm</span>(<span class="number">0</span>, <span class="number">0</span>, m, n, k, <span class="number">1</span>, a, k, b, n, <span class="number">1</span>, c, n);</span><br><span class="line">                <span class="comment">// bit-count to float</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//c += n*m;</span></span><br><span class="line">            <span class="comment">//state.input += l.c*l.h*l.w;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 如果卷积层使用了BatchNorm，那么执行forward_batchnorm，如果没有，则添加偏置</span></span><br><span class="line">    <span class="keyword">if</span>(l.batch_normalize)&#123;</span><br><span class="line">        forward_batchnorm_layer(l, state);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">add_bias</span>(l.output, l.biases, l.batch, l.n, out_h*out_w);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//activate_array(l.output, m*n*l.batch, l.activation);</span></span><br><span class="line">	<span class="comment">// 使用不同的激活函数</span></span><br><span class="line">    <span class="keyword">if</span> (l.activation == SWISH) <span class="built_in">activate_array_swish</span>(l.output, l.outputs*l.batch, l.activation_input, l.output);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == MISH) <span class="built_in">activate_array_mish</span>(l.output, l.outputs*l.batch, l.activation_input, l.output);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN) <span class="built_in">activate_array_normalize_channels</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN_SOFTMAX) <span class="built_in">activate_array_normalize_channels_softmax</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN_SOFTMAX_MAXVAL) <span class="built_in">activate_array_normalize_channels_softmax</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.output, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">activate_array_cpu_custom</span>(l.output, l.outputs*l.batch, l.activation);</span><br><span class="line">	<span class="comment">// 二值网络，前向传播结束之后转回float</span></span><br><span class="line">    <span class="keyword">if</span>(l.binary || l.xnor) <span class="built_in">swap_binary</span>(&amp;l);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//visualize_convolutional_layer(l, &quot;conv_visual&quot;, NULL);</span></span><br><span class="line">    <span class="comment">//wait_until_press_key_cv();</span></span><br><span class="line">	<span class="comment">// 暂时不懂</span></span><br><span class="line">    <span class="keyword">if</span>(l.assisted_excitation &amp;&amp; state.train) <span class="built_in">assisted_excitation_forward</span>(l, state);</span><br><span class="line">	<span class="comment">// 暂时不懂</span></span><br><span class="line">    <span class="keyword">if</span> (l.antialiasing) &#123;</span><br><span class="line">        network_state s = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">        s.train = state.train;</span><br><span class="line">        s.workspace = state.workspace;</span><br><span class="line">        s.net = state.net;</span><br><span class="line">        s.input = l.output;</span><br><span class="line">        forward_convolutional_layer(*(l.input_layer), s);</span><br><span class="line">        <span class="comment">//simple_copy_ongpu(l.outputs*l.batch, l.output, l.input_antialiasing);</span></span><br><span class="line">        <span class="built_in">memcpy</span>(l.output, l.input_layer-&gt;output, l.input_layer-&gt;outputs * l.input_layer-&gt;batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="im2col解析"><a href="#im2col解析" class="headerlink" title="im2col解析"></a>im2col解析</h2><p>从上面的代码可以知道，卷积层的前向传播核心点是im2col操作还有sgemm矩阵计算方法对使用im2col进行重排后的数据进行计算。现在来解析一下im2col算法，sgemm算法就是im2col运行后直接调用即可，就不细讲了。</p>
<p>这里考虑到结合图片更容易理解im2col的思想，我利用CSDN Tiger-Gao博主的图描述一下。首先，我们把一个单通道的长宽均为4的图片通过im2col重新排布后会变成什么样呢？看下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/649.webp" alt></p>
<p>来具体看一下变化过程：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/650.webp" alt></p>
<p>这是单通道的变化过程，那么多通道的呢？首先来看原图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/651.png" alt></p>
<p>多通道的im2col的过程，是首先im2col第一通道，然后再im2col第二通道，最后im2col第三通道。各通道im2col的数据在内存中也是连续存储的。看下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/652.webp" alt></p>
<p>这是原图经过im2col的变化，那么kernel呢？看原图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/653.webp" alt></p>
<p>kernel的通道数据在内存中也是连续存储的。所以上面的kernel图像经过im2col算法后可以表示为下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/654.webp" alt></p>
<p>那么我们是如何得到前向传播的结果呢？在DarkNet中和Caffe的实现方式一样，都是Kernel*Img，即是在矩阵乘法中：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">M=<span class="number">1</span> </span><br><span class="line">N=output_h * output_w</span><br><span class="line">K=input_channels * kernel_h * kernel_w</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/655.webp" alt></p>
<p>图像数据是连续存储，因此输出图像也可以如下图所示【output_h x output_w】=【2 x 2】：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/656.png" alt></p>
<p>对于多通道图像过程类似：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/657.webp" alt></p>
<p>同样，多个输出通道图像的数据是连续存储，因此输出图像也可以如下图所示【output_channels x output_h x output_w】=【3 x 2 x 2】</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/658.webp" alt></p>
<p>im2col算法的实现在<code>src/im2col.c</code>中，即<code>im2col_cpu</code>函数。代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 从输入的多通道数组im（存储图像数据）中获取指定行，列，通道数处的元素值</span></span><br><span class="line"><span class="comment">** im:  函数的输入，所有的数据存成一个一维数组</span></span><br><span class="line"><span class="comment">** height: 每一个通道的高度(即是输入图像的真正高度，补0之前)</span></span><br><span class="line"><span class="comment">** width: 每一个通道的宽度(即是输入图像的真正宽度，补0之前)</span></span><br><span class="line"><span class="comment">** channles：输入通道数</span></span><br><span class="line"><span class="comment">** row: 要提取的元素所在的行(padding之后的行数)</span></span><br><span class="line"><span class="comment">** col: 要提取的元素所在的列(padding之后的列数)</span></span><br><span class="line"><span class="comment">** channel: 要提取的元素所在的通道</span></span><br><span class="line"><span class="comment">** pad: 图像上下左右补0的个数，四周是一样的</span></span><br><span class="line"><span class="comment">** 返回im中channel通道，row-pad行,col-pad列处的元素值</span></span><br><span class="line"><span class="comment">** 在im中并没有存储补0的元素值，因此height，width都是没有补0时输入图像真正的高、宽；</span></span><br><span class="line"><span class="comment">** 而row与col则是补0之后，元素所在的行列，因此，要准确获取在im中的元素值，首先需要</span></span><br><span class="line"><span class="comment">** 减去pad以获取在im中真实的行列数</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">im2col_get_pixel</span><span class="params">(<span class="keyword">float</span> *im, <span class="keyword">int</span> height, <span class="keyword">int</span> width, <span class="keyword">int</span> channels,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">int</span> channel, <span class="keyword">int</span> pad)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//减去补0长度，获取像素真实的行列数</span></span><br><span class="line">    row -= pad;</span><br><span class="line">    col -= pad;</span><br><span class="line">	<span class="comment">// 如果行列数&lt;0，或者超过height/width，则返回0(刚好是补0的效果)</span></span><br><span class="line">    <span class="keyword">if</span> (row &lt; <span class="number">0</span> || col &lt; <span class="number">0</span> ||</span><br><span class="line">        row &gt;= height || col &gt;= width) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// im存储多通道二维图像的数据格式为: 各个通道所有的所有行并成1行，再多通道依次并成一行</span></span><br><span class="line">    <span class="comment">// 因此width*height*channel首先移位到所在通道的起点位置，再加上width*row移位到所在指定</span></span><br><span class="line">    <span class="comment">// 通道行，再加上col移位到所在列</span></span><br><span class="line">    <span class="keyword">return</span> im[col + width*(row + height*channel)];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//From Berkeley Vision&#x27;s Caffe!</span></span><br><span class="line"><span class="comment">//https://github.com/BVLC/caffe/blob/master/LICENSE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 将输入图片转为便于计算的数组格式</span></span><br><span class="line"><span class="comment">** data_im: 输入图像</span></span><br><span class="line"><span class="comment">** height: 输入图像的高度(行)</span></span><br><span class="line"><span class="comment">** width: 输入图像的宽度(列)</span></span><br><span class="line"><span class="comment">** ksize: 卷积核尺寸</span></span><br><span class="line"><span class="comment">** stride: 卷积核跨度</span></span><br><span class="line"><span class="comment">** pad: 四周补0的长度</span></span><br><span class="line"><span class="comment">** data_col: 相当于输出，为进行格式重排后的输入图像数据</span></span><br><span class="line"><span class="comment">** 输出data_col的元素个数与data_im个数不相等，一般比data_im个数多，因为stride较小，各个卷积核之间有很多重叠，</span></span><br><span class="line"><span class="comment">** 实际data_col中的元素个数为channels*ksize*ksize*height_col*width_col，其中channels为data_im的通道数，</span></span><br><span class="line"><span class="comment">** ksize为卷积核大小，height_col和width_col如下所注。data_col的还是按行排列，只是行数为channels*ksize*ksize,</span></span><br><span class="line"><span class="comment">** 列数为height_col*width_col，即一张特征图总的元素个数，每整列包含与某个位置处的卷积核计算的所有通道上的像素，</span></span><br><span class="line"><span class="comment">** （比如输入图像通道数为3,卷积核尺寸为3*3，则共有27行，每列有27个元素），不同列对应卷积核在图像上的不同位置做卷积</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">im2col_cpu</span><span class="params">(<span class="keyword">float</span>* data_im,</span></span></span><br><span class="line"><span class="params"><span class="function">     <span class="keyword">int</span> channels,  <span class="keyword">int</span> height,  <span class="keyword">int</span> width,</span></span></span><br><span class="line"><span class="params"><span class="function">     <span class="keyword">int</span> ksize,  <span class="keyword">int</span> stride, <span class="keyword">int</span> pad, <span class="keyword">float</span>* data_col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> c,h,w;</span><br><span class="line">	<span class="comment">// 计算该层神经网络的输出图像尺寸（其实没有必要再次计算的，因为在构建卷积层时，make_convolutional_layer()函数</span></span><br><span class="line">    <span class="comment">// 已经调用convolutional_out_width()，convolutional_out_height()函数求取了这两个参数，</span></span><br><span class="line">    <span class="comment">// 此处直接使用l.out_h,l.out_w即可，函数参数只要传入该层网络指针就可了，没必要弄这么多参数）</span></span><br><span class="line">    <span class="keyword">int</span> height_col = (height + <span class="number">2</span>*pad - ksize) / stride + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> width_col = (width + <span class="number">2</span>*pad - ksize) / stride + <span class="number">1</span>;</span><br><span class="line">	<span class="comment">// 卷积核大小：ksize*ksize是一个卷积核的大小，之所以乘以通道数channels，是因为输入图像有多通道，每个卷积核在做卷积时，</span></span><br><span class="line">    <span class="comment">// 是同时对同一位置多通道的图像进行卷积运算，这里为了实现这一目的，将三个通道将三通道上的卷积核并在一起以便进行计算，因此卷积核</span></span><br><span class="line">    <span class="comment">// 实际上并不是二维的，而是三维的，比如对于3通道图像，卷积核尺寸为3*3，该卷积核将同时作用于三通道图像上，这样并起来就得</span></span><br><span class="line">    <span class="comment">// 到含有27个元素的卷积核，且这27个元素都是独立的需要训练的参数。所以在计算训练参数个数时，一定要注意每一个卷积核的实际</span></span><br><span class="line">    <span class="comment">// 训练参数需要乘以输入通道数。</span></span><br><span class="line">    <span class="keyword">int</span> channels_col = channels * ksize * ksize;</span><br><span class="line">	<span class="comment">// 外循环次数为一个卷积核的尺寸数，循环次数即为最终得到的data_col的总行数</span></span><br><span class="line">    <span class="keyword">for</span> (c = <span class="number">0</span>; c &lt; channels_col; ++c) &#123;</span><br><span class="line">		<span class="comment">// 列偏移，卷积核是一个二维矩阵，并按行存储在一维数组中，利用求余运算获取对应在卷积核中的列数，比如对于</span></span><br><span class="line">        <span class="comment">// 3*3的卷积核（3通道），当c=0时，显然在第一列，当c=5时，显然在第2列，当c=9时，在第二通道上的卷积核的第一列，</span></span><br><span class="line">        <span class="comment">// 当c=26时，在第三列（第三通道上）</span></span><br><span class="line">        <span class="keyword">int</span> w_offset = c % ksize;</span><br><span class="line">		<span class="comment">// 行偏移，卷积核是一个二维的矩阵，且是按行（卷积核所有行并成一行）存储在一维数组中的，</span></span><br><span class="line">        <span class="comment">// 比如对于3*3的卷积核，处理3通道的图像，那么一个卷积核具有27个元素，每9个元素对应一个通道上的卷积核（互为一样），</span></span><br><span class="line">        <span class="comment">// 每当c为3的倍数，就意味着卷积核换了一行，h_offset取值为0,1,2，对应3*3卷积核中的第1, 2, 3行</span></span><br><span class="line">        <span class="keyword">int</span> h_offset = (c / ksize) % ksize;</span><br><span class="line">		<span class="comment">// 通道偏移，channels_col是多通道的卷积核并在一起的，比如对于3通道，3*3卷积核，每过9个元素就要换一通道数，</span></span><br><span class="line">        <span class="comment">// 当c=0~8时，c_im=0;c=9~17时，c_im=1;c=18~26时，c_im=2</span></span><br><span class="line">        <span class="keyword">int</span> c_im = c / ksize / ksize;</span><br><span class="line">		<span class="comment">// 中循环次数等于该层输出图像行数height_col，说明data_col中的每一行存储了一张特征图，这张特征图又是按行存储在data_col中的某行中</span></span><br><span class="line">        <span class="keyword">for</span> (h = <span class="number">0</span>; h &lt; height_col; ++h) &#123;</span><br><span class="line">			<span class="comment">// 内循环等于该层输出图像列数width_col，说明最终得到的data_col总有channels_col行，height_col*width_col列</span></span><br><span class="line">            <span class="keyword">for</span> (w = <span class="number">0</span>; w &lt; width_col; ++w) &#123;</span><br><span class="line">				<span class="comment">// 由上面可知，对于3*3的卷积核，h_offset取值为0,1,2,当h_offset=0时，会提取出所有与卷积核第一行元素进行运算的像素，</span></span><br><span class="line">                <span class="comment">// 依次类推；加上h*stride是对卷积核进行行移位操作，比如卷积核从图像(0,0)位置开始做卷积，那么最先开始涉及(0,0)~(3,3)</span></span><br><span class="line">                <span class="comment">// 之间的像素值，若stride=2，那么卷积核进行一次行移位时，下一行的卷积操作是从元素(2,0)（2为图像行号，0为列号）开始</span></span><br><span class="line">                <span class="keyword">int</span> im_row = h_offset + h * stride;</span><br><span class="line">				<span class="comment">// 对于3*3的卷积核，w_offset取值也为0,1,2，当w_offset取1时，会提取出所有与卷积核中第2列元素进行运算的像素，</span></span><br><span class="line">                <span class="comment">// 实际在做卷积操作时，卷积核对图像逐行扫描做卷积，加上w*stride就是为了做列移位，</span></span><br><span class="line">                <span class="comment">// 比如前一次卷积其实像素元素为(0,0)，若stride=2,那么下次卷积元素起始像素位置为(0,2)（0为行号，2为列号）</span></span><br><span class="line">                <span class="keyword">int</span> im_col = w_offset + w * stride;</span><br><span class="line">				<span class="comment">// col_index为重排后图像中的像素索引，等于c * height_col * width_col + h * width_col +w（还是按行存储，所有通道再并成一行），</span></span><br><span class="line">                <span class="comment">// 对应第c通道，h行，w列的元素</span></span><br><span class="line">                <span class="keyword">int</span> col_index = (c * height_col + h) * width_col + w;</span><br><span class="line">				<span class="comment">// im2col_get_pixel函数获取输入图像data_im中第c_im通道，im_row,im_col的像素值并赋值给重排后的图像，</span></span><br><span class="line">                <span class="comment">// height和width为输入图像data_im的真实高、宽，pad为四周补0的长度（注意im_row,im_col是补0之后的行列号，</span></span><br><span class="line">                <span class="comment">// 不是真实输入图像中的行列号，因此需要减去pad获取真实的行列号）</span></span><br><span class="line">                data_col[col_index] = <span class="built_in">im2col_get_pixel</span>(data_im, height, width, channels,</span><br><span class="line">                        im_row, im_col, c_im, pad);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB DarkNet卷积层的反向传播解析</title>
    <url>/2020/02/24/AlexeyAB-DarkNet%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面已经详细讲解了卷积层的前向传播过程，大致思路就是使用im2col方法对数据进行重排，然后利用sgemm算法计算出结果，反向传播实际上就是前向传播的逆过程，我们一起来分析一下源码吧。</p>
<h2 id="反向传播解析"><a href="#反向传播解析" class="headerlink" title="反向传播解析"></a>反向传播解析</h2><ul>
<li>首先调用<code>gradient_array()</code>计算当前层<code>l</code>所有输出元素关于加权输入的导数值（也即激活函数关于输入的导数值），并乘上上一次调用<code>backward_convolutional_layer()</code>还没计算完的<code>l.delta</code>，得到当前层最终的敏感度图。这部分的代码如下：<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 计算激活函数对加权输入的导数，并乘以delta，得到当前层最终的delta（敏感度图）</span></span><br><span class="line"><span class="comment">** 输入：x    当前层的所有输出（维度为l.batch * l.out_c * l.out_w * l.out_h）</span></span><br><span class="line"><span class="comment">**      n    l.output的维度，即为l.batch * l.out_c * l.out_w * l.out_h（包含整个batch的）</span></span><br><span class="line"><span class="comment">**      ACTIVATION    激活函数类型</span></span><br><span class="line"><span class="comment">**      delta     当前层敏感度图（与当前成输出x维度一样）</span></span><br><span class="line"><span class="comment">** 说明1：该函数不但计算了激活函数对于加权输入的导数，还将该导数乘以了之前完成大部分计算的敏感度图delta（对应元素相乘），因此调用改函数之后，将得到该层最终的敏感度图</span></span><br><span class="line"><span class="comment">** 说明2：这里直接利用输出值求激活函数关于输入的导数值是因为神经网络中所使用的绝大部分激活函数，其关于输入的导数值都可以描述为输出值的函数表达式，</span></span><br><span class="line"><span class="comment">          比如对于Sigmoid激活函数（记作f(x)），其导数值为f(x)&#x27;=f(x)*(1-f(x)),因此如果给出y=f(x)，那么f(x)&#x27;=y*(1-y)，只需要输出值y就可以了，不需要输入x的值，</span></span><br><span class="line"><span class="comment">          （暂时不确定darknet中有没有使用特殊的激活函数，以致于必须要输入值才能够求出导数值，在activiation.c文件中，有几个激活函数暂时没看懂，也没在网上查到）。</span></span><br><span class="line"><span class="comment">** 说明3：关于l.delta的初值，可能你有注意到在看某一类型网络层的时候，比如卷积层中的backward_convolutional_layer()函数，没有发现在此之前对l.delta赋初值的语句，</span></span><br><span class="line"><span class="comment">**        只是用calloc为其动态分配了内存，这样的l.delta其所有元素的值都为0,那么这里使用*=运算符得到的值将恒为0。是的，如果只看某一层，或者说某一类型的层，的确有这个疑惑，</span></span><br><span class="line"><span class="comment">**        但是整个网络是有很多层的，且有多种类型，一般来说，不会以卷积层为最后一层，而回以COST或者REGION为最后一层，这些层中，会对l.delta赋初值，又由于l.delta是由后</span></span><br><span class="line"><span class="comment">**        网前逐层传播的，因此，当反向运行到某一层时，l.delta的值将都不会为0.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">gradient_array</span><span class="params">(<span class="keyword">const</span> <span class="keyword">float</span> *x, <span class="keyword">const</span> <span class="keyword">int</span> n, <span class="keyword">const</span> ACTIVATION a, <span class="keyword">float</span> *delta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n; ++i)&#123;</span><br><span class="line">        delta[i] *= <span class="built_in">gradient</span>(x[i], a);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><code>gradient</code>函数的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 根据不同的激活函数求取对输入的梯度（导数）</span></span><br><span class="line"><span class="comment">** 输入：x    激活函数接收的输入值</span></span><br><span class="line"><span class="comment">**      a    激活函数类型，包括的激活函数类型见activations.h中枚举类型ACTIVATION的定义</span></span><br><span class="line"><span class="comment">** 输出：激活函数关于输入x的导数值</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">gradient</span><span class="params">(<span class="keyword">float</span> x, ACTIVATION a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 以下分别求取各种激活函数对输入的导数值，详见各个导数求取函数的内部注释</span></span><br><span class="line">    <span class="built_in"><span class="keyword">switch</span></span>(a)&#123;</span><br><span class="line">        <span class="keyword">case</span> LINEAR:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">linear_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> LOGISTIC:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">logistic_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> LOGGY:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">loggy_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> RELU:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">relu_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> NORM_CHAN:</span><br><span class="line">            <span class="comment">//return relu_gradient(x);</span></span><br><span class="line">        <span class="keyword">case</span> NORM_CHAN_SOFTMAX_MAXVAL:</span><br><span class="line">            <span class="comment">//...</span></span><br><span class="line">        <span class="keyword">case</span> NORM_CHAN_SOFTMAX:</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot; Error: should be used custom NORM_CHAN or NORM_CHAN_SOFTMAX-function for gradient \n&quot;</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">case</span> ELU:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">elu_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> SELU:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">selu_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> RELIE:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">relie_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> RAMP:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">ramp_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> LEAKY:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">leaky_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> TANH:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">tanh_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> PLSE:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">plse_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> STAIR:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">stair_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> HARDTAN:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">hardtan_gradient</span>(x);</span><br><span class="line">        <span class="keyword">case</span> LHTAN:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">lhtan_gradient</span>(x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>然后，如果网络进行了BN，则调用backward_batchnorm_layer，否则直接调用  backward_bias()计算当前层所有卷积核的偏置更新值。backward_batchnorm_layer之后会单独讲，这里来看看backward_bias()的实现。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 计算每个卷积核的偏置更新值，所谓偏置更新值，就是bias = bias - alpha * bias_update中的bias_update</span></span><br><span class="line"><span class="comment">** 输入：bias_updates     当前层所有偏置的更新值，维度为l.n（即当前层卷积核的个数）</span></span><br><span class="line"><span class="comment">**      delta            当前层的敏感度图（即l.delta）</span></span><br><span class="line"><span class="comment">**      batch            一个batch含有的图片张数（即l.batch）</span></span><br><span class="line"><span class="comment">**      n                当前层卷积核个数（即l.n）</span></span><br><span class="line"><span class="comment">**      k                当前层输入特征图尺寸（即l.out_w*l.out_h）</span></span><br><span class="line"><span class="comment">** 原理：当前层的敏感度图l.delta是误差函数对加权输入的导数，也就是偏置更新值，只是其中每l.out_w*l.out_h个元素都对应同一个</span></span><br><span class="line"><span class="comment">**      偏置，因此需要将其加起来，得到的和就是误差函数对当前层各偏置的导数（l.delta的维度为l.batch*l.n*l.out_h*l.out_w,</span></span><br><span class="line"><span class="comment">**      可理解成共有l.batch行，每行有l.n*l.out_h*l.out_w列，而这一大行又可以理解成有l.n，l.out_h*l.out_w列，这每一小行就</span></span><br><span class="line"><span class="comment">**      对应同一个卷积核也即同一个偏置）</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_bias</span><span class="params">(<span class="keyword">float</span> *bias_updates, <span class="keyword">float</span> *delta, <span class="keyword">int</span> batch, <span class="keyword">int</span> n, <span class="keyword">int</span> size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,b;</span><br><span class="line">	<span class="comment">// 遍历batch中每张输入图片</span></span><br><span class="line">    <span class="comment">// 注意，最后的偏置更新值是所有输入图片的总和（多张图片无非就是重复一张图片的操作，求和即可）。</span></span><br><span class="line">    <span class="comment">// 总之：一个卷积核对应一个偏置更新值，该偏置更新值等于batch中所有输入图片累积的偏置更新值，</span></span><br><span class="line">    <span class="comment">// 而每张图片也需要进行偏置更新值求和（因为每个卷积核在每张图片多个位置做了卷积运算，这都对偏置更新值有贡献）以得到每张图片的总偏置更新值。</span></span><br><span class="line">    <span class="keyword">for</span>(b = <span class="number">0</span>; b &lt; batch; ++b)&#123;</span><br><span class="line">        <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n; ++i)&#123;</span><br><span class="line">            bias_updates[i] += <span class="built_in">sum_array</span>(delta+size*(i+b*n), size);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>接下来依次调用im2col_cpu()，gemm_nt()函数计算当前层权重系数更新值；如果上一层的delta已经动态分配了内存，则依次调用gemm_tn(), col2im_cpu()计算上一层的敏感度图（并未完成所有计算，还差一个步骤）。整个反向传播的核心函数解释如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 卷积神经网络反向传播核心函数</span></span><br><span class="line"><span class="comment">** 主要流程：1） 调用gradient_array()计算当前层l所有输出元素关于加权输入的导数值（也即激活函数关于输入的导数值），</span></span><br><span class="line"><span class="comment">**             并乘上上一次调用backward_convolutional_layer()还没计算完的l.delta，得到当前层最终的敏感度图；</span></span><br><span class="line"><span class="comment">**          2） 如果网络进行了BN，则backward_batchnorm_layer。</span></span><br><span class="line"><span class="comment">**          3） 如果网络没有进行BN，则直接调用 backward_bias()计算当前层所有卷积核的偏置更新值；</span></span><br><span class="line"><span class="comment">**          4） 依次调用im2col_cpu()，gemm_nt()函数计算当前层权重系数更新值；</span></span><br><span class="line"><span class="comment">**          5） 如果上一层的delta已经动态分配了内存，则依次调用gemm_tn(), col2im_cpu()计算上一层的敏感度图（并未完成所有计算，还差一个步骤）；</span></span><br><span class="line"><span class="comment">** 强调：每次调用本函数会计算完成当前层的敏感度计算，同时计算当前层的偏置、权重更新值，除此之外，还会计算上一层的敏感度图，但是要注意的是，</span></span><br><span class="line"><span class="comment">**      并没有完全计算完，还差一步：乘上激活函数对加权输入的导数值。这一步在下一次调用本函数时完成。</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_convolutional_layer</span><span class="params">(convolutional_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j;</span><br><span class="line">	<span class="comment">// 卷积核个数，考虑到分组卷积</span></span><br><span class="line">    <span class="keyword">int</span> m = l.n / l.groups;</span><br><span class="line">	<span class="comment">// 每一个卷积核元素个数（包括l.c（l.c为该层网络接受的输入图片的通道数）个通道上的卷积核元素个数总数，比如卷积核尺寸为3*3,</span></span><br><span class="line">    <span class="comment">// 输入图片有3个通道，因为要同时作用于输入的3个通道上，所以实际上这个卷积核是一个立体的，共有3*3*3=27个元素，这些元素都是要训练的参数），同样需要考虑分组数</span></span><br><span class="line">    <span class="keyword">int</span> n = l.size*l.size*l.c / l.groups;</span><br><span class="line">	<span class="comment">// 每张输出特征图的元素个数：out_w，out_h是输出特征图的宽高</span></span><br><span class="line">    <span class="keyword">int</span> k = l.out_w*l.out_h;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算当前层激活函数对加权输入的导数值并乘以l.delta相应元素，从而彻底完成当前层敏感度图的计算，得到当前层的敏感度图l.delta。</span></span><br><span class="line">    <span class="comment">// l.output存储了该层网络的所有输出：该层网络接受一个batch的输入图片，其中每张图片经卷积处理后得到的特征图尺寸为：l.out_w,l.out_h，</span></span><br><span class="line">    <span class="comment">// 该层卷积网络共有l.n个卷积核，因此一张输入图片共输出l.n张宽高为l.out_w,l.out_h的特征图（l.output为一张图所有输出特征图的总元素个数），</span></span><br><span class="line">    <span class="comment">// 所以所有输入图片也即l.output中的总元素个数为：l.n*l.out_w*l.out_h*l.batch；</span></span><br><span class="line">    <span class="comment">// l.activation为该卷积层的激活函数类型，l.delta就是gradient_array()函数计算得到的l.output中每一个元素关于激活函数函数输入的导数值，</span></span><br><span class="line">    <span class="comment">// 注意，这里直接利用输出值求得激活函数关于输入的导数值是因为神经网络中所使用的绝大部分激活函数关于输入的导数值都可以描述为输出值的函数表达式，</span></span><br><span class="line">    <span class="comment">// 比如对于Sigmoid激活函数（记作f(x)），其导数值为f(x)&#x27;=f(x)*(1-f(x)),因此如果给出y=f(x)，那么f(x)&#x27;=y*(1-y)，只需要输出值y就可以了，不需要输入x的值，</span></span><br><span class="line">    <span class="comment">// （暂时不确定darknet中有没有使用特殊的激活函数，以致于必须要输入值才能够求出导数值，在activiation.c文件中，有几个激活函数暂时没看懂，也没在网上查到）。</span></span><br><span class="line">    <span class="comment">// l.delta是一个一维数组，长度为l.batch * l.outputs（其中l.outputs = l.out_h * l.out_w * l.out_c），在make_convolutional_layer()动态分配内存；</span></span><br><span class="line">    <span class="comment">// 再强调一次：gradient_array()不单单是完成激活函数对输入的求导运算，还完成计算当前层敏感度图的最后一步：l.delta中每个元素乘以激活函数对输入的导数（注意gradient_arry中使用的是*=运算符）。</span></span><br><span class="line">    <span class="comment">// 每次调用backward_convolutional_laye时，都会完成当前层敏感度图的计算，同时会计算上一层的敏感度图，但对于上一层，其敏感度图并没有完全计算完成，还差一步，</span></span><br><span class="line">    <span class="comment">// 需要等到下一次调用backward_convolutional_layer()时来完成，诚如col2im_cpu()中注释一样。</span></span><br><span class="line">    <span class="keyword">if</span> (l.activation == SWISH) <span class="built_in">gradient_array_swish</span>(l.output, l.outputs*l.batch, l.activation_input, l.delta);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == MISH) <span class="built_in">gradient_array_mish</span>(l.outputs*l.batch, l.activation_input, l.delta);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN_SOFTMAX || l.activation == NORM_CHAN_SOFTMAX_MAXVAL) <span class="built_in">gradient_array_normalize_channels_softmax</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.delta);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (l.activation == NORM_CHAN) <span class="built_in">gradient_array_normalize_channels</span>(l.output, l.outputs*l.batch, l.batch, l.out_c, l.out_w*l.out_h, l.delta);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">gradient_array</span>(l.output, l.outputs*l.batch, l.activation, l.delta);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (l.batch_normalize) &#123;</span><br><span class="line">		<span class="comment">// 之后单独讲BN层的前向和反向传播</span></span><br><span class="line">        <span class="built_in">backward_batchnorm_layer</span>(l, state);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="comment">// 计算偏置的更新值：每个卷积核都有一个偏置，偏置的更新值也即误差函数对偏置的导数，这个导数的计算很简单，实际所有的导数已经求完了，都存储在l.delta中，</span></span><br><span class="line">        <span class="comment">// 接下来只需把l.delta中对应同一个卷积核的项加起来就可以（卷积核在图像上逐行逐列跨步移动做卷积，每个位置处都有一个输出，共有l.out_w*l.out_h个，</span></span><br><span class="line">        <span class="comment">// 这些输出都与同一个偏置关联，因此将l.delta中对应同一个卷积核的项加起来即得误差函数对这个偏置的导数）</span></span><br><span class="line">        <span class="built_in">backward_bias</span>(l.bias_updates, l.delta, l.batch, l.n, k);</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 遍历batch中的每张照片，对于l.delta来说，每张照片是分开存的，因此其维度会达到：l.batch*l.n*l.out_w*l.out_h，</span></span><br><span class="line">    <span class="comment">// 对于l.weights,l.weight_updates以及上面提到的l.bias,l.bias_updates，是将所有照片对应元素叠加起来</span></span><br><span class="line">    <span class="comment">// （循环的过程就是叠加的过程，注意gemm()这系列函数含有叠加效果，不是覆盖输入C的值，而是叠加到之前的C上），</span></span><br><span class="line">    <span class="comment">// 因此l.weights与l.weight_updates维度为l.n*l.size*l.size，l.bias与l.bias_updates的维度为l.h，都与l.batch无关</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.batch; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.groups; ++j) &#123;</span><br><span class="line">			<span class="keyword">float</span> *a = l.delta + (i*l.groups + j)*m*k;</span><br><span class="line">			<span class="comment">// net.workspace的元素个数为所有层中最大的l.workspace_size（在make_convolutional_layer()计算得到workspace_size的大小，在parse_network_cfg()中动态分配内存，此值对应未使用gpu时的情况）,</span></span><br><span class="line">			<span class="comment">// net.workspace充当一个临时工作空间的作用，存储临时所需要的计算参数，比如每层单张图片重排后的结果（这些参数马上就会参与卷积运算），一旦用完，就会被马上更新（因此该变量的值的更新频率比较大）</span></span><br><span class="line">            <span class="keyword">float</span> *b = state.workspace;</span><br><span class="line">			</span><br><span class="line">            <span class="keyword">float</span> *c = l.weight_updates + j*l.nweights / l.groups;</span><br><span class="line">			<span class="comment">// 进入本函数之前，在backward_network()函数中，已经将net.input赋值为prev.output，也即若当前层为第l层，net.input此时已经是第l-1层的输出</span></span><br><span class="line">			<span class="comment">// 注意反向传播从后往前来看</span></span><br><span class="line">            <span class="keyword">float</span> *im = state.input + (i*l.groups + j)* (l.c / l.groups)*l.h*l.w;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//im2col_cpu(im, l.c / l.groups, l.h, l.w, l.size, l.stride, l.pad, b);</span></span><br><span class="line">			<span class="comment">// 下面两步：im2col_cpu()与gemm()是为了计算当前层的权重更新值（其实也就是误差函数对当前层权重的导数）</span></span><br><span class="line">			<span class="comment">// 将多通道二维图像net.input变成按一定存储规则排列的数组b，以方便、高效地进行矩阵（卷积）计算，详细查看该函数注释（比较复杂），</span></span><br><span class="line">			<span class="comment">// im2col_cpu_ext每次仅处理net.input（包含整个batch）中的一张输入图片（对于第一层，则就是读入的图片，对于之后的层，这些图片都是上一层的输出，通道数等于上一层卷积核个数）。</span></span><br><span class="line">			<span class="comment">// 最终重排的b为l.c * l.size * l.size行，l.out_h * l.out_w列。</span></span><br><span class="line">			<span class="comment">// 你会发现在前向forward_convolutional_layer()函数中，也为每层的输入进行了重排，但是很遗憾的是，并没有一个l.workspace把每一层的重排结果保存下来，而是统一存储到net.workspace中，</span></span><br><span class="line">			<span class="comment">// 并被不断擦除更新，那为什么不保存呢？保存下来不是省掉一大笔额外重复计算开销？原因有两个：1）net.workspace中只存储了一张输入图片的重排结果，所以重排下张图片时，马上就会被擦除，</span></span><br><span class="line">			<span class="comment">// 当然你可能会想，那为什么不弄一个l.worspaces将每层所有输入图片的结果保存呢？这引出第二个原因；2）计算成本是降低了，但存储空间需求急剧增加，想想每一层都有l.batch张图，且每张都是多通道的，</span></span><br><span class="line">			<span class="comment">// 重排后其元素个数还会增多，这个存储量搁谁都受不了，如果一个batch有128张图，输入图片尺寸为400*400，3通道，网络有16层（假设每层输入输出尺寸及通道数都一样），那么单单为了存储这些重排结果，</span></span><br><span class="line">			<span class="comment">// 就需要128*400*400*3*16*4/1024/1024/1024 = 3.66G，所以为了权衡，只能重复计算！</span></span><br><span class="line">            <span class="built_in">im2col_cpu_ext</span>(</span><br><span class="line">                im,                 <span class="comment">// input</span></span><br><span class="line">                l.c / l.groups,     <span class="comment">// input channels</span></span><br><span class="line">                l.h, l.w,           <span class="comment">// input size (h, w)</span></span><br><span class="line">                l.size, l.size,     <span class="comment">// kernel size (h, w)</span></span><br><span class="line">                l.pad, l.pad,       <span class="comment">// padding (h, w)</span></span><br><span class="line">                l.stride_y, l.stride_x, <span class="comment">// stride (h, w)</span></span><br><span class="line">                l.dilation, l.dilation, <span class="comment">// dilation (h, w)</span></span><br><span class="line">                b);                 <span class="comment">// output</span></span><br><span class="line">			<span class="comment">// 下面计算当前层的权重更新值，所谓权重更新值就是weight = weight - alpha * weight_update中的weight_update，</span></span><br><span class="line">			<span class="comment">// 权重更新值等于当前层敏感度图中每个元素乘以相应的像素值，因为一个权重跟当前层多个输出有关联（权值共享，即卷积核在图像中跨步移动做卷积，每个位置卷积得到的值</span></span><br><span class="line">			<span class="comment">// 都与该权值相关），所以对每一个权重更新值来说，需要在l.delta中找出所有与之相关的敏感度，乘以相应像素值，再求和，具体实现的方式依靠im2col_cpu()与gemm_nt()完成。</span></span><br><span class="line">			<span class="comment">// （backward_convolutional_layer整个函数的代码非常重要，仅靠文字没有公式与图表辅助说明可能很难说清，所以这部分更为清晰详细的说明，请参考个人博客！）</span></span><br><span class="line">			<span class="comment">// GEneral Matrix to Matrix Multiplication</span></span><br><span class="line">			<span class="comment">// 此处在im2col_cpu操作基础上，利用矩阵乘法c=alpha*a*b+beta*c完成对图像卷积的操作；</span></span><br><span class="line">			<span class="comment">// 0表示不对输入a进行转置，1表示对输入b进行转置；</span></span><br><span class="line">			<span class="comment">// m是输入a,c的行数，具体含义为卷积核的个数(l.n)；</span></span><br><span class="line">			<span class="comment">// n是输入b,c的列数，具体含义为每个卷积核元素个数乘以输入图像的通道数(l.size*l.size*l.c)；</span></span><br><span class="line">			<span class="comment">// k是输入a的列数也是b的行数，具体含义为每个输出特征图的元素个数（l.out_w*l.out_h）；</span></span><br><span class="line">			<span class="comment">// a,b,c即为三个参与运算的矩阵（用一维数组存储）,alpha=beta=1为常系数；</span></span><br><span class="line">			<span class="comment">// a为l.delta的一大行。l.delta为本层所有输出元素（包含整个batch中每张图片的所有输出特征图）关于加权输入的导数（即激活函数的导数值）集合,</span></span><br><span class="line">			<span class="comment">// 元素个数为l.batch * l.out_h * l.out_w * l.out_c（l.out_c = l.n），按行存储，共有l.batch行，l.out_c * l.out_h * l.out_w列，</span></span><br><span class="line">			<span class="comment">// 即l.delta中每行包含一张图的所有输出图，故这么一大行，又可以视作有l.out_c（l.out_c=l.n）小行，l.out_h*l*out_w小列，而一次循环就是处理l.delta的一大行，</span></span><br><span class="line">			<span class="comment">// 故可以将a视作l.out_c行，l.out_h*l*out_w列的矩阵；</span></span><br><span class="line">			<span class="comment">// b为单张输入图像经过im2col_cpu重排后的图像数据；</span></span><br><span class="line">			<span class="comment">// c为输出，按行存储，可视作有l.n行，l.c*l.size*l.size列（l.c是输入图像的通道数，l.n是卷积核个数），</span></span><br><span class="line">			<span class="comment">// 即c就是所谓的误差项（输出关于加权输入的导数），或者敏感度（强烈推荐：https://www.zybuluo.com/hanbingtao/note/485480）（一个核有l.c*l.size*l.size个权重，共有l.n个核）。</span></span><br><span class="line">			<span class="comment">// 由上可知：</span></span><br><span class="line">			<span class="comment">// a: (l.out_c) * (l.out_h*l*out_w)</span></span><br><span class="line">			<span class="comment">// b: (l.c * l.size * l.size) * (l.out_h * l.out_w)</span></span><br><span class="line">			<span class="comment">// c: (l.n) * (l.c*l.size*l.size)（注意：l.n = l.out_c）</span></span><br><span class="line">			<span class="comment">// 故要进行a * b + c计算，必须对b进行转置（否则行列不匹配），因故调用gemm_nt()函数</span></span><br><span class="line">            <span class="built_in">gemm</span>(<span class="number">0</span>, <span class="number">1</span>, m, n, k, <span class="number">1</span>, a, k, b, k, <span class="number">1</span>, c, n);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 接下来，用当前层的敏感度图l.delta以及权重l.weights（还未更新）来获取上一层网络的敏感度图，BP算法的主要流程就是依靠这种层与层之间敏感度反向递推传播关系来实现。</span></span><br><span class="line">			<span class="comment">// 在network.c的backward_network()中，会从最后一层网络往前遍循环历至第一层，而每次开始遍历某一层网络之前，都会更新net.input为这一层网络前一层的输出，即prev.output,</span></span><br><span class="line">			<span class="comment">// 同时更新net.delta为prev.delta，因此，这里的net.delta是当前层前一层的敏感度图。</span></span><br><span class="line">			<span class="comment">// 已经强调很多次了，再说一次：下面得到的上一层的敏感度并不完整，完整的敏感度图是损失函数对上一层的加权输入的导数，</span></span><br><span class="line">			<span class="comment">// 而这里得到的敏感度图是损失函数对上一层输出值的导数，还差乘以一个输出值也即激活函数对加权输入的导数。</span></span><br><span class="line">            <span class="keyword">if</span> (state.delta) &#123;</span><br><span class="line">				<span class="comment">// 当前层还未更新的权重</span></span><br><span class="line">                a = l.weights + j*l.nweights / l.groups;</span><br><span class="line">				</span><br><span class="line">				<span class="comment">// 每次循环仅处理一张输入图，注意移位（l.delta的维度为l.batch * l.out_c * l.out_w * l.out_h）（注意l.n = l.out_c，另外提一下，对整个网络来说，每一层的l.batch其实都是一样的）</span></span><br><span class="line">                b = l.delta + (i*l.groups + j)*m*k;</span><br><span class="line">				</span><br><span class="line">				<span class="comment">// net.workspace和上面一样，还是一张输入图片的重排，不同的是，此处我们只需要这个容器，而里面存储的值我们并不需要，在后面的处理过程中，</span></span><br><span class="line">				<span class="comment">// 会将其中存储的值一一覆盖掉（尺寸维持不变，还是(l.c * l.size * l.size) * (l.out_h * l.out_w）</span></span><br><span class="line">                c = state.workspace;</span><br><span class="line">				</span><br><span class="line">				 <span class="comment">// 相比上一个gemm，此处的a对应上一个的c,b对应上一个的a，c对应上一个的b，即此处a,b,c的行列分别为：</span></span><br><span class="line">				<span class="comment">// a: (l.n) * (l.c*l.size*l.size)，表示当前层所有权重系数</span></span><br><span class="line">				<span class="comment">// b: (l.out_c) * (l.out_h*l*out_w)（注意：l.n = l.out_c），表示当前层的敏感度图</span></span><br><span class="line">				<span class="comment">// c: (l.c * l.size * l.size) * (l.out_h * l.out_w)，表示上一层的敏感度图（其元素个数等于上一层网络单张输入图片的所有输出元素个数），</span></span><br><span class="line">				<span class="comment">// 此时要完成a * b + c计算，必须对a进行转置（否则行列不匹配），因故调用gemm_tn()函数。</span></span><br><span class="line">				<span class="comment">// 此操作含义是用：用当前层还未更新的权重值对敏感度图做卷积，得到包含上一层所有敏感度信息的矩阵，但这不是上一层最终的敏感度图，</span></span><br><span class="line">				<span class="comment">// 因为此时的c，也即net.workspace的尺寸为(l.c * l.size * l.size) * (l.out_h * l.out_w)，明显不是上一层的输出尺寸l.c*l.w*l.h，</span></span><br><span class="line">				<span class="comment">// 接下来还需要调用col2im_cpu()函数将其恢复至l.c*l.w*l.h（可视为l.c行，l.w*l.h列），这才是上一层的敏感度图（实际还差一个环节，</span></span><br><span class="line">				<span class="comment">// 这个环节需要等到下一次调用backward_convolutional_layer()才完成：将net.delta中每个元素乘以激活函数对加权输入的导数值）。</span></span><br><span class="line">				<span class="comment">// 完成gemm这一步，如col2im_cpu()中注释，是考虑了多个卷积核导致的一对多关系（上一层的一个输出元素会流入到下一层多个输出元素中），</span></span><br><span class="line">				<span class="comment">// 接下来调用col2im_cpu()则是考虑卷积核重叠（步长较小）导致的一对多关系。</span></span><br><span class="line">                <span class="built_in">gemm</span>(<span class="number">1</span>, <span class="number">0</span>, n, k, m, <span class="number">1</span>, a, n, b, k, <span class="number">0</span>, c, k);</span><br><span class="line"></span><br><span class="line">                <span class="comment">//col2im_cpu(state.workspace, l.c / l.groups, l.h, l.w, l.size, l.stride,</span></span><br><span class="line">                <span class="comment">//     l.pad, state.delta + (i*l.groups + j)*l.c / l.groups*l.h*l.w);</span></span><br><span class="line">				</span><br><span class="line">				<span class="comment">// 对c也即state.workspace进行重排，得到的结果存储在state.delta中，每次循环只会处理一张输入图片，因此，此处只会得到一张输入图产生的敏感图（注意net.delta的移位）,</span></span><br><span class="line">				<span class="comment">// 整个循环结束后，net.delta的总尺寸为l.batch * l.h * l.w * l.c，这就是上一层网络整个batch的敏感度图，可视为有l.batch行，l.h*l.w*l.c列，</span></span><br><span class="line">				<span class="comment">// 每行存储了一张输入图片所有输出特征图的敏感度</span></span><br><span class="line">				<span class="comment">// col2im_cpu()函数中会调用col2im_add_pixel()函数，该函数中使用了+=运算符，也即该函数要求输入的net.delta的初始值为0,而在gradient_array()中注释到l.delta的元素是不为0（也不能为0）的，</span></span><br><span class="line">				<span class="comment">// 看上去是矛盾的，实则不然，gradient_array()使用的l.delta是当前层的敏感度图，而在col2im_cpu()使用的net.delta是上一层的敏感度图，正如gradient_array()中所注释的，</span></span><br><span class="line">				<span class="comment">// 当前层l.delta之所以不为0,是因为从后面层反向传播过来的，对于上一层，显然还没有反向传播到那，因此net.delta的初始值都是为0的（注意，每一层在构建时，就为其delta动态分配了内存，</span></span><br><span class="line">				<span class="comment">// 且在前向传播时，为每一层的delta都赋值为0,可以参考network.c中forward_network()函数）</span></span><br><span class="line">                <span class="built_in">col2im_cpu_ext</span>(</span><br><span class="line">                    state.workspace,        <span class="comment">// input</span></span><br><span class="line">                    l.c / l.groups,         <span class="comment">// input channels (h, w)</span></span><br><span class="line">                    l.h, l.w,               <span class="comment">// input size (h, w)</span></span><br><span class="line">                    l.size, l.size,         <span class="comment">// kernel size (h, w)</span></span><br><span class="line">                    l.pad, l.pad,           <span class="comment">// padding (h, w)</span></span><br><span class="line">                    l.stride_y, l.stride_x,     <span class="comment">// stride (h, w)</span></span><br><span class="line">                    l.dilation, l.dilation, <span class="comment">// dilation (h, w)</span></span><br><span class="line">                    state.delta + (i*l.groups + j)* (l.c / l.groups)*l.h*l.w); <span class="comment">// output (delta)</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="col2im函数解析"><a href="#col2im函数解析" class="headerlink" title="col2im函数解析"></a>col2im函数解析</h2><p>col2im函数是im2col的逆过程，代码在<code>src/col2im.c</code>中实现，具体如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 注释来自https://github.com/hgpvision/darknet/blob/master/src/col2im.c</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*  将输入图像im的channel通道上的第row行，col列像素灰度值加上val（直接修改im的值，因此im相当于是返回值）</span></span><br><span class="line"><span class="comment">** 输入：im         输入图像</span></span><br><span class="line"><span class="comment">**       channels   输入图像的im通道数（这个参数没用。。。）</span></span><br><span class="line"><span class="comment">**       height     输入图像im的高度（行）</span></span><br><span class="line"><span class="comment">**       width      输入图像im的宽度（列）</span></span><br><span class="line"><span class="comment">**       row        需要加上val的像素所在的行数（补零之后的行数，因此需要先减去pad才能得到真正在im中的行数）</span></span><br><span class="line"><span class="comment">**       col        需要加上val的像素所在的列数（补零之后的列数，因此需要先减去pad才能得到真正在im中的列数）</span></span><br><span class="line"><span class="comment">**       channel    需要加上val的像素所在的通道数</span></span><br><span class="line"><span class="comment">**       pad        四周补0长度</span></span><br><span class="line"><span class="comment">**       val        像素灰度添加值</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">col2im_add_pixel</span><span class="params">(<span class="keyword">float</span> *im, <span class="keyword">int</span> height, <span class="keyword">int</span> width, <span class="keyword">int</span> channels,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="keyword">int</span> row, <span class="keyword">int</span> col, <span class="keyword">int</span> channel, <span class="keyword">int</span> pad, <span class="keyword">float</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    row -= pad;</span><br><span class="line">    col -= pad;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (row &lt; <span class="number">0</span> || col &lt; <span class="number">0</span> ||</span><br><span class="line">        row &gt;= height || col &gt;= width) <span class="keyword">return</span>;</span><br><span class="line">    im[col + width*(row + height*channel)] += val;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//This one might be too, can&#x27;t remember.</span></span><br><span class="line"><span class="comment">// 注释来自：https://github.com/hgpvision/darknet/blob/master/src/col2im.c</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">** 此函数与im2col_cpu()函数的流程相反，目地是将im2col_cpu()函数重排得到的图片data_col恢复至正常的图像矩阵排列，并与data_im相加，最终data_im相当于是输出值，</span></span><br><span class="line"><span class="comment">** 要注意的是，data_im的尺寸是在函数外确定的，且并没有显示的将data_col转为一个与data_im尺寸相同的矩阵，而是将其中元素直接加在data_im对应元素上（data_im初始所有元素值都为0）。</span></span><br><span class="line"><span class="comment">** 得到的data_im尺寸为l.c*l.h*l.w，即为当前层的输入图像尺寸，上一层的输出图像尺寸，按行存储，可视为l.c行，l.h*l.w列，即其中每行对应一张输出特征图的敏感度图（实际上这还不是最终的敏感度，</span></span><br><span class="line"><span class="comment">** 还差一个环节：乘以激活函数对加权输入的导数，这将在下一次调用backward_convolutional_laye时完成）。</span></span><br><span class="line"><span class="comment">**</span></span><br><span class="line"><span class="comment">** 举个例子：第L-1层每张输入图片（本例子只分析单张输入图片）的输出为5*5*3（3为输出通道数），第L层共有2个卷积核，每个卷积核的尺寸为3*3，stride = 2,</span></span><br><span class="line"><span class="comment">**         第L-1层的输出是第L层的输入，第L层的2个卷积核同时对上一层3个通道的输出做卷积运算，为了做到这一点，需要调用im2col_cpu()函数将</span></span><br><span class="line"><span class="comment">**         上一层的输出，也就是本层的输入重排为27行4列的图，也就是由5*5*3变换至27*4，你会发现总的元素个数变多了（75增多到了98），</span></span><br><span class="line"><span class="comment">**         这是因为卷积核stride=2,小于卷积核的尺寸3,因此卷积在两个连续位置做卷积，会有重叠部分，而im2col_cpu()函数为了便于卷积运算，完全将其</span></span><br><span class="line"><span class="comment">**         铺排开来，并没有在空间上避免重复元素，因此像素元素会增多。此外，之所以是27行，是因为卷积核尺寸为3*3，而上一层的输出即本层输入有3个通道，</span></span><br><span class="line"><span class="comment">**         为了同时给3个通道做卷积运算，需要将3个通道上的输入一起考虑，即得到3*3*3行，4列是因为对于对于5*5的图像，使用3*3的卷积核，stride=2的卷积跨度，</span></span><br><span class="line"><span class="comment">**         最终会得到2*2的特征图，也就是4个元素。除了调用im2col_cpu()对输入图像做重排，相应的，也要将所有卷积核重排成一个2*27的矩阵，为什么是2呢？</span></span><br><span class="line"><span class="comment">**         因为有两个卷积核，为了做到同时将两个卷积核作用到输入图像上，需要将两个核合到一个矩阵中，每个核对应一行，因此有2行，那为什么是27呢？每个核</span></span><br><span class="line"><span class="comment">**         元素个数不是3*3=9吗？是的，但是考虑到要同时作用到3个通道上，所以实际一个卷积核有9*3=27个元素。综述，得到2*27的卷积核矩阵与27*4的输入图像矩阵，</span></span><br><span class="line"><span class="comment">**         两个矩阵相乘，即可完成将2个卷积核同时作用于3通道的输入图像上（非常方便，不枉前面非这么大劲的重排！），最终得到2*4的矩阵，这2*4矩阵又代表这什么呢？</span></span><br><span class="line"><span class="comment">**         2代表这有两个输出图（对应2个卷积核，即l.out_c=2），每个输出图占一行，4代表这每个输出图元素有4个（前面说了，每个卷积核会得到2*2的特征图，即l.out_h=l.out_w=2）。这个例子说到这，只说完了</span></span><br><span class="line"><span class="comment">**         前向传播部分，可以看出im2col_cpu()这个函数的重要性。而此处的col2im_cpu()是一个逆过程，主要用于反向传播中，由L层的敏感度图(sensitivity map，</span></span><br><span class="line"><span class="comment">**         可能每个地方叫的不一样，此处参考博客：https://www.zybuluo.com/hanbingtao/note/485480)反向求得第L-1层的敏感度图。顺承上面的例子，第L-1层的输出</span></span><br><span class="line"><span class="comment">**         是一个5*5*3（l.w=l.h=5,l.c=3）的矩阵，也就是敏感度图的维度为5*5*3（每个输出元素，对应一个敏感度值），第L层的输出是一个2*4的矩阵，敏感度图的维度为2*4，假设已经计算得到了</span></span><br><span class="line"><span class="comment">**         第L层的2*4的敏感度图，那么现在的问题是，如何由第L层的2*4敏感度图以及2个卷积核（2*27）反向获取第L-1层的敏感度图呢？上面给的博客链接给出了一种很好的求解方式，</span></span><br><span class="line"><span class="comment">**         但darknet并不是这样做的，为什么？因为前面有im2col_cpu()，im2col_cpu()函数中的重排方式，使得我们不再需要博客中提到的将sensitivity map还原为步长为1的sensitivity map，</span></span><br><span class="line"><span class="comment">**         只需再使用col2im_cpu()就可以了！过程是怎样的呢，看backward_convolutional_layer()函数中if(net.delta)中的语句就知道了，此处仅讨论col2im_cpu()的过程，</span></span><br><span class="line"><span class="comment">**         在backward_convolutional_layer()已经得到了data_col，这个矩阵含有了所有的第L-1层敏感度的信息，但遗憾的是，不能直接用，需要整理，因为此时的data_col还是一个</span></span><br><span class="line"><span class="comment">**         27*4的矩阵，而我们知道第L-1层的敏感度图是一个5*5*3的矩阵，如何将一个27*4的矩阵变换至一个5*5*3的矩阵是本函数要完成的工作，前面说到27*4元素个数多于5*5*3,</span></span><br><span class="line"><span class="comment">**         很显然要从27*4变换至5*5*3，肯定会将某些元素相加合并（下面col2im_add_pixel()函数就是干这个的），具体怎样，先不说，先来看看输入参数都代表什么意思吧：</span></span><br><span class="line"><span class="comment">** 输入：data_col    backward_convolutional_layer()中计算得到的包含上一层所有敏感度信息的矩阵，行数为l.n*l.size*l.size（l代表本层/当前层），列数为l.out_h*l.out_w（对于本例子，行数为27,列数为4,上一层为第L-1层，本层是第L层）</span></span><br><span class="line"><span class="comment">**       channels    当前层输入图像的通道数（对于本例子，为3）</span></span><br><span class="line"><span class="comment">**       height      当前层输入图像的行数（对于本例子，为5）</span></span><br><span class="line"><span class="comment">**       width       当前层输入图像的列数（对于本例子，为5）</span></span><br><span class="line"><span class="comment">**       ksize       当前层卷积核尺寸（对于本例子，为3）</span></span><br><span class="line"><span class="comment">**       stride      当前层卷积跨度（对于本例子，为2）</span></span><br><span class="line"><span class="comment">**       pad         当前层对输入图像做卷积时四周补0的长度</span></span><br><span class="line"><span class="comment">**       data_im     经col2im_cpu()重排恢复之后得到的输出矩阵，也即上一层的敏感度图，尺寸为l.c * l.h * l.w（刚好就是上一层的输出当前层输入的尺寸，对于本例子，5行5列3通道），</span></span><br><span class="line"><span class="comment">**                   注意data_im的尺寸，是在本函数之外就已经确定的，不是在本函数内部计算出来的，这与im2col_cpu()不同，im2col_cpu()计算得到的data_col的尺寸都是在函数内部计算得到的，</span></span><br><span class="line"><span class="comment">**                   并不是事先指定的。也就是说，col2im_cpu()函数完成的是指定尺寸的输入矩阵往指定尺寸的输出矩阵的转换。</span></span><br><span class="line"><span class="comment">** 原理：原理比较复杂，很难用文字叙述，博客：https://www.zybuluo.com/hanbingtao/note/485480中基本原理说得很详细了，但是此处的实现与博客中并不一样，所以具体实现的原理此处简要叙述一下，具体见个人博客。</span></span><br><span class="line"><span class="comment">**      第L-1层得到l.h*l.w*l.c输出，也是第L层的输入，经L层卷积及激活函数处理之后，得到l.out_h*l.out_w*l.out_c的输出，也就是由l.h*l.w*l.c--&gt;l.out_h*l.out_w*l.out_c，</span></span><br><span class="line"><span class="comment">**      由于第L层有多个卷积核，所以第L-1层中的一个输出元素会流入到第L层多个输出中，除此之外，由于卷积核之间的重叠，也导致部分元素流入到第L层的多个输出中，这两种情况，都导致第L-1层中的某个敏感度会与第L层多个输出有关，</span></span><br><span class="line"><span class="comment">**      为清晰，还是用上面的例子来解释，第L-1层得到5*5*3(3*25)的输出，第L层得到2*2*2（2*4）的输出，在backward_convolutional_layer()已经计算得到的data_col实际是27*2矩阵与2*4矩阵相乘的结果，</span></span><br><span class="line"><span class="comment">**      为方便，我们记27*2的矩阵为a，记2*4矩阵为b，那么a中一行（2个元素）与b中一列（2个元素）相乘对应这什么呢？对应第一情况，因为有两个卷积核，使得L-1中一个输出至少与L层中两个输出有关系，经此矩阵相乘，得到27*4的矩阵，</span></span><br><span class="line"><span class="comment">**      已经考虑了第一种情况（27*4这个矩阵中的每一个元素都是两个卷积核影响结果的求和），那么接下来的就是要考虑第二种情况：卷积核重叠导致的一对多关系，具体做法就是将data_col中对应相同像素的值相加，这是由</span></span><br><span class="line"><span class="comment">**      im2col_cpu()函数决定的（可以配合im2col_cpu()来理解），因为im2col_cpu()将这些重叠元素也铺陈保存在data_col中，所以接下来，只要按照im2col_cpu()逆向将这些重叠元素的影响叠加就可以了，</span></span><br><span class="line"><span class="comment">**      大致就是这个思路，具体的实现细节可能得见个人博客了（这段写的有点罗嗦～）。</span></span><br><span class="line"><span class="comment">**</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">col2im_cpu</span><span class="params">(<span class="keyword">float</span>* data_col,</span></span></span><br><span class="line"><span class="params"><span class="function">         <span class="keyword">int</span> channels,  <span class="keyword">int</span> height,  <span class="keyword">int</span> width,</span></span></span><br><span class="line"><span class="params"><span class="function">         <span class="keyword">int</span> ksize,  <span class="keyword">int</span> stride, <span class="keyword">int</span> pad, <span class="keyword">float</span>* data_im)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> c,h,w;</span><br><span class="line">	<span class="comment">// 当前层输出图的尺寸（对于上面的例子，height_col=2,width_col=2）</span></span><br><span class="line">    <span class="keyword">int</span> height_col = (height + <span class="number">2</span>*pad - ksize) / stride + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> width_col = (width + <span class="number">2</span>*pad - ksize) / stride + <span class="number">1</span>;</span><br><span class="line">	<span class="comment">// 当前层每个卷积核在所有输入图像通道上的总元素个数（对于上面的例子，channels_col=3*3*3=27）</span></span><br><span class="line">    <span class="comment">// 注意channels_col实际是data_col的行数</span></span><br><span class="line">    <span class="keyword">int</span> channels_col = channels * ksize * ksize;</span><br><span class="line">	<span class="comment">// 开始遍历：外循环遍历data_col的每一行（对于上面的例子，data_col共27行）</span></span><br><span class="line">    <span class="keyword">for</span> (c = <span class="number">0</span>; c &lt; channels_col; ++c) &#123;</span><br><span class="line">		<span class="comment">// 列偏移，卷积核是一个二维矩阵，并按行存储在一维数组中，利用求余运算获取对应在卷积核中的列数，比如对于</span></span><br><span class="line">        <span class="comment">// 3*3的卷积核，当c=0时，显然在第一列，当c=5时，显然在第2列，当c=9时，在第二通道上的卷积核的第一列</span></span><br><span class="line">        <span class="keyword">int</span> w_offset = c % ksize;</span><br><span class="line">		<span class="comment">// 行偏移，卷积核是一个二维的矩阵，且是按行（卷积核所有行并成一行）存储在一维数组中的，</span></span><br><span class="line">        <span class="comment">// 比如对于3*3的卷积核，处理3通道的图像，那么一个卷积核具有27个元素，每9个元素对应一个通道上的卷积核（互为一样），</span></span><br><span class="line">        <span class="comment">// 每当c为3的倍数，就意味着卷积核换了一行，h_offset取值为0,1,2</span></span><br><span class="line">        <span class="keyword">int</span> h_offset = (c / ksize) % ksize;</span><br><span class="line">		<span class="comment">// 通道偏移，channels_col是多通道的卷积核并在一起的，比如对于3通道，3*3卷积核，每过9个元素就要换一通道数，</span></span><br><span class="line">        <span class="comment">// 当c=0~8时，c_im=0;c=9~17时，c_im=1;c=18~26时，c_im=2</span></span><br><span class="line">        <span class="comment">// c_im是data_im的通道数（即上一层输出当前层输入的通道数），对于上面的例子，c_im取值为0,1,2</span></span><br><span class="line">        <span class="keyword">int</span> c_im = c / ksize / ksize;</span><br><span class="line">		<span class="comment">// 中循环与内循环和起来刚好遍历data_col的每一行（对于上面的例子，data_col的列数为4,height_col*width_col=4）</span></span><br><span class="line">        <span class="keyword">for</span> (h = <span class="number">0</span>; h &lt; height_col; ++h) &#123;</span><br><span class="line">            <span class="keyword">for</span> (w = <span class="number">0</span>; w &lt; width_col; ++w) &#123;</span><br><span class="line">				<span class="comment">// 获取在输出data_im中的行数im_row与列数im_col</span></span><br><span class="line">                <span class="comment">// 由上面可知，对于3*3的卷积核，h_offset取值为0,1,2,当h_offset=0时，会提取出所有与卷积核第一行元素进行运算的像素，</span></span><br><span class="line">                <span class="comment">// 依次类推；加上h*stride是对卷积核进行行移位操作，比如卷积核从图像(0,0)位置开始做卷积，那么最先开始涉及(0,0)~(3,3)</span></span><br><span class="line">                <span class="comment">// 之间的像素值，若stride=2，那么卷积核进行行移位一次时，下一行的卷积操作是从元素(2,0)（2为图像行号，0为列号）开始</span></span><br><span class="line">                <span class="keyword">int</span> im_row = h_offset + h * stride;</span><br><span class="line">				<span class="comment">// 对于3*3的卷积核，w_offset取值也为0,1,2，当w_offset取1时，会提取出所有与卷积核中第2列元素进行运算的像素，</span></span><br><span class="line">                <span class="comment">// 实际在做卷积操作时，卷积核对图像逐行扫描做卷积，加上w*stride就是为了做列移位，</span></span><br><span class="line">                <span class="comment">// 比如前一次卷积其实像素元素为(0,0)，若stride=2,那么下次卷积元素起始像素位置为(0,2)（0为行号，2为列号）</span></span><br><span class="line">                <span class="keyword">int</span> im_col = w_offset + w * stride;</span><br><span class="line">				<span class="comment">// 计算在输出data_im中的索引号</span></span><br><span class="line">                <span class="comment">// 对于上面的例子，im_row的取值范围为0~4,im_col从0~4，c从0~2（其中h_offset从0~2,w_offset从0~2, h从0~1,w从0~1）</span></span><br><span class="line">                <span class="comment">// 输出的data_im的尺寸为l.c * l.h * lw，对于上面的例子，为3*5*5,因此，im_row,im_col,c的取值范围刚好填满data_im</span></span><br><span class="line"></span><br><span class="line">                <span class="comment">// 获取data_col中索引为col_index的元素，对于上面的例子，data_col为27*4行，按行存储</span></span><br><span class="line">                <span class="comment">// col_index = c * height_col * width_col + h * width_col + w逐行读取data_col中的每一个元素。</span></span><br><span class="line">                <span class="comment">// 相同的im_row,im_col与c_im可能会对应多个不同的col_index，这就是卷积核重叠带来的影响，处理的方式是将这些val都加起来，</span></span><br><span class="line">                <span class="comment">// 存在data_im的第im_row - pad行，第im_col - pad列（c_im通道上）中。</span></span><br><span class="line">                <span class="comment">// 比如上面的例子，上面的例子，如果固定im_row = 0, im_col =2, c_im =0，由c_im = 0可以知道c在0~8之间，由im_row=0,可以确定h = 0, h_offset =0，</span></span><br><span class="line">                <span class="comment">// 可以得到两组：1)w_offset = 0, w = 1; 2) w_offset = 2, w =0，第一组，则可以完全定下：c=0,h=0,w=1，此时col_index=1，由第二组，可完全定下：c=2,h=0,w=0，</span></span><br><span class="line">                <span class="comment">// 此时col_index = 2*2*2=8</span></span><br><span class="line">                <span class="keyword">int</span> col_index = (c * height_col + h) * width_col + w;</span><br><span class="line">                <span class="keyword">float</span> val = data_col[col_index];</span><br><span class="line">				<span class="comment">// 从data_im找出c_im通道上第im_row - pad行im_col - pad列处的像素，使其加上val</span></span><br><span class="line">                <span class="comment">// height, width, channels都是上一层输出即当前层输入图像的尺寸，也是data_im的尺寸（对于本例子，三者的值分别为5,5,3）,</span></span><br><span class="line">                <span class="comment">// im_row - pad,im_col - pad,c_im都是某一具体元素在data_im中的行数与列数与通道数（因为im_row与im_col是根据卷积过程计算的，</span></span><br><span class="line">                <span class="comment">// 所以im_col和im_row中实际还包含了补零长度pad，需要减去之后，才是原本的没有补零矩阵data_im中的行列号）</span></span><br><span class="line">                <span class="built_in">col2im_add_pixel</span>(data_im, height, width, channels,</span><br><span class="line">                        im_row, im_col, c_im, pad, val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h2><p>上面介绍的反向传播可以用下图来表示，更容易理解。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/659.webp" alt></p>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>AlexeyAB版Darknet使用教程</title>
    <url>/2020/02/20/AlexeyAB%E7%89%88Darknet%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自从Joseph Redmon提出了yolov3后，其darknet仓库已经获得了16k的star，足以说明darknet的流行。该作者最新一次更新也是一年前了，没有继续维护。不过自来自俄国的大神AlexeyAB在不断地更新darknet, 不仅添加了darknet在window下的适配，而且实现了多种SOTA目标检测算法。AlexeyAB也在库中提供了一份详细的建议，从编译、配置、涉及网络到测量指标等，一应俱全。通过阅读和理解AlexeyAB的建议，可以为我们带来很多启发。本文是来自翻译AlexeyAB的darknet中的README。</p>
<p>下图是CSPNet中统计的目前的State of the Art的目标检测模型。其中csresnext50-panet-spp-optimal模型是CSPNet中提出来的，结合AlexeyAB版本的Darknet就可以实现。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/640.jpg" alt></p>
<h2 id="1-依赖"><a href="#1-依赖" class="headerlink" title="1. 依赖"></a>1. 依赖</h2><h3 id="1-1-环境要求"><a href="#1-1-环境要求" class="headerlink" title="1.1 环境要求"></a>1.1 环境要求</h3><ul>
<li>window系统或者linux系统。</li>
<li>CMake版本高于3.8。</li>
<li>CUDA 10.0，cuDNN&gt;=7.0。</li>
<li>OpenCV版本高于2.4。</li>
<li>Linux下需要GCC 或者Clang, Window下需要Visual Studio 15、17或19版。</li>
</ul>
<h3 id="1-2-数据集获取"><a href="#1-2-数据集获取" class="headerlink" title="1.2 数据集获取"></a>1.2 数据集获取</h3><ol>
<li>MS COCO数据集: 使用<code>./scripits/get_coco_dataset.sh</code>来获取数据集。</li>
<li>OpenImages数据集: 使用<code>./scripits/get_openimages_dataset.py</code>获取数据集,并按照规定的格式重排训练集。</li>
<li>Pascal VOC数据集: 使用<code>./scripits/voc_label.py</code>对数据集标注进行处理。</li>
<li>ILSVRC2012数据集(ImageNet Classification): 使用<code>./scripits/get_imagenet_train.sh</code>获取数据集，运行<code>./scripits/imagenet_label.sh</code>用于验证集。</li>
<li>German/Belgium/Russian/LISA/MASTIF 交通标志数据集。</li>
<li>其他数据集，请访问<code>https://github.com/AlexeyAB/darknet/tree/master/scripts#datasets</code></li>
</ol>
<p>结果示意：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/641.webp" alt></p>
<p>其他测试结果可以访问:<code>https://www.youtube.com/user/pjreddie/videos</code></p>
<h2 id="2-相比原作者Darknet的改进"><a href="#2-相比原作者Darknet的改进" class="headerlink" title="2. 相比原作者Darknet的改进"></a>2. 相比原作者Darknet的改进</h2><ul>
<li>添加了对windows下运行darknet的支持。</li>
<li>添加了SOTA模型： CSPNet, PRN, EfficientNet。</li>
<li>在官方Darknet的基础上添加了新的层：[conv_lstm], [scale_channels] SE/ASFF/BiFPN, [local_avgpool], [sam],  [Gaussian_yolo], [reorg3d] (修复 [reorg]), 修复 [batchnorm]。</li>
<li>可以使用<code>[conv_lstm]</code>层或者<code>[crnn]</code>层来实现针对视频的目标检测。</li>
<li>添加了多种数据增强策略: <code>[net] mixup=1 cutmix=1 mosaic=1 blur=1</code>。</li>
<li>添加了多种激活函数: SWISH, MISH, NORM_CHAN, NORM\CHAN_SOFTMAX。</li>
<li>增加了使用CPU-RAM提高GPU处理训练的能力，以增加<code>mini_batch_size</code>和准确性。</li>
<li>提升了二值网络，让其在CPU和GPU上的训练和测试速度变为原来的2-4倍。</li>
<li>通过将Convolutional层和Batch-Norm层合并成一个层，提升了约7%速度。</li>
<li>如果在Makefile中使用CUDNN_HALF参数，可以让网络在TeslaV100，GeForce RTX等型号的GPU上的检测速度提升两倍。</li>
<li>针对视频的检测进行了优化，对高清视频检测速度可以提升1.2倍，对4k的视频检测速度可以提升2倍。</li>
<li>数据增强部分使用Opencv SSE/AVX指令优化了原来朴素实现的数据增强，数据增强速度提升为原来的3.5倍。</li>
<li>在CPU上使用AVX指令来提高了检测速度，yolov3提高了约85%。</li>
<li>在网络多尺度训练（<code>random=1</code>）的时候优化了内存分配。</li>
<li>优化了检测时的GPU初始化策略，在bacth=1的时候执行初始化而不是当batch=1的时候重新初始化。</li>
<li>添加了计算mAP,F1,IoU, Precision-Recall等指标的方法，只需要运行<code>darknet detector map</code>命令即可。</li>
<li>支持在训练的过程中画loss曲线和准确率曲线，只需要添加<code>-map</code>标志即可。</li>
<li>提供了<code>-json_port</code>,<code>-mjpeg_port</code>选项，支持作为json和mjpeg 服务器来在线获取的结果。可以使用你的编写的软件或者web浏览器与<strong>json和mjpeg服务器</strong>连接。</li>
<li>添加了Anchor的计算功能，可以根据数据集来聚类得到合适的Anchor。</li>
<li>添加了一些目标检测和目标跟踪的示例：<code>https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp</code></li>
<li>在使用错误的cfg文件或者数据集的时候，添加了运行时的建议和警告。</li>
<li>其它一些代码修复。</li>
</ul>
<h2 id="3-命令行使用"><a href="#3-命令行使用" class="headerlink" title="3. 命令行使用"></a>3. 命令行使用</h2><p>Linux中使用./darknet，window下使用darknet.exe.</p>
<p>Linux中命令格式类似<code>./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights</code></p>
<p>Linux中的可执行文件在根目录下，Window下则在<code>\build\darknet\x64</code>文件夹中。以是不同情况下应该使用的命令：</p>
<ul>
<li>Yolo v3 COCO - <strong>图片测试</strong>: <code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -thresh 0.25</code></li>
<li><strong>输出坐标</strong> of objects: <code>darknet.exe detector test cfg/coco.data yolov3.cfg yolov3.weights -ext_output dog.jpg</code></li>
<li>Yolo v3 COCO - <strong>视频测试</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -ext_output test.mp4</code></li>
<li><strong>网络摄像头</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -c 0</code></li>
<li><strong>网络视频摄像头</strong> - Smart WebCam: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg</code></li>
<li>Yolo v3 - <strong>保存视频结果为res.avi</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights test.mp4 -out_filename res.avi</code></li>
<li>Yolo v3 <strong>Tiny版本</strong> COCO - video: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights test.mp4</code></li>
<li><strong>JSON and MJPEG 服务器</strong> ：创建JSON和MJPEG服务器，允许软件或Web浏览器进行与服务器之间进行多个连接 。假设两者需要的端口为<code>ip-address:8070</code> 和 <code>8090</code>: <code>./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights  test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output</code></li>
<li>Yolo v3 <strong>Tiny</strong> <strong>on GPU</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights -i 1 test.mp4</code></li>
<li>另一个可进行图片测试的命令 Yolo v3 COCO - <strong>图片测试</strong>: <code>darknet.exe detect cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25</code></li>
<li>在 <strong>Amazon EC2</strong>上训练, 如果想要看mAP和Loss曲线，运行以下命令: <code>http://ec2-35-160-228-91.us-west-2.compute.amazonaws.com:8090</code>  (<strong>Darknet 必须使用OpenCV进行编译才能使用该功能</strong>): <code>./darknet detector train cfg/coco.data yolov3.cfg darknet53.conv.74 -dont_show -mjpeg_port 8090 -map</code></li>
<li>186 MB Yolo9000 - <strong>图片分类</strong>: <code>darknet.exe detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights</code></li>
<li><strong>处理一系列图片，并保存结果为json文件</strong>：<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -ext_output  -dont_show -out result.json &lt; data/train.txt</code></li>
<li><strong>处理一系列图片，并保存结果为txt文件</strong>:<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -dont_show -ext_output &lt; data/train.txt &gt; result.txt</code></li>
<li><strong>伪标注：</strong> 处理一个list的图片 <code>data/new_train.txt</code> ，可以让结果保存为Yolo训练所需的格式，标注文件为 <code>.txt</code> 。通过这种方法可以迅速增加训练数据量。具体命令为:<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -thresh 0.25  -dont_show -save_labels &lt; data/new_train.txt</code></li>
<li><strong>如何计算anchor</strong>(通过聚类得到): <code>darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416</code></li>
<li><strong>计算mAP@IoU=50</strong>: <code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights</code></li>
<li><strong>计算mAP@IoU=75</strong>: <code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights -iou_thresh 0.75</code></li>
</ul>
<p><strong>利用Video-Camera和Mjepg-Stream在Android智能设备中运行YOLOv3</strong></p>
<ol>
<li><p>下载 mjpeg-stream APP: IP Webcam / Smart WebCam:</p>
</li>
<li><ul>
<li>Smart WebCam - 从此处下载: <code>https://play.google.com/store/apps/details?id=com.acontech.android.SmartWebCam2</code></li>
<li>IP Webcam下载地址: <code>https://play.google.com/store/apps/details?id=com.pas.webcam</code></li>
</ul>
</li>
<li><p>将你的手机与电脑通过WIFI或者USB相连。</p>
</li>
<li><p>开启手机中的Smart WebCam APP。</p>
</li>
<li><p>将以下IP地址替换,在Smart WebCam APP中显示，并运行以下命令：</p>
</li>
</ol>
<p>Yolo v3 COCO-model: <code>darknet.exe detector demo data/coco.data yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0</code></p>
<h2 id="4-Linux下如何编译Darknet"><a href="#4-Linux下如何编译Darknet" class="headerlink" title="4. Linux下如何编译Darknet"></a>4. Linux下如何编译Darknet</h2><h3 id="4-1-使用CMake编译Darknet"><a href="#4-1-使用CMake编译Darknet" class="headerlink" title="4.1 使用CMake编译Darknet"></a>4.1 使用CMake编译Darknet</h3><p>CMakeList.txt是一个尝试发现所有安装过的、可选的依赖项(比如CUDA，cuDNN, ZED)的配置文件，然后使用这些依赖项进行编译。它将创建一个共享库文件，这样就可以使用Darknet进行代码开发。</p>
<p>在克隆了项目库以后按照以下命令进行执行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir build-release</span><br><span class="line">cd build-release</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<h3 id="4-2-使用make编译Darknet"><a href="#4-2-使用make编译Darknet" class="headerlink" title="4.2 使用make编译Darknet"></a>4.2 使用make编译Darknet</h3><p>在克隆了项目库以后，直接运行<code>make</code>命令，需要注意的是Makefile中有一些可选参数：</p>
<ul>
<li>GPU=1代表编译完成后将可以使用CUDA来进行GPU加速(CUDA应该在<code>/usr/local/cuda</code>中)。</li>
<li>CUDNN=1代表通过cuDNN v5-v7进行编译，这样将可以加速使用GPU训练过程(cuDNN应该在<code>/usr/local/cudnn</code>中)。</li>
<li>CUDNN_HALF=1代表在编译的过程中是否添加Tensor Cores, 编译完成后将可以将目标检测速度提升为原来的3倍，训练网络的速度提高为原来的2倍。</li>
<li>OPENCV=1代表编译的过程中加入OpenCV, 目前支持的OpenCV的版本有4.x/3.x/2.4.x， 编译结束后将允许Darknet对网络摄像头的视频流或者视频文件进行目标检测。</li>
<li>DEBUG=1 代表是否开启YOLO的debug模式。</li>
<li>OPENMP=1代表编译过程将引入openmp,编译结束后将代表可以使用多核CPU对yolo进行加速。</li>
<li>LIBSO=1 代表编译库darknet.so。</li>
<li>ZED_CAMERA=1 构建具有ZED-3D相机支持的库(应安装ZED SDK)，然后运行。</li>
</ul>
<h2 id="5-如何在Window下编译Darknet"><a href="#5-如何在Window下编译Darknet" class="headerlink" title="5. 如何在Window下编译Darknet"></a>5. 如何在Window下编译Darknet</h2><h3 id="5-1-使用CMake-GUI进行编译"><a href="#5-1-使用CMake-GUI进行编译" class="headerlink" title="5.1 使用CMake-GUI进行编译"></a>5.1 使用CMake-GUI进行编译</h3><p>建议使用以下方法来完成Window下Darknet的编译，需要环境有：Visual Studio 15/17/19, CUDA&gt;10.0, cuDNN&gt;7.0, OpenCV&gt;2.4</p>
<p>使用CMake-GUI编译流程：</p>
<ol>
<li>Configure.</li>
<li>Optional platform for generator (Set: x64) .</li>
<li>Finish.</li>
<li>Generate.</li>
<li>Open Project.</li>
<li>Set: x64 &amp; Release.</li>
<li>Build.</li>
<li>Build solution.</li>
</ol>
<h3 id="5-2-使用vcpkg进行编译"><a href="#5-2-使用vcpkg进行编译" class="headerlink" title="5.2 使用vcpkg进行编译"></a>5.2 使用vcpkg进行编译</h3><p>如果你已经满足Visual Studio 15/17/19 、CUDA&gt;10.0、 cuDNN&gt;7.0、OpenCV&gt;2.4的条件, 那么推荐使用通过CMake-GUI的方式进行编译。</p>
<p>否则按照以下步骤进行编译:</p>
<ul>
<li>安装或更新Visual Studio到17+,确保已经对其进行全面修补。</li>
<li>安装CUDA和cuDNN。</li>
<li>安装Git和CMake, 并将它们加入环境变量中。</li>
<li>安装vcpkg然后尝试安装一个测试库来确认安装是正确的，比如：<code>vcpkg install opengl</code>。</li>
<li>定义一个环境变量<code>VCPKG_ROOT</code>, 指向vcpkg的安装路径。</li>
<li>定义另一个环境变量<code>VCPKG_DEFAULT_TRIPLET</code>将其指向x64-windows。</li>
<li>打开Powershell然后运行以下命令：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PS \&gt;                  cd $env:VCPKG_ROOT</span><br><span class="line">PS Code\vcpkg&gt;         .\vcpkg install pthreads opencv[ffmpeg] </span><br><span class="line">#replace with opencv[cuda,ffmpeg] in case you want to use cuda-accelerated openCV</span><br></pre></td></tr></table></figure>
<ul>
<li>打开Powershell, 切换到darknet文件夹，然后运行<code>.\build.ps1</code>进行编译。如果要使用Visual Studio，将在Build后找到CMake为您创建的两个自定义解决方案，一个在<code>build_win_debug</code>中，另一个在<code>build_win_release</code>中，其中包含适用于系统的所有配置标志。</li>
</ul>
<h3 id="5-3-使用legacy-way进行编译"><a href="#5-3-使用legacy-way进行编译" class="headerlink" title="5.3 使用legacy way进行编译"></a>5.3 使用legacy way进行编译</h3><ul>
<li><p>如果你有CUDA10.0、cuDNN 7.4 和OpenCV 3.x , 那么打开<code>build\darknet\darknet.sln</code>, 设置x64和Release 然后运行Build， 进行darknet的编译，将cuDNN加入环境变量中。</p>
<ul>
<li>在<code>C:\opencv_3.0\opencv\build\x64\vc14\bin</code>找到<code>opencv_world320.dll</code>和<code>opencv_ffmpeg320_64.dll</code>, 然后将其复制到<code>darknet.exe</code>同级目录中。</li>
<li>在<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</code>中检查是否含有bin和include文件夹。如果没有这两个文件夹，那就将他们从CUDA安装的地方复制到这个地方。</li>
<li>安装cuDNN 7.4.1 来匹配CUDA 10.0, 将cuDNN添加到环境变量<code>CUDNN</code>。将<code>cudnn64_7.dll</code>复制到<code>\build\darknet\x64</code>中。</li>
</ul>
</li>
<li><p>如果你是用的是其他版本的CUDA（不是CUDA 10.0）, 那么使用Notepad打开<code>build\darknet\darknet.vxcproj</code>, 将其中的CUDA 10.0替换为你的CUDA的版本。然后打开<code>\darknet.sln</code>, 然后右击工程，点击属性properties, 选择CUDA C/C++, 然后选择Device , 然后移除<code>compute_75,sm_75</code>。之后从第一步从头开始执行。</p>
</li>
<li><p>如果你没有GPU但是有OpenCV3.0， 那么打开<code>build\darknet\darknet_no_gpu.sln</code>, 设置x64和Release， 然后运行build -&gt; build darknet_no_gpu。</p>
</li>
<li><p>如果你只安装了OpenCV 2.4.14，那你应该修改<code>\darknet.sln</code>中的路径。</p>
</li>
<li><ul>
<li>(右键点击工程) -&gt; properties -&gt; C/C++ -&gt; General -&gt; Additional Include Directories: <code>C:\opencv_2.4.13\opencv\build\include</code></li>
<li>(右键点击工程)-&gt; properties -&gt; Linker -&gt; General -&gt; Additional Library Directories: <code>C:\opencv_2.4.13\opencv\build\x64\vc14\lib</code></li>
</ul>
</li>
<li><p>如果你的GPU有Tensor Cores(Nvidia Titan V/ Tesla V100/ DGX-2等型号)， 可以提升目标检测模型测试速度为原来的3倍，训练速度变为原来的2倍。<code>\darknet.sln</code> -&gt; (右键点击工程) -&gt; properties -&gt; C/C++ -&gt; Preprocessor -&gt; Preprocessor Definitions, and add here: <code>CUDNN_HALF;</code></p>
<p><strong>注意</strong>：CUDA 必须在Visual Studio安装后再安装。</p>
</li>
</ul>
<h2 id="6-如何训练"><a href="#6-如何训练" class="headerlink" title="6. 如何训练"></a>6. 如何训练</h2><h3 id="6-1-Pascal-VOC-dataset"><a href="#6-1-Pascal-VOC-dataset" class="headerlink" title="6.1 Pascal VOC dataset"></a>6.1 Pascal VOC dataset</h3><ol>
<li><p>下载预训练模型 (154 MB): <code>http://pjreddie.com/media/files/darknet53.conv.74</code> 将其放在 <code>build\darknet\x64</code>文件夹中。</p>
</li>
<li><p>下载pascal voc数据集并解压到 <code>build\darknet\x64\data\voc</code> 放在 <code>build\darknet\x64\data\voc\VOCdevkit\</code>文件夹中:</p>
<p>2.1 下载 <code>voc_label.py</code> 到 <code>build\darknet\x64\data\voc</code>，地址为: <code>http://pjreddie.com/media/files/voc_label.py。</code></p>
</li>
<li><ul>
<li><code>http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar</code>。</li>
<li><code>http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</code>。</li>
<li><code>http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar</code>。</li>
</ul>
</li>
<li><p>下载并安装python: <code>https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe</code></p>
</li>
<li><p>运行命令: <code>python build\darknet\x64\data\voc\voc_label.py</code> (来生成文件: 2007_test.txt, 2007_train.txt, 2007_val.txt, 2012_train.txt, 2012_val.txt)。</p>
</li>
<li><p>运行命令: <code>type 2007_train.txt 2007_val.txt 2012_*.txt &gt; train.txt</code>。</p>
</li>
<li><p>在 <code>yolov3-voc.cfg</code>文件中设置 <code>batch=64</code> 和<code>subdivisions=8</code>。</p>
</li>
<li><p>使用 <code>train_voc.cmd</code> 或者使用以下命令开始训练:</p>
<p><code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74</code>。</p>
</li>
</ol>
<p>(<strong>Note:</strong> 如果想要停止loss显示，添加 <code>-dont_show</code>标志. 如果使用CPU运行, 用<code>darknet_no_gpu.exe</code> 代替 <code>darknet.exe</code>。)</p>
<p>如果想要改数据集路径的话，请修改 <code>build\darknet\cfg\voc.data</code>文件。</p>
<p><strong>Note:</strong> 在训练中如果你看到avg为nan，那证明训练出错。但是如果在其他部分出现nan，这属于正常现象，训练过程是正常的。</p>
<h3 id="6-2-如何使用多GPU训练？"><a href="#6-2-如何使用多GPU训练？" class="headerlink" title="6.2 如何使用多GPU训练？"></a>6.2 如何使用多GPU训练？</h3><ol>
<li>首先在一个GPU中训练大概1000个轮次: <code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74</code>。</li>
<li>然后停下来基于这个保存的模型 <code>/backup/yolov3-voc_1000.weights</code> 使用多GPU (最多4个GPU): <code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg /backup/yolov3-voc_1000.weights -gpus 0,1,2,3</code>。</li>
</ol>
<p>在多GPU训练的时候，<code>learning rate</code>需要进行修改，比如单<code>gpu使用0.001</code>，那么多gpu应该使用0.001/GPUS。然后<code>cfg</code>文件中的<code>burn_in</code>参数和<code>max_batches</code>参数要设置为原来的GPUS倍。</p>
<h3 id="6-3-训练自定义数据集-重点关注"><a href="#6-3-训练自定义数据集-重点关注" class="headerlink" title="6.3 训练自定义数据集(重点关注)"></a>6.3 训练自定义数据集(重点关注)</h3><p>训练较早提出的Yolo系列算法如<code>yolov2-voc.cfg</code>, <code>yolov2-tiny-voc.cfg</code>, <code>yolo-voc.cfg</code>, <code>yolo-voc.2.0.cfg</code>，请看<code>https://github.com/AlexeyAB/darknet/tree/47c7af1cea5bbdedf1184963355e6418cb8b1b4f#how-to-train-pascal-voc-data</code>。</p>
<p>Training Yolo v3:</p>
<ol>
<li>创建与 <code>yolov3.cfg</code>内容相同的 <code>yolo-obj.cfg</code> 或者直接复制然后重命名为<code>yolo-obj.cfg</code> 然后</li>
</ol>
<ul>
<li><p>设置<code>cfg</code>文件中 <code>batch=64</code>。</p>
</li>
<li><p>设置<code>cfg</code>文件中 <code>subdivisions=16</code>。</p>
</li>
<li><p>设置<code>cfg</code>文件中<code>max_batches</code>参数 (一般可以设置为<code>classes*2000</code> 但是不要低于 <code>4000</code>), 比如 如果你有三个类，那么设置<code>max_batches=6000</code>。</p>
</li>
<li><p>设置<code>steps</code>参数，一般为80%和90%的<code>max_batches</code>。比如 <code>steps=4800,5400</code></p>
</li>
<li><p>设置网络输入长宽必须能够整除32，比如 <code>width=416 height=416</code> `</p>
</li>
<li><p>修改yolo层中的 <code>classes=80</code> 改为你的类别的个数，比如<code>classes=3</code>:</p>
</li>
<li><p>修改yolo层前一个卷积层convolutional输出通道数。修改的<code>filter</code>个数有一定要求，按照公式<code>filters=(classes+5)×3</code>来设置。这里的<code>5</code>代表<code>x, y, w, h, conf</code>, 这里的<code>3</code>代表分配<code>3</code>个anchor。</p>
</li>
<li><p>如果使用 <code>[Gaussian_yolo]</code> (Gaussian_yolov3_BDD.cfg)，<code>filters</code>计算方式不太一样，按照 <code>filters=(classes + 9)x3</code>进行计算。</p>
</li>
<li><p>通常来讲，filters的个数计算依赖于类别个数，坐标以及<code>mask</code>的个数（<code>cfg</code>中的<code>mask</code>参数也就是<code>anchors</code>的个数）。</p>
<p>举个例子,对于两个目标,你的 <code>yolo-obj.cfg</code> 和<code>yolov3.cfg</code> 不同的地方应该在每个<code>[yolo]/[region]</code>层的下面几行:</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">filters=21</span><br><span class="line"></span><br><span class="line">[region]</span><br><span class="line">classes=2</span><br></pre></td></tr></table></figure>
<ol>
<li>在<code>build\darknet\x64\data\</code>创建文件 <code>obj.names</code> , 每行一个类别的名称。</li>
<li>在<code>build\darknet\x64\data\</code> 创建<code>obj.data</code>, 具体内容如下:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classes= 2 # 你的类别的个数</span><br><span class="line">train  = data/train.txt # 存储用于训练的图片位置</span><br><span class="line">valid  = data/test.txt # 存储用于测试的图片的位置</span><br><span class="line">names = data/obj.names # 每行一个类别的名称</span><br><span class="line">backup = backup/</span><br></pre></td></tr></table></figure>
<ol>
<li>将你的图片放在 <code>build\darknet\x64\data\obj\</code>文件夹下。</li>
<li>你应该标注你的数据集中的每一张图片，使用<code>Yolo_mark</code>这个可视化GUI软件来标注出目标框并且产生标注文件。地址： <code>https://github.com/AlexeyAB/Yolo_mark</code>。</li>
</ol>
<p>软件将会为每一个图像创建一个<code>txt</code>文件，并将其放在同一个文件夹中，命名与原图片的名称相同，唯一不同的就是后缀是txt。txt标注文件中每一个目标独占一行，按照<code>&lt;object-class&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code>的格式排布。</p>
<p>具体参数解释：</p>
<ul>
<li><p><code>&lt;object-class&gt;</code>- 是从 <code>0</code> 到 <code>(classes-1)</code>的整数，代表具体的类别。</p>
</li>
<li><p><code>&lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code> -  是归一化到<code>(0.0 to 1.0]</code>之间的浮点数，都是相对于图片整体的宽和高的一个相对值。</p>
</li>
<li><p>比如: <code>&lt;x&gt; = &lt;absolute_x&gt; / &lt;image_width&gt;</code> 或者 <code>&lt;height&gt; = &lt;absolute_height&gt; / &lt;image_height&gt;</code></p>
</li>
<li><p>需要注意的是: <code>&lt;x_center&gt; &lt;y_center&gt;</code> - 是标注框的中心点，而不是左上角。请注意格式。</p>
<p>举个例子，img1.txt中内容如下，代表有两个类别的三个目标：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 0.716797 0.395833 0.216406 0.147222</span><br><span class="line">0 0.687109 0.379167 0.255469 0.158333</span><br><span class="line">1 0.420312 0.395833 0.140625 0.166667</span><br></pre></td></tr></table></figure>
<ol>
<li>在<code>build\darknet\x64\data\</code>文件夹中创建train.txt文件，每行包含的是训练集图片的内容。其路径是相对于 <code>darknet.exe</code>的路径或者绝对路径：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">data/obj/img1.jpg</span><br><span class="line">data/obj/img2.jpg</span><br><span class="line">data/obj/img3.jpg</span><br></pre></td></tr></table></figure>
<ol>
<li><p>下载预训练权重，并将其放在 <code>build\darknet\x64</code>文件夹中。</p>
<ul>
<li>对于<code>csresnext50-panet-spp.cfg</code> (133 MB)：请查看原工程。</li>
<li>对于<code>yolov3.cfg, yolov3-spp.cfg</code> (154 MB)：请查看原工程。</li>
<li>对于<code>yolov3-tiny-prn.cfg , yolov3-tiny.cfg</code> (6 MB)：请查看原工程。</li>
<li>对于<code>enet-coco.cfg (EfficientNetB0-Yolov3)</code>：请查看原工程。</li>
</ul>
</li>
<li><p>使用以下命令行开始训练: <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74</code>。</p>
<p>对于linux用户使用以下命令开始训练: <code>./darknet detector train data/obj.data yolo-obj.cfg darknet53.conv.74</code> (使用<code>./darknet</code> 而不是 <code>darknet.exe</code>)。</p>
<p>如果想训练的过程中同步显示mAP（每四个epoch进行一次更新），运行命令: <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -map</code>。</p>
<ul>
<li>权重文件 <code>yolo-obj_last.weights</code> 将会保存在 <code>build\darknet\x64\backup\</code> 文件夹中，每100个迭代保存一次。</li>
<li>权重文件<code>yolo-obj_xxxx.weights</code> 将会保存在 <code>build\darknet\x64\backup\</code> 文件夹中，每1000个迭代保存一次。</li>
<li>如果不想在训练的过程中同步展示loss曲线，请执行以下命令 <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -dont_show</code>。</li>
<li>如果想在训练过程中查看mAP和Loss曲线，可以使用以下命令：<code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -dont_show -mjpeg_port 8090 -map</code> ，然后在浏览器中打开 URL <code>http://ip-address:8090</code> 。</li>
</ul>
</li>
<li><p>训练结束以后，将会在文件夹<code>build\darknet\x64\backup\</code>中得到权重文件 <code>yolo-obj_final.weights</code> 。</p>
</li>
</ol>
<ul>
<li>在100次迭代以后，你可以停下来，然后从这个点加载模型继续训练。比如说, 你在2000次迭代以后停止训练，如果你之后想要恢复训练，只需要运行命令： <code>darknet.exe detector train data/obj.data yolo-obj.cfg backup\yolo-obj_2000.weights</code>，而不需要重头开始训练。</li>
</ul>
<p><strong>注意</strong>：</p>
<ol>
<li>如果在训练的过程中，发现<code>avg</code>指标变为<code>nan</code>，那证明训练过程有误，可能是数据标注越界导致的问题。但是其他指标有<code>nan</code>是正常的。</li>
<li>修改<code>width</code>,<code>height</code>的时候必须要保证两者都能够被32整除。</li>
<li>训练结束后，可以使用以下命令来进行测试：<code>darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights</code></li>
<li>如果出现<code>Ouf of memery</code>问题，那说明显卡的显存不够，你可以通过设置<code>subdivisions</code>参数，将其从原来的<code>16</code>提高为<code>32</code>或者<code>64</code>，这样就能降低使用的显存，保证程序正常运行。</li>
</ol>
<h3 id="6-4-训练tiny-yolo"><a href="#6-4-训练tiny-yolo" class="headerlink" title="6.4 训练tiny-yolo"></a>6.4 训练tiny-yolo</h3><p>训练tiny yolo与以上的训练过程并无明显区别，除了以下几点：</p>
<ul>
<li>下载tiny yolo的预训练权重：<code>https://pjreddie.com/media/files/yolov3-tiny.weights</code></li>
<li>使用以下命令行来获取预训练权重: <code>darknet.exe partial cfg/yolov3-tiny.cfg yolov3-tiny.weights yolov3-tiny.conv.15 15</code>， 这里的15代表前15个层，也就是backbone所在的层。</li>
<li>使用的配置文件应该是 <code>cfg/yolov3-tiny_obj.cfg</code> 而不是 <code>yolov3.cfg</code></li>
<li>使用以下命令开始训练: <code>darknet.exe detector train data/obj.data yolov3-tiny-obj.cfg yolov3-tiny.conv.15</code></li>
</ul>
<p>如果想使用其他backbone进行训练比如 DenseNet201-Yolo或者ResNet50-Yolo, 你可以在以下链接中找到:<code>https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/partial.cmd</code></p>
<p>如果你采用的是自己设计的backbone,那就无法进行迁移学习，backbone可以直接进行参数随机初始化。</p>
<h3 id="6-5-什么时候停止训练"><a href="#6-5-什么时候停止训练" class="headerlink" title="6.5 什么时候停止训练"></a>6.5 什么时候停止训练</h3><p>建议为每个类分配至少2000次迭代，但是整体迭代次数不应少于4000次。如果想要更加精准地定义什么时候该停止训练，需要使用以下方法：</p>
<ol>
<li>训练过程中，你将会看到日志中有很多错误的度量指标，你需要在avg指标不再下降的时候停止训练，如下图所示:</li>
</ol>
<blockquote>
<p>Region Avg IOU: 0.798363, Class: 0.893232, Obj: 0.700808, No Obj: 0.004567, Avg Recall: 1.000000,  count: 8 Region Avg IOU: 0.800677, Class: 0.892181, Obj: 0.701590, No Obj: 0.004574, Avg Recall: 1.000000,  count: 8</p>
<p><strong>9002</strong>: 0.211667, <strong>0.60730 avg</strong>, 0.001000 rate, 3.868000 seconds, 576128 images Loaded: 0.000000 seconds</p>
</blockquote>
<ul>
<li><p><strong>9002</strong> - 代表当前的迭代次数。</p>
</li>
<li><p><strong>0.60730 avg</strong> - average loss (error) - <strong>这个指标是平均loss, 其越低越好。</strong></p>
<p>在这个指标不再下降的时候就可以停止训练了。最终的值大概分布在0.05-3.0之间，小而简单的模型通常最终loss比较小，大而复杂的loss可能会比较大。</p>
</li>
</ul>
<p>训练完成后，你就可以从 <code>darknet\build\darknet\x64\backup</code> 文件夹中取出比较靠后的几个<code>weights</code>文件，并对他们进行测试，选择最好的权重文件。</p>
<p>举个例子，你在<code>9000</code>次迭代后停止训练，但最好的权重可能是<code>7000,8000,9000</code>次的值。这种情况的出现是由于<strong>过拟合</strong>导致的。<strong>过拟合</strong>是由于过度学习训练集的分布，而降低了模型在测试集的泛化能力。</p>
<p><strong>Early Stopping Point</strong>示意图:</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/642.webp" alt></p>
<p>为了得到在early stopping point处的权重：</p>
<p>2.1 首先，你的obj.data文件中应该含有valid=valid.txt一项，用于测试在验证集的准确率。如果你没有验证集图片，那就直接复制train.txt重命名为valid.txt。</p>
<p>2.2 假如你选择在<code>9000</code>次迭代后停止，那可以通过以下命令测试<code>7000,8000,9000</code>三个模型的相关指标。选择最高<code>mAP</code>或者最高<code>IoU</code>的模型最为最终模型。</p>
<ul>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights</code></li>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_8000.weights</code></li>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_9000.weights</code></li>
</ul>
<p>或者你可以选择使用<code>-map</code>标志符来直接实时测试mAP值：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -map</span><br></pre></td></tr></table></figure>
<p>然后你就能得到loss曲线和mAP曲线，mAP每4个epoch对验证集进行一次测试，并将结果显示在图中。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/643.webp" alt></p>
<p>指标解释</p>
<ul>
<li><p><strong>IoU</strong> (intersect over union) - 平均交并比</p>
</li>
<li><p><strong>mAP</strong> (mean average precision) - 每个类的平均精度。</p>
</li>
</ul>
<p><strong>mAP</strong> 是Pascal VOC竞赛的默认指标，与MS COCO竞赛中的AP50指标是一致的。</p>
<p>Precision和Recall参数在Pascal VOC竞赛中略微不同，但 <strong>IoU 的意义都是相同的</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/644.jpg" alt></p>
<h3 id="6-6-如何在pascal-voc2007数据集上计算mAP指标"><a href="#6-6-如何在pascal-voc2007数据集上计算mAP指标" class="headerlink" title="6.6 如何在pascal voc2007数据集上计算mAP指标"></a>6.6 如何在pascal voc2007数据集上计算mAP指标</h3><ol>
<li>在VOC2007中计算mAP：</li>
</ol>
<ul>
<li>下载VOC数据集，安装python并且下载<code>`2007_test.txt</code>文件，具体可以参考链接：<code>https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data</code></li>
<li>下载文件 <code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/voc_label_difficult.py</code> 到 <code>build\darknet\x64\data\</code> 文件夹，然后运行 <code>voc_label_difficult.py</code> 从而得到 <code>difficult_2007_test.txt</code>。</li>
<li>将下面voc.data文件中的第四行#删除</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">classes= 20</span><br><span class="line">train  = data/train_voc.txt</span><br><span class="line">valid  = data/2007_test.txt</span><br><span class="line">#difficult = data/difficult_2007_test.txt</span><br><span class="line">names = data/voc.names</span><br><span class="line">backup = backup/</span><br></pre></td></tr></table></figure>
<p>然后就有两个方法来计算得到mAP:</p>
<ol>
<li>使用Darknet + Python: 运行 <code>build/darknet/x64/calc_mAP_voc_py.cmd</code> ，你将得到 <code>yolo-voc.cfg</code> 模型的mAP值, mAP = 75.9%</li>
<li>直接使用命令: 运行文件 <code>build/darknet/x64/calc_mAP.cmd</code> -你将得到 <code>yolo-voc.cfg</code> 模型, 得到mAP = 75.8%</li>
</ol>
<p>YOLOv3的论文：<code>https://arxiv.org/pdf/1612.08242v1.pdf</code>指出对于416x416的YOLOv2，Pascal Voc上的mAP值是76.8%。我们得到的值较低，可能是由于模型在进行检测时的代码略有不同。</p>
<p>如果你想为<code>tiny-yolo-voc</code>计算mAP值，将脚本中<code>tiny-yolo-voc.cfg</code>取消注释，将<code>yolo-voc.cfg</code>注释掉。</p>
<p>如果你是用的是python 2.x 而不是python 3.x, 而且你选择使用Darknet+Python的方式来计算mAP, 那你应该使用 <code>reval_voc.py</code> 和 <code>voc_eval.py</code> 而不是使用 <code>reval_voc_py3.py</code> 和 <code>voc_eval_py3.py</code> 。以上脚本来自以下目录：<code>https://github.com/AlexeyAB/darknet/tree/master/scripts</code>。</p>
<p>目标检测的例子：<code>darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights</code></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/645.webp" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/646.webp" alt></p>
<h2 id="7-如何提升目标检测性能？"><a href="#7-如何提升目标检测性能？" class="headerlink" title="7. 如何提升目标检测性能？"></a>7. 如何提升目标检测性能？</h2><ol>
<li><p>训练之前：</p>
<ul>
<li><code>train_network_width * train_obj_width / train_image_width ~= detection_network_width *  detection_obj_width / detection_image_width</code></li>
<li><p><code>train_network_height * train_obj_height / train_image_height ~= detection_network_height *  detection_obj_height / detection_image_height</code></p>
</li>
<li><p>完整模型（5个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3_5l.cfg</code>。</p>
</li>
<li><p>Tiny模型（3个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-tiny_3l.cfg</code>。</p>
</li>
<li><p>带空间金字塔池化的完整模型（3个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-spp.cfg</code>。</p>
</li>
<li><p>在<code>cfg</code>文件中将<code>random</code>设为1：这将在Yolo中使用多尺度训练，会提升检测模型准确率。</p>
</li>
<li><p>在<code>cfg</code>文件中把输入分辨率增大(<code>height=608</code>, <code>width=608</code>或者其他任意32的倍数)：这将提升检测模型准确率。</p>
</li>
<li><p>检查你要检测的每个目标在数据集中是否被标记，数据集中任何目标都不应该没有标签。在大多数训练出问题的情况中基本都是有错误的标签（通过使用某些转换脚本，使用第三方工具标注来获得标签），可以通过<code>https://github.com/AlexeyAB/Yolo_mark</code>来检查你的数据集是否全部标注正确。</p>
</li>
<li><p>我的损失函数很高并且mAP很低，训练出错了吗？在训练命令末端使用<code>-show_imgs</code> 标志来运行训练，你是否能看到有正确的边界预测框的目标（在窗口或者<code>aug_...jpg</code>）？如果没有，训练是发生错误了。</p>
</li>
<li><p>对于你要检测的每个目标，训练数据集中必须至少有一个相似的目标，它们具有大致相同的形状，物体侧面姿态，相对大小，旋转角度，倾斜度，照明度等。理想的是，你的训练数据集包括具有不同比例，旋转角度，照明度，物体侧面姿态和处于不同背景的目标图像，你最好拥有2000张不同的图像，并且至少训练<code>2000×classes</code>轮次。</p>
</li>
<li><p>希望你的训练数据集图片包含你不想检测的未标注的目标，也即是无边界框的负样本图片(空的<code>.txt</code>文件)，并且负样本图片的数量和带有目标的正样本图片数量最好一样多。</p>
</li>
<li><p>标注目标的最佳方法是：仅仅标记目标的可见部分或者标记目标的可见和重叠部分，或标记比整个目标多一点(有一点间隙)?根据你希望如何检测目标来进行标记。</p>
</li>
<li><p>为了对图片中包含大量目标的数据进行训练，添加<code>max=200</code>或者更高的值在你<code>cfg</code>文件中<code>yolo</code>层或者<code>region</code>层的最后一行（YOLOv3可以检测到的目标全局最大数量为<code>0,0615234375*(width*height)</code>其中<code>width</code>和<code>height</code>是在<code>cfg</code>文件中的<code>[net]</code>部分指定的）。</p>
</li>
<li><p>对于小目标的训练（把图像resize到416x416大小后小于16x16的目标）：设置<code>layers = -1, 11</code>而不是<code>layers=-1, 36</code>；设置<code>stride=4</code>而不是<code>stride=2</code>。</p>
</li>
<li><p>对于既有大目标又有小目标的训练使用下面的模型：</p>
</li>
<li><p>如果你要训练模型将左右目标分为单独的类别（左/右手，左/右交通标志），那就禁用翻转的数据扩充方式，即在数据输入部分添加<code>flip=0</code>。</p>
</li>
<li><p>一般规则：你的训练数据集应包括一组您想要检测的相对大小的目标，如下：</p>
<p>即，对于测试集中的每个目标，训练集中必须至少有一个同类目标和它具有大约相同的尺寸：</p>
<p><code>object width in percent from Training dataset</code> ~= <code>object width in percent from Test dataset</code></p>
<p>也就是说，如果训练集中仅存在占图像比例80%-90%的目标，则训练后的目标检测网络将无法检测到占图像比例为1-10%的目标。</p>
</li>
<li><p>为了加快训练速度（同时会降低检测精度）使用微调而不是迁移学习，在[net]下面设置<code>stopbackward=1</code>。然后执行下面的命令：<code>./darknet partial cfg/yolov3.cfg yolov3.weights yolov3.conv.81 81</code>这将会创建<code>yolov3.conv.81</code>文件，然后使用<code>yolov3.conv.81</code>文件进行训练而不是<code>darknet53.conv.74</code>。</p>
</li>
<li><p>在观察目标的时候，从不同的方向、不同的照明情况、不同尺度、不同的转角和倾斜角度来看，对神经网络来说，它们都是不同的目标。因此，要检测的目标越多，应使用越复杂的网络模型。</p>
</li>
<li><p>为了让检测框更准，你可以在每个<code>yolo</code>层添加下面三个参数<code>ignore_thresh = .9 iou_normalizer=0.5 iou_loss=giou</code>，这回提高map@0.9，但会降低map@0.5。</p>
</li>
<li><p>当你是神经网络方面的专家时，可以重新计算相对于<code>width</code>和<code>height</code>的<code>anchors</code>：<code>darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416</code>然后在3个<code>[yolo]</code>层放置这9个<code>anchors</code>。但是你需要修改每个<code>[yolo]</code>层的<code>masks</code>参数，让第一个<code>[yolo]</code>层的<code>anchors</code>尺寸大于60x60，第二个<code>[yolo]</code>层的<code>anchors</code>尺寸大于30x30，剩下就是第三个<code>[yolo]</code>层的<code>mask</code>。宁外，你需要修改每一个<code>[yolo]</code>层前面的<code>filters=(classes + 5)x</code>。如果很多计算的<code>anchors</code>都找不到合适的层，那还是使用Yolo的默认<code>anchors</code>吧。</p>
</li>
</ul>
</li>
<li><p>训练之后：</p>
<ul>
<li>没有必要重新训练模型，直接使用用<code>416x416</code>分辨率训练出来的<code>.weights</code>模型文件。</li>
<li>但是要获得更高的准确率，你应该使用<code>608x608</code>或者<code>832x832</code>来训练，注意如果<code>Out of memory</code>发生了，你应该在<code>.cfg</code>文件中增加<code>subdivisions=16，32，64</code>。</li>
<li>通过在<code>.cfg</code>文件中设置（<code>height=608</code> and <code>width=608</code>）或者（<code>height=832</code> and <code>width=832</code>）或者任何32的倍数，这会提升准确率并使得对小目标的检测更加容易。</li>
</ul>
</li>
</ol>
<h2 id="8-如何标注以及创建标注文件"><a href="#8-如何标注以及创建标注文件" class="headerlink" title="8. 如何标注以及创建标注文件"></a>8. 如何标注以及创建标注文件</h2><p>下面的工程提供了用于标记目标边界框并为YOLO v2&amp;v3 生成标注文件的带图像界面软件，地址为：<code>https://github.com/AlexeyAB/Yolo_mark</code>。</p>
<p>例如对于只有两类目标的数据集标注后有以下文件<code>train.txt</code>,<code>obj.names</code>,<code>obj.data</code>,<code>yolo-obj.cfg</code>,<code>air 1-6.txt</code>,<code>bird 1-4.txt</code>，接着配合<code>train_obj.cmd</code>就可以使用YOLO v2和YOLO v3来训练这个数据集了。</p>
<p>下面提供了5重常见的目标标注工具：</p>
<ul>
<li>C++实现的：<code>https://github.com/AlexeyAB/Yolo_mark</code></li>
<li>Python实现的：<code>https://github.com/tzutalin/labelImg</code></li>
<li>Python实现的：<code>https://github.com/Cartucho/OpenLabeling</code></li>
<li>C++实现的：<code>https://www.ccoderun.ca/darkmark/</code></li>
<li>JavaScript实现的：<code>https://github.com/opencv/cvat</code></li>
</ul>
<h2 id="9-使用YOLO9000"><a href="#9-使用YOLO9000" class="headerlink" title="9. 使用YOLO9000"></a>9. 使用YOLO9000</h2><p>同时检测和分类9000个目标：<code>darknet.exe detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights data/dog.jpg</code></p>
<ul>
<li><p><code>yolo9000.weights</code>：186Mb的YOLO9000模型需要4G GPU显存，训练好的模型下载地址：<code>http://pjreddie.com/media/files/yolo9000.weights</code>。</p>
</li>
<li><p><code>yolo9000.cfg</code>：YOLO9000的c网络结构文件，同时这里也有<code>9k.tree</code>和<code>coco9k.map</code>文件的路径。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tree=data/9k.tree</span><br><span class="line">map = data/coco9k.map</span><br></pre></td></tr></table></figure>
<ul>
<li><code>9k.tree</code>：9418个类别的单词数，每一行的形式为<code>`，如果</code>parent_id==-1<code>那么这个标签没有父类别，地址为：</code><a href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.tree`。">https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.tree`。</a></li>
<li><code>coco9k.map</code>：将MSCOCO的80个目标类别映射到<code>9k.tree</code>的文件，地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/coco9k.map</code>。</li>
</ul>
</li>
<li><p><code>combine9k.data</code>：数据文件，分别是<code>9k.labels</code>。<code>9k.names</code>，<code>inet9k.map</code>的路径（修改<code>combine9k.train.list</code>文件的路径为你自己的）。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/combine9k.data</code>。</p>
</li>
<li><p><code>9k.labels</code>：9418类目标的标签。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.labels</code>。</p>
</li>
<li><p><code>9k.names</code>：9418类目标的名字。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.names</code>。</p>
</li>
<li><p><code>inet9k.map</code>：将ImageNet的200个目标类别映射到<code>9k.tree</code>的文件，地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/inet9k.map</code>。</p>
</li>
</ul>
<h2 id="10-如何将YOLO作为DLL和SO库进行使用？"><a href="#10-如何将YOLO作为DLL和SO库进行使用？" class="headerlink" title="10. 如何将YOLO作为DLL和SO库进行使用？"></a>10. 如何将YOLO作为DLL和SO库进行使用？</h2><ul>
<li><p>在Linux上。</p>
<ul>
<li>使用<code>build.sh</code> 或者</li>
<li>使用<code>cmake</code>编译<code>darknet</code> 或者</li>
<li>将<code>Makefile</code>重的<code>LIBSO=0</code>改为<code>LIBSO=1</code>，然后执行<code>make</code>编译<code>darknet</code></li>
</ul>
</li>
<li><p>在Windows上。</p>
<ul>
<li>使用<code>build.ps1</code> 或者</li>
<li>使用<code>cmake</code>编译<code>darknet</code> 或者</li>
<li>使用<code>build\darknet\yolo_cpp_dll.sln</code>或<code>build\darknet\yolo_cpp_dll_no_gpu.sln</code>解决方法编译<code>darknet</code></li>
</ul>
</li>
<li><p>这里有两个API：</p>
<ul>
<li>使用C++ API的C++例子：<code>https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp</code></li>
<li>使用C API的Python例子：<br><code>https://github.com/AlexeyAB/darknet/blob/master/darknet.py</code><br><code>https://github.com/AlexeyAB/darknet/blob/master/darknet_video.py</code></li>
<li>C API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/darknet.h</code></li>
<li>C++ API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp</code></li>
</ul>
</li>
</ul>
<h2 id="11-附录"><a href="#11-附录" class="headerlink" title="11. 附录"></a>11. 附录</h2><ol>
<li><p>为了将Yolo编译成C++的DLL文件<code>yolo_cpp_dll.dll</code>：打开<code>build\darknet\yolo_cpp_dll.sln</code>解决方案，编译选项选<strong>X64</strong>和<strong>Release</strong>，然后执行Build-&gt;Build yolo_cpp_dll就，编译的一些前置条件为：</p>
<ul>
<li>安装<strong>CUDA 10.0</strong>。</li>
<li>为了使用cuDNN执行以下步骤：点击工程属性-&gt;properties-&gt;C++-&gt;Preprocessor-&gt;Preprocessor Definitions，然后在开头添加一行<code>CUDNN</code>。</li>
</ul>
</li>
<li><p>在自己的C++工程中将Yolo当成DLL文件使用：打开<code>build\darknet\yolo_console_dll.sln</code>解决方案，编译选项选<strong>X64</strong>和<strong>Release</strong>，然后执行Build-&gt;Build yolo_console_dll：</p>
<p><code>yolo_cpp_dll.dll</code>-API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp</code></p>
<ul>
<li>你可以利用Windows资源管理器运行<code>build\darknet\x64\yolo_console_dll.exe</code>可执行程序并<strong>使用下面的命令</strong>:  <code>yolo_console_dll.exe data/coco.names yolov3.cfg yolov3.weights test.mp4</code></li>
<li>启动控制台应用程序并输入图像文件名后，你将看到每个目标的信息：<code> </code></li>
<li>如果要使用OpenCV-GUI你应该将<code>yolo_console_dll.cpp</code>中的<code>//#define OPENCV</code>取消注释。</li>
<li>你可以看到视频检测例子的源代码，地址为yolo_console_dll.cpp的第75行。<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bbox_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> x, y, w, h;    <span class="comment">// (x,y) - top-left corner, (w, h) - width &amp; height of bounded box</span></span><br><span class="line">    <span class="keyword">float</span> prob;                    <span class="comment">// confidence - probability that the object was found correctly</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> obj_id;        <span class="comment">// class of object - from range [0, classes-1]</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> track_id;        <span class="comment">// tracking id for video (0 - untracked, 1 - inf - tracked object)</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> frames_counter;<span class="comment">// counter of frames on which the object was detected</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Detector</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Detector</span>(std::string cfg_filename, std::string weight_filename, <span class="keyword">int</span> gpu_id = <span class="number">0</span>);</span><br><span class="line">        ~<span class="built_in">Detector</span>();</span><br><span class="line"></span><br><span class="line">        <span class="function">std::vector&lt;<span class="keyword">bbox_t</span>&gt; <span class="title">detect</span><span class="params">(std::string image_filename, <span class="keyword">float</span> thresh = <span class="number">0.2</span>, <span class="keyword">bool</span> use_mean = <span class="literal">false</span>)</span></span>;</span><br><span class="line">        <span class="function">std::vector&lt;<span class="keyword">bbox_t</span>&gt; <span class="title">detect</span><span class="params">(<span class="keyword">image_t</span> img, <span class="keyword">float</span> thresh = <span class="number">0.2</span>, <span class="keyword">bool</span> use_mean = <span class="literal">false</span>)</span></span>;</span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">image_t</span> <span class="title">load_image</span><span class="params">(std::string image_filename)</span></span>;</span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">free_image</span><span class="params">(<span class="keyword">image_t</span> m)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> OPENCV</span></span><br><span class="line">        <span class="function">std::vector&lt;<span class="keyword">bbox_t</span>&gt; <span class="title">detect</span><span class="params">(cv::Mat mat, <span class="keyword">float</span> thresh = <span class="number">0.2</span>, <span class="keyword">bool</span> use_mean = <span class="literal">false</span>)</span></span>;</span><br><span class="line">	<span class="function">std::shared_ptr&lt;<span class="keyword">image_t</span>&gt; <span class="title">mat_to_image_resize</span><span class="params">(cv::Mat mat)</span> <span class="keyword">const</span></span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>SSD代码解析</title>
    <url>/2020/04/23/SSD%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本篇文章是在SSD算法原理解析的基础上做的代码解析，今天要解析的SSD源码来自于github一个非常火的Pytorch实现，已经有3K+星，地址为：<a href="https://github.com/amdegroot/ssd.pytorch/">https://github.com/amdegroot/ssd.pytorch/</a></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>为了比较好的对应SSD的结构来看代码，我们首先放出SSD的网络结构，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ssd/640.webp" alt></p>
<p>可以看到原始的SSD网络是以VGG-16作Backbone（骨干网络）的。为了更加清晰看到相比于VGG16，SSD的网络使用了哪些变化，带有特征图维度信息的更清晰的骨干网络和VGG16的对比图如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ssd/641.webp" alt></p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>OK，现在我们就要开始从源码剖析SSD了 。主要弄清楚三个方面，网络结构的搭建，Anchor还有损失函数，就算是理解这个源码了。</p>
<h3 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h3><p>从上面的图中我们可以清晰的看到在以VGG16做骨干网络时，在conv5后丢弃了VGG16中的全连接层改为了1024 x 3 x 3和1024 x 1 x 1 的卷积层。其中<code>conv4-1</code>卷积层前面的<code>maxpooling</code>层的<code>ceil_model=True</code>，使得输出特征图长宽为38 x 38。还有<code>conv5-3</code>后面的一层<code>maxpooling</code>层参数为$(\text {kernelsize}=3, \text {stride}=1, \text {padding}=1)$，不进行下采样。然后在<code>fc7</code>后面接上多尺度提取的另外4个卷积层就构成了完整的SSD网络。这里VGG16修改后的代码如下，来自ssd.py：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span>(<span class="params">cfg, i, batch_norm=<span class="literal">False</span></span>):</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = i</span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">&#x27;M&#x27;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">elif</span> v == <span class="string">&#x27;C&#x27;</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, ceil_mode=<span class="literal">True</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    pool5 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">    conv6 = nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">6</span>, dilation=<span class="number">6</span>)</span><br><span class="line">    conv7 = nn.Conv2d(<span class="number">1024</span>, <span class="number">1024</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">    layers += [pool5, conv6,</span><br><span class="line">               nn.ReLU(inplace=<span class="literal">True</span>), conv7, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">    <span class="keyword">return</span> layers</span><br></pre></td></tr></table></figure>
<p>可以看到和我们上面的那张图是完全一致的。代码里面最后获得的<code>conv7</code>就是我们上面图里面的<code>fc7</code>，特征维度是：$[\text { None }, 1024,19,19]$。现在可以开始搭建SSD网络后面的多尺度提取网络了。也就是网络结构图中的Extra Feature Layers。我们从开篇的结构图中截取一下这一部分，方便我们对照代码。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ssd/642.webp" alt></p>
<p>实现的代码如下（同样来自ssd.py）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_extras</span>(<span class="params">cfg, i, batch_norm=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="comment"># Extra layers added to VGG for feature scaling</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = i</span><br><span class="line">    flag = <span class="literal">False</span> <span class="comment">#flag 用来控制 kernel_size= 1 or 3</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(cfg):</span><br><span class="line">        <span class="keyword">if</span> in_channels != <span class="string">&#x27;S&#x27;</span>:</span><br><span class="line">            <span class="keyword">if</span> v == <span class="string">&#x27;S&#x27;</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels, cfg[k + <span class="number">1</span>],</span><br><span class="line">                           kernel_size=(<span class="number">1</span>, <span class="number">3</span>)[flag], stride=<span class="number">2</span>, padding=<span class="number">1</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels, v, kernel_size=(<span class="number">1</span>, <span class="number">3</span>)[flag])]</span><br><span class="line">            flag = <span class="keyword">not</span> flag</span><br><span class="line">        in_channels = v</span><br><span class="line"><span class="keyword">return</span> layers</span><br></pre></td></tr></table></figure>
<p>可以看到网络结构中除了魔改后的VGG16和Extra  Layers还有6个横着的线，这代表的是对6个尺度的特征图进行卷积获得预测框的回归(loc)和类别(cls)信息，注意SSD将背景也看成类别了，所以对于VOC数据集类别数就是20+1=21。这部分的代码为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multibox</span>(<span class="params">vgg, extra_layers, cfg, num_classes</span>):</span></span><br><span class="line">    loc_layers = []<span class="comment">#多尺度分支的回归网络</span></span><br><span class="line">    conf_layers = []<span class="comment">#多尺度分支的分类网络</span></span><br><span class="line">    <span class="comment"># 第一部分，vgg 网络的 Conv2d-4_3(21层)， Conv2d-7_1(-2层)</span></span><br><span class="line">    vgg_source = [<span class="number">21</span>, -<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(vgg_source):</span><br><span class="line">        <span class="comment"># 回归 box*4(坐标)</span></span><br><span class="line">        loc_layers += [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">                                 cfg[k] * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">        <span class="comment"># 置信度 box*(num_classes)</span></span><br><span class="line">        conf_layers += [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">                        cfg[k] * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="comment"># 第二部分，cfg从第三个开始作为box的个数，而且用于多尺度提取的网络分别为1,3,5,7层</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(extra_layers[<span class="number">1</span>::<span class="number">2</span>], <span class="number">2</span>):</span><br><span class="line">        loc_layers += [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">                                 * <span class="number">4</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">        conf_layers += [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">                                  * num_classes, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)]</span><br><span class="line">    <span class="keyword">return</span> vgg, extra_layers, (loc_layers, conf_layers)</span><br><span class="line"><span class="comment"># 用下面的测试代码测试一下</span></span><br><span class="line"><span class="keyword">if</span> __name__  == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    vgg, extra_layers, (l, c) = multibox(vgg(base[<span class="string">&#x27;300&#x27;</span>], <span class="number">3</span>),</span><br><span class="line">                                         add_extras(extras[<span class="string">&#x27;300&#x27;</span>], <span class="number">1024</span>),</span><br><span class="line">                                         [<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>], <span class="number">21</span>)</span><br><span class="line">    <span class="built_in">print</span>(nn.Sequential(*l))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;---------------------------&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(nn.Sequential(*c))</span><br></pre></td></tr></table></figure>
<p>在jupter notebook输出信息为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">loc layers:</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">)</span><br><span class="line">---------------------------</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">conf layers:</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="Anchor生成-Prior-Box层"><a href="#Anchor生成-Prior-Box层" class="headerlink" title="Anchor生成(Prior_Box层)"></a>Anchor生成(Prior_Box层)</h3><p>这个在前面SSD的原理篇中讲过了，这里不妨再回忆一下，SSD从魔改后的VGG16的<code>conv4_3</code>开始一共使用了6个不同大小的特征图，大小分别为<code>(38,28),(19,19),(10,10),(5,5),(3,3),(1,1)</code>，但每个特征图上设置的先验框(Anchor)的数量不同。先验框的设置包含尺度和长宽比两个方面。对于先验框的设置，公式如下： $s_{k}=s_{\min }+\frac{s_{m a x}-s_{\min }}{m-1}(k-1), k \in[1, m]$，其中$m$指的是特征图个数，这里为5，因为第一层<code>conv4_3</code>的Anchor是单独设置的，$s_{k}$代表先验框大小相对于原图的比例。最后，$s_{min}$和$s_{max}$表示比例的最小值和最大值，论文中分别取0.2和0.9。对于第一个特征图，它的先验框尺度比例设置为$s_{min}/2=0.1$，则他的尺度为300 x 0.1 = 30，后面的特征图带入公式计算，计算时$\frac{s_{m a x}-s_{\min }}{m-1}$保留两位小数为0.17，比如300 x (0.17 x 0 + 0.2) = 60，300 x  (0.17 x 1 + 0.2) = 111，所以剩下的5个特征图的min_size尺度$s_{k}$为60，111，162，213，264。综合起来，6个特征图的min_size尺度$s_{k}$为30，60，111，162，213，264。有了Anchor的尺度，接下来设置Anchor的长宽，论文中长宽设置一般为$a_{r}=1,2,3, \frac{1}{2}, \frac{1}{3}$，根据面积和长宽比可以得到先验框的宽度和高度：$w_{k}^{a}=s_{k} \sqrt{a_{r}}, h_{k}^{a}=s_{k} / \sqrt{a_{r}}$ 。这里有一些值得注意的点，如下：</p>
<ul>
<li><p>上面的$s_{k}$是相对于原图的大小。</p>
</li>
<li><p>默认情况下，每个特征图除了上面5个比例的Anchor，还会设置一个尺度为$s_{k}^{\prime}=\sqrt{s_{k} s_{k+1}}$且$a_{r}=1$的先验框，这样每个特征图都设置了两个长宽比为1但大小不同的正方形先验框。最后一个特征图需要参考一个虚拟$s_{k+1}=300\times(0.17\times5 + 0.2) = 315$所以综合起来，6个特征图的max_size尺度$s_{k}$为60，111，162，213，264，315。</p>
</li>
<li><p>在实现<code>conv4_3</code>,<code>conv10_2</code>,<code>conv11_2</code>层时仅使用4个先验框，不使用长宽比为$3, \frac{1}{3}$的Anchor。</p>
</li>
<li><p>每个单元的先验框中心点分布在每个单元的中心，即：$\left[\frac{i+0.5}{\left|f_{k}\right|}, \frac{j+0.5}{\left|f_{k}\right|}\right], i, j \in\left[0,\left|f_{k}\right|\right]$ ，其中$f_{k}$是特征图的大小。</p>
</li>
</ul>
<p>从Anchor的值来看，越前面的特征图Anchor的尺寸越小，也就是说对小目标的效果越好。先验框的总数为<code>num_priors = 38x38x4+19x19x6+10x10x6+5x5x6+3x3x4+1x1x4=8732</code>。</p>
<p>生成先验框的代码如下（来自layers/functions/prior_box.py）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriorBox</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute priorbox coordinates in center-offset form for each source</span></span><br><span class="line"><span class="string">    feature map.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfg</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PriorBox, self).__init__()</span><br><span class="line">        self.image_size = cfg[<span class="string">&#x27;min_dim&#x27;</span>]</span><br><span class="line">        <span class="comment"># number of priors for feature map location (either 4 or 6)</span></span><br><span class="line">        self.num_priors = <span class="built_in">len</span>(cfg[<span class="string">&#x27;aspect_ratios&#x27;</span>])</span><br><span class="line">        self.variance = cfg[<span class="string">&#x27;variance&#x27;</span>] <span class="keyword">or</span> [<span class="number">0.1</span>]</span><br><span class="line">        self.feature_maps = cfg[<span class="string">&#x27;feature_maps&#x27;</span>]</span><br><span class="line">        self.min_sizes = cfg[<span class="string">&#x27;min_sizes&#x27;</span>]</span><br><span class="line">        self.max_sizes = cfg[<span class="string">&#x27;max_sizes&#x27;</span>]</span><br><span class="line">        self.steps = cfg[<span class="string">&#x27;steps&#x27;</span>]</span><br><span class="line">        self.aspect_ratios = cfg[<span class="string">&#x27;aspect_ratios&#x27;</span>]</span><br><span class="line">        self.clip = cfg[<span class="string">&#x27;clip&#x27;</span>]</span><br><span class="line">        self.version = cfg[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variance:</span><br><span class="line">            <span class="keyword">if</span> v &lt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&#x27;Variances must be greater than 0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self</span>):</span></span><br><span class="line">        mean = []</span><br><span class="line">        <span class="comment"># 遍历多尺度的 特征图: [38, 19, 10, 5, 3, 1]</span></span><br><span class="line">        <span class="keyword">for</span> k, f <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.feature_maps):</span><br><span class="line">            <span class="comment"># 遍历每个像素</span></span><br><span class="line">            <span class="keyword">for</span> i, j <span class="keyword">in</span> product(<span class="built_in">range</span>(f), repeat=<span class="number">2</span>):</span><br><span class="line">                <span class="comment"># k-th 层的feature map 大小</span></span><br><span class="line">                f_k = self.image_size / self.steps[k]</span><br><span class="line">                <span class="comment"># # 每个框的中心坐标</span></span><br><span class="line">                cx = (j + <span class="number">0.5</span>) / f_k</span><br><span class="line">                cy = (i + <span class="number">0.5</span>) / f_k</span><br><span class="line"></span><br><span class="line">                <span class="comment"># aspect_ratio: 1 当 ratio==1的时候，会产生两个 box</span></span><br><span class="line">                <span class="comment"># r==1, size = s_k， 正方形</span></span><br><span class="line">                s_k = self.min_sizes[k]/self.image_size</span><br><span class="line">                mean += [cx, cy, s_k, s_k]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># r==1, size = sqrt(s_k * s_(k+1)), 正方形</span></span><br><span class="line">                <span class="comment"># rel size: sqrt(s_k * s_(k+1))</span></span><br><span class="line">                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))</span><br><span class="line">                mean += [cx, cy, s_k_prime, s_k_prime]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 当 ratio != 1 的时候，产生的box为矩形</span></span><br><span class="line">                <span class="keyword">for</span> ar <span class="keyword">in</span> self.aspect_ratios[k]:</span><br><span class="line">                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]</span><br><span class="line">                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]</span><br><span class="line">        <span class="comment"># 转化为 torch的Tensor</span></span><br><span class="line">        output = torch.Tensor(mean).view(-<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="comment">#归一化，把输出设置在 [0,1]</span></span><br><span class="line">        <span class="keyword">if</span> self.clip:</span><br><span class="line">            output.clamp_(<span class="built_in">max</span>=<span class="number">1</span>, <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p>结合了前面介绍的魔改后的VGG16，还有Extra Layers，还有生成Anchor的Priobox策略，我们可以写出SSD的整体结构如下（代码在ssd.py）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SSD</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Single Shot Multibox Architecture</span></span><br><span class="line"><span class="string">    The network is composed of a base VGG network followed by the</span></span><br><span class="line"><span class="string">    added multibox conv layers.  Each multibox layer branches into</span></span><br><span class="line"><span class="string">        1) conv2d for class conf scores</span></span><br><span class="line"><span class="string">        2) conv2d for localization predictions</span></span><br><span class="line"><span class="string">        3) associated priorbox layer to produce default bounding</span></span><br><span class="line"><span class="string">           boxes specific to the layer&#x27;s feature map size.</span></span><br><span class="line"><span class="string">    See: https://arxiv.org/pdf/1512.02325.pdf for more details.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        phase: (string) Can be &quot;test&quot; or &quot;train&quot;</span></span><br><span class="line"><span class="string">        size: input image size</span></span><br><span class="line"><span class="string">        base: VGG16 layers for input, size of either 300 or 500</span></span><br><span class="line"><span class="string">        extras: extra layers that feed to multibox loc and conf layers</span></span><br><span class="line"><span class="string">        head: &quot;multibox head&quot; consists of loc and conf conv layers</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, phase, size, base, extras, head, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SSD, self).__init__()</span><br><span class="line">        self.phase = phase</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        <span class="comment"># 配置config</span></span><br><span class="line">        self.cfg = (coco, voc)[num_classes == <span class="number">21</span>]</span><br><span class="line">        <span class="comment"># 初始化先验框</span></span><br><span class="line">        self.priorbox = PriorBox(self.cfg)</span><br><span class="line">        self.priors = Variable(self.priorbox.forward(), volatile=<span class="literal">True</span>)</span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">        <span class="comment"># SSD network</span></span><br><span class="line">        <span class="comment"># backbone网络</span></span><br><span class="line">        self.vgg = nn.ModuleList(base)</span><br><span class="line">        <span class="comment"># Layer learns to scale the l2 normalized features from conv4_3</span></span><br><span class="line">        <span class="comment"># conv4_3后面的网络，L2 正则化</span></span><br><span class="line">        self.L2Norm = L2Norm(<span class="number">512</span>, <span class="number">20</span>)</span><br><span class="line">        self.extras = nn.ModuleList(extras)</span><br><span class="line">        <span class="comment"># 回归和分类网络</span></span><br><span class="line">        self.loc = nn.ModuleList(head[<span class="number">0</span>])</span><br><span class="line">        self.conf = nn.ModuleList(head[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> phase == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">            self.detect = Detect(num_classes, <span class="number">0</span>, <span class="number">200</span>, <span class="number">0.01</span>, <span class="number">0.45</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Applies network layers and ops on input image(s) x.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: input image or batch of images. Shape: [batch,3,300,300].</span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            Depending on phase:</span></span><br><span class="line"><span class="string">            test:</span></span><br><span class="line"><span class="string">                Variable(tensor) of output class label predictions,</span></span><br><span class="line"><span class="string">                confidence score, and corresponding location predictions for</span></span><br><span class="line"><span class="string">                each object detected. Shape: [batch,topk,7]</span></span><br><span class="line"><span class="string">            train:</span></span><br><span class="line"><span class="string">                list of concat outputs from:</span></span><br><span class="line"><span class="string">                    1: confidence layers, Shape: [batch*num_priors,num_classes]</span></span><br><span class="line"><span class="string">                    2: localization layers, Shape: [batch,num_priors*4]</span></span><br><span class="line"><span class="string">                    3: priorbox layers, Shape: [2,num_priors*4]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        sources = <span class="built_in">list</span>()</span><br><span class="line">        loc = <span class="built_in">list</span>()</span><br><span class="line">        conf = <span class="built_in">list</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg up to conv4_3 relu</span></span><br><span class="line">        <span class="comment"># vgg网络到conv4_3</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">23</span>):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        <span class="comment"># l2 正则化</span></span><br><span class="line">        s = self.L2Norm(x)</span><br><span class="line">        sources.append(s)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply vgg up to fc7</span></span><br><span class="line">        <span class="comment"># conv4_3 到 fc</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">23</span>, <span class="built_in">len</span>(self.vgg)):</span><br><span class="line">            x = self.vgg[k](x)</span><br><span class="line">        sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply extra layers and cache source layer outputs</span></span><br><span class="line">        <span class="comment"># extras 网络</span></span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.extras):</span><br><span class="line">            x = F.relu(v(x), inplace=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">if</span> k % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># 把需要进行多尺度的网络输出存入 sources</span></span><br><span class="line">                sources.append(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># apply multibox head to source layers</span></span><br><span class="line">        <span class="comment"># 多尺度回归和分类网络</span></span><br><span class="line">        <span class="keyword">for</span> (x, l, c) <span class="keyword">in</span> <span class="built_in">zip</span>(sources, self.loc, self.conf):</span><br><span class="line">            loc.append(l(x).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous())</span><br><span class="line">            conf.append(c(x).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous())</span><br><span class="line"></span><br><span class="line">        loc = torch.cat([o.view(o.size(<span class="number">0</span>), -<span class="number">1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> loc], <span class="number">1</span>)</span><br><span class="line">        conf = torch.cat([o.view(o.size(<span class="number">0</span>), -<span class="number">1</span>) <span class="keyword">for</span> o <span class="keyword">in</span> conf], <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.phase == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">            output = self.detect(</span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>), -<span class="number">1</span>, <span class="number">4</span>),                   <span class="comment"># loc preds</span></span><br><span class="line">                self.softmax(conf.view(conf.size(<span class="number">0</span>), -<span class="number">1</span>,</span><br><span class="line">                             self.num_classes)),                <span class="comment"># conf preds</span></span><br><span class="line">                self.priors.<span class="built_in">type</span>(<span class="built_in">type</span>(x.data))                  <span class="comment"># default boxes</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            output = (</span><br><span class="line">                <span class="comment"># loc的输出，size:(batch, 8732, 4)</span></span><br><span class="line">                loc.view(loc.size(<span class="number">0</span>), -<span class="number">1</span>, <span class="number">4</span>),</span><br><span class="line">                <span class="comment"># conf的输出，size:(batch, 8732, 21)</span></span><br><span class="line">                conf.view(conf.size(<span class="number">0</span>), -<span class="number">1</span>, self.num_classes),</span><br><span class="line">                <span class="comment"># 生成所有的候选框 size([8732, 4])</span></span><br><span class="line">                self.priors</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line">    <span class="comment"># 加载模型参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_weights</span>(<span class="params">self, base_file</span>):</span></span><br><span class="line">        other, ext = os.path.splitext(base_file)</span><br><span class="line">        <span class="keyword">if</span> ext == <span class="string">&#x27;.pkl&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;.pth&#x27;</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Loading weights into state dict...&#x27;</span>)</span><br><span class="line">            self.load_state_dict(torch.load(base_file,</span><br><span class="line">                                 map_location=<span class="keyword">lambda</span> storage, loc: storage))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Finished!&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">			<span class="built_in">print</span>(<span class="string">&#x27;Sorry only .pth and .pkl files supported.&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>然后为了增加可读性，重新封装了一下，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">base = &#123;</span><br><span class="line">    <span class="string">&#x27;300&#x27;</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;C&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>,</span><br><span class="line">            <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>],</span><br><span class="line">    <span class="string">&#x27;512&#x27;</span>: [],</span><br><span class="line">&#125;</span><br><span class="line">extras = &#123;</span><br><span class="line">    <span class="string">&#x27;300&#x27;</span>: [<span class="number">256</span>, <span class="string">&#x27;S&#x27;</span>, <span class="number">512</span>, <span class="number">128</span>, <span class="string">&#x27;S&#x27;</span>, <span class="number">256</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">128</span>, <span class="number">256</span>],</span><br><span class="line">    <span class="string">&#x27;512&#x27;</span>: [],</span><br><span class="line">&#125;</span><br><span class="line">mbox = &#123;</span><br><span class="line">    <span class="string">&#x27;300&#x27;</span>: [<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>],  <span class="comment"># number of boxes per feature map location</span></span><br><span class="line">    <span class="string">&#x27;512&#x27;</span>: [],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_ssd</span>(<span class="params">phase, size=<span class="number">300</span>, num_classes=<span class="number">21</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> phase != <span class="string">&quot;test&quot;</span> <span class="keyword">and</span> phase != <span class="string">&quot;train&quot;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;ERROR: Phase: &quot;</span> + phase + <span class="string">&quot; not recognized&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> size != <span class="number">300</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;ERROR: You specified size &quot;</span> + <span class="built_in">repr</span>(size) + <span class="string">&quot;. However, &quot;</span> +</span><br><span class="line">              <span class="string">&quot;currently only SSD300 (size=300) is supported!&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 调用multibox，生成vgg,extras,head</span></span><br><span class="line">    base_, extras_, head_ = multibox(vgg(base[<span class="built_in">str</span>(size)], <span class="number">3</span>),</span><br><span class="line">                                     add_extras(extras[<span class="built_in">str</span>(size)], <span class="number">1024</span>),</span><br><span class="line">                                     mbox[<span class="built_in">str</span>(size)], num_classes)</span><br><span class="line">	<span class="keyword">return</span> SSD(phase, size, base_, extras_, head_, num_classes)</span><br></pre></td></tr></table></figure>
<h3 id="Loss解析"><a href="#Loss解析" class="headerlink" title="Loss解析"></a>Loss解析</h3><p>SSD的损失函数包含两个部分，一个是定位损失$L_{l o c}$，一个是分类损失$L_{conf}$，整个损失函数表达如下：$L(x, c, l, g)=\frac{1}{N}\left(L_{c o n f}(x, c)+\alpha L_{l o c}(x, l, g)\right)$ 其中，$N$是先验框的正样本数量，$c$是类别置信度预测值，$l$是先验框对应的边界框预测值，$g$是ground truth的位置参数，$x$代表网络的预测值。对于位置损失，采用Smooth L1 Loss，位置信息都是<code>encode</code>之后的数值，后面会讲这个encode的过程。而对于分类损失，首先需要使用<code>hard negtive mining</code>将正负样本按照<code>1:3</code> 的比例把负样本抽样出来，抽样的方法是：针对所有batch的confidence，按照置信度误差进行降序排列，取出前<code>top_k</code>个负样本。损失函数可以用下图表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ssd/643.png" alt></p>
<h4 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h4><ul>
<li>Reshape所有batch中的conf，即代码中的<code>batch_conf = conf_data.view(-1, self.num_classes)</code>，方便后续排序。</li>
<li>置信度误差越大，实际上就是预测背景的置信度越小。</li>
<li>把所有conf进行<code>logsoftmax</code>处理(均为负值)，预测的置信度越小，则<code>logsoftmax</code>越小，取绝对值，则<code>|logsoftmax|</code>越大，降序排列<code>-logsoftmax</code>，取前<code>top_k</code>的负样本。其中，log_sum_exp函数的代码如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">log_sum_exp</span>(<span class="params">x</span>):</span></span><br><span class="line">    x_max = x.detach().<span class="built_in">max</span>()</span><br><span class="line">    <span class="keyword">return</span> torch.log(torch.<span class="built_in">sum</span>(torch.exp(x-x_max), <span class="number">1</span>, keepdim=<span class="literal">True</span>))+x_max</span><br></pre></td></tr></table></figure>
<p>分类损失<code>conf_logP</code>函数如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conf_logP = log_sum_exp(batch_conf) - batch_conf.gather(<span class="number">1</span>, conf_t.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>这样计算的原因主要是为了增强<code>logsoftmax</code>损失的数值稳定性。放一张手推图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ssd/644.webp" alt></p>
<p>损失函数完整代码实现，来自<code>layers/modules/multibox_loss.py</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiBoxLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;SSD Weighted Loss Function</span></span><br><span class="line"><span class="string">    Compute Targets:</span></span><br><span class="line"><span class="string">        1) Produce Confidence Target Indices by matching  ground truth boxes</span></span><br><span class="line"><span class="string">           with (default) &#x27;priorboxes&#x27; that have jaccard index &gt; threshold parameter</span></span><br><span class="line"><span class="string">           (default threshold: 0.5).</span></span><br><span class="line"><span class="string">        2) Produce localization target by &#x27;encoding&#x27; variance into offsets of ground</span></span><br><span class="line"><span class="string">           truth boxes and their matched  &#x27;priorboxes&#x27;.</span></span><br><span class="line"><span class="string">        3) Hard negative mining to filter the excessive number of negative examples</span></span><br><span class="line"><span class="string">           that comes with using a large number of default bounding boxes.</span></span><br><span class="line"><span class="string">           (default negative:positive ratio 3:1)</span></span><br><span class="line"><span class="string">    Objective Loss:</span></span><br><span class="line"><span class="string">        L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N</span></span><br><span class="line"><span class="string">        Where, Lconf is the CrossEntropy Loss and Lloc is the SmoothL1 Loss</span></span><br><span class="line"><span class="string">        weighted by α which is set to 1 by cross val.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            c: class confidences,</span></span><br><span class="line"><span class="string">            l: predicted boxes,</span></span><br><span class="line"><span class="string">            g: ground truth boxes</span></span><br><span class="line"><span class="string">            N: number of matched default boxes</span></span><br><span class="line"><span class="string">        See: https://arxiv.org/pdf/1512.02325.pdf for more details.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, overlap_thresh, prior_for_matching,</span></span></span><br><span class="line"><span class="params"><span class="function">                 bkg_label, neg_mining, neg_pos, neg_overlap, encode_target,</span></span></span><br><span class="line"><span class="params"><span class="function">                 use_gpu=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MultiBoxLoss, self).__init__()</span><br><span class="line">        self.use_gpu = use_gpu</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.threshold = overlap_thresh</span><br><span class="line">        self.background_label = bkg_label</span><br><span class="line">        self.encode_target = encode_target</span><br><span class="line">        self.use_prior_for_matching = prior_for_matching</span><br><span class="line">        self.do_neg_mining = neg_mining</span><br><span class="line">        self.negpos_ratio = neg_pos</span><br><span class="line">        self.neg_overlap = neg_overlap</span><br><span class="line">        self.variance = cfg[<span class="string">&#x27;variance&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, predictions, targets</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Multibox Loss</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            predictions (tuple): A tuple containing loc preds, conf preds,</span></span><br><span class="line"><span class="string">            and prior boxes from SSD net.</span></span><br><span class="line"><span class="string">                conf shape: torch.size(batch_size,num_priors,num_classes)</span></span><br><span class="line"><span class="string">                loc shape: torch.size(batch_size,num_priors,4)</span></span><br><span class="line"><span class="string">                priors shape: torch.size(num_priors,4)</span></span><br><span class="line"><span class="string">            targets (tensor): Ground truth boxes and labels for a batch,</span></span><br><span class="line"><span class="string">                shape: [batch_size,num_objs,5] (last idx is the label).</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        loc_data, conf_data, priors = predictions</span><br><span class="line">        num = loc_data.size(<span class="number">0</span>)<span class="comment"># batch_size</span></span><br><span class="line">        priors = priors[:loc_data.size(<span class="number">1</span>), :]</span><br><span class="line">        num_priors = (priors.size(<span class="number">0</span>)) <span class="comment"># 先验框个数</span></span><br><span class="line">        num_classes = self.num_classes <span class="comment">#类别数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># match priors (default boxes) and ground truth boxes</span></span><br><span class="line">        <span class="comment"># 获取匹配每个prior box的 ground truth</span></span><br><span class="line">        <span class="comment"># 创建 loc_t 和 conf_t 保存真实box的位置和类别</span></span><br><span class="line">        loc_t = torch.Tensor(num, num_priors, <span class="number">4</span>)</span><br><span class="line">        conf_t = torch.LongTensor(num, num_priors)</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            truths = targets[idx][:, :-<span class="number">1</span>].data <span class="comment">#ground truth box信息</span></span><br><span class="line">            labels = targets[idx][:, -<span class="number">1</span>].data <span class="comment"># ground truth conf信息</span></span><br><span class="line">            defaults = priors.data <span class="comment"># priors的 box 信息</span></span><br><span class="line">            <span class="comment"># 匹配 ground truth</span></span><br><span class="line">            match(self.threshold, truths, defaults, self.variance, labels,</span><br><span class="line">                  loc_t, conf_t, idx)</span><br><span class="line">        <span class="keyword">if</span> self.use_gpu:</span><br><span class="line">            loc_t = loc_t.cuda()</span><br><span class="line">            conf_t = conf_t.cuda()</span><br><span class="line">        <span class="comment"># wrap targets</span></span><br><span class="line">        loc_t = Variable(loc_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        conf_t = Variable(conf_t, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 匹配中所有的正样本mask,shape[b,M]</span></span><br><span class="line">        pos = conf_t &gt; <span class="number">0</span></span><br><span class="line">        num_pos = pos.<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># Localization Loss,使用 Smooth L1</span></span><br><span class="line">        <span class="comment"># shape[b,M]--&gt;shape[b,M,4]</span></span><br><span class="line">        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)</span><br><span class="line">        loc_p = loc_data[pos_idx].view(-<span class="number">1</span>, <span class="number">4</span>) <span class="comment">#预测的正样本box信息</span></span><br><span class="line">        loc_t = loc_t[pos_idx].view(-<span class="number">1</span>, <span class="number">4</span>) <span class="comment">#真实的正样本box信息</span></span><br><span class="line">        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=<span class="literal">False</span>) <span class="comment">#Smooth L1 损失</span></span><br><span class="line">		</span><br><span class="line">		<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        Target；</span></span><br><span class="line"><span class="string">            下面进行hard negative mining</span></span><br><span class="line"><span class="string">        过程:</span></span><br><span class="line"><span class="string">            1、 针对所有batch的conf，按照置信度误差(预测背景的置信度越小，误差越大)进行降序排列;</span></span><br><span class="line"><span class="string">            2、 负样本的label全是背景，那么利用log softmax 计算出logP,</span></span><br><span class="line"><span class="string">               logP越大，则背景概率越低,误差越大;</span></span><br><span class="line"><span class="string">            3、 选取误差较大的top_k作为负样本，保证正负样本比例接近1:3;</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># Compute max conf across batch for hard negative mining</span></span><br><span class="line">        <span class="comment"># shape[b*M,num_classes]</span></span><br><span class="line">        batch_conf = conf_data.view(-<span class="number">1</span>, self.num_classes)</span><br><span class="line">        <span class="comment"># 使用logsoftmax，计算置信度,shape[b*M, 1]</span></span><br><span class="line">        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(<span class="number">1</span>, conf_t.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Hard Negative Mining</span></span><br><span class="line">        loss_c[pos] = <span class="number">0</span>  <span class="comment"># 把正样本排除，剩下的就全是负样本，可以进行抽样</span></span><br><span class="line">        loss_c = loss_c.view(num, -<span class="number">1</span>)<span class="comment"># shape[b, M]</span></span><br><span class="line">        <span class="comment"># 难预测的损失大</span></span><br><span class="line">        <span class="comment"># 两次sort排序，能够得到每个元素在降序排列中的位置idx_rank</span></span><br><span class="line">        <span class="comment"># 即得到原Tensor的元素按dim指定维度，排第几，索引变成了排名</span></span><br><span class="line">        <span class="comment"># 比如[4, 9, 7, 8, 5]</span></span><br><span class="line">        <span class="comment"># 第一次sort排序结果为[9,8,7,5,4] 对应索引为[1,3,2,4,0]</span></span><br><span class="line">        <span class="comment"># 第二次sort排序结果为[0,1,2,3,4] 对应索引为[4,0,2,1,3]</span></span><br><span class="line">        <span class="comment"># 即第一排的元素9，它是第一排（也就是按dim=1看）里面最大的，所以它的排名是0，原Tensor第一排的元素4，它是第一排里面最小的，所以它的排名是4</span></span><br><span class="line">        _, loss_idx = loss_c.sort(<span class="number">1</span>, descending=<span class="literal">True</span>) </span><br><span class="line">        _, idx_rank = loss_idx.sort(<span class="number">1</span>) </span><br><span class="line">        <span class="comment"># 抽取负样本</span></span><br><span class="line">        <span class="comment"># 每个batch中正样本的数目，shape[b,1]</span></span><br><span class="line">        num_pos = pos.long().<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        num_neg = torch.clamp(self.negpos_ratio*num_pos, <span class="built_in">max</span>=pos.size(<span class="number">1</span>)-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 小于num_neg为True，限制负样本的数量，shape[b, M]</span></span><br><span class="line">        <span class="comment"># 排名靠前的留下</span></span><br><span class="line">        neg = idx_rank &lt; num_neg.expand_as(idx_rank)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Confidence Loss Including Positive and Negative Examples</span></span><br><span class="line">        <span class="comment"># shape[b,M] --&gt; shape[b,M,num_classes]</span></span><br><span class="line">        pos_idx = pos.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">        neg_idx = neg.unsqueeze(<span class="number">2</span>).expand_as(conf_data)</span><br><span class="line">        <span class="comment"># 提取出所有筛选好的正负样本(预测的和真实的)</span></span><br><span class="line">        conf_p = conf_data[(pos_idx+neg_idx).gt(<span class="number">0</span>)].view(-<span class="number">1</span>, self.num_classes)</span><br><span class="line">        targets_weighted = conf_t[(pos+neg).gt(<span class="number">0</span>)]</span><br><span class="line">        <span class="comment"># 计算conf交叉熵</span></span><br><span class="line">        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N</span></span><br><span class="line">		<span class="comment"># 正样本个数</span></span><br><span class="line">        N = num_pos.data.<span class="built_in">sum</span>()</span><br><span class="line">        loss_l /= N</span><br><span class="line">        loss_c /= N</span><br><span class="line">		<span class="keyword">return</span> loss_l, loss_c</span><br></pre></td></tr></table></figure>
<h4 id="先验框匹配策略"><a href="#先验框匹配策略" class="headerlink" title="先验框匹配策略"></a>先验框匹配策略</h4><p>上面的代码中还有一个地方没讲到，就是match函数。这是SSD算法的先验框匹配函数。在训练时首先需要确定训练图片中的ground truth是由哪一个先验框来匹配，与之匹配的先验框所对应的边界框将负责预测它。SSD的先验框和ground  truth匹配原则主要有2点。第一点是对于图片中的每个ground  truth，找到和它IOU最大的先验框，该先验框与其匹配，这样可以保证每个ground  truth一定与某个prior匹配。第二点是对于剩余的未匹配的先验框，若某个ground  truth和它的IOU大于某个阈值(一般设为0.5)，那么该prior和这个ground  truth匹配，剩下没有匹配上的先验框都是负样本（如果多个ground  truth和某一个先验框的IOU均大于阈值，那么prior只与IOU最大的那个进行匹配）。代码实现如下，来自<code>layers/box_utils.py</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match</span>(<span class="params">threshold, truths, priors, variances, labels, loc_t, conf_t, idx</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;把和每个prior box 有最大的IOU的ground truth box进行匹配，</span></span><br><span class="line"><span class="string">    同时，编码包围框，返回匹配的索引，对应的置信度和位置</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        threshold: IOU阈值，小于阈值设为背景</span></span><br><span class="line"><span class="string">        truths: ground truth boxes, shape[N,4]</span></span><br><span class="line"><span class="string">        priors: 先验框， shape[M,4]</span></span><br><span class="line"><span class="string">        variances: prior的方差, list(float)</span></span><br><span class="line"><span class="string">        labels: 图片的所有类别，shape[num_obj]</span></span><br><span class="line"><span class="string">        loc_t: 用于填充encoded loc 目标张量</span></span><br><span class="line"><span class="string">        conf_t: 用于填充encoded conf 目标张量</span></span><br><span class="line"><span class="string">        idx: 现在的batch index</span></span><br><span class="line"><span class="string">        The matched indices corresponding to 1)location and 2)confidence preds.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># jaccard index</span></span><br><span class="line">    <span class="comment"># 计算IOU</span></span><br><span class="line">    overlaps = jaccard(</span><br><span class="line">        truths,</span><br><span class="line">        point_form(priors)</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># (Bipartite Matching)</span></span><br><span class="line">    <span class="comment"># [1,num_objects] 和每个ground truth box 交集最大的 prior box</span></span><br><span class="line">    best_prior_overlap, best_prior_idx = overlaps.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># [1,num_priors] 和每个prior box 交集最大的 ground truth box</span></span><br><span class="line">    best_truth_overlap, best_truth_idx = overlaps.<span class="built_in">max</span>(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">    best_truth_idx.squeeze_(<span class="number">0</span>) <span class="comment">#M</span></span><br><span class="line">    best_truth_overlap.squeeze_(<span class="number">0</span>) <span class="comment">#M</span></span><br><span class="line">    best_prior_idx.squeeze_(<span class="number">1</span>) <span class="comment">#N</span></span><br><span class="line">    best_prior_overlap.squeeze_(<span class="number">1</span>) <span class="comment">#N</span></span><br><span class="line">    <span class="comment"># 保证每个ground truth box 与某一个prior box 匹配，固定值为 2 &gt; threshold</span></span><br><span class="line">    best_truth_overlap.index_fill_(<span class="number">0</span>, best_prior_idx, <span class="number">2</span>)  <span class="comment"># ensure best prior</span></span><br><span class="line">    <span class="comment"># TODO refactor: index  best_prior_idx with long tensor</span></span><br><span class="line">    <span class="comment"># ensure every gt matches with its prior of max overlap</span></span><br><span class="line">    <span class="comment"># 保证每一个ground truth 匹配它的都是具有最大IOU的prior</span></span><br><span class="line">    <span class="comment"># 根据 best_prior_dix 锁定 best_truth_idx里面的最大IOU prior</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(best_prior_idx.size(<span class="number">0</span>)):</span><br><span class="line">        best_truth_idx[best_prior_idx[j]] = j</span><br><span class="line">    matches = truths[best_truth_idx]          <span class="comment"># 提取出所有匹配的ground truth box, Shape: [M,4]</span></span><br><span class="line">    conf = labels[best_truth_idx] + <span class="number">1</span>         <span class="comment"># 提取出所有GT框的类别， Shape:[M]</span></span><br><span class="line">    <span class="comment"># 把 iou &lt; threshold 的框类别设置为 bg,即为0</span></span><br><span class="line">    conf[best_truth_overlap &lt; threshold] = <span class="number">0</span>  <span class="comment"># label as background</span></span><br><span class="line">    <span class="comment"># 编码包围框</span></span><br><span class="line">    loc = encode(matches, priors, variances)</span><br><span class="line">    <span class="comment"># 保存匹配好的loc和conf到loc_t和conf_t中</span></span><br><span class="line">    loc_t[idx] = loc    <span class="comment"># [num_priors,4] encoded offsets to learn</span></span><br><span class="line">    conf_t[idx] = conf  <span class="comment"># [num_priors] top class label for each prior</span></span><br></pre></td></tr></table></figure>
<h3 id="位置坐标转换"><a href="#位置坐标转换" class="headerlink" title="位置坐标转换"></a>位置坐标转换</h3><p>我们看到上面出现了一个point_form函数，这是什么意思呢？这是因为目标框有2种表示方式：</p>
<ul>
<li>$\left(x_{\min }, y_{\min }, x_{\max }, y_{\max }\right)$</li>
<li>$(x, y, w, h)$这部分的代码在<code>layers/box_utils.py</code>下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">point_form</span>(<span class="params">boxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Convert prior_boxes to (xmin, ymin, xmax, ymax)</span></span><br><span class="line"><span class="string">   把 prior_box (cx, cy, w, h)转化为(xmin, ymin, xmax, ymax)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat((boxes[:, :<span class="number">2</span>] - boxes[:, <span class="number">2</span>:]/<span class="number">2</span>,     <span class="comment"># xmin, ymin</span></span><br><span class="line">                     boxes[:, :<span class="number">2</span>] + boxes[:, <span class="number">2</span>:]/<span class="number">2</span>), <span class="number">1</span>)  <span class="comment"># xmax, ymax</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">center_size</span>(<span class="params">boxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Convert prior_boxes to (cx, cy, w, h)</span></span><br><span class="line"><span class="string">    把 prior_box (xmin, ymin, xmax, ymax) 转化为 (cx, cy, w, h)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat((boxes[:, <span class="number">2</span>:] + boxes[:, :<span class="number">2</span>])/<span class="number">2</span>,  <span class="comment"># cx, cy</span></span><br><span class="line">                            boxes[:, <span class="number">2</span>:] - boxes[:, :<span class="number">2</span>], <span class="number">1</span>) <span class="comment"># w, h</span></span><br></pre></td></tr></table></figure>
<h3 id="IOU计算"><a href="#IOU计算" class="headerlink" title="IOU计算"></a>IOU计算</h3><p>这部分比较简单，对于两个Box来讲，首先计算两个box左上角点坐标的最大值和右下角坐标的最小值，然后计算交集面积，最后把交集面积除以对应的并集面积。代码仍在<code>layers/box_utils.py</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">box_a, box_b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; We resize both tensors to [A,B,2] without new malloc:</span></span><br><span class="line"><span class="string">    [A,2] -&gt; [A,1,2] -&gt; [A,B,2]</span></span><br><span class="line"><span class="string">    [B,2] -&gt; [1,B,2] -&gt; [A,B,2]</span></span><br><span class="line"><span class="string">    Then we compute the area of intersect between box_a and box_b.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      box_a: (tensor) bounding boxes, Shape: [A,4].</span></span><br><span class="line"><span class="string">      box_b: (tensor) bounding boxes, Shape: [B,4].</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">      (tensor) intersection area, Shape: [A,B].</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    A = box_a.size(<span class="number">0</span>)</span><br><span class="line">    B = box_b.size(<span class="number">0</span>)</span><br><span class="line">     <span class="comment"># 右下角，选出最小值</span></span><br><span class="line">    max_xy = torch.<span class="built_in">min</span>(box_a[:, <span class="number">2</span>:].unsqueeze(<span class="number">1</span>).expand(A, B, <span class="number">2</span>),</span><br><span class="line">                       box_b[:, <span class="number">2</span>:].unsqueeze(<span class="number">0</span>).expand(A, B, <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># 左上角，选出最大值</span></span><br><span class="line">    min_xy = torch.<span class="built_in">max</span>(box_a[:, :<span class="number">2</span>].unsqueeze(<span class="number">1</span>).expand(A, B, <span class="number">2</span>),</span><br><span class="line">                       box_b[:, :<span class="number">2</span>].unsqueeze(<span class="number">0</span>).expand(A, B, <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># 负数用0截断，为0代表交集为0</span></span><br><span class="line">    inter = torch.clamp((max_xy - min_xy), <span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> inter[:, :, <span class="number">0</span>] * inter[:, :, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">jaccard</span>(<span class="params">box_a, box_b</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute the jaccard overlap of two sets of boxes.  The jaccard overlap</span></span><br><span class="line"><span class="string">    is simply the intersection over union of two boxes.  Here we operate on</span></span><br><span class="line"><span class="string">    ground truth boxes and default boxes.</span></span><br><span class="line"><span class="string">    E.g.:</span></span><br><span class="line"><span class="string">        A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]</span></span><br><span class="line"><span class="string">        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    inter = intersect(box_a, box_b)<span class="comment"># A∩B</span></span><br><span class="line">     <span class="comment"># box_a和box_b的面积</span></span><br><span class="line">    area_a = ((box_a[:, <span class="number">2</span>]-box_a[:, <span class="number">0</span>]) *</span><br><span class="line">              (box_a[:, <span class="number">3</span>]-box_a[:, <span class="number">1</span>])).unsqueeze(<span class="number">1</span>).expand_as(inter)  <span class="comment"># [A,B]#(N,)</span></span><br><span class="line">    area_b = ((box_b[:, <span class="number">2</span>]-box_b[:, <span class="number">0</span>]) *</span><br><span class="line">              (box_b[:, <span class="number">3</span>]-box_b[:, <span class="number">1</span>])).unsqueeze(<span class="number">0</span>).expand_as(inter)  <span class="comment"># [A,B]#(M,)</span></span><br><span class="line">    union = area_a + area_b - inter</span><br><span class="line">    <span class="keyword">return</span> inter / union  <span class="comment"># [A,B]</span></span><br></pre></td></tr></table></figure>
<h3 id="L2标准化"><a href="#L2标准化" class="headerlink" title="L2标准化"></a>L2标准化</h3><p>VGG16的<code>conv4_3</code>特征图的大小为38 x 38，网络层靠前，方差比较大，需要加一个L2标准化，以保证和后面的检测层差异不是很大。L2标准化的公式如下：$\hat{x}=\frac{x}{|x|^{2}}$ ，其中$x=\left(x_{1} \ldots x_{d}\right)|x|_{2}=\left(\sum_{i=1}^{d}\left|x_{i}\right|^{2}\right)^{1 / 2}$。同时，这里还要注意的是如果简单的对一个layer的输入进行L2标准化就会改变该层的规模，并且会减慢学习速度，因此这里引入了一个缩放系数$\gamma_{i}$ ，对于每一个通道l2标准化后的结果为：$y_{i}=\gamma_{i} \hat{x}_{i}$ ，通常的值设10或者20，效果比较好。代码来自layers/modules/l2norm.py。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">L2Norm</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    conv4_3特征图大小38x38，网络层靠前，norm较大，需要加一个L2 Normalization,以保证和后面的检测层差异不是很大，具体可以参考：ParseNet。这个前面的推文里面有讲。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_channels, scale</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(L2Norm, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.gamma = scale <span class="keyword">or</span> <span class="literal">None</span></span><br><span class="line">        self.eps = <span class="number">1e-10</span></span><br><span class="line">        <span class="comment"># 将一个不可训练的类型Tensor转换成可以训练的类型 parameter</span></span><br><span class="line">        self.weight = nn.Parameter(torch.Tensor(self.n_channels))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_parameters</span>(<span class="params">self</span>):</span></span><br><span class="line">        nn.init.constant_(self.weight, self.gamma)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 计算x的2范数</span></span><br><span class="line">        norm = x.<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).sqrt()+self.eps <span class="comment"># shape[b,1,38,38]</span></span><br><span class="line">        x = torch.div(x,norm)   <span class="comment"># shape[b,512,38,38]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 扩展self.weight的维度为shape[1,512,1,1]，然后参考公式计算</span></span><br><span class="line">        out = self.weight.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">3</span>).expand_as(x) * x</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h3 id="位置信息编解码"><a href="#位置信息编解码" class="headerlink" title="位置信息编解码"></a>位置信息编解码</h3><p>上面提到了计算坐标损失的时候，坐标是<code>encoding</code>之后的，这是怎么回事呢？根据论文的描述，预测框和ground truth边界框存在一个转换关系，先定义一些变量：</p>
<ul>
<li><p>先验框位置：$d=\left(d^{c x}, d^{c y}, d^{w}, d^{h}\right)$</p>
</li>
<li><p>ground truth框位置：$g=\left(g^{c x}, g^{c y}, g^{w}, g^{h}\right)$</p>
</li>
<li><p>variance是先验框的坐标方差。然后<strong>编码</strong>的过程可以表示为：$g_{j}^{\hat{c} x}=\left(g_{j}^{c x}-d_{i}^{c x}\right) / d_{i}^{w} /$varicance[0]，$g_{j}^{\hat{c} y}=\left(g_{j}^{c y}-d_{i}^{c y}\right) / d_{i}^{h} /$varicance[1]，$g_{j}^{\hat{w}}=\log \left(\frac{g_{j}^{w}}{d_{i}^{w}}\right) /$variance[2]，$g_{j}^{\hat{h}}=\log \left(\frac{g_{j}^{h}}{d_{i}^{h}}\right) /$variance[3]</p>
</li>
</ul>
<p><strong>解码</strong>的过程可以表示为：$g_{\text {predict}}^{c x}=d^{w} <em>\left(\text {variance}[0] </em> l^{c x}\right)+d^{c x}$，$g_{\text {predict}}^{c y}=d^{h} <em>\left(\text {variance}[1] </em> l^{c y}\right)+d^{c y}$，$g_{\text {predict}}^{w}=d^{w} \exp \left(\text {vairance}[2] <em> l^{w}\right)$，$g_{\text {predict}}^{h}=d^{h} \exp \left(\text {vairance}[3] </em> l^{h}\right)$</p>
<p>这部分对应的代码在<code>layers/box_utils.py</code>里面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode</span>(<span class="params">matched, priors, variances</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Encode the variances from the priorbox layers into the ground truth boxes</span></span><br><span class="line"><span class="string">    we have matched (based on jaccard overlap) with the prior boxes.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        matched: (tensor) Coords of ground truth for each prior in point-form</span></span><br><span class="line"><span class="string">            Shape: [num_priors, 4].</span></span><br><span class="line"><span class="string">        priors: (tensor) Prior boxes in center-offset form</span></span><br><span class="line"><span class="string">            Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        variances: (list[float]) Variances of priorboxes</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        encoded boxes (tensor), Shape: [num_priors, 4]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># dist b/t match center and prior&#x27;s center</span></span><br><span class="line">    g_cxcy = (matched[:, :<span class="number">2</span>] + matched[:, <span class="number">2</span>:])/<span class="number">2</span> - priors[:, :<span class="number">2</span>]</span><br><span class="line">    <span class="comment"># encode variance</span></span><br><span class="line">    g_cxcy /= (variances[<span class="number">0</span>] * priors[:, <span class="number">2</span>:])</span><br><span class="line">    <span class="comment"># match wh / prior wh</span></span><br><span class="line">    g_wh = (matched[:, <span class="number">2</span>:] - matched[:, :<span class="number">2</span>]) / priors[:, <span class="number">2</span>:]</span><br><span class="line">    g_wh = torch.log(g_wh) / variances[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># return target for smooth_l1_loss</span></span><br><span class="line">    <span class="keyword">return</span> torch.cat([g_cxcy, g_wh], <span class="number">1</span>)  <span class="comment"># [num_priors,4]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Adapted from https://github.com/Hakuyume/chainer-ssd</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">loc, priors, variances</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Decode locations from predictions using priors to undo</span></span><br><span class="line"><span class="string">    the encoding we did for offset regression at train time.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        loc (tensor): location predictions for loc layers,</span></span><br><span class="line"><span class="string">            Shape: [num_priors,4]</span></span><br><span class="line"><span class="string">        priors (tensor): Prior boxes in center-offset form.</span></span><br><span class="line"><span class="string">            Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        variances: (list[float]) Variances of priorboxes</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        decoded bounding box predictions</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    boxes = torch.cat((</span><br><span class="line">        priors[:, :<span class="number">2</span>] + loc[:, :<span class="number">2</span>] * variances[<span class="number">0</span>] * priors[:, <span class="number">2</span>:],</span><br><span class="line">        priors[:, <span class="number">2</span>:] * torch.exp(loc[:, <span class="number">2</span>:] * variances[<span class="number">1</span>])), <span class="number">1</span>)</span><br><span class="line">    boxes[:, :<span class="number">2</span>] -= boxes[:, <span class="number">2</span>:] / <span class="number">2</span></span><br><span class="line">    boxes[:, <span class="number">2</span>:] += boxes[:, :<span class="number">2</span>]</span><br><span class="line"><span class="keyword">return</span> boxes</span><br></pre></td></tr></table></figure>
<h3 id="后处理NMS"><a href="#后处理NMS" class="headerlink" title="后处理NMS"></a>后处理NMS</h3><p>这里不再赘述了。这里IOU阈值取了0.5。这部分的代码也在<code>layers/box_utils.py</code>里面。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span>(<span class="params">boxes, scores, overlap=<span class="number">0.5</span>, top_k=<span class="number">200</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Apply non-maximum suppression at test time to avoid detecting too many</span></span><br><span class="line"><span class="string">    overlapping bounding boxes for a given object.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        scores: (tensor) The class predscores for the img, Shape:[num_priors].</span></span><br><span class="line"><span class="string">        overlap: (float) The overlap thresh for suppressing unnecessary boxes.</span></span><br><span class="line"><span class="string">        top_k: (int) The Maximum number of box preds to consider.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        The indices of the kept boxes with respect to num_priors.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    keep = scores.new(scores.size(<span class="number">0</span>)).zero_().long()</span><br><span class="line">    <span class="keyword">if</span> boxes.numel() == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> keep</span><br><span class="line">    x1 = boxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = boxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = boxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = boxes[:, <span class="number">3</span>]</span><br><span class="line">    area = torch.mul(x2 - x1, y2 - y1)</span><br><span class="line">    v, idx = scores.sort(<span class="number">0</span>)  <span class="comment"># sort in ascending order</span></span><br><span class="line">    <span class="comment"># I = I[v &gt;= 0.01]</span></span><br><span class="line">    idx = idx[-top_k:]  <span class="comment"># indices of the top-k largest vals</span></span><br><span class="line">    xx1 = boxes.new()</span><br><span class="line">    yy1 = boxes.new()</span><br><span class="line">    xx2 = boxes.new()</span><br><span class="line">    yy2 = boxes.new()</span><br><span class="line">    w = boxes.new()</span><br><span class="line">    h = boxes.new()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># keep = torch.Tensor()</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> idx.numel() &gt; <span class="number">0</span>:</span><br><span class="line">        i = idx[-<span class="number">1</span>]  <span class="comment"># index of current largest val</span></span><br><span class="line">        <span class="comment"># keep.append(i)</span></span><br><span class="line">        keep[count] = i</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> idx.size(<span class="number">0</span>) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        idx = idx[:-<span class="number">1</span>]  <span class="comment"># remove kept element from view</span></span><br><span class="line">        <span class="comment"># load bboxes of next highest vals</span></span><br><span class="line">        torch.index_select(x1, <span class="number">0</span>, idx, out=xx1)</span><br><span class="line">        torch.index_select(y1, <span class="number">0</span>, idx, out=yy1)</span><br><span class="line">        torch.index_select(x2, <span class="number">0</span>, idx, out=xx2)</span><br><span class="line">        torch.index_select(y2, <span class="number">0</span>, idx, out=yy2)</span><br><span class="line">        <span class="comment"># store element-wise max with next highest score</span></span><br><span class="line">        xx1 = torch.clamp(xx1, <span class="built_in">min</span>=x1[i])</span><br><span class="line">        yy1 = torch.clamp(yy1, <span class="built_in">min</span>=y1[i])</span><br><span class="line">        xx2 = torch.clamp(xx2, <span class="built_in">max</span>=x2[i])</span><br><span class="line">        yy2 = torch.clamp(yy2, <span class="built_in">max</span>=y2[i])</span><br><span class="line">        w.resize_as_(xx2)</span><br><span class="line">        h.resize_as_(yy2)</span><br><span class="line">        w = xx2 - xx1</span><br><span class="line">        h = yy2 - yy1</span><br><span class="line">        <span class="comment"># check sizes of xx1 and xx2.. after each iteration</span></span><br><span class="line">        w = torch.clamp(w, <span class="built_in">min</span>=<span class="number">0.0</span>)</span><br><span class="line">        h = torch.clamp(h, <span class="built_in">min</span>=<span class="number">0.0</span>)</span><br><span class="line">        inter = w*h</span><br><span class="line">        <span class="comment"># IoU = i / (area(a) + area(b) - i)</span></span><br><span class="line">        rem_areas = torch.index_select(area, <span class="number">0</span>, idx)  <span class="comment"># load remaining areas)</span></span><br><span class="line">        union = (rem_areas - inter) + area[i]</span><br><span class="line">        IoU = inter/union  <span class="comment"># store result in iou</span></span><br><span class="line">        <span class="comment"># keep only elements with an IoU &lt;= overlap</span></span><br><span class="line">        idx = idx[IoU.le(overlap)]</span><br><span class="line">    <span class="keyword">return</span> keep, count</span><br></pre></td></tr></table></figure>
<h3 id="检测函数"><a href="#检测函数" class="headerlink" title="检测函数"></a>检测函数</h3><p>模型在测试的时候，需要把loc和conf输入到detect函数进行nms，然后给出结果。这部分的代码在<code>layers/functions/detection.py</code>里面，如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Detect</span>(<span class="params">Function</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;At test time, Detect is the final layer of SSD.  Decode location preds,</span></span><br><span class="line"><span class="string">    apply non-maximum suppression to location predictions based on conf</span></span><br><span class="line"><span class="string">    scores and threshold to a top_k number of output predictions for both</span></span><br><span class="line"><span class="string">    confidence score and locations.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh</span>):</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.background_label = bkg_label</span><br><span class="line">        self.top_k = top_k</span><br><span class="line">        <span class="comment"># Parameters used in nms.</span></span><br><span class="line">        self.nms_thresh = nms_thresh</span><br><span class="line">        <span class="keyword">if</span> nms_thresh &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;nms_threshold must be non negative.&#x27;</span>)</span><br><span class="line">        self.conf_thresh = conf_thresh</span><br><span class="line">        self.variance = cfg[<span class="string">&#x27;variance&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, loc_data, conf_data, prior_data</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            loc_data: 预测出的loc张量，shape[b,M,4], eg:[b, 8732, 4]</span></span><br><span class="line"><span class="string">            conf_data:预测出的置信度，shape[b,M,num_classes], eg:[b, 8732, 21]</span></span><br><span class="line"><span class="string">            prior_data:先验框，shape[M,4], eg:[8732, 4]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        num = loc_data.size(<span class="number">0</span>)  <span class="comment"># batch size</span></span><br><span class="line">        num_priors = prior_data.size(<span class="number">0</span>)</span><br><span class="line">        output = torch.zeros(num, self.num_classes, self.top_k, <span class="number">5</span>)<span class="comment"># 初始化输出</span></span><br><span class="line">        conf_preds = conf_data.view(num, num_priors,</span><br><span class="line">                                    self.num_classes).transpose(<span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码loc的信息，变为正常的bboxes</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num):</span><br><span class="line">            <span class="comment"># 解码loc</span></span><br><span class="line">            decoded_boxes = decode(loc_data[i], prior_data, self.variance)</span><br><span class="line">            <span class="comment"># 拷贝每个batch内的conf，用于nms</span></span><br><span class="line">            conf_scores = conf_preds[i].clone()</span><br><span class="line">            <span class="comment"># 遍历每一个类别</span></span><br><span class="line">            <span class="keyword">for</span> cl <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.num_classes):</span><br><span class="line">                <span class="comment"># 筛选掉 conf &lt; conf_thresh 的conf</span></span><br><span class="line">                c_mask = conf_scores[cl].gt(self.conf_thresh)</span><br><span class="line">                scores = conf_scores[cl][c_mask]</span><br><span class="line">                <span class="comment"># 如果都被筛掉了，则跳入下一类</span></span><br><span class="line">                <span class="keyword">if</span> scores.size(<span class="number">0</span>) == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># 筛选掉 conf &lt; conf_thresh 的框</span></span><br><span class="line">                l_mask = c_mask.unsqueeze(<span class="number">1</span>).expand_as(decoded_boxes)</span><br><span class="line">                boxes = decoded_boxes[l_mask].view(-<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">                <span class="comment"># idx of highest scoring and non-overlapping boxes per class</span></span><br><span class="line">                <span class="comment"># nms</span></span><br><span class="line">                ids, count = nms(boxes, scores, self.nms_thresh, self.top_k)</span><br><span class="line">                <span class="comment"># nms 后得到的输出拼接</span></span><br><span class="line">                output[i, cl, :count] = \</span><br><span class="line">                    torch.cat((scores[ids[:count]].unsqueeze(<span class="number">1</span>),</span><br><span class="line">                               boxes[ids[:count]]), <span class="number">1</span>)</span><br><span class="line">        flt = output.contiguous().view(num, -<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">        _, idx = flt[:, :, <span class="number">0</span>].sort(<span class="number">1</span>, descending=<span class="literal">True</span>)</span><br><span class="line">        _, rank = idx.sort(<span class="number">1</span>)</span><br><span class="line">        flt[(rank &lt; self.top_k).unsqueeze(-<span class="number">1</span>).expand_as(flt)].fill_(<span class="number">0</span>)</span><br><span class="line">	<span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOV3损失函数代码详解(yolo_layer.c)</title>
    <url>/2020/02/28/YOLOV3%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(yolo_layer.c)/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>YOLOV3的损失函数在YOLOV2的基础上，用多个独立的逻辑回归损失代替了YOLOV2里面的softmax损失，然后去掉了对Anchor在前12800次训练轮次中的回归损失，也即是YOLOV2损失函数的第二项。另外新增了一个ignore_thresh参数来忽略一些和GT box的IOU大于ignore_thresh的预测框的objectness损失。除了以上细节，其它部分和YOLOV2的处理类似。</p>
<h2 id="AlexeyAB的一些更新"><a href="#AlexeyAB的一些更新" class="headerlink" title="AlexeyAB的一些更新"></a>AlexeyAB的一些更新</h2><p>除了上面提到的相对于YOLOV2一些基础改动，AlexeyAB大神在目标框回归过程中新增了IOU/GIOU/DIOU/CIOU Loss，并且在分类过程中新增了Focal Loss，方便大家在自己的数据集上进行试验，预祝涨点。</p>
<h2 id="代码解析步骤"><a href="#代码解析步骤" class="headerlink" title="代码解析步骤"></a>代码解析步骤</h2><h3 id="yolo-层"><a href="#yolo-层" class="headerlink" title="[yolo]层"></a>[yolo]层</h3><p>YOLOV3使用[yolo] 层来计算损失函数以及预测分类和边界框回归，前面经过 darknet-53 的基础网络提取特征，又经过一些特征融合，就得到了3个不同尺度的 yolo 层，分别预测大、中、小物体。主要代码在<code>/src/yolo_layer.c</code>。cfg文件的配置如下：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[yolo]</span><br><span class="line">mask = 0,1,2  #该层预测哪个规模的框，0,1,2表示预测小物体</span><br><span class="line">anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326 </span><br><span class="line">classes=80</span><br><span class="line">num=9</span><br><span class="line">jitter=.3</span><br><span class="line">ignore_thresh = .7</span><br><span class="line">truth_thresh = 1</span><br><span class="line">random=1</span><br></pre></td></tr></table></figure></p>
<h3 id="make-yolo-layer-完成-yolo-层初始化操作"><a href="#make-yolo-layer-完成-yolo-层初始化操作" class="headerlink" title="make_yolo_layer 完成 yolo 层初始化操作"></a>make_yolo_layer 完成 yolo 层初始化操作</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 构造YOLOV3的yolo层</span></span><br><span class="line"><span class="comment">// batch 一个batch中包含图片的张数</span></span><br><span class="line"><span class="comment">// w 输入图片的宽度</span></span><br><span class="line"><span class="comment">// h 输入图片的高度</span></span><br><span class="line"><span class="comment">// n 一个cell预测多少个bbox</span></span><br><span class="line"><span class="comment">// total total Anchor bbox的数目</span></span><br><span class="line"><span class="comment">// mask 使用的是0,1,2 还是</span></span><br><span class="line"><span class="comment">// classes 网络需要识别的物体类别数</span></span><br><span class="line"><span class="function">layer <span class="title">make_yolo_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> n, <span class="keyword">int</span> total, <span class="keyword">int</span> *mask, <span class="keyword">int</span> classes, <span class="keyword">int</span> max_boxes)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    l.type = YOLO; <span class="comment">//层类别</span></span><br><span class="line"></span><br><span class="line">    l.n = n; <span class="comment">//一个cell预测多少个bbox</span></span><br><span class="line">    l.total = total; <span class="comment">//anchors的数目，为9</span></span><br><span class="line">    l.batch = batch;<span class="comment">// 一个batch包含图片的张数</span></span><br><span class="line">    l.h = h; <span class="comment">// 输入图片的宽度</span></span><br><span class="line">    l.w = w; <span class="comment">// 输入图片的高度</span></span><br><span class="line">    l.c = n*(classes + <span class="number">4</span> + <span class="number">1</span>); <span class="comment">// 输入图片的通道数, 3*(20 + 5)</span></span><br><span class="line">    l.out_w = l.w;<span class="comment">// 输出图片的宽度</span></span><br><span class="line">    l.out_h = l.h;<span class="comment">// 输出图片的高度</span></span><br><span class="line">    l.out_c = l.c;<span class="comment">// 输出图片的通道数</span></span><br><span class="line">    l.classes = classes;<span class="comment">//目标类别数</span></span><br><span class="line">    l.cost = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//yolo层总的损失</span></span><br><span class="line">    l.biases = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(total * <span class="number">2</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//存储bbox的Anchor box的[w,h]</span></span><br><span class="line">    <span class="keyword">if</span>(mask) l.mask = mask; <span class="comment">//yolov3有mask传入</span></span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        l.mask = (<span class="keyword">int</span>*)<span class="built_in">xcalloc</span>(n, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">int</span>));</span><br><span class="line">        <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n; ++i)&#123;</span><br><span class="line">            l.mask[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//存储bbox的Anchor box的[w,h]的更新值</span></span><br><span class="line">    l.bias_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(n * <span class="number">2</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">// 一张训练图片经过yolo层后得到的输出元素个数（等于网格数*每个网格预测的矩形框数*每个矩形框的参数个数）</span></span><br><span class="line">    l.outputs = h*w*n*(classes + <span class="number">4</span> + <span class="number">1</span>);</span><br><span class="line">	<span class="comment">//一张训练图片输入到yolo层的元素个数（注意是一张图片，对于yolo_layer，输入和输出的元素个数相等）</span></span><br><span class="line">    l.inputs = l.outputs;</span><br><span class="line">	<span class="comment">//每张图片含有的真实矩形框参数的个数（max_boxes表示一张图片中最多有max_boxes个ground truth矩形框，每个真实矩形框有</span></span><br><span class="line">    <span class="comment">//5个参数，包括x,y,w,h四个定位参数，以及物体类别）,注意max_boxes是darknet程序内写死的，实际上每张图片可能</span></span><br><span class="line">    <span class="comment">//并没有max_boxes个真实矩形框，也能没有这么多参数，但为了保持一致性，还是会留着这么大的存储空间，只是其中的</span></span><br><span class="line">    <span class="comment">//值为空而已.</span></span><br><span class="line">    l.max_boxes = max_boxes;</span><br><span class="line">	<span class="comment">// GT: max_boxes*(4+1) 存储max_boxes个bbox的信息，这里是假设图片中GT bbox的数量是</span></span><br><span class="line">	<span class="comment">//小于max_boxes的，这里是写死的；此处与yolov1是不同的</span></span><br><span class="line">    l.truths = l.max_boxes*(<span class="number">4</span> + <span class="number">1</span>);    <span class="comment">// 90*(4 + 1);</span></span><br><span class="line">	<span class="comment">// yolo层误差项(包含整个batch的)</span></span><br><span class="line">    l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">//yolo层所有输出（包含整个batch的）</span></span><br><span class="line">    <span class="comment">//yolo的输出维度是l.out_w*l.out_h，等于输出的维度，输出的通道数为l.out_c，也即是输入的通道数，具体为：n*(classes+coords+1)</span></span><br><span class="line">	<span class="comment">//YOLO检测模型将图片分成S*S个网格，每个网格又预测B个矩形框，最后输出的就是这些网格中包含的所有矩形框的信息</span></span><br><span class="line">    l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">// 存储bbox的Anchor box的[w,h]的初始化,在src/parse.c中parse_yolo函数会加载cfg中Anchor尺寸</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; total*<span class="number">2</span>; ++i)&#123;</span><br><span class="line">        l.biases[i] = <span class="number">.5</span>;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// yolo层的前向传播</span></span><br><span class="line">    l.forward = forward_yolo_layer;</span><br><span class="line">	<span class="comment">// yolo层的反向传播</span></span><br><span class="line">    l.backward = backward_yolo_layer;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    l.forward_gpu = forward_yolo_layer_gpu;</span><br><span class="line">    l.backward_gpu = backward_yolo_layer_gpu;</span><br><span class="line">    l.output_gpu = <span class="built_in">cuda_make_array</span>(l.output, batch*l.outputs);</span><br><span class="line">    l.delta_gpu = <span class="built_in">cuda_make_array</span>(l.delta, batch*l.outputs);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(l.output);</span><br><span class="line">    <span class="keyword">if</span> (cudaSuccess == <span class="built_in">cudaHostAlloc</span>(&amp;l.output, batch*l.outputs*<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>), cudaHostRegisterMapped)) l.output_pinned = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">cudaGetLastError</span>(); <span class="comment">// reset CUDA-error</span></span><br><span class="line">        l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(l.delta);</span><br><span class="line">    <span class="keyword">if</span> (cudaSuccess == <span class="built_in">cudaHostAlloc</span>(&amp;l.delta, batch*l.outputs*<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>), cudaHostRegisterMapped)) l.delta_pinned = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">cudaGetLastError</span>(); <span class="comment">// reset CUDA-error</span></span><br><span class="line">        l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;yolo\n&quot;</span>);</span><br><span class="line">    <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="get-yolo-box-获得预测的边界框"><a href="#get-yolo-box-获得预测的边界框" class="headerlink" title="get_yolo_box 获得预测的边界框"></a>get_yolo_box 获得预测的边界框</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获取某个矩形框的4个定位信息，即根据输入的矩形框索引从l.output中获取该矩形框的定位信息x,y,w,h</span></span><br><span class="line"><span class="comment">//x  yolo_layer的输出，即l.output，包含所有batch预测得到的矩形框信息</span></span><br><span class="line"><span class="comment">//biases 表示Anchor框的长和宽</span></span><br><span class="line"><span class="comment">//index 矩形框的首地址（索引，矩形框中存储的首个参数x在l.output中的索引）</span></span><br><span class="line"><span class="comment">//i 第几行（yolo_layer维度为l.out_w*l.out_c）</span></span><br><span class="line"><span class="comment">//j 第几列</span></span><br><span class="line"><span class="comment">//lw 特征图的宽度</span></span><br><span class="line"><span class="comment">//lh 特征图的高度</span></span><br><span class="line"><span class="comment">//w 输入图像的宽度</span></span><br><span class="line"><span class="comment">//h 输入图像的高度</span></span><br><span class="line"><span class="comment">//stride 不同的特征图具有不同的步长(即是两个grid cell之间跨的像素个数不同)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//biases中存储的是预定以的anchor box的宽和高（输入图尺度），(lw,lh)是yolo层输入的特征图尺度，</span></span><br><span class="line"><span class="comment">//(w,h)是整个网络输入图尺度，get_yolo_box()函数利用了论文截图中的公式，而且把结果分别利用特征</span></span><br><span class="line"><span class="comment">//图宽高和输入图宽高做了归一化。既然这个机制是用来限制回归，避免预测很远的目标，那么这个预测</span></span><br><span class="line"><span class="comment">//范围是多大呢？(b.x,by)最小是(i,j),最大是(i+1,x+1)，即中心点在特征图上最多一定一个像素（假设</span></span><br><span class="line"><span class="comment">//输入图下采样n得到特征图，特征图中一个像素对应输入图的n个像素）(b.w,b.h)最大是(2.7 * anchor.w,</span></span><br><span class="line"><span class="comment">//2.7 * anchor.h),最小就是(anchor.w,anchor.h)，这是在输入图尺寸下的值。</span></span><br><span class="line"></span><br><span class="line"><span class="function">box <span class="title">get_yolo_box</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> lw, <span class="keyword">int</span> lh, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> stride)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    box b;</span><br><span class="line">    <span class="comment">// ln - natural logarithm (base = e)</span></span><br><span class="line">    <span class="comment">// x` = t.x * lw - i;   // x = ln(x`/(1-x`))   // x - output of previous conv-layer</span></span><br><span class="line">    <span class="comment">// y` = t.y * lh - i;   // y = ln(y`/(1-y`))   // y - output of previous conv-layer</span></span><br><span class="line">                            <span class="comment">// w = ln(t.w * net.w / anchors_w); // w - output of previous conv-layer</span></span><br><span class="line">                            <span class="comment">// h = ln(t.h * net.h / anchors_h); // h - output of previous conv-layer</span></span><br><span class="line">    b.x = (i + x[index + <span class="number">0</span>*stride]) / lw;</span><br><span class="line">    b.y = (j + x[index + <span class="number">1</span>*stride]) / lh;</span><br><span class="line">    b.w = <span class="built_in">exp</span>(x[index + <span class="number">2</span>*stride]) * biases[<span class="number">2</span>*n]   / w;</span><br><span class="line">    b.h = <span class="built_in">exp</span>(x[index + <span class="number">3</span>*stride]) * biases[<span class="number">2</span>*n+<span class="number">1</span>] / h;</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="delta-yolo-box-计算预测边界框的误差"><a href="#delta-yolo-box-计算预测边界框的误差" class="headerlink" title="delta_yolo_box 计算预测边界框的误差"></a>delta_yolo_box 计算预测边界框的误差</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//调用方式：delta_yolo_box(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, state.net.w, state.net.h, l.delta, (2 - truth.w*truth.h), l.w*l.h, l.iou_normalizer * class_multiplier, l.iou_loss, 1, l.max_delta);</span></span><br><span class="line"><span class="comment">// 计算预测边界框的误差</span></span><br><span class="line"><span class="function">ious <span class="title">delta_yolo_box</span><span class="params">(box truth, <span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> lw, <span class="keyword">int</span> lh, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">float</span> *delta, <span class="keyword">float</span> scale, <span class="keyword">int</span> stride, <span class="keyword">float</span> iou_normalizer, IOU_LOSS iou_loss, <span class="keyword">int</span> accumulate, <span class="keyword">int</span> max_delta)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ious all_ious = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">    <span class="comment">// i - step in layer width</span></span><br><span class="line">    <span class="comment">// j - step in layer height</span></span><br><span class="line">    <span class="comment">//  Returns a box in absolute coordinates</span></span><br><span class="line">	<span class="comment">// 获得第j*w+i个cell的第n个bbox在当前特征图的[x,y,w,h]</span></span><br><span class="line">    box pred = <span class="built_in">get_yolo_box</span>(x, biases, n, index, i, j, lw, lh, w, h, stride);</span><br><span class="line">	<span class="comment">//iou</span></span><br><span class="line">    all_ious.iou = <span class="built_in">box_iou</span>(pred, truth);</span><br><span class="line">	<span class="comment">//giou</span></span><br><span class="line">    all_ious.giou = <span class="built_in">box_giou</span>(pred, truth);</span><br><span class="line">	<span class="comment">//diou</span></span><br><span class="line">    all_ious.diou = <span class="built_in">box_diou</span>(pred, truth);</span><br><span class="line">	<span class="comment">//ciou</span></span><br><span class="line">    all_ious.ciou = <span class="built_in">box_ciou</span>(pred, truth);</span><br><span class="line">    <span class="comment">// avoid nan in dx_box_iou</span></span><br><span class="line">	</span><br><span class="line">    <span class="keyword">if</span> (pred.w == <span class="number">0</span>) &#123; pred.w = <span class="number">1.0</span>; &#125;</span><br><span class="line">    <span class="keyword">if</span> (pred.h == <span class="number">0</span>) &#123; pred.h = <span class="number">1.0</span>; &#125;</span><br><span class="line">    <span class="keyword">if</span> (iou_loss == MSE)    <span class="comment">// old loss</span></span><br><span class="line">    &#123;</span><br><span class="line">		<span class="comment">// 计算GT bbox的tx, ty, tw, th</span></span><br><span class="line">        <span class="keyword">float</span> tx = (truth.x*lw - i); <span class="comment">//和预测值匹配</span></span><br><span class="line">        <span class="keyword">float</span> ty = (truth.y*lh - j);</span><br><span class="line">        <span class="keyword">float</span> tw = <span class="built_in">log</span>(truth.w*w / biases[<span class="number">2</span> * n]); <span class="comment">//log 使大框和小框的误差影响接近</span></span><br><span class="line">        <span class="keyword">float</span> th = <span class="built_in">log</span>(truth.h*h / biases[<span class="number">2</span> * n + <span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// accumulate delta</span></span><br><span class="line">		<span class="comment">//计算tx, ty, tw, th的梯度</span></span><br><span class="line">        delta[index + <span class="number">0</span> * stride] += scale * (tx - x[index + <span class="number">0</span> * stride]) * iou_normalizer;  <span class="comment">//计算误差 delta，乘了权重系数 scale=(2-truth.w*truth.h)</span></span><br><span class="line">        delta[index + <span class="number">1</span> * stride] += scale * (ty - x[index + <span class="number">1</span> * stride]) * iou_normalizer;</span><br><span class="line">        delta[index + <span class="number">2</span> * stride] += scale * (tw - x[index + <span class="number">2</span> * stride]) * iou_normalizer;</span><br><span class="line">        delta[index + <span class="number">3</span> * stride] += scale * (th - x[index + <span class="number">3</span> * stride]) * iou_normalizer;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// https://github.com/generalized-iou/g-darknet</span></span><br><span class="line">        <span class="comment">// https://arxiv.org/abs/1902.09630v2</span></span><br><span class="line">        <span class="comment">// https://giou.stanford.edu/</span></span><br><span class="line">        all_ious.dx_iou = <span class="built_in">dx_box_iou</span>(pred, truth, iou_loss);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// jacobian^t (transpose)</span></span><br><span class="line">        <span class="comment">//float dx = (all_ious.dx_iou.dl + all_ious.dx_iou.dr);</span></span><br><span class="line">        <span class="comment">//float dy = (all_ious.dx_iou.dt + all_ious.dx_iou.db);</span></span><br><span class="line">        <span class="comment">//float dw = ((-0.5 * all_ious.dx_iou.dl) + (0.5 * all_ious.dx_iou.dr));</span></span><br><span class="line">        <span class="comment">//float dh = ((-0.5 * all_ious.dx_iou.dt) + (0.5 * all_ious.dx_iou.db));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// jacobian^t (transpose)</span></span><br><span class="line">        <span class="keyword">float</span> dx = all_ious.dx_iou.dt;</span><br><span class="line">        <span class="keyword">float</span> dy = all_ious.dx_iou.db;</span><br><span class="line">        <span class="keyword">float</span> dw = all_ious.dx_iou.dl;</span><br><span class="line">        <span class="keyword">float</span> dh = all_ious.dx_iou.dr;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// predict exponential, apply gradient of e^delta_t ONLY for w,h</span></span><br><span class="line">        dw *= <span class="built_in">exp</span>(x[index + <span class="number">2</span> * stride]);</span><br><span class="line">        dh *= <span class="built_in">exp</span>(x[index + <span class="number">3</span> * stride]);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// normalize iou weight</span></span><br><span class="line">        dx *= iou_normalizer;</span><br><span class="line">        dy *= iou_normalizer;</span><br><span class="line">        dw *= iou_normalizer;</span><br><span class="line">        dh *= iou_normalizer;</span><br><span class="line"></span><br><span class="line">        dx = <span class="built_in">fix_nan_inf</span>(dx);</span><br><span class="line">        dy = <span class="built_in">fix_nan_inf</span>(dy);</span><br><span class="line">        dw = <span class="built_in">fix_nan_inf</span>(dw);</span><br><span class="line">        dh = <span class="built_in">fix_nan_inf</span>(dh);</span><br><span class="line"></span><br><span class="line">        dx = <span class="built_in">clip_value</span>(dx, max_delta);</span><br><span class="line">        dy = <span class="built_in">clip_value</span>(dy, max_delta);</span><br><span class="line">        dw = <span class="built_in">clip_value</span>(dw, max_delta);</span><br><span class="line">        dh = <span class="built_in">clip_value</span>(dh, max_delta);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!accumulate) &#123;</span><br><span class="line">            delta[index + <span class="number">0</span> * stride] = <span class="number">0</span>;</span><br><span class="line">            delta[index + <span class="number">1</span> * stride] = <span class="number">0</span>;</span><br><span class="line">            delta[index + <span class="number">2</span> * stride] = <span class="number">0</span>;</span><br><span class="line">            delta[index + <span class="number">3</span> * stride] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// accumulate delta</span></span><br><span class="line">        delta[index + <span class="number">0</span> * stride] += dx;</span><br><span class="line">        delta[index + <span class="number">1</span> * stride] += dy;</span><br><span class="line">        delta[index + <span class="number">2</span> * stride] += dw;</span><br><span class="line">        delta[index + <span class="number">3</span> * stride] += dh;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//返回梯度</span></span><br><span class="line">    <span class="keyword">return</span> all_ious;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="delta-yolo-class-计算类别误差"><a href="#delta-yolo-class-计算类别误差" class="headerlink" title="delta_yolo_class 计算类别误差"></a>delta_yolo_class 计算类别误差</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//计算类别误差</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">delta_yolo_class</span><span class="params">(<span class="keyword">float</span> *output, <span class="keyword">float</span> *delta, <span class="keyword">int</span> index, <span class="keyword">int</span> class_id, <span class="keyword">int</span> classes, <span class="keyword">int</span> stride, <span class="keyword">float</span> *avg_cat, <span class="keyword">int</span> focal_loss, <span class="keyword">float</span> label_smooth_eps, <span class="keyword">float</span> *classes_multipliers)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">if</span> (delta[index + stride*class_id])&#123; <span class="comment">//应该不会进入这个判断，因为 delta[index] 初值为0</span></span><br><span class="line">        delta[index + stride*class_id] = (<span class="number">1</span> - label_smooth_eps) - output[index + stride*class_id];</span><br><span class="line">        <span class="keyword">if</span> (classes_multipliers) delta[index + stride*class_id] *= classes_multipliers[class_id];</span><br><span class="line">        <span class="keyword">if</span>(avg_cat) *avg_cat += output[index + stride*class_id];</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Focal loss</span></span><br><span class="line">    <span class="keyword">if</span> (focal_loss) &#123;</span><br><span class="line">        <span class="comment">// Focal Loss</span></span><br><span class="line">        <span class="keyword">float</span> alpha = <span class="number">0.5</span>;    <span class="comment">// 0.25 or 0.5</span></span><br><span class="line">        <span class="comment">//float gamma = 2;    // hardcoded in many places of the grad-formula</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> ti = index + stride*class_id;</span><br><span class="line">        <span class="keyword">float</span> pt = output[ti] + <span class="number">0.000000000000001F</span>;</span><br><span class="line">        <span class="comment">// http://fooplot.com/#W3sidHlwZSI6MCwiZXEiOiItKDEteCkqKDIqeCpsb2coeCkreC0xKSIsImNvbG9yIjoiIzAwMDAwMCJ9LHsidHlwZSI6MTAwMH1d</span></span><br><span class="line">        <span class="keyword">float</span> grad = -(<span class="number">1</span> - pt) * (<span class="number">2</span> * pt*<span class="built_in">logf</span>(pt) + pt - <span class="number">1</span>);    <span class="comment">// http://blog.csdn.net/linmingan/article/details/77885832</span></span><br><span class="line">        <span class="comment">//float grad = (1 - pt) * (2 * pt*logf(pt) + pt - 1);    // https://github.com/unsky/focal-loss</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; classes; ++n) &#123; <span class="comment">//对所有类别，如果预测正确，则误差为 1-predict，否则为 0-predict</span></span><br><span class="line">            delta[index + stride*n] = (((n == class_id) ? <span class="number">1</span> : <span class="number">0</span>) - output[index + stride*n]);</span><br><span class="line"></span><br><span class="line">            delta[index + stride*n] *= alpha*grad;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (n == class_id &amp;&amp; avg_cat) *avg_cat += output[index + stride*n];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// default</span></span><br><span class="line">        <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; classes; ++n) &#123;</span><br><span class="line">            delta[index + stride*n] = ((n == class_id) ? (<span class="number">1</span> - label_smooth_eps) : (<span class="number">0</span> + label_smooth_eps/classes)) - output[index + stride*n];</span><br><span class="line">            <span class="keyword">if</span> (classes_multipliers &amp;&amp; n == class_id) delta[index + stride*class_id] *= classes_multipliers[class_id];</span><br><span class="line">            <span class="keyword">if</span> (n == class_id &amp;&amp; avg_cat) *avg_cat += output[index + stride*n];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="entry-index-得到指针偏移量，即入口需要的索引"><a href="#entry-index-得到指针偏移量，即入口需要的索引" class="headerlink" title="entry_index 得到指针偏移量，即入口需要的索引"></a>entry_index 得到指针偏移量，即入口需要的索引</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief 计算某个矩形框中某个参数在l.output中的索引。一个矩形框包含了x,y,w,h,c,C1,C2...,Cn信息，</span></span><br><span class="line"><span class="comment"> *        前四个用于定位，第五个为矩形框含有物体的置信度信息c，即矩形框中存在物体的概率为多大，而C1到Cn</span></span><br><span class="line"><span class="comment"> *        为矩形框中所包含的物体分别属于这n类物体的概率。本函数负责获取该矩形框首个定位信息也即x值在</span></span><br><span class="line"><span class="comment"> *        l.output中索引、获取该矩形框置信度信息c在l.output中的索引、获取该矩形框分类所属概率的首个</span></span><br><span class="line"><span class="comment"> *        概率也即C1值的索引，具体是获取矩形框哪个参数的索引，取决于输入参数entry的值，这些在</span></span><br><span class="line"><span class="comment"> *        forward_region_layer()函数中都有用到，由于l.output的存储方式，当entry=0时，就是获取矩形框</span></span><br><span class="line"><span class="comment"> *        x参数在l.output中的索引；当entry=4时，就是获取矩形框置信度信息c在l.output中的索引；当</span></span><br><span class="line"><span class="comment"> *        entry=5时，就是获取矩形框首个所属概率C1在l.output中的索引，具体可以参考forward_region_layer()</span></span><br><span class="line"><span class="comment"> *        中调用本函数时的注释.</span></span><br><span class="line"><span class="comment"> * @param l 当前region_layer</span></span><br><span class="line"><span class="comment"> * @param batch 当前照片是整个batch中的第几张，因为l.output中包含整个batch的输出，所以要定位某张训练图片</span></span><br><span class="line"><span class="comment"> *              输出的众多网格中的某个矩形框，当然需要该参数.</span></span><br><span class="line"><span class="comment"> * @param location 这个参数，说实话，感觉像个鸡肋参数，函数中用这个参数获取n和loc的值，这个n就是表示网格中</span></span><br><span class="line"><span class="comment"> *                 的第几个预测矩形框（比如每个网格预测5个矩形框，那么n取值范围就是从0~4，loc就是某个</span></span><br><span class="line"><span class="comment"> *                 通道上的元素偏移（region_layer输出的通道数为l.out_c = (classes + coords + 1)，</span></span><br><span class="line"><span class="comment"> *                 这样说可能没有说明白，这都与l.output的存储结构相关，见下面详细注释以及其他说明。总之，</span></span><br><span class="line"><span class="comment"> *                 查看一下调用本函数的父函数forward_region_layer()就知道了，可以直接输入n和j*l.w+i的，</span></span><br><span class="line"><span class="comment"> *                 没有必要输入location，这样还得重新计算一次n和loc.</span></span><br><span class="line"><span class="comment"> * @param entry 切入点偏移系数，关于这个参数，就又要扯到l.output的存储结构了，见下面详细注释以及其他说明.</span></span><br><span class="line"><span class="comment"> * @details l.output这个参数的存储内容以及存储方式已经在多个地方说明了，再多的文字都不及图文说明，此处再</span></span><br><span class="line"><span class="comment"> *          简要罗嗦几句，更为具体的参考图文说明。l.output中存储了整个batch的训练输出，每张训练图片都会输出</span></span><br><span class="line"><span class="comment"> *          l.out_w*l.out_h个网格，每个网格会预测l.n个矩形框，每个矩形框含有l.classes+l.coords+1个参数，</span></span><br><span class="line"><span class="comment"> *          而最后一层的输出通道数为l.n*(l.classes+l.coords+1)，可以想象下最终输出的三维张量是个什么样子的。</span></span><br><span class="line"><span class="comment"> *          展成一维数组存储时，l.output可以首先分成batch个大段，每个大段存储了一张训练图片的所有输出；进一步细分，</span></span><br><span class="line"><span class="comment"> *          取其中第一大段分析，该大段中存储了第一张训练图片所有输出网格预测的矩形框信息，每个网格预测了l.n个矩形框，</span></span><br><span class="line"><span class="comment"> *          存储时，l.n个矩形框是分开存储的，也就是先存储所有网格中的第一个矩形框，而后存储所有网格中的第二个矩形框，</span></span><br><span class="line"><span class="comment"> *          依次类推，如果每个网格中预测5个矩形框，则可以继续把这一大段分成5个中段。继续细分，5个中段中取第</span></span><br><span class="line"><span class="comment"> *          一个中段来分析，这个中段中按行（有l.out_w*l.out_h个网格，按行存储）依次存储了这张训练图片所有输出网格中</span></span><br><span class="line"><span class="comment"> *          的第一个矩形框信息，要注意的是，这个中段存储的顺序并不是挨个挨个存储每个矩形框的所有信息，</span></span><br><span class="line"><span class="comment"> *          而是先存储所有矩形框的x，而后是所有的y,然后是所有的w,再是h，c，最后的的概率数组也是拆分进行存储，</span></span><br><span class="line"><span class="comment"> *          并不是一下子存储完一个矩形框所有类的概率，而是先存储所有网格所属第一类的概率，再存储所属第二类的概率，</span></span><br><span class="line"><span class="comment"> *          具体来说这一中段首先存储了l.out_w*l.out_h个x，然后是l.out_w*l.out_c个y，依次下去，</span></span><br><span class="line"><span class="comment"> *          最后是l.out_w*l.out_h个C1（属于第一类的概率，用C1表示，下面类似），l.out_w*l.outh个C2,...,</span></span><br><span class="line"><span class="comment"> *          l.out_w*l.out_c*Cn（假设共有n类），所以可以继续将中段分成几个小段，依次为x,y,w,h,c,C1,C2,...Cn</span></span><br><span class="line"><span class="comment"> *          小段，每小段的长度都为l.out_w*l.out_c.</span></span><br><span class="line"><span class="comment"> *          现在回过来看本函数的输入参数，batch就是大段的偏移数（从第几个大段开始，对应是第几张训练图片），</span></span><br><span class="line"><span class="comment"> *          由location计算得到的n就是中段的偏移数（从第几个中段开始，对应是第几个矩形框），</span></span><br><span class="line"><span class="comment"> *          entry就是小段的偏移数（从几个小段开始，对应具体是那种参数，x,c还是C1），而loc则是最后的定位，</span></span><br><span class="line"><span class="comment"> *          前面确定好第几大段中的第几中段中的第几小段的首地址，loc就是从该首地址往后数loc个元素，得到最终定位</span></span><br><span class="line"><span class="comment"> *          某个具体参数（x或c或C1）的索引值，比如l.output中存储的数据如下所示（这里假设只存了一张训练图片的输出，</span></span><br><span class="line"><span class="comment"> *          因此batch只能为0；并假设l.out_w=l.out_h=2,l.classes=2）：</span></span><br><span class="line"><span class="comment"> *          xxxxyyyywwwwhhhhccccC1C1C1C1C2C2C2C2-#-xxxxyyyywwwwhhhhccccC1C1C1C1C2C2C2C2，</span></span><br><span class="line"><span class="comment"> *          n=0则定位到-#-左边的首地址（表示每个网格预测的第一个矩形框），n=1则定位到-#-右边的首地址（表示每个网格预测的第二个矩形框）</span></span><br><span class="line"><span class="comment"> *          entry=0,loc=0获取的是x的索引，且获取的是第一个x也即l.out_w*l.out_h个网格中第一个网格中第一个矩形框x参数的索引；</span></span><br><span class="line"><span class="comment"> *          entry=4,loc=1获取的是c的索引，且获取的是第二个c也即l.out_w*l.out_h个网格中第二个网格中第一个矩形框c参数的索引；</span></span><br><span class="line"><span class="comment"> *          entry=5,loc=2获取的是C1的索引，且获取的是第三个C1也即l.out_w*l.out_h个网格中第三个网格中第一个矩形框C1参数的索引；</span></span><br><span class="line"><span class="comment"> *          如果要获取第一个网格中第一个矩形框w参数的索引呢？如果已经获取了其x值的索引，显然用x的索引加上3*l.out_w*l.out_h即可获取到，</span></span><br><span class="line"><span class="comment"> *          这正是delta_region_box()函数的做法；</span></span><br><span class="line"><span class="comment"> *          如果要获取第三个网格中第一个矩形框C2参数的索引呢？如果已经获取了其C1值的索引，显然用C1的索引加上l.out_w*l.out_h即可获取到，</span></span><br><span class="line"><span class="comment"> *          这正是delta_region_class()函数中的做法；</span></span><br><span class="line"><span class="comment"> *          由上可知，entry=0时,即偏移0个小段，是获取x的索引；entry=4,是获取自信度信息c的索引；entry=5，是获取C1的索引.</span></span><br><span class="line"><span class="comment"> *          l.output的存储方式大致就是这样，个人觉得说的已经很清楚了，但可视化效果终究不如图文说明～</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">entry_index</span><span class="params">(layer l, <span class="keyword">int</span> batch, <span class="keyword">int</span> location, <span class="keyword">int</span> entry)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n =   location / (l.w*l.h);</span><br><span class="line">    <span class="keyword">int</span> loc = location % (l.w*l.h);</span><br><span class="line">    <span class="keyword">return</span> batch*l.outputs + n*l.w*l.h*(<span class="number">4</span>+l.classes+<span class="number">1</span>) + entry*l.w*l.h + loc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="forward-yolo-layer-前向传播函数"><a href="#forward-yolo-layer-前向传播函数" class="headerlink" title="forward_yolo_layer 前向传播函数"></a>forward_yolo_layer 前向传播函数</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//前向传播</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_yolo_layer</span><span class="params">(<span class="keyword">const</span> layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j, b, t, n;</span><br><span class="line">	<span class="comment">//将层输入直接拷贝到层输出</span></span><br><span class="line">    <span class="built_in">memcpy</span>(l.output, state.input, l.outputs*l.batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">   <span class="comment">//在 cpu 里，把预测输出的 x,y,confidence 和80种类别都 sigmoid 激活，确保值在0~1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> GPU</span></span><br><span class="line">    <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">        <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123;</span><br><span class="line">			<span class="comment">// 获取第b个batch开始的index</span></span><br><span class="line">            <span class="keyword">int</span> index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h, <span class="number">0</span>);</span><br><span class="line">			<span class="comment">// 对预测的tx,ty进行逻辑回归预测,</span></span><br><span class="line">            <span class="built_in">activate_array</span>(l.output + index, <span class="number">2</span> * l.w*l.h, LOGISTIC);        <span class="comment">// x,y,</span></span><br><span class="line">            <span class="built_in">scal_add_cpu</span>(<span class="number">2</span> * l.w*l.h, l.scale_x_y, <span class="number">-0.5</span>*(l.scale_x_y - <span class="number">1</span>), l.output + index, <span class="number">1</span>);    <span class="comment">// scale x,y</span></span><br><span class="line">            <span class="comment">// 获取第b个batch confidence开始的index</span></span><br><span class="line">			index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h, <span class="number">4</span>);</span><br><span class="line">			<span class="comment">// 对预测的confidence以及class进行逻辑回归</span></span><br><span class="line">            <span class="built_in">activate_array</span>(l.output + index, (<span class="number">1</span> + l.classes)*l.w*l.h, LOGISTIC);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// delta is zeroed</span></span><br><span class="line">	<span class="comment">//将yolo层的误差项进行初始化(包含整个batch的)</span></span><br><span class="line">    <span class="built_in">memset</span>(l.delta, <span class="number">0</span>, l.outputs * l.batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">// inference阶段,到此结束</span></span><br><span class="line">    <span class="keyword">if</span> (!state.train) <span class="keyword">return</span>;</span><br><span class="line">    <span class="comment">//float avg_iou = 0;</span></span><br><span class="line">    <span class="keyword">float</span> tot_iou = <span class="number">0</span>; <span class="comment">//总的IoU（Intersection over Union）</span></span><br><span class="line">    <span class="keyword">float</span> tot_giou = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_diou = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_ciou = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_iou_loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_giou_loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_diou_loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> tot_ciou_loss = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> recall = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> recall75 = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> avg_cat = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> avg_obj = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> avg_anyobj = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> class_count = <span class="number">0</span>;</span><br><span class="line">    *(l.cost) = <span class="number">0</span>; <span class="comment">// yolo层的总损失初始化为0</span></span><br><span class="line">    <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;<span class="comment">// 遍历batch中的每一张图片</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.h; ++j) &#123;</span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w; ++i) &#123;<span class="comment">// 遍历每个cell, 当前cell编号[j, i]</span></span><br><span class="line">                <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123;<span class="comment">// 遍历每一个bbox, 当前bbox编号 [n]</span></span><br><span class="line">					<span class="comment">// 在这里与yolov2 reorg层是相似的, 获得第j*w+i个cell第n个bbox的index</span></span><br><span class="line">                    <span class="keyword">int</span> box_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</span><br><span class="line">					<span class="comment">// 计算第j*w+i个cell第n个bbox在当前特征图上的相对位置[x,y],在网络输入图片上的相对宽度,高度[w,h]</span></span><br><span class="line">                    box pred = <span class="built_in">get_yolo_box</span>(l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, state.net.w, state.net.h, l.w*l.h);</span><br><span class="line">                    <span class="keyword">float</span> best_match_iou = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">int</span> <span class="keyword">best_match_t</span> = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">float</span> best_iou = <span class="number">0</span>; <span class="comment">// 保存最大iou</span></span><br><span class="line">                    <span class="keyword">int</span> <span class="keyword">best_t</span> = <span class="number">0</span>;<span class="comment">// 保存最大iou的bbox id</span></span><br><span class="line">                    <span class="keyword">for</span> (t = <span class="number">0</span>; t &lt; l.max_boxes; ++t) &#123;<span class="comment">// 遍历每一个GT bbox</span></span><br><span class="line">						<span class="comment">// 将第t个bbox由float数组转bbox结构体,方便计算iou</span></span><br><span class="line">                        box truth = <span class="built_in">float_to_box_stride</span>(state.truth + t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</span><br><span class="line">						<span class="comment">//获取第t个bbox的类别，检查是否有标注错误</span></span><br><span class="line">                        <span class="keyword">int</span> class_id = state.truth[t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                        <span class="keyword">if</span> (class_id &gt;= l.classes) &#123;</span><br><span class="line">                            <span class="built_in">printf</span>(<span class="string">&quot; Warning: in txt-labels class_id=%d &gt;= classes=%d in cfg-file. In txt-labels class_id should be [from 0 to %d] \n&quot;</span>, class_id, l.classes, l.classes - <span class="number">1</span>);</span><br><span class="line">                            <span class="built_in">printf</span>(<span class="string">&quot; truth.x = %f, truth.y = %f, truth.w = %f, truth.h = %f, class_id = %d \n&quot;</span>, truth.x, truth.y, truth.w, truth.h, class_id);</span><br><span class="line">                            <span class="built_in">getchar</span>();</span><br><span class="line">                            <span class="keyword">continue</span>; <span class="comment">// if label contains class_id more than number of classes in the cfg-file</span></span><br><span class="line">                        &#125;</span><br><span class="line">						<span class="comment">// 如果x坐标为0则取消,因为yolov3这里定义了max_boxes个bbox</span></span><br><span class="line">                        <span class="keyword">if</span> (!truth.x) <span class="keyword">break</span>;  <span class="comment">// continue;</span></span><br><span class="line"></span><br><span class="line">                        <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);<span class="comment">//预测bbox 类别s下标</span></span><br><span class="line">                        <span class="keyword">int</span> obj_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span>); <span class="comment">//预测bbox objectness下标</span></span><br><span class="line">                        <span class="keyword">float</span> objectness = l.output[obj_index]; <span class="comment">//预测bbox object置信度</span></span><br><span class="line">						<span class="comment">//获得预测bbox 的类别信息，如果某个类别的概率超过0.25返回1</span></span><br><span class="line">                        <span class="keyword">int</span> class_id_match = <span class="built_in">compare_yolo_class</span>(l.output, l.classes, class_index, l.w*l.h, objectness, class_id, <span class="number">0.25f</span>);</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth); <span class="comment">// 计算pred bbox与第t个GT bbox之间的iou</span></span><br><span class="line">						<span class="comment">// 这个地方和原始的DarkNet实现不太一样，多了一个class_id_match=1的限制，即预测bbox的置信度必须大于0.25</span></span><br><span class="line">                        <span class="keyword">if</span> (iou &gt; best_match_iou &amp;&amp; class_id_match == <span class="number">1</span>) &#123;</span><br><span class="line">                            best_match_iou = iou;</span><br><span class="line">                            <span class="keyword">best_match_t</span> = t;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (iou &gt; best_iou) &#123;</span><br><span class="line">                            best_iou = iou; <span class="comment">// 记录iou最大的iou</span></span><br><span class="line">                            <span class="keyword">best_t</span> = t; <span class="comment">// 记录该GT bbox的编号t</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">					<span class="comment">// 在这里与yolov2 reorg层是相似的, 获得第j*w+i个cell第n个bbox的confidence</span></span><br><span class="line">                    <span class="keyword">int</span> obj_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span>);</span><br><span class="line">					<span class="comment">// 统计pred bbox的confidence</span></span><br><span class="line">                    avg_anyobj += l.output[obj_index];</span><br><span class="line">					 <span class="comment">// 与yolov1相似,先将所有pred bbox都当做noobject, 计算其confidence梯度，不过这里多了一个平衡系数</span></span><br><span class="line">                    l.delta[obj_index] = l.cls_normalizer * (<span class="number">0</span> - l.output[obj_index]);</span><br><span class="line">					<span class="comment">// best_iou大于阈值则说明pred box有物体,在yolov3中正样本阈值ignore_thresh=.5</span></span><br><span class="line">                    <span class="keyword">if</span> (best_match_iou &gt; l.ignore_thresh) &#123;</span><br><span class="line">                        l.delta[obj_index] = <span class="number">0</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">					<span class="comment">// pred bbox为完全预测正确样本,在yolov3完全预测正确样本的阈值truth_thresh=1.</span></span><br><span class="line">					<span class="comment">//这个参数在cfg文件中，值为1，这个条件语句永远不可能成立</span></span><br><span class="line">                    <span class="keyword">if</span> (best_iou &gt; l.truth_thresh) &#123;</span><br><span class="line">						<span class="comment">// 作者在YOLOV3论文中的第4节提到了这部分。</span></span><br><span class="line">						<span class="comment">// 作者尝试Faster-RCNN中提到的双IOU策略，当Anchor与GT的IoU大于0.7时，该Anchor被算作正样本</span></span><br><span class="line">						<span class="comment">//计入损失中，但训练过程中并没有产生好的结果，所以最后放弃了。</span></span><br><span class="line">                        l.delta[obj_index] = l.cls_normalizer * (<span class="number">1</span> - l.output[obj_index]);</span><br><span class="line">						 <span class="comment">// 获得best_iou对应GT bbox的class的index</span></span><br><span class="line">                        <span class="keyword">int</span> class_id = state.truth[<span class="keyword">best_t</span>*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</span><br><span class="line">						<span class="comment">//yolov3 yolo层中map=0, 不参与计算</span></span><br><span class="line">                        <span class="keyword">if</span> (l.map) class_id = l.map[class_id];</span><br><span class="line">						<span class="comment">// 获得best_iou对应pred bbox的class的index</span></span><br><span class="line">                        <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</span><br><span class="line">                        <span class="built_in">delta_yolo_class</span>(l.output, l.delta, class_index, class_id, l.classes, l.w*l.h, <span class="number">0</span>, l.focal_loss, l.label_smooth_eps, l.classes_multipliers);</span><br><span class="line">                        box truth = <span class="built_in">float_to_box_stride</span>(state.truth + <span class="keyword">best_t</span>*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</span><br><span class="line">                        <span class="keyword">const</span> <span class="keyword">float</span> class_multiplier = (l.classes_multipliers) ? l.classes_multipliers[class_id] : <span class="number">1.0f</span>;</span><br><span class="line">                        <span class="comment">// 计算pred bbox的[x,y,w,h]的梯度</span></span><br><span class="line">						<span class="built_in">delta_yolo_box</span>(truth, l.output, l.biases, l.mask[n], box_index, i, j, l.w, l.h, state.net.w, state.net.h, l.delta, (<span class="number">2</span> - truth.w*truth.h), l.w*l.h, l.iou_normalizer * class_multiplier, l.iou_loss, <span class="number">1</span>, l.max_delta);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (t = <span class="number">0</span>; t &lt; l.max_boxes; ++t) &#123;</span><br><span class="line">			<span class="comment">//遍历每一个GT box</span></span><br><span class="line">			<span class="comment">// 将第t个bbox由float数组转bbox结构体,方便计算iou</span></span><br><span class="line">            box truth = <span class="built_in">float_to_box_stride</span>(state.truth + t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths, <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (truth.x &lt; <span class="number">0</span> || truth.y &lt; <span class="number">0</span> || truth.x &gt; <span class="number">1</span> || truth.y &gt; <span class="number">1</span> || truth.w &lt; <span class="number">0</span> || truth.h &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">char</span> buff[<span class="number">256</span>];</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot; Wrong label: truth.x = %f, truth.y = %f, truth.w = %f, truth.h = %f \n&quot;</span>, truth.x, truth.y, truth.w, truth.h);</span><br><span class="line">                <span class="built_in">sprintf</span>(buff, <span class="string">&quot;echo \&quot;Wrong label: truth.x = %f, truth.y = %f, truth.w = %f, truth.h = %f\&quot; &gt;&gt; bad_label.list&quot;</span>,</span><br><span class="line">                    truth.x, truth.y, truth.w, truth.h);</span><br><span class="line">                <span class="built_in">system</span>(buff);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> class_id = state.truth[t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</span><br><span class="line">            <span class="keyword">if</span> (class_id &gt;= l.classes) <span class="keyword">continue</span>; <span class="comment">// if label contains class_id more than number of classes in the cfg-file</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!truth.x) <span class="keyword">break</span>;  <span class="comment">// 如果x坐标为0则取消，因为yolov3定义了max_boxes个bbox,可能实际上没那么多</span></span><br><span class="line">            <span class="keyword">float</span> best_iou = <span class="number">0</span>; <span class="comment">//保存最大的IOU</span></span><br><span class="line">            <span class="keyword">int</span> best_n = <span class="number">0</span>; <span class="comment">//保存最大IOU的bbox index</span></span><br><span class="line">            i = (truth.x * l.w); <span class="comment">// 获得当前t个GT bbox所在的cell</span></span><br><span class="line">            j = (truth.y * l.h);</span><br><span class="line">            box truth_shift = truth;</span><br><span class="line">            truth_shift.x = truth_shift.y = <span class="number">0</span>; <span class="comment">//将truth_shift的box位置移动到0,0</span></span><br><span class="line">            <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.total; ++n) &#123; <span class="comment">// 遍历每一个anchor bbox找到与GT bbox最大的IOU</span></span><br><span class="line">                box pred = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">                pred.w = l.biases[<span class="number">2</span> * n] / state.net.w; <span class="comment">// 计算pred bbox的w在相对整张输入图片的位置</span></span><br><span class="line">                pred.h = l.biases[<span class="number">2</span> * n + <span class="number">1</span>] / state.net.h; <span class="comment">// 计算pred bbox的h在相对整张输入图片的位置</span></span><br><span class="line">                <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth_shift); <span class="comment">// 计算GT box truth_shift 与 预测bbox pred二者之间的IOU</span></span><br><span class="line">                <span class="keyword">if</span> (iou &gt; best_iou) &#123;</span><br><span class="line">                    best_iou = iou;<span class="comment">// 记录最大的IOU</span></span><br><span class="line">                    best_n = n;<span class="comment">// 以及记录该bbox的编号n</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 上面记录bbox的编号,是否由该层Anchor预测的</span></span><br><span class="line">            <span class="keyword">int</span> mask_n = <span class="built_in">int_index</span>(l.mask, best_n, l.n);</span><br><span class="line">            <span class="keyword">if</span> (mask_n &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> class_id = state.truth[t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                <span class="keyword">if</span> (l.map) class_id = l.map[class_id];</span><br><span class="line">				<span class="comment">// 获得best_iou对应anchor box的index</span></span><br><span class="line">                <span class="keyword">int</span> box_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</span><br><span class="line">				<span class="comment">//这个参数是用来控制样本数量不均衡的，即Focal Loss中的alpha</span></span><br><span class="line">                <span class="keyword">const</span> <span class="keyword">float</span> class_multiplier = (l.classes_multipliers) ? l.classes_multipliers[class_id] : <span class="number">1.0f</span>;</span><br><span class="line">				<span class="comment">// 计算best_iou对应Anchor bbox的[x,y,w,h]的梯度</span></span><br><span class="line">                ious all_ious = <span class="built_in">delta_yolo_box</span>(truth, l.output, l.biases, best_n, box_index, i, j, l.w, l.h, state.net.w, state.net.h, l.delta, (<span class="number">2</span> - truth.w*truth.h), l.w*l.h, l.iou_normalizer * class_multiplier, l.iou_loss, <span class="number">1</span>, l.max_delta);</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 下面的都是模板检测最新的工作，metricl learning，包括IOU/GIOU/DIOU/CIOU Loss</span></span><br><span class="line">                <span class="comment">// range is 0 &lt;= 1</span></span><br><span class="line">                tot_iou += all_ious.iou;</span><br><span class="line">                tot_iou_loss += <span class="number">1</span> - all_ious.iou;</span><br><span class="line">                <span class="comment">// range is -1 &lt;= giou &lt;= 1</span></span><br><span class="line">                tot_giou += all_ious.giou;</span><br><span class="line">                tot_giou_loss += <span class="number">1</span> - all_ious.giou;</span><br><span class="line"></span><br><span class="line">                tot_diou += all_ious.diou;</span><br><span class="line">                tot_diou_loss += <span class="number">1</span> - all_ious.diou;</span><br><span class="line"></span><br><span class="line">                tot_ciou += all_ious.ciou;</span><br><span class="line">                tot_ciou_loss += <span class="number">1</span> - all_ious.ciou;</span><br><span class="line">				<span class="comment">// 获得best_iou对应anchor box的confidence的index</span></span><br><span class="line">                <span class="keyword">int</span> obj_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span>);</span><br><span class="line">				<span class="comment">//统计confidence</span></span><br><span class="line">                avg_obj += l.output[obj_index];</span><br><span class="line">				<span class="comment">// 计算confidence的梯度</span></span><br><span class="line">                l.delta[obj_index] = class_multiplier * l.cls_normalizer * (<span class="number">1</span> - l.output[obj_index]);</span><br><span class="line">				<span class="comment">// 获得best_iou对应GT box的class的index</span></span><br><span class="line">                <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</span><br><span class="line">				<span class="comment">// 获得best_iou对应anchor box的class的index</span></span><br><span class="line">                <span class="built_in">delta_yolo_class</span>(l.output, l.delta, class_index, class_id, l.classes, l.w*l.h, &amp;avg_cat, l.focal_loss, l.label_smooth_eps, l.classes_multipliers);</span><br><span class="line"></span><br><span class="line">                ++count;</span><br><span class="line">                ++class_count;</span><br><span class="line">                <span class="keyword">if</span> (all_ious.iou &gt; <span class="number">.5</span>) recall += <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span> (all_ious.iou &gt; <span class="number">.75</span>) recall75 += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">			<span class="comment">//下面这个过程和上面一样，不过多约束了一个iou_thresh</span></span><br><span class="line">            <span class="comment">// iou_thresh</span></span><br><span class="line">            <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.total; ++n) &#123;</span><br><span class="line">                <span class="keyword">int</span> mask_n = <span class="built_in">int_index</span>(l.mask, n, l.n);</span><br><span class="line">                <span class="keyword">if</span> (mask_n &gt;= <span class="number">0</span> &amp;&amp; n != best_n &amp;&amp; l.iou_thresh &lt; <span class="number">1.0f</span>) &#123;</span><br><span class="line">                    box pred = &#123; <span class="number">0</span> &#125;;</span><br><span class="line">                    pred.w = l.biases[<span class="number">2</span> * n] / state.net.w;</span><br><span class="line">                    pred.h = l.biases[<span class="number">2</span> * n + <span class="number">1</span>] / state.net.h;</span><br><span class="line">                    <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth_shift);</span><br><span class="line">                    <span class="comment">// iou, n</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (iou &gt; l.iou_thresh) &#123;</span><br><span class="line">                        <span class="keyword">int</span> class_id = state.truth[t*(<span class="number">4</span> + <span class="number">1</span>) + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                        <span class="keyword">if</span> (l.map) class_id = l.map[class_id];</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">int</span> box_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</span><br><span class="line">                        <span class="keyword">const</span> <span class="keyword">float</span> class_multiplier = (l.classes_multipliers) ? l.classes_multipliers[class_id] : <span class="number">1.0f</span>;</span><br><span class="line">                        ious all_ious = <span class="built_in">delta_yolo_box</span>(truth, l.output, l.biases, n, box_index, i, j, l.w, l.h, state.net.w, state.net.h, l.delta, (<span class="number">2</span> - truth.w*truth.h), l.w*l.h, l.iou_normalizer * class_multiplier, l.iou_loss, <span class="number">1</span>, l.max_delta);</span><br><span class="line"></span><br><span class="line">                        <span class="comment">// range is 0 &lt;= 1</span></span><br><span class="line">                        tot_iou += all_ious.iou;</span><br><span class="line">                        tot_iou_loss += <span class="number">1</span> - all_ious.iou;</span><br><span class="line">                        <span class="comment">// range is -1 &lt;= giou &lt;= 1</span></span><br><span class="line">                        tot_giou += all_ious.giou;</span><br><span class="line">                        tot_giou_loss += <span class="number">1</span> - all_ious.giou;</span><br><span class="line"></span><br><span class="line">                        tot_diou += all_ious.diou;</span><br><span class="line">                        tot_diou_loss += <span class="number">1</span> - all_ious.diou;</span><br><span class="line"></span><br><span class="line">                        tot_ciou += all_ious.ciou;</span><br><span class="line">                        tot_ciou_loss += <span class="number">1</span> - all_ious.ciou;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">int</span> obj_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span>);</span><br><span class="line">                        avg_obj += l.output[obj_index];</span><br><span class="line">                        l.delta[obj_index] = class_multiplier * l.cls_normalizer * (<span class="number">1</span> - l.output[obj_index]);</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, b, mask_n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</span><br><span class="line">                        <span class="built_in">delta_yolo_class</span>(l.output, l.delta, class_index, class_id, l.classes, l.w*l.h, &amp;avg_cat, l.focal_loss, l.label_smooth_eps, l.classes_multipliers);</span><br><span class="line"></span><br><span class="line">                        ++count;</span><br><span class="line">                        ++class_count;</span><br><span class="line">                        <span class="keyword">if</span> (all_ious.iou &gt; <span class="number">.5</span>) recall += <span class="number">1</span>;</span><br><span class="line">                        <span class="keyword">if</span> (all_ious.iou &gt; <span class="number">.75</span>) recall75 += <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// averages the deltas obtained by the function: delta_yolo_box()_accumulate</span></span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.h; ++j) &#123;</span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w; ++i) &#123;</span><br><span class="line">                <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123;</span><br><span class="line">					<span class="comment">// 在这里与yolov2 reorg层是相似的, 获得第j*w+i个cell第n个bbox的index</span></span><br><span class="line">                    <span class="keyword">int</span> box_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</span><br><span class="line">					<span class="comment">//获得第j*w+i个cell第n个bbox的类别</span></span><br><span class="line">                    <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">4</span> + <span class="number">1</span>);</span><br><span class="line">					<span class="comment">//特征图的大小</span></span><br><span class="line">                    <span class="keyword">const</span> <span class="keyword">int</span> stride = l.w*l.h;</span><br><span class="line">					<span class="comment">//对梯度进行平均</span></span><br><span class="line">                    <span class="built_in">averages_yolo_deltas</span>(class_index, box_index, stride, l.classes, l.delta);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//*(l.cost) = pow(mag_array(l.delta, l.outputs * l.batch), 2);</span></span><br><span class="line">    <span class="comment">//printf(&quot;Region %d Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, .5R: %f, .75R: %f,  count: %d\n&quot;, state.index, avg_iou / count, avg_cat / class_count, avg_obj / count, avg_anyobj / (l.w*l.h*l.n*l.batch), recall / count, recall75 / count, count);</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> stride = l.w*l.h;</span><br><span class="line">    <span class="keyword">float</span>* no_iou_loss_delta = (<span class="keyword">float</span> *)<span class="built_in">calloc</span>(l.batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="built_in">memcpy</span>(no_iou_loss_delta, l.delta, l.batch * l.outputs * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.h; ++j) &#123;</span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w; ++i) &#123;</span><br><span class="line">                <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123;</span><br><span class="line">					<span class="comment">//yolov3如果使用的是iou loss，也就是metric learning的方式，那么x,y,w,h的loss可以设置为0</span></span><br><span class="line">                    <span class="keyword">int</span> index = <span class="built_in">entry_index</span>(l, b, n*l.w*l.h + j*l.w + i, <span class="number">0</span>);</span><br><span class="line">                    no_iou_loss_delta[index + <span class="number">0</span> * stride] = <span class="number">0</span>;</span><br><span class="line">                    no_iou_loss_delta[index + <span class="number">1</span> * stride] = <span class="number">0</span>;</span><br><span class="line">                    no_iou_loss_delta[index + <span class="number">2</span> * stride] = <span class="number">0</span>;</span><br><span class="line">                    no_iou_loss_delta[index + <span class="number">3</span> * stride] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">//计算所有的分类loss</span></span><br><span class="line">    <span class="keyword">float</span> classification_loss = l.cls_normalizer * <span class="built_in">pow</span>(<span class="built_in">mag_array</span>(no_iou_loss_delta, l.outputs * l.batch), <span class="number">2</span>);</span><br><span class="line">    <span class="built_in">free</span>(no_iou_loss_delta);</span><br><span class="line">	<span class="comment">//计算总的loss</span></span><br><span class="line">    <span class="keyword">float</span> loss = <span class="built_in">pow</span>(<span class="built_in">mag_array</span>(l.delta, l.outputs * l.batch), <span class="number">2</span>);</span><br><span class="line">	<span class="comment">//计算回归loss</span></span><br><span class="line">    <span class="keyword">float</span> iou_loss = loss - classification_loss;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> avg_iou_loss = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// gIOU loss + MSE (objectness) loss</span></span><br><span class="line">    <span class="keyword">if</span> (l.iou_loss == MSE) &#123;</span><br><span class="line">        *(l.cost) = <span class="built_in">pow</span>(<span class="built_in">mag_array</span>(l.delta, l.outputs * l.batch), <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Always compute classification loss both for iou + cls loss and for logging with mse loss</span></span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> remove IOU loss fields before computing MSE on class</span></span><br><span class="line">        <span class="comment">//   probably split into two arrays</span></span><br><span class="line">        <span class="keyword">if</span> (l.iou_loss == GIOU) &#123;</span><br><span class="line">            avg_iou_loss = count &gt; <span class="number">0</span> ? l.iou_normalizer * (tot_giou_loss / count) : <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">//count代表目标个数</span></span><br><span class="line">            avg_iou_loss = count &gt; <span class="number">0</span> ? l.iou_normalizer * (tot_iou_loss / count) : <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        *(l.cost) = avg_iou_loss + classification_loss;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    loss /= l.batch;</span><br><span class="line">    classification_loss /= l.batch;</span><br><span class="line">    iou_loss /= l.batch;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;v3 (%s loss, Normalizer: (iou: %f, cls: %f) Region %d Avg (IOU: %f, GIOU: %f), Class: %f, Obj: %f, No Obj: %f, .5R: %f, .75R: %f, count: %d, loss = %f, class_loss = %f, iou_loss = %f\n&quot;</span>,</span><br><span class="line">        (l.iou_loss == MSE ? <span class="string">&quot;mse&quot;</span> : (l.iou_loss == GIOU ? <span class="string">&quot;giou&quot;</span> : <span class="string">&quot;iou&quot;</span>)), l.iou_normalizer, l.cls_normalizer, state.index, tot_iou / count, tot_giou / count, avg_cat / class_count, avg_obj / count, avg_anyobj / (l.w*l.h*l.n*l.batch), recall / count, recall75 / count, count,</span><br><span class="line">        loss, classification_loss, iou_loss);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="backward-yolo-layer-误差反向传播"><a href="#backward-yolo-layer-误差反向传播" class="headerlink" title="backward_yolo_layer 误差反向传播"></a>backward_yolo_layer 误差反向传播</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//误差反向传播</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backward_yolo_layer</span><span class="params">(<span class="keyword">const</span> layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//直接把 l.delta 拷贝给上一层的 delta。注意 net.delta 指向 prev_layer.delta。</span></span><br><span class="line">   <span class="built_in">axpy_cpu</span>(l.batch*l.inputs, <span class="number">1</span>, l.delta, <span class="number">1</span>, state.delta, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="correct-yolo-boxes-调整预测-box-中心和大小"><a href="#correct-yolo-boxes-调整预测-box-中心和大小" class="headerlink" title="correct_yolo_boxes 调整预测 box 中心和大小"></a>correct_yolo_boxes 调整预测 box 中心和大小</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//调整预测 box 中心和大小</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">correct_yolo_boxes</span><span class="params">(detection *dets, <span class="keyword">int</span> n, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> netw, <span class="keyword">int</span> neth, <span class="keyword">int</span> relative, <span class="keyword">int</span> letter)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//w 和 h 是输入图片的尺寸，netw 和 neth 是网络输入尺寸</span></span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="comment">// network height (or width)</span></span><br><span class="line">    <span class="keyword">int</span> new_w = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// network height (or width)</span></span><br><span class="line">    <span class="keyword">int</span> new_h = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// Compute scale given image w,h vs network w,h</span></span><br><span class="line">    <span class="comment">// I think this &quot;rotates&quot; the image to match network to input image w/h ratio</span></span><br><span class="line">    <span class="comment">// new_h and new_w are really just network width and height</span></span><br><span class="line">    <span class="keyword">if</span> (letter) &#123;</span><br><span class="line">        <span class="keyword">if</span> (((<span class="keyword">float</span>)netw / w) &lt; ((<span class="keyword">float</span>)neth / h)) &#123; <span class="comment">//新图片尺寸</span></span><br><span class="line">            new_w = netw;</span><br><span class="line">            new_h = (h * netw) / w;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            new_h = neth;</span><br><span class="line">            new_w = (w * neth) / h;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        new_w = netw;</span><br><span class="line">        new_h = neth;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// difference between network width and &quot;rotated&quot; width</span></span><br><span class="line">    <span class="keyword">float</span> deltaw = netw - new_w;</span><br><span class="line">    <span class="comment">// difference between network height and &quot;rotated&quot; height</span></span><br><span class="line">    <span class="keyword">float</span> deltah = neth - new_h;</span><br><span class="line">    <span class="comment">// ratio between rotated network width and network width</span></span><br><span class="line">    <span class="keyword">float</span> ratiow = (<span class="keyword">float</span>)new_w / netw;</span><br><span class="line">    <span class="comment">// ratio between rotated network width and network width</span></span><br><span class="line">    <span class="keyword">float</span> ratioh = (<span class="keyword">float</span>)new_h / neth;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; ++i) &#123; <span class="comment">//调整 box 相对新图片尺寸的位置</span></span><br><span class="line"></span><br><span class="line">        box b = dets[i].bbox;</span><br><span class="line">        <span class="comment">// x = ( x - (deltaw/2)/netw ) / ratiow;</span></span><br><span class="line">        <span class="comment">//   x - [(1/2 the difference of the network width and rotated width) / (network width)]</span></span><br><span class="line">        b.x = (b.x - deltaw / <span class="number">2.</span> / netw) / ratiow;</span><br><span class="line">        b.y = (b.y - deltah / <span class="number">2.</span> / neth) / ratioh;</span><br><span class="line">        <span class="comment">// scale to match rotation of incoming image</span></span><br><span class="line">        b.w *= <span class="number">1</span> / ratiow;</span><br><span class="line">        b.h *= <span class="number">1</span> / ratioh;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// relative seems to always be == 1, I don&#x27;t think we hit this condition, ever.</span></span><br><span class="line">        <span class="keyword">if</span> (!relative) &#123;</span><br><span class="line">            b.x *= w;</span><br><span class="line">            b.w *= w;</span><br><span class="line">            b.y *= h;</span><br><span class="line">            b.h *= h;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        dets[i].bbox = b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="yolo-num-detections-预测输出中置信度超过阈值的-box-个数"><a href="#yolo-num-detections-预测输出中置信度超过阈值的-box-个数" class="headerlink" title="yolo_num_detections 预测输出中置信度超过阈值的 box 个数"></a>yolo_num_detections 预测输出中置信度超过阈值的 box 个数</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//预测输出中置信度超过阈值的 box 个数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">yolo_num_detections</span><span class="params">(layer l, <span class="keyword">float</span> thresh)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, n;</span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w*l.h; ++i)&#123;</span><br><span class="line">        <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.n; ++n)&#123;</span><br><span class="line">			<span class="comment">////获得置信度偏移位置</span></span><br><span class="line">            <span class="keyword">int</span> obj_index  = <span class="built_in">entry_index</span>(l, <span class="number">0</span>, n*l.w*l.h + i, <span class="number">4</span>);</span><br><span class="line">			<span class="comment">//置信度超过阈值</span></span><br><span class="line">            <span class="keyword">if</span>(l.output[obj_index] &gt; thresh)&#123;</span><br><span class="line">                ++count;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="get-yolo-detections-获得预测输出中超过阈值的-box"><a href="#get-yolo-detections-获得预测输出中超过阈值的-box" class="headerlink" title="get_yolo_detections 获得预测输出中超过阈值的 box"></a>get_yolo_detections 获得预测输出中超过阈值的 box</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//获得预测输出中超过阈值的 box</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get_yolo_detections</span><span class="params">(layer l, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> netw, <span class="keyword">int</span> neth, <span class="keyword">float</span> thresh, <span class="keyword">int</span> *map, <span class="keyword">int</span> relative, detection *dets, <span class="keyword">int</span> letter)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//printf(&quot;\n l.batch = %d, l.w = %d, l.h = %d, l.n = %d \n&quot;, l.batch, l.w, l.h, l.n);</span></span><br><span class="line">    <span class="keyword">int</span> i,j,n;</span><br><span class="line">    <span class="keyword">float</span> *predictions = l.output;</span><br><span class="line">    <span class="comment">// This snippet below is not necessary</span></span><br><span class="line">    <span class="comment">// Need to comment it in order to batch processing &gt;= 2 images</span></span><br><span class="line">    <span class="comment">//if (l.batch == 2) avg_flipped_yolo(l);</span></span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w*l.h; ++i)&#123;</span><br><span class="line">        <span class="keyword">int</span> row = i / l.w;</span><br><span class="line">        <span class="keyword">int</span> col = i % l.w;</span><br><span class="line">        <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.n; ++n)&#123;</span><br><span class="line">            <span class="keyword">int</span> obj_index  = <span class="built_in">entry_index</span>(l, <span class="number">0</span>, n*l.w*l.h + i, <span class="number">4</span>);</span><br><span class="line">            <span class="keyword">float</span> objectness = predictions[obj_index]; <span class="comment">//置信度</span></span><br><span class="line">            <span class="comment">//if(objectness &lt;= thresh) continue;    // incorrect behavior for Nan values</span></span><br><span class="line">            <span class="keyword">if</span> (objectness &gt; thresh) &#123;</span><br><span class="line">                <span class="comment">//printf(&quot;\n objectness = %f, thresh = %f, i = %d, n = %d \n&quot;, objectness, thresh, i, n);</span></span><br><span class="line">                <span class="keyword">int</span> box_index = <span class="built_in">entry_index</span>(l, <span class="number">0</span>, n*l.w*l.h + i, <span class="number">0</span>);</span><br><span class="line">                dets[count].bbox = <span class="built_in">get_yolo_box</span>(predictions, l.biases, l.mask[n], box_index, col, row, l.w, l.h, netw, neth, l.w*l.h);</span><br><span class="line">                dets[count].objectness = objectness;</span><br><span class="line">                dets[count].classes = l.classes;</span><br><span class="line">                <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.classes; ++j) &#123;</span><br><span class="line">                    <span class="keyword">int</span> class_index = <span class="built_in">entry_index</span>(l, <span class="number">0</span>, n*l.w*l.h + i, <span class="number">4</span> + <span class="number">1</span> + j);</span><br><span class="line">                    <span class="keyword">float</span> prob = objectness*predictions[class_index];<span class="comment">//置信度 x 类别概率</span></span><br><span class="line">                    dets[count].prob[j] = (prob &gt; thresh) ? prob : <span class="number">0</span>;<span class="comment">//小于阈值则概率置0</span></span><br><span class="line">                &#125;</span><br><span class="line">                ++count;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">correct_yolo_boxes</span>(dets, count, w, h, netw, neth, relative, letter);<span class="comment">//调整 box 大小</span></span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOV2损失函数代码详解(region_layer.c)</title>
    <url>/2020/02/27/YOLOV2%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(region_layer.c)/</url>
    <content><![CDATA[<h2 id="YOLOV2损失函数"><a href="#YOLOV2损失函数" class="headerlink" title="YOLOV2损失函数"></a>YOLOV2损失函数</h2><p>YOLOV2对每个预测<code>box</code>的<code>[x,y]</code>，<code>confidence</code>进行逻辑回归，类别进行<code>softmax</code>回归；</p>
<p>在Darknet中，损失函数可以用下图来进行表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/661.webp" alt></p>
<p>可以看到这个损失函数是相当复杂的，损失函数的定义在Darknet/src/region_layer.c中。对于上面这一堆公式，我们先简单看一下，然后我们在源码中去找到对应部分。这里的$W$和$H$代表的是特征图的高宽，都为13，而$A$指的是Anchor个数，YOLOv2中是5，各个$\lambda$值是各个loss部分的权重系数。我们将损失函数分成3大部分来解释：</p>
<ul>
<li><p>第一部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/662.png" alt><br>第一项需要好好解释一下，这个loss是计算background的置信度误差，这也是YOLO系列算法的特色，但是用哪些预测框来预测背景呢？这里需要计算各个预测框和所有的ground  truth之间的IOU值，并且取最大值记作MaxIOU，如果该值小于一定的阈值，YOLOv2论文取了0.6，那么这个预测框就标记为background，需要计算$\lambda_{n o o b j}$这么多倍的损失函数。为什么这个公式可以这样表达呢？因为我们有物体的话，那么$\lambda_{n o o b j}=0$，如果没有物体$\lambda_{\text {noob} j}=1$，我们把这个值带入到下面的公式就可以推出第一项啦！<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/663.webp" alt></p>
</li>
<li><p>第二部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/664.png" alt><br>这一部分是计算Anchor boxes和预测框的坐标误差，但是只在前12800个iter计算，这一项应该是促进网络学习到Anchor的形状。</p>
</li>
<li><p>第三部分：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/ABDarknet/665.webp" alt><br>这一部分计算的是和ground truth匹配的预测框各部分的损失总和，包括坐标损失，置信度损失以及分类损失。<br><strong>3.1 坐标损失</strong> 这里的匹配原则是指对于某个特定的ground truth，首先要计算其中心点落在哪个cell上，然后计算这个cell的5个先验框和grond  truth的IOU值，计算IOU值的时候不考虑坐标只考虑形状，所以先将Anchor boxes和ground  truth的中心都偏移到同一位置，然后计算出对应的IOU值，IOU值最大的先验框和ground  truth匹配，对应的预测框用来预测这个ground truth。<br><strong>3.2 置信度损失</strong> 在计算obj置信度时， 增加了一项权重系数，也被称为rescore参数，当其为1时，损失是预测框和ground truth的真实IOU值(darknet中采用了这种实现方式)。而对于没有和ground  truth匹配的先验框，除去那些Max_IOU低于阈值的，其它就全部忽略。YOLOv2和SSD与RPN网络的处理方式有很大不同，因为它们可以将一个ground truth分配给多个先验框。<br><strong>3.3 分类损失</strong> 这个和YOLOv1一致，没什么好说的了。</p>
</li>
</ul>
<p>我看了一篇讲解YOLOv2损失函数非常好的文章：<a href="https://www.cnblogs.com/YiXiaoZhou/p/7429481.html">https://www.cnblogs.com/YiXiaoZhou/p/7429481.html</a> 。里面还有一个关键点：</p>
<p>在计算boxes的$w$和$h$误差时，YOLOv1中采用的是平方根以降低boxes的大小对误差的影响，而YOLOv2是直接计算，但是根据ground truth的大小对权重系数进行修正：l.coord_scale x (2 - truth.w x truth.h)（这里和都归一化到(0,1))，这样对于尺度较小的boxes其权重系数会更大一些，可以放大误差，起到和YOLOv1计算平方根相似的效果。</p>
<h2 id="代码详解"><a href="#代码详解" class="headerlink" title="代码详解"></a>代码详解</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> DOABS 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 构建YOLOv2 region_layer层</span></span><br><span class="line"><span class="comment">// batch 一个batch中包含的图片数</span></span><br><span class="line"><span class="comment">// w 输入特征图的宽度</span></span><br><span class="line"><span class="comment">// h 输入特征图的高度</span></span><br><span class="line"><span class="comment">// n 一个cell预测多少个bbox</span></span><br><span class="line"><span class="comment">// classes 网络需要识别的物体类别数</span></span><br><span class="line"><span class="comment">// coord 一个bbox包含的[x,y,w,h]</span></span><br><span class="line"><span class="function">region_layer <span class="title">make_region_layer</span><span class="params">(<span class="keyword">int</span> batch, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">int</span> n, <span class="keyword">int</span> classes, <span class="keyword">int</span> coords, <span class="keyword">int</span> max_boxes)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    region_layer l = &#123; (LAYER_TYPE)<span class="number">0</span> &#125;;</span><br><span class="line">    l.type = REGION; <span class="comment">//层类别</span></span><br><span class="line">	<span class="comment">// 这些变量都可以参考darknet.h中的注释</span></span><br><span class="line">    l.n = n; <span class="comment">//一个cell中预测多少个box</span></span><br><span class="line">    l.batch = batch; <span class="comment">//一个batch中包含的图片数</span></span><br><span class="line">    l.h = h; <span class="comment">//输入图片的宽度</span></span><br><span class="line">    l.w = w; <span class="comment">//输入图片的宽度</span></span><br><span class="line">    l.classes = classes; <span class="comment">//网络需要识别的物体类数</span></span><br><span class="line">    l.coords = coords; <span class="comment">//定位一个物体所需的参数个数（一般值为4,包括矩形中心点坐标x,y以及长宽w,h）</span></span><br><span class="line">    l.cost = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(<span class="number">1</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)); <span class="comment">//目标函数值，为单精度浮点型指针</span></span><br><span class="line">    l.biases = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(n * <span class="number">2</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    l.bias_updates = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(n * <span class="number">2</span>, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    l.outputs = h*w*n*(classes + coords + <span class="number">1</span>);  <span class="comment">//一张训练图片经过region_layer层后得到的输出元素个数（等于网格数*每个网格预测的矩形框数*每个矩形框的参数个数）</span></span><br><span class="line">    l.inputs = l.outputs;   <span class="comment">//一张训练图片输入到reigon_layer层的元素个数（注意是一张图片，对于region_layer，输入和输出的元素个数相等）</span></span><br><span class="line">    <span class="comment">//每张图片含有的真实矩形框参数的个数（max_boxes表示一张图片中最多有max_boxes个ground truth矩形框，每个真实矩形框有</span></span><br><span class="line">    <span class="comment">//5个参数，包括x,y,w,h四个定位参数，以及物体类别）,注意max_boxes是darknet程序内写死的，实际上每张图片可能</span></span><br><span class="line">    <span class="comment">//并没有max_boxes个真实矩形框，也能没有这么多参数，但为了保持一致性，还是会留着这么大的存储空间，只是其中的</span></span><br><span class="line">    <span class="comment">//值为空而已.</span></span><br><span class="line">	l.max_boxes = max_boxes;</span><br><span class="line">	<span class="comment">// GT: max_boxes*(4+1) 存储max_boxes个bbox的信息，这里是假设图片中GT bbox的数量是</span></span><br><span class="line">	<span class="comment">//小于max_boxes的，这里是写死的；此处与yolov1是不同的</span></span><br><span class="line">    l.truths = max_boxes*(<span class="number">5</span>);</span><br><span class="line">	<span class="comment">//  region层误差项（包含整个batch的）</span></span><br><span class="line">    l.delta = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">// region层所有输出（包含整个batch的）</span></span><br><span class="line">    <span class="comment">//region_layer的输出维度是l.out_w*l.out_h，等于输出的维度，输出的通道数为l.out_c，也即是输入的通道数，具体为：n*(classes+coords+1)</span></span><br><span class="line">	<span class="comment">//YOLO检测模型将图片分成S*S个网格，每个网格又预测B个矩形框，最后一层输出的就是这些网格中包含的所有矩形框的信息</span></span><br><span class="line">	l.output = (<span class="keyword">float</span>*)<span class="built_in">xcalloc</span>(batch * l.outputs, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">	<span class="comment">//存储bbox的Anchor box的[w,h]的初始化,在src/parse.c中parse_yolo函数会加载cfg中Anchor尺寸</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n*<span class="number">2</span>; ++i)&#123;</span><br><span class="line">        l.biases[i] = <span class="number">.5</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    l.forward = forward_region_layer;</span><br><span class="line">    l.backward = backward_region_layer;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    l.forward_gpu = forward_region_layer_gpu;</span><br><span class="line">    l.backward_gpu = backward_region_layer_gpu;</span><br><span class="line">    l.output_gpu = <span class="built_in">cuda_make_array</span>(l.output, batch*l.outputs);</span><br><span class="line">    l.delta_gpu = <span class="built_in">cuda_make_array</span>(l.delta, batch*l.outputs);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;detection\n&quot;</span>);</span><br><span class="line">    <span class="built_in">srand</span>(<span class="built_in">time</span>(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> l;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">resize_region_layer</span><span class="params">(layer *l, <span class="keyword">int</span> w, <span class="keyword">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="keyword">int</span> old_w = l-&gt;w;</span><br><span class="line">    <span class="keyword">int</span> old_h = l-&gt;h;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    l-&gt;w = w;</span><br><span class="line">    l-&gt;h = h;</span><br><span class="line"></span><br><span class="line">    l-&gt;outputs = h*w*l-&gt;n*(l-&gt;classes + l-&gt;coords + <span class="number">1</span>);</span><br><span class="line">    l-&gt;inputs = l-&gt;outputs;</span><br><span class="line"></span><br><span class="line">    l-&gt;output = (<span class="keyword">float</span>*)<span class="built_in">xrealloc</span>(l-&gt;output, l-&gt;batch * l-&gt;outputs * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    l-&gt;delta = (<span class="keyword">float</span>*)<span class="built_in">xrealloc</span>(l-&gt;delta, l-&gt;batch * l-&gt;outputs * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> GPU</span></span><br><span class="line">    <span class="keyword">if</span> (old_w &lt; w || old_h &lt; h) &#123;</span><br><span class="line">        <span class="built_in">cuda_free</span>(l-&gt;delta_gpu);</span><br><span class="line">        <span class="built_in">cuda_free</span>(l-&gt;output_gpu);</span><br><span class="line"></span><br><span class="line">        l-&gt;delta_gpu = <span class="built_in">cuda_make_array</span>(l-&gt;delta, l-&gt;batch*l-&gt;outputs);</span><br><span class="line">        l-&gt;output_gpu = <span class="built_in">cuda_make_array</span>(l-&gt;output, l-&gt;batch*l-&gt;outputs);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//获取某个矩形框的4个定位信息，即根据输入的矩形框索引从l.output中获取该矩形框的定位信息x,y,w,h</span></span><br><span class="line"><span class="comment">//x  region_layer的输出，即l.output，包含所有batch预测得到的矩形框信息</span></span><br><span class="line"><span class="comment">//biases 表示Anchor框的长和宽</span></span><br><span class="line"><span class="comment">//index 矩形框的首地址（索引，矩形框中存储的首个参数x在l.output中的索引）</span></span><br><span class="line"><span class="comment">//i 第几行（region_layer维度为l.out_w*l.out_c）</span></span><br><span class="line"><span class="comment">//j 第几列</span></span><br><span class="line"><span class="comment">//w 特征图的宽度</span></span><br><span class="line"><span class="comment">//h 特征图的高度</span></span><br><span class="line"><span class="function">box <span class="title">get_region_box</span><span class="params">(<span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> w, <span class="keyword">int</span> h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    box b;</span><br><span class="line">    b.x = (i + <span class="built_in">logistic_activate</span>(x[index + <span class="number">0</span>])) / w;</span><br><span class="line">    b.y = (j + <span class="built_in">logistic_activate</span>(x[index + <span class="number">1</span>])) / h;</span><br><span class="line">    b.w = <span class="built_in">exp</span>(x[index + <span class="number">2</span>]) * biases[<span class="number">2</span>*n];</span><br><span class="line">    b.h = <span class="built_in">exp</span>(x[index + <span class="number">3</span>]) * biases[<span class="number">2</span>*n+<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">if</span>(DOABS)&#123;</span><br><span class="line">        b.w = <span class="built_in">exp</span>(x[index + <span class="number">2</span>]) * biases[<span class="number">2</span>*n]   / w;</span><br><span class="line">        b.h = <span class="built_in">exp</span>(x[index + <span class="number">3</span>]) * biases[<span class="number">2</span>*n+<span class="number">1</span>] / h;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">delta_region_box</span><span class="params">(box truth, <span class="keyword">float</span> *x, <span class="keyword">float</span> *biases, <span class="keyword">int</span> n, <span class="keyword">int</span> index, <span class="keyword">int</span> i, <span class="keyword">int</span> j, <span class="keyword">int</span> w, <span class="keyword">int</span> h, <span class="keyword">float</span> *delta, <span class="keyword">float</span> scale)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">// 获得第j*w+i个cell第n个bbox在当前特征图上位置和宽高</span></span><br><span class="line">    box pred = <span class="built_in">get_region_box</span>(x, biases, n, index, i, j, w, h);</span><br><span class="line">	<span class="comment">// 计算pred bbox 与 GT bbox的IOU【前12800GT boox为当前cell第n个bbox的Anchor】</span></span><br><span class="line">    <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算GT bbox的tx,ty,tw,th</span></span><br><span class="line">    <span class="keyword">float</span> tx = (truth.x*w - i);</span><br><span class="line">    <span class="keyword">float</span> ty = (truth.y*h - j);</span><br><span class="line">    <span class="keyword">float</span> tw = <span class="built_in">log</span>(truth.w / biases[<span class="number">2</span>*n]);</span><br><span class="line">    <span class="keyword">float</span> th = <span class="built_in">log</span>(truth.h / biases[<span class="number">2</span>*n + <span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">if</span>(DOABS)&#123;</span><br><span class="line">        tw = <span class="built_in">log</span>(truth.w*w / biases[<span class="number">2</span>*n]);</span><br><span class="line">        th = <span class="built_in">log</span>(truth.h*h / biases[<span class="number">2</span>*n + <span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算tx,ty,tw,th梯度</span></span><br><span class="line">    delta[index + <span class="number">0</span>] = scale * (tx - <span class="built_in">logistic_activate</span>(x[index + <span class="number">0</span>])) * <span class="built_in">logistic_gradient</span>(<span class="built_in">logistic_activate</span>(x[index + <span class="number">0</span>]));</span><br><span class="line">    delta[index + <span class="number">1</span>] = scale * (ty - <span class="built_in">logistic_activate</span>(x[index + <span class="number">1</span>])) * <span class="built_in">logistic_gradient</span>(<span class="built_in">logistic_activate</span>(x[index + <span class="number">1</span>]));</span><br><span class="line">    delta[index + <span class="number">2</span>] = scale * (tw - x[index + <span class="number">2</span>]);</span><br><span class="line">    delta[index + <span class="number">3</span>] = scale * (th - x[index + <span class="number">3</span>]);</span><br><span class="line">    <span class="keyword">return</span> iou;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">delta_region_class</span><span class="params">(<span class="keyword">float</span> *output, <span class="keyword">float</span> *delta, <span class="keyword">int</span> index, <span class="keyword">int</span> class_id, <span class="keyword">int</span> classes, tree *hier, <span class="keyword">float</span> scale, <span class="keyword">float</span> *avg_cat, <span class="keyword">int</span> focal_loss)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, n;</span><br><span class="line">    <span class="keyword">if</span>(hier)&#123; <span class="comment">// 在yolov2 中region层, 此部分不参与计算【这是在yolo9000才参与计算】</span></span><br><span class="line">        <span class="keyword">float</span> pred = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(class_id &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">            pred *= output[index + class_id];</span><br><span class="line">            <span class="keyword">int</span> g = hier-&gt;group[class_id];</span><br><span class="line">            <span class="keyword">int</span> offset = hier-&gt;group_offset[g];</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; hier-&gt;group_size[g]; ++i)&#123;</span><br><span class="line">                delta[index + offset + i] = scale * (<span class="number">0</span> - output[index + offset + i]);</span><br><span class="line">            &#125;</span><br><span class="line">            delta[index + class_id] = scale * (<span class="number">1</span> - output[index + class_id]);</span><br><span class="line"></span><br><span class="line">            class_id = hier-&gt;parent[class_id];</span><br><span class="line">        &#125;</span><br><span class="line">        *avg_cat += pred;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Focal loss</span></span><br><span class="line">        <span class="keyword">if</span> (focal_loss) &#123; <span class="comment">//如果使用focal loss</span></span><br><span class="line">            <span class="comment">// Focal Loss</span></span><br><span class="line">            <span class="keyword">float</span> alpha = <span class="number">0.5</span>;    <span class="comment">// 0.25 or 0.5</span></span><br><span class="line">            <span class="comment">//float gamma = 2;    // hardcoded in many places of the grad-formula</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">int</span> ti = index + class_id;</span><br><span class="line">            <span class="keyword">float</span> pt = output[ti] + <span class="number">0.000000000000001F</span>;</span><br><span class="line">            <span class="comment">// http://fooplot.com/#W3sidHlwZSI6MCwiZXEiOiItKDEteCkqKDIqeCpsb2coeCkreC0xKSIsImNvbG9yIjoiIzAwMDAwMCJ9LHsidHlwZSI6MTAwMH1d</span></span><br><span class="line">            <span class="keyword">float</span> grad = -(<span class="number">1</span> - pt) * (<span class="number">2</span> * pt*<span class="built_in">logf</span>(pt) + pt - <span class="number">1</span>);    <span class="comment">// http://blog.csdn.net/linmingan/article/details/77885832</span></span><br><span class="line">            <span class="comment">//float grad = (1 - pt) * (2 * pt*logf(pt) + pt - 1);    // https://github.com/unsky/focal-loss</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; classes; ++n) &#123;</span><br><span class="line">				<span class="comment">// focal loss的梯度</span></span><br><span class="line">                delta[index + n] = scale * (((n == class_id) ? <span class="number">1</span> : <span class="number">0</span>) - output[index + n]);</span><br><span class="line"></span><br><span class="line">                delta[index + n] *= alpha*grad;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (n == class_id) *avg_cat += output[index + n];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// default</span></span><br><span class="line">            <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; classes; ++n) &#123;</span><br><span class="line">				<span class="comment">// 计算类别损失的梯度, 反向传递到误差项l.delta中, 在yolo v2中scale=1</span></span><br><span class="line">                delta[index + n] = scale * (((n == class_id) ? <span class="number">1</span> : <span class="number">0</span>) - output[index + n]);</span><br><span class="line">                <span class="keyword">if</span> (n == class_id) *avg_cat += output[index + n];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">logit</span><span class="params">(<span class="keyword">float</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">log</span>(x/(<span class="number">1.</span>-x));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">tisnan</span><span class="params">(<span class="keyword">float</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (x != x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief 计算某个矩形框中某个参数在l.output中的索引。一个矩形框包含了x,y,w,h,c,C1,C2...,Cn信息，</span></span><br><span class="line"><span class="comment"> *        前四个用于定位，第五个为矩形框含有物体的置信度信息c，即矩形框中存在物体的概率为多大，而C1到Cn</span></span><br><span class="line"><span class="comment"> *        为矩形框中所包含的物体分别属于这n类物体的概率。本函数负责获取该矩形框首个定位信息也即x值在</span></span><br><span class="line"><span class="comment"> *        l.output中索引、获取该矩形框置信度信息c在l.output中的索引、获取该矩形框分类所属概率的首个</span></span><br><span class="line"><span class="comment"> *        概率也即C1值的索引，具体是获取矩形框哪个参数的索引，取决于输入参数entry的值，这些在</span></span><br><span class="line"><span class="comment"> *        forward_region_layer()函数中都有用到，由于l.output的存储方式，当entry=0时，就是获取矩形框</span></span><br><span class="line"><span class="comment"> *        x参数在l.output中的索引；当entry=4时，就是获取矩形框置信度信息c在l.output中的索引；当</span></span><br><span class="line"><span class="comment"> *        entry=5时，就是获取矩形框首个所属概率C1在l.output中的索引，具体可以参考forward_region_layer()</span></span><br><span class="line"><span class="comment"> *        中调用本函数时的注释.</span></span><br><span class="line"><span class="comment"> * @param l 当前region_layer</span></span><br><span class="line"><span class="comment"> * @param batch 当前照片是整个batch中的第几张，因为l.output中包含整个batch的输出，所以要定位某张训练图片</span></span><br><span class="line"><span class="comment"> *              输出的众多网格中的某个矩形框，当然需要该参数.</span></span><br><span class="line"><span class="comment"> * @param location 这个参数，说实话，感觉像个鸡肋参数，函数中用这个参数获取n和loc的值，这个n就是表示网格中</span></span><br><span class="line"><span class="comment"> *                 的第几个预测矩形框（比如每个网格预测5个矩形框，那么n取值范围就是从0~4，loc就是某个</span></span><br><span class="line"><span class="comment"> *                 通道上的元素偏移（region_layer输出的通道数为l.out_c = (classes + coords + 1)，</span></span><br><span class="line"><span class="comment"> *                 这样说可能没有说明白，这都与l.output的存储结构相关，见下面详细注释以及其他说明。总之，</span></span><br><span class="line"><span class="comment"> *                 查看一下调用本函数的父函数forward_region_layer()就知道了，可以直接输入n和j*l.w+i的，</span></span><br><span class="line"><span class="comment"> *                 没有必要输入location，这样还得重新计算一次n和loc.</span></span><br><span class="line"><span class="comment"> * @param entry 切入点偏移系数，关于这个参数，就又要扯到l.output的存储结构了，见下面详细注释以及其他说明.</span></span><br><span class="line"><span class="comment"> * @details l.output这个参数的存储内容以及存储方式已经在多个地方说明了，再多的文字都不及图文说明，此处再</span></span><br><span class="line"><span class="comment"> *          简要罗嗦几句，更为具体的参考图文说明。l.output中存储了整个batch的训练输出，每张训练图片都会输出</span></span><br><span class="line"><span class="comment"> *          l.out_w*l.out_h个网格，每个网格会预测l.n个矩形框，每个矩形框含有l.classes+l.coords+1个参数，</span></span><br><span class="line"><span class="comment"> *          而最后一层的输出通道数为l.n*(l.classes+l.coords+1)，可以想象下最终输出的三维张量是个什么样子的。</span></span><br><span class="line"><span class="comment"> *          展成一维数组存储时，l.output可以首先分成batch个大段，每个大段存储了一张训练图片的所有输出；进一步细分，</span></span><br><span class="line"><span class="comment"> *          取其中第一大段分析，该大段中存储了第一张训练图片所有输出网格预测的矩形框信息，每个网格预测了l.n个矩形框，</span></span><br><span class="line"><span class="comment"> *          存储时，l.n个矩形框是分开存储的，也就是先存储所有网格中的第一个矩形框，而后存储所有网格中的第二个矩形框，</span></span><br><span class="line"><span class="comment"> *          依次类推，如果每个网格中预测5个矩形框，则可以继续把这一大段分成5个中段。继续细分，5个中段中取第</span></span><br><span class="line"><span class="comment"> *          一个中段来分析，这个中段中按行（有l.out_w*l.out_h个网格，按行存储）依次存储了这张训练图片所有输出网格中</span></span><br><span class="line"><span class="comment"> *          的第一个矩形框信息，要注意的是，这个中段存储的顺序并不是挨个挨个存储每个矩形框的所有信息，</span></span><br><span class="line"><span class="comment"> *          而是先存储所有矩形框的x，而后是所有的y,然后是所有的w,再是h，c，最后的的概率数组也是拆分进行存储，</span></span><br><span class="line"><span class="comment"> *          并不是一下子存储完一个矩形框所有类的概率，而是先存储所有网格所属第一类的概率，再存储所属第二类的概率，</span></span><br><span class="line"><span class="comment"> *          具体来说这一中段首先存储了l.out_w*l.out_h个x，然后是l.out_w*l.out_c个y，依次下去，</span></span><br><span class="line"><span class="comment"> *          最后是l.out_w*l.out_h个C1（属于第一类的概率，用C1表示，下面类似），l.out_w*l.outh个C2,...,</span></span><br><span class="line"><span class="comment"> *          l.out_w*l.out_c*Cn（假设共有n类），所以可以继续将中段分成几个小段，依次为x,y,w,h,c,C1,C2,...Cn</span></span><br><span class="line"><span class="comment"> *          小段，每小段的长度都为l.out_w*l.out_c.</span></span><br><span class="line"><span class="comment"> *          现在回过来看本函数的输入参数，batch就是大段的偏移数（从第几个大段开始，对应是第几张训练图片），</span></span><br><span class="line"><span class="comment"> *          由location计算得到的n就是中段的偏移数（从第几个中段开始，对应是第几个矩形框），</span></span><br><span class="line"><span class="comment"> *          entry就是小段的偏移数（从几个小段开始，对应具体是那种参数，x,c还是C1），而loc则是最后的定位，</span></span><br><span class="line"><span class="comment"> *          前面确定好第几大段中的第几中段中的第几小段的首地址，loc就是从该首地址往后数loc个元素，得到最终定位</span></span><br><span class="line"><span class="comment"> *          某个具体参数（x或c或C1）的索引值，比如l.output中存储的数据如下所示（这里假设只存了一张训练图片的输出，</span></span><br><span class="line"><span class="comment"> *          因此batch只能为0；并假设l.out_w=l.out_h=2,l.classes=2）：</span></span><br><span class="line"><span class="comment"> *          xxxxyyyywwwwhhhhccccC1C1C1C1C2C2C2C2-#-xxxxyyyywwwwhhhhccccC1C1C1C1C2C2C2C2，</span></span><br><span class="line"><span class="comment"> *          n=0则定位到-#-左边的首地址（表示每个网格预测的第一个矩形框），n=1则定位到-#-右边的首地址（表示每个网格预测的第二个矩形框）</span></span><br><span class="line"><span class="comment"> *          entry=0,loc=0获取的是x的索引，且获取的是第一个x也即l.out_w*l.out_h个网格中第一个网格中第一个矩形框x参数的索引；</span></span><br><span class="line"><span class="comment"> *          entry=4,loc=1获取的是c的索引，且获取的是第二个c也即l.out_w*l.out_h个网格中第二个网格中第一个矩形框c参数的索引；</span></span><br><span class="line"><span class="comment"> *          entry=5,loc=2获取的是C1的索引，且获取的是第三个C1也即l.out_w*l.out_h个网格中第三个网格中第一个矩形框C1参数的索引；</span></span><br><span class="line"><span class="comment"> *          如果要获取第一个网格中第一个矩形框w参数的索引呢？如果已经获取了其x值的索引，显然用x的索引加上3*l.out_w*l.out_h即可获取到，</span></span><br><span class="line"><span class="comment"> *          这正是delta_region_box()函数的做法；</span></span><br><span class="line"><span class="comment"> *          如果要获取第三个网格中第一个矩形框C2参数的索引呢？如果已经获取了其C1值的索引，显然用C1的索引加上l.out_w*l.out_h即可获取到，</span></span><br><span class="line"><span class="comment"> *          这正是delta_region_class()函数中的做法；</span></span><br><span class="line"><span class="comment"> *          由上可知，entry=0时,即偏移0个小段，是获取x的索引；entry=4,是获取自信度信息c的索引；entry=5，是获取C1的索引.</span></span><br><span class="line"><span class="comment"> *          l.output的存储方式大致就是这样，个人觉得说的已经很清楚了，但可视化效果终究不如图文说明～</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">entry_index</span><span class="params">(layer l, <span class="keyword">int</span> batch, <span class="keyword">int</span> location, <span class="keyword">int</span> entry)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = location / (l.w*l.h);</span><br><span class="line">    <span class="keyword">int</span> loc = location % (l.w*l.h);</span><br><span class="line">    <span class="keyword">return</span> batch*l.outputs + n*l.w*l.h*(l.coords + l.classes + <span class="number">1</span>) + entry*l.w*l.h + loc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">softmax_tree</span><span class="params">(<span class="keyword">float</span> *input, <span class="keyword">int</span> batch, <span class="keyword">int</span> inputs, <span class="keyword">float</span> temp, tree *hierarchy, <span class="keyword">float</span> *output)</span></span>;</span><br><span class="line"><span class="comment">//本函数多次调用了entry_index()函数，且使用的参数不尽相同，尤其是最后一个参数，通过最后一个参数，</span></span><br><span class="line"><span class="comment">//可以确定出region_layer输出l.output的数据存储方式。为方便叙述，假设本层输出参数l.w = 2, l.h= 3,</span></span><br><span class="line"><span class="comment">//l.n = 2, l.classes = 2, l.coords = 4, l.c = l.n * (l.coords + l.classes + 1) = 21,</span></span><br><span class="line"><span class="comment">//l.output中存储了所有矩形框的信息参数，每个矩形框包括4条定位信息参数x,y,w,h，一条置信度（confidience）</span></span><br><span class="line"><span class="comment">//参数c，以及所有类别的概率C1,C2（本例中，假设就只有两个类别，l.classes=2），那么一张样本图片最终会有</span></span><br><span class="line"><span class="comment">//l.w*l.h*l.n个矩形框（l.w*l.h即为最终图像划分层网格的个数，每个网格预测l.n个矩形框），那么</span></span><br><span class="line"><span class="comment">//l.output中存储的元素个数共有l.w*l.h*l.n*(l.coords + 1 + l.classes)，这些元素全部拉伸成一维数组</span></span><br><span class="line"><span class="comment">//的形式存储在l.output中，存储的顺序为：</span></span><br><span class="line"><span class="comment">//xxxxxx-yyyyyy-wwwwww-hhhhhh-cccccc-C1C1C1C1C1C1C2C2C2C2C2C2-##-xxxxxx-yyyyyy-wwwwww-hhhhhh-cccccc-C1C2C1C2C1C2C1C2C1C2C1C2</span></span><br><span class="line"><span class="comment">//文字说明如下：-##-隔开分成两段，左右分别是代表所有网格的第1个box和第2个box（因为l.n=2，表示每个网格预测两个box）</span></span><br><span class="line"><span class="comment">//总共有l.w*l.h个网格，且存储时，把所有网格的x,y,w,h,c信息聚到一起再拼接起来，因此xxxxxx及其他信息都有l.w*l.h=6个，</span></span><br><span class="line"><span class="comment">//因为每个有l.classes个物体类别，而且也是和xywh一样，每一类都集中存储，先存储l.w*l.h=6个C1类，而后存储6个C2类，</span></span><br><span class="line"><span class="comment">//置信度参数c表示的是该矩形框内存在物体的概率，而C1，C2分别表示矩形框内存在物体时属于物体1和物体2的概率，</span></span><br><span class="line"><span class="comment">//因此c*C1即得矩形框内存在物体1的概率，c*C2即得矩形框内存在物体2的概率</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">forward_region_layer</span><span class="params">(<span class="keyword">const</span> region_layer l, network_state state)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,j,b,t,n;</span><br><span class="line">    <span class="keyword">int</span> size = l.coords + l.classes + <span class="number">1</span>;</span><br><span class="line">	<span class="comment">//内存拷贝, l.output = state.input</span></span><br><span class="line">    <span class="built_in">memcpy</span>(l.output, state.input, l.outputs*l.batch*<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">	<span class="comment">//这个#ifndef预编译指令没有必要用的，因为forward_region_layer()函数本身就对应没有定义gpu版的，所以肯定会执行其中的语句</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifndef</span> GPU</span></span><br><span class="line">    <span class="built_in">flatten</span>(l.output, l.w*l.h, size*l.n, l.batch, <span class="number">1</span>);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</span><br><span class="line">        <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.h*l.w*l.n; ++i)&#123;</span><br><span class="line">            <span class="keyword">int</span> index = size*i + b*l.outputs;</span><br><span class="line">			<span class="comment">// 对confidence进行逻辑回归</span></span><br><span class="line">            l.output[index + <span class="number">4</span>] = <span class="built_in">logistic_activate</span>(l.output[index + <span class="number">4</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> GPU</span></span><br><span class="line">    <span class="keyword">if</span> (l.softmax_tree)&#123;</span><br><span class="line">        <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.h*l.w*l.n; ++i)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = size*i + b*l.outputs;</span><br><span class="line">                <span class="built_in">softmax_tree</span>(l.output + index + <span class="number">5</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, l.softmax_tree, l.output + index + <span class="number">5</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (l.softmax)&#123;</span><br><span class="line">        <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b)&#123;</span><br><span class="line">            <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; l.h*l.w*l.n; ++i)&#123;</span><br><span class="line">                <span class="keyword">int</span> index = size*i + b*l.outputs;</span><br><span class="line">				<span class="comment">// l.softmax 对class进行softmax回归</span></span><br><span class="line">                <span class="built_in">softmax</span>(l.output + index + <span class="number">5</span>, l.classes, <span class="number">1</span>, l.output + index + <span class="number">5</span>, <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">	<span class="comment">// inference阶段，则到此结束</span></span><br><span class="line">    <span class="keyword">if</span>(!state.train) <span class="keyword">return</span>;</span><br><span class="line">	<span class="comment">// 将reorg层的误差项进行初始化（包含整个batch的）</span></span><br><span class="line">    <span class="built_in">memset</span>(l.delta, <span class="number">0</span>, l.outputs * l.batch * <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="keyword">float</span> avg_iou = <span class="number">0</span>; <span class="comment">//平均IoU（Intersection over Union）</span></span><br><span class="line">    <span class="keyword">float</span> recall = <span class="number">0</span>; <span class="comment">//召回率</span></span><br><span class="line">    <span class="keyword">float</span> avg_cat = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> avg_obj = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">float</span> avg_anyobj = <span class="number">0</span>; <span class="comment">//一张训练图片所有预测矩形框的平均置信度（矩形框中含有物体的概率），该参数没有实际用处，仅用于输出打印</span></span><br><span class="line">    <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> class_count = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// region层的总损失初始化为0</span></span><br><span class="line">    *(l.cost) = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">// 遍历batch中每一张图片</span></span><br><span class="line">    <span class="keyword">for</span> (b = <span class="number">0</span>; b &lt; l.batch; ++b) &#123;</span><br><span class="line">        <span class="keyword">if</span>(l.softmax_tree)&#123; <span class="comment">//【这是在yolo9000才参与计算】</span></span><br><span class="line">            <span class="keyword">int</span> onlyclass_id = <span class="number">0</span>;</span><br><span class="line">			<span class="comment">// 循环max_boxes次，每张图片固定处理max_boxes个矩形框</span></span><br><span class="line">            <span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; l.max_boxes; ++t)&#123;</span><br><span class="line">				<span class="comment">// 通过移位来获取每一个真实矩形框的信息，net.truth存储了网络吞入的所有图片的真实矩形框信息（一次吞入一个batch的训练图片），</span></span><br><span class="line">                <span class="comment">// net.truth作为这一个大数组的首地址，l.truths参数是每一张图片含有的真实值参数个数（可参考layer.h中的truths参数中的注释），</span></span><br><span class="line">                <span class="comment">// b是batch中已经处理完图片的图片的张数，5是每个真实矩形框需要5个参数值（也即每条矩形框真值有5个参数），t是本张图片已经处理</span></span><br><span class="line">                <span class="comment">// 过的矩形框的个数（每张图片最多处理max_boxes个矩形框），明白了上面的参数之后对于下面的移位获取对应矩形框真实值的代码就不难了</span></span><br><span class="line">                box truth = <span class="built_in">float_to_box</span>(state.truth + t*<span class="number">5</span> + b*l.truths);</span><br><span class="line">                <span class="comment">// 这个if语句是用来判断一下是否有读到真实矩形框值（每个矩形框有5个参数,float_to_box只读取其中的4个定位参数，</span></span><br><span class="line">                <span class="comment">// 只要验证x的值不为0,那肯定是4个参数值都读取到了，要么全部读取到了，要么一个也没有），另外，因为程序中写死了每张图片处理max_boxes个矩形框，</span></span><br><span class="line">                <span class="comment">// 那么有些图片没有这么多矩形框，就会出现没有读到的情况。</span></span><br><span class="line">				<span class="keyword">if</span>(!truth.x) <span class="keyword">break</span>; <span class="comment">// continue;</span></span><br><span class="line">				<span class="comment">//float_to_box()中没有读取矩形框中包含的物体类别编号的信息，就在此处获取。（darknet中，物体类别标签值为编号，</span></span><br><span class="line">				<span class="comment">//每一个类别都有一个编号值，这些物体具体的字符名称存储在一个文件中，如data/*.names文件，其所在行数就是其编号值）</span></span><br><span class="line">                <span class="keyword">int</span> class_id = state.truth[t*<span class="number">5</span> + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                <span class="keyword">float</span> maxp = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">int</span> maxi = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">if</span>(truth.x &gt; <span class="number">100000</span> &amp;&amp; truth.y &gt; <span class="number">100000</span>)&#123;</span><br><span class="line">                    <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.n*l.w*l.h; ++n)&#123;</span><br><span class="line">                        <span class="keyword">int</span> index = size*n + b*l.outputs + <span class="number">5</span>;</span><br><span class="line">                        <span class="keyword">float</span> scale =  l.output[index<span class="number">-1</span>];</span><br><span class="line">                        <span class="keyword">float</span> p = scale*<span class="built_in">get_hierarchy_probability</span>(l.output + index, l.softmax_tree, class_id);</span><br><span class="line">                        <span class="keyword">if</span>(p &gt; maxp)&#123;</span><br><span class="line">                            maxp = p;</span><br><span class="line">                            maxi = n;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="keyword">int</span> index = size*maxi + b*l.outputs + <span class="number">5</span>;</span><br><span class="line">                    <span class="built_in">delta_region_class</span>(l.output, l.delta, index, class_id, l.classes, l.softmax_tree, l.class_scale, &amp;avg_cat, l.focal_loss);</span><br><span class="line">                    ++class_count;</span><br><span class="line">                    onlyclass_id = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(onlyclass_id) <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">		</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; l.h; ++j) &#123;</span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; l.w; ++i) &#123; <span class="comment">// 遍历每个cell, 当前cell编号为[j, i]</span></span><br><span class="line">                <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; l.n; ++n) &#123; <span class="comment">// 遍历每个bbox，当前bbox编号为[n]</span></span><br><span class="line">					<span class="comment">//根据i,j,n计算该矩形框的索引，实际是矩形框中存储的x参数在l.output中的索引，矩形框中包含多个参数，</span></span><br><span class="line">					<span class="comment">//x是其存储的首个参数，所以也可以说是获取该矩形框的首地址。</span></span><br><span class="line">                    <span class="keyword">int</span> index = size*(j*l.w*l.n + i*l.n + n) + b*l.outputs;</span><br><span class="line">					<span class="comment">// 根据矩形框的索引，获取矩形框的定位信息</span></span><br><span class="line">                    box pred = <span class="built_in">get_region_box</span>(l.output, l.biases, n, index, i, j, l.w, l.h);</span><br><span class="line">                    <span class="comment">// 最高IoU，赋初值0</span></span><br><span class="line">					<span class="keyword">float</span> best_iou = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">int</span> best_class_id = <span class="number">-1</span>;</span><br><span class="line">					<span class="comment">// 遍历每一个GT bbox</span></span><br><span class="line">                    <span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; l.max_boxes; ++t)&#123;</span><br><span class="line">						<span class="comment">//将第t个bbox由float数组转bbox结构体,方便计算IOU</span></span><br><span class="line">                        box truth = <span class="built_in">float_to_box</span>(state.truth + t*<span class="number">5</span> + b*l.truths);</span><br><span class="line">						<span class="comment">//获取第t个bbox的物体类别</span></span><br><span class="line">                        <span class="keyword">int</span> class_id = state.truth[t * <span class="number">5</span> + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                        <span class="keyword">if</span> (class_id &gt;= l.classes) <span class="keyword">continue</span>; <span class="comment">// if label contains class_id more than number of classes in the cfg-file</span></span><br><span class="line">                        <span class="keyword">if</span>(!truth.x) <span class="keyword">break</span>; <span class="comment">// continue;</span></span><br><span class="line">						<span class="comment">// 计算pred与第t个GT之间的IOU</span></span><br><span class="line">                        <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth);</span><br><span class="line">                        <span class="keyword">if</span> (iou &gt; best_iou) &#123;</span><br><span class="line">                            best_class_id = state.truth[t*<span class="number">5</span> + b*l.truths + <span class="number">4</span>];</span><br><span class="line">                            best_iou = iou; <span class="comment">// 最大IOU更新</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">					<span class="comment">// 统计有目标的概率</span></span><br><span class="line">                    avg_anyobj += l.output[index + <span class="number">4</span>];</span><br><span class="line">					<span class="comment">// 与yolov1相似, 先将所有pred bbox都当做noobject，计算其confidence损失梯度</span></span><br><span class="line">                    l.delta[index + <span class="number">4</span>] = l.noobject_scale * ((<span class="number">0</span> - l.output[index + <span class="number">4</span>]) * <span class="built_in">logistic_gradient</span>(l.output[index + <span class="number">4</span>]));</span><br><span class="line">                    <span class="comment">// 在yolov2中并没有执行</span></span><br><span class="line">					<span class="keyword">if</span>(l.classfix == <span class="number">-1</span>) l.delta[index + <span class="number">4</span>] = l.noobject_scale * ((best_iou - l.output[index + <span class="number">4</span>]) * <span class="built_in">logistic_gradient</span>(l.output[index + <span class="number">4</span>]));</span><br><span class="line">                    <span class="keyword">else</span>&#123;</span><br><span class="line">						<span class="comment">// best_iou大于阈值则说明有object, 在yolo v2中阈值为0.6</span></span><br><span class="line">                        <span class="keyword">if</span> (best_iou &gt; l.thresh) &#123;</span><br><span class="line">                            l.delta[index + <span class="number">4</span>] = <span class="number">0</span>;</span><br><span class="line">                            <span class="keyword">if</span>(l.classfix &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                                <span class="built_in">delta_region_class</span>(l.output, l.delta, index + <span class="number">5</span>, best_class_id, l.classes, l.softmax_tree, l.class_scale*(l.classfix == <span class="number">2</span> ? l.output[index + <span class="number">4</span>] : <span class="number">1</span>), &amp;avg_cat, l.focal_loss);</span><br><span class="line">                                ++class_count;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">					<span class="comment">// net.seen 保存当前是训练第多少张图片</span></span><br><span class="line">                    <span class="keyword">if</span>(*(state.net.seen) &lt; <span class="number">12800</span>)&#123;</span><br><span class="line">						<span class="comment">// 对于训练阶段的前12800张图片,GT bbox 直接用了anchor box</span></span><br><span class="line">                        box truth = &#123;<span class="number">0</span>&#125;; <span class="comment">// 计算第[j, i]cell, 第n个bbox的anchor bbox</span></span><br><span class="line">                        truth.x = (i + <span class="number">.5</span>)/l.w; <span class="comment">// +0.5是因为x位于几何中心, 然后计算x相对整张特征图的位置</span></span><br><span class="line">                        truth.y = (j + <span class="number">.5</span>)/l.h;</span><br><span class="line">                        truth.w = l.biases[<span class="number">2</span>*n];</span><br><span class="line">                        truth.h = l.biases[<span class="number">2</span>*n+<span class="number">1</span>];</span><br><span class="line">                        <span class="keyword">if</span>(DOABS)&#123;</span><br><span class="line">                            truth.w = l.biases[<span class="number">2</span>*n]/l.w;</span><br><span class="line">                            truth.h = l.biases[<span class="number">2</span>*n+<span class="number">1</span>]/l.h;</span><br><span class="line">                        &#125;</span><br><span class="line">						<span class="comment">// 将pred bbox的tx,ty,tw,th和上面的truth box的差值反向传递到l.detla</span></span><br><span class="line">                        <span class="built_in">delta_region_box</span>(truth, l.output, l.biases, n, index, i, j, l.w, l.h, l.delta, <span class="number">.01</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">		<span class="comment">// 遍历每一个GT bbox</span></span><br><span class="line">        <span class="keyword">for</span>(t = <span class="number">0</span>; t &lt; l.max_boxes; ++t)&#123;</span><br><span class="line">			<span class="comment">// 将第t个bbox由float数组转bbox结构体,方便计算IOU</span></span><br><span class="line">            box truth = <span class="built_in">float_to_box</span>(state.truth + t*<span class="number">5</span> + b*l.truths);</span><br><span class="line">			</span><br><span class="line">            <span class="keyword">int</span> class_id = state.truth[t * <span class="number">5</span> + b*l.truths + <span class="number">4</span>];</span><br><span class="line">            <span class="keyword">if</span> (class_id &gt;= l.classes) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot; Warning: in txt-labels class_id=%d &gt;= classes=%d in cfg-file. In txt-labels class_id should be [from 0 to %d] \n&quot;</span>, class_id, l.classes, l.classes<span class="number">-1</span>);</span><br><span class="line">                <span class="built_in">getchar</span>();</span><br><span class="line">                <span class="keyword">continue</span>; <span class="comment">// if label contains class_id more than number of classes in the cfg-file</span></span><br><span class="line">            &#125;</span><br><span class="line">			<span class="comment">// 如果x坐标为0则取消, 因为yolov2这里定义了30 bbox, 可能实际上没有bbox</span></span><br><span class="line">            <span class="keyword">if</span>(!truth.x) <span class="keyword">break</span>; <span class="comment">// continue;</span></span><br><span class="line">            <span class="keyword">float</span> best_iou = <span class="number">0</span>; <span class="comment">// 保存最大IOU</span></span><br><span class="line">            <span class="keyword">int</span> best_index = <span class="number">0</span>;<span class="comment">// 保存最大IOU的bbox index</span></span><br><span class="line">            <span class="keyword">int</span> best_n = <span class="number">0</span>;</span><br><span class="line">            i = (truth.x * l.w); <span class="comment">// 获得当前第t个GT bbox所在cell</span></span><br><span class="line">            j = (truth.y * l.h);</span><br><span class="line">            <span class="comment">//printf(&quot;%d %f %d %f\n&quot;, i, truth.x*l.w, j, truth.y*l.h);</span></span><br><span class="line">            box truth_shift = truth; <span class="comment">// 将truth_shift的box移动到0,0</span></span><br><span class="line">            truth_shift.x = <span class="number">0</span>;</span><br><span class="line">            truth_shift.y = <span class="number">0</span>;</span><br><span class="line">            <span class="comment">//printf(&quot;index %d %d\n&quot;,i, j);</span></span><br><span class="line">            <span class="keyword">for</span>(n = <span class="number">0</span>; n &lt; l.n; ++n)&#123; <span class="comment">// 遍历cell[j,i]所在的n个预测bbox</span></span><br><span class="line">				<span class="comment">// 获得第j*w+i个cell第n个bbox的index</span></span><br><span class="line">                <span class="keyword">int</span> index = size*(j*l.w*l.n + i*l.n + n) + b*l.outputs;</span><br><span class="line">				<span class="comment">// 获得第j*w+i个cell第n个bbox在当前特征图上位置和宽高</span></span><br><span class="line">                box pred = <span class="built_in">get_region_box</span>(l.output, l.biases, n, index, i, j, l.w, l.h);</span><br><span class="line">                <span class="keyword">if</span>(l.bias_match)&#123;<span class="comment">// yolov2 reorg层 bias_match = 1</span></span><br><span class="line">                    pred.w = l.biases[<span class="number">2</span>*n];</span><br><span class="line">                    pred.h = l.biases[<span class="number">2</span>*n+<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">if</span>(DOABS)&#123;</span><br><span class="line">                        pred.w = l.biases[<span class="number">2</span>*n]/l.w; <span class="comment">// 然后计算pred box的w相对整张特征图的位置</span></span><br><span class="line">                        pred.h = l.biases[<span class="number">2</span>*n+<span class="number">1</span>]/l.h;  <span class="comment">// 然后计算pred box的h相对整张特征图的位置</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//printf(&quot;pred: (%f, %f) %f x %f\n&quot;, pred.x, pred.y, pred.w, pred.h);</span></span><br><span class="line">                pred.x = <span class="number">0</span>; <span class="comment">// 将预测的bbox移动到0,0</span></span><br><span class="line">                pred.y = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">float</span> iou = <span class="built_in">box_iou</span>(pred, truth_shift); <span class="comment">// 计算GT box truth_shift 与 预测bbox pred 二者之间的IOU</span></span><br><span class="line">                <span class="keyword">if</span> (iou &gt; best_iou)&#123;</span><br><span class="line">                    best_index = index;  <span class="comment">// 记录best_iou对应bbox的index</span></span><br><span class="line">                    best_iou = iou; <span class="comment">// 记录IOU最大的IOU</span></span><br><span class="line">                    best_n = n; <span class="comment">// 以及记录该bbox的编号n</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//printf(&quot;%d %f (%f, %f) %f x %f\n&quot;, best_n, best_iou, truth.x, truth.y, truth.w, truth.h);</span></span><br><span class="line">			<span class="comment">// 计算获得best_iou的pred bbox 与 GT bbox之间的真实iou, 之前best_iou是方便计算,以及加速,</span></span><br><span class="line">            <span class="comment">// 同时完成坐标损失的反向传递</span></span><br><span class="line">            <span class="keyword">float</span> iou = <span class="built_in">delta_region_box</span>(truth, l.output, l.biases, best_n, best_index, i, j, l.w, l.h, l.delta, l.coord_scale);</span><br><span class="line">            <span class="comment">// 如果iou大于0.5, recall ++;</span></span><br><span class="line">			<span class="keyword">if</span>(iou &gt; <span class="number">.5</span>) recall += <span class="number">1</span>;</span><br><span class="line">            avg_iou += iou;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//l.delta[best_index + 4] = iou - l.output[best_index + 4];</span></span><br><span class="line">			<span class="comment">// 统计有目标的概率</span></span><br><span class="line">            avg_obj += l.output[best_index + <span class="number">4</span>];</span><br><span class="line">			<span class="comment">// 与yolov1相似, 该pred bbox中是有object，计算其confidence损失梯度; object_scale = 5</span></span><br><span class="line">            l.delta[best_index + <span class="number">4</span>] = l.object_scale * (<span class="number">1</span> - l.output[best_index + <span class="number">4</span>]) * <span class="built_in">logistic_gradient</span>(l.output[best_index + <span class="number">4</span>]);</span><br><span class="line">            <span class="keyword">if</span> (l.rescore) &#123; <span class="comment">// yolov2 reorg层中rescore = 1, 参于计算</span></span><br><span class="line">				<span class="comment">//定义了rescore表示同时对confidence score进行回归</span></span><br><span class="line">				<span class="comment">// 该pred bbox中是有object，计算其confidence损失梯度的方法发生变化; object_scale = 5,</span></span><br><span class="line">				l.delta[best_index + <span class="number">4</span>] = l.object_scale * (iou - l.output[best_index + <span class="number">4</span>]) * <span class="built_in">logistic_gradient</span>(l.output[best_index + <span class="number">4</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">			<span class="comment">// yolov2 reorg层中map = 0, 不参与计算 【这是在yolo9000才参与计算】</span></span><br><span class="line">            <span class="keyword">if</span> (l.map) class_id = l.map[class_id];</span><br><span class="line">			 <span class="comment">// 与yolov1相似, 该pred bbox中是有object，计算其class损失梯度; class_scale = 1</span></span><br><span class="line">            <span class="built_in">delta_region_class</span>(l.output, l.delta, best_index + <span class="number">5</span>, class_id, l.classes, l.softmax_tree, l.class_scale, &amp;avg_cat, l.focal_loss);</span><br><span class="line">            ++count;<span class="comment">// 正样本个数+1</span></span><br><span class="line">            ++class_count;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//printf(&quot;\n&quot;);</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">ifndef</span> GPU</span></span><br><span class="line">    <span class="built_in">flatten</span>(l.delta, l.w*l.h, size*l.n, l.batch, <span class="number">0</span>);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    *(l.cost) = <span class="built_in">pow</span>(<span class="built_in">mag_array</span>(l.delta, l.outputs * l.batch), <span class="number">2</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Region Avg IOU: %f, Class: %f, Obj: %f, No Obj: %f, Avg Recall: %f,  count: %d\n&quot;</span>, avg_iou/count, avg_cat/class_count, avg_obj/count, avg_anyobj/(l.w*l.h*l.n*l.batch), recall/count, count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测调研</title>
    <url>/2020/01/14/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="53775a075510e009c32b545e4b008f1ea38e682ee9c5abd2b657bf00eb2d3d48">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>蓝桥杯试题及答案分享(Python版)</title>
    <url>/2022/03/02/%E8%93%9D%E6%A1%A5%E6%9D%AF%E8%AF%95%E9%A2%98%E5%8F%8A%E7%AD%94%E6%A1%88%E5%88%86%E4%BA%AB(Python%E7%89%88)/</url>
    <content><![CDATA[<h2 id="比赛介绍"><a href="#比赛介绍" class="headerlink" title="比赛介绍"></a>比赛介绍</h2><p>蓝桥杯大赛的举办得到了教育部、工业和信息化部有关领导的高度重视，相关司局的大力支持，也得到了各省教育厅和各有关院校的积极响应，更得到了参赛师生的广泛好评，参赛学校超过 1200 余所，参赛规模已达四十万人次，取得了良好的社会效果。</p>
<p>省级在我们学校为B类，国家级则为A类，省级中获一等奖的可参加国家级，因此比赛含金量高，建议大家好好把握😊</p>
<p>其中个人赛软件类分：</p>
<ul>
<li>C/C++程序设计（研究生组、大学A组、B组、C组）</li>
<li>Java软件开发（研究生组、大学A组、B组、C组）</li>
<li>Python程序设计（大学组）</li>
</ul>
<h2 id="Python组竞赛规则及说明"><a href="#Python组竞赛规则及说明" class="headerlink" title="Python组竞赛规则及说明"></a>Python组竞赛规则及说明</h2><h3 id="组别"><a href="#组别" class="headerlink" title="组别"></a>组别</h3><p>本次竞赛不分组别。所有研究生、重点本科、普通本科和高职高专院校均可报名该组，统一评奖。</p>
<h3 id="竞赛赛程"><a href="#竞赛赛程" class="headerlink" title="竞赛赛程"></a>竞赛赛程</h3><p>全国选拔赛时长：4 小时。<br>总决赛时长：4 小时。<br>详细赛程安排以组委会公布信息为准。</p>
<h3 id="竞赛形式"><a href="#竞赛形式" class="headerlink" title="竞赛形式"></a>竞赛形式</h3><p>个人赛，一人一机，全程机考。选手机器通过局域网连接到赛场的竞赛服务器。选手答题过程中无法访问互联网，也不允许使用本机以外的资源（如USB 连接）。竞赛系统以“服务器-浏览器”方式发放试题、回收选手答案。</p>
<h3 id="参赛选手机器环境"><a href="#参赛选手机器环境" class="headerlink" title="参赛选手机器环境"></a>参赛选手机器环境</h3><p><strong>选手机器配置：</strong></p>
<p>X86兼容机器，内存不小于 4G ，硬盘不小于 60G<br>操作系统：Windows7 及以上</p>
<p><strong>编程环境：</strong></p>
<p>编译器：Python 3.8.6<br>编辑器：IDLE Python 自带编辑器</p>
<h3 id="试题形式"><a href="#试题形式" class="headerlink" title="试题形式"></a>试题形式</h3><p>竞赛题目完全为客观题型。根据选手所提交答案的测评结果为评分依据。共有两种题型。</p>
<p><strong>结果填空题</strong></p>
<p>题目描述一个具有确定解的问题。要求选手对问题的解填空。<br>不要求解题过程，不限制解题手段（可以使用任何开发语言或工具，甚至是手工计算），只要求填写最终的结果。最终的解是一个整数或者是一个字符串，最终的解可以使用ASCII 字符表达。</p>
<p><strong>编程大题</strong></p>
<p>题目包含明确的问题描述、输入和输出格式，以及用于解释问题的样例数据。</p>
<p>编程大题所涉及的问题一定是有明确客观的标准来判断结果是否正确，并可以通过程序对结果进行评判。果进行评判。</p>
<p>选手应当根据问题描述，编写程序（使用 Python 编写）来解决问题，在评测时选手的程序应当从标准输入读入数据，并将最终的结果输出到标准输出中。</p>
<p>在问题描述中会明确说明给定的条件和限制，明确问题的任务，选手的程序应当能解决在给定条件和限制下的所有可能的情况。在给定条件和限制下的所有可能的情况。</p>
<p>选手的程序应当具有普遍性，不能只适用于题目的样例数据。</p>
<p>为了测试选手给出解法的性能，评分时用的测试用例可能包含大数据量的压力测试用例，选手选择算法时要尽可能考虑可行性和效率问题。</p>
<h3 id="试题考查范围试题考查范围"><a href="#试题考查范围试题考查范围" class="headerlink" title="试题考查范围试题考查范围"></a>试题考查范围试题考查范围</h3><p>Python程序设计基础：包含使用 Python编写程序的能力。该部分不考查选手对某一语法的理解程度，选手可以使用自己喜欢的语句编写程序。</p>
<p>计算机算法：枚举、排序、搜索、计数、贪心、动态规划、图论、数论、博弈论、概率论、计算几何、字符串算法等。</p>
<p>数据结构：数组、对象/结构、字符串、队列、栈、树、图、堆、平衡树结构、字符串、队列、栈、树、图、堆、平衡树/线段树、复杂数据线段树、复杂数据结构、嵌套数据结构等。</p>
<h3 id="答案提交"><a href="#答案提交" class="headerlink" title="答案提交"></a>答案提交</h3><p>选手只有在比赛时间内提交的答案内容是可以用来评测的，比赛之后的任何提交均无效。</p>
<p>选手应使用考试指定的网页来提交代码，任何其他方式的提交（如邮件、U盘）都不作为评测依据。</p>
<p>选手可在比赛中的任何时间查看自己之前提交的代码，也可以重新提交任何题目的答案，对于每个试题，仅有最后的一次提交被保存并作为评测的依据。在比赛中，评测结果不会显示给选手，选手应当在没有反馈的情况下自行设计数据调试自己的程序。</p>
<p>对于每个试题，选手应将试题的答案内容拷贝粘贴到网页上进行提交。</p>
<p>Python程序仅可以使用Python自带的库，评测时不会安装其他的扩展库。</p>
<p>程序中应只包含计算模块，不要包含任何其他的模块，比如图形、系统接口调用、系统中断等。对于系统接口的调用都应通过标准库来进行。</p>
<p>程序中引用的库应该在程序中以源代码的方式写出，在提交时也应当和程序的其他部分一起提交。</p>
<h3 id="评分"><a href="#评分" class="headerlink" title="评分"></a>评分</h3><p>全部使用机器自动评分。对于结果填空题，题目保证只有唯一解，选手的结果只有和解完全相同才得分，出现格式错误或有多余内容时不得分。</p>
<p>对于编程大题，评测系统将使用多个评测数据来测试程序。每个评测数据有对应的分数。选手所提交的程序将分别用每个评测数据作为输入来运行。对于某个评测数据，如果选手程序的输出与正确答案是匹配的，则选手获得该评测数据的分数。</p>
<p>评测使用的评测数据一般与试题中给定的样例输入输出不一样。因此建议选手在提交程序前使用不同的数据测试自己的程序。</p>
<p>提交的程序应严格按照输出格式的要求来输出，包括输出空格和换行的要求。如果程序没有遵循输出格式的要求将被判定为答案错误。请注意，程序在输出的时候多输出了内容也属于没有遵循输出格式要求的一种，所以在输出的时候请不要输出任何多余的内容，比如调试输出。</p>
<h2 id="试题及答案"><a href="#试题及答案" class="headerlink" title="试题及答案"></a>试题及答案</h2><p>试题由本人从历年搜集并附了程序解答，由于本人编程能力有限，可能有错或并非最优解，欢迎指正！</p>
<p>当初本人刷完题，将解答过程分享给老魏，最终老魏获得了省二（成为我心中的阴影😢），说明刷题还是有一定帮助，希望大家能认真做好每一题。</p>
<h3 id="成绩统计"><a href="#成绩统计" class="headerlink" title="成绩统计"></a>成绩统计</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小蓝给学生们组织了一场考试，卷面总分为100分，每个学生的得分都是一个0到100的整数。如果得分至少是60分，则称为及格。如果得分至少为85分，则称为优秀。请计算及格率和优秀率，用百分数表示，百分号前的部分四舍五入保留整数。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含一个整数 n (1≤n≤$10^4$)，表示考试人数。接下来n行，每行包含一个0至100的整数，表示一个学生的得分。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出两行，每行一个百分数，分别表示及格率和优秀率。百分号前的部分四舍五入保留整数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 及格的数量</span></span><br><span class="line">passNum = <span class="number">0</span></span><br><span class="line"><span class="comment"># 优秀的数量</span></span><br><span class="line">goodNum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    score = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">    <span class="keyword">if</span> score &gt;= <span class="number">60</span>:</span><br><span class="line">        passNum += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> score &gt;= <span class="number">85</span>:</span><br><span class="line">        goodNum += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>(<span class="built_in">round</span>(passNum/n*<span class="number">100</span>))+<span class="string">&#x27;%&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">str</span>(<span class="built_in">round</span>(goodNum/n*<span class="number">100</span>))+<span class="string">&#x27;%&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="FJ字符串"><a href="#FJ字符串" class="headerlink" title="FJ字符串"></a>FJ字符串</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>FJ在沙盘上写了这样一些字符串：</p>
<p>A1 = “A”</p>
<p>A2 = “ABA”</p>
<p>A3 = “ABACABA”</p>
<p>A4 = “ABACABADABACABA”</p>
<p>… …</p>
<p>你能找出其中的规律并写所有的数列AN吗？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>仅有一个数：N ≤ 26。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>请输出相应的字符串AN，以一个换行符结束。输出中不得含有多余的空格或换行、回车符。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>ABACABA</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">result = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    result = result + <span class="built_in">chr</span>(<span class="built_in">ord</span>(<span class="string">&#x27;A&#x27;</span>) + i) + result</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="K好数"><a href="#K好数" class="headerlink" title="K好数"></a>K好数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>如果一个自然数N的K进制表示中任意的相邻的两位都不是相邻的数字，那么我们就说这个数是K好数。求L位K进制数中K好数的数目。例如K = 4，L = 2的时候，所有K好数为11、13、20、22、30、31、33 共7个。由于这个数目很大，请你输出它对1000000007取模后的值。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入包含两个正整数，K和L。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数，表示答案对1000000007取模后的值。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4 2</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>7</p>
</blockquote>
<p>对于30%的数据，KL &lt;= 106；</p>
<p>对于50%的数据，K &lt;= 16, L &lt;= 10；</p>
<p>对于100%的数据，1 &lt;= K, L &lt;= 100。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">K, L = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># dp[i][j]表示i + 1位上存放j的方法个数。</span></span><br><span class="line">dp = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(K)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(L)]</span><br><span class="line"><span class="comment"># 当只有一位时不管这位放哪个数字都只有一种方法</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, K):</span><br><span class="line">    dp[<span class="number">0</span>][i] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 当位数大等2位时</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, L):</span><br><span class="line">    <span class="comment"># 以2为数为例，j为十位，m为个位</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">            <span class="comment"># 不相邻才能存放</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(j - m) != <span class="number">1</span>:</span><br><span class="line">                <span class="comment"># 当前位数的放j情况的总个数 = 当前位置放j的个数 + 上一位置放[0,k)的总个数</span></span><br><span class="line">                dp[i][j] = dp[i][j]+dp[i-<span class="number">1</span>][m]</span><br><span class="line">                dp[i][j] %= <span class="number">1000000007</span></span><br><span class="line">    <span class="comment"># 不断递归下去，如三位数放k进制的个数 = 三位数的最高位（看成十位）放k进制的个数+两位数（看成一个整体为个位）放k进制的个数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># L位数K好数的总个数</span></span><br><span class="line"><span class="comment"># i从1开始排除L位为最高位放0的情况</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, K):</span><br><span class="line">    count += dp[L-<span class="number">1</span>][i]</span><br><span class="line">    count %= <span class="number">1000000007</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="N皇后"><a href="#N皇后" class="headerlink" title="N皇后"></a>N皇后</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>在N*N的方格棋盘放置了N个皇后，使得它们不相互攻击（即任意2个皇后不允许处在同一排，同一列，也不允许处在与棋盘边框成45角的斜线上。<br>你的任务是，对于给定的N，求出有多少种合法的放置方法。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入N。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数，表示总共有多少种放法。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 递归回溯思想解决n皇后问题，cur代表当前行，从0开始一行行遍历</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">queen</span>(<span class="params">A, cur=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="comment"># 判断上行放置的棋子是否有问题，如果有则回退</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(cur-<span class="number">1</span>): </span><br><span class="line">        <span class="comment"># 由于是一行行遍历肯定不存在同行，只需检测是否同列和同对角线</span></span><br><span class="line">        <span class="comment"># 若在该列或对角线上存在其他皇后</span></span><br><span class="line">        <span class="keyword">if</span> A[row] - A[cur-<span class="number">1</span>] == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">abs</span>(A[row] - A[cur-<span class="number">1</span>]) == cur - <span class="number">1</span> - row: </span><br><span class="line">            <span class="comment"># 该位置不能放</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 所有的皇后都正确放置完毕，输出每个皇后所在的位置</span></span><br><span class="line">    <span class="keyword">if</span> cur == <span class="built_in">len</span>(A): </span><br><span class="line">        <span class="built_in">print</span>(A)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 行数=列数，遍历每列</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A)):</span><br><span class="line">        <span class="comment"># 当前行存储皇后所在的列数</span></span><br><span class="line">        A[cur] = col</span><br><span class="line">        <span class="comment"># 继续放下一个皇后</span></span><br><span class="line">        queen(A, cur+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># n为8，就是著名的八皇后问题啦</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>()) </span><br><span class="line"><span class="comment"># 初始传入8行的数组</span></span><br><span class="line">queen([<span class="literal">None</span>] * n)</span><br></pre></td></tr></table></figure>
<h3 id="2N皇后"><a href="#2N皇后" class="headerlink" title="2N皇后"></a>2N皇后</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定一个n*n的棋盘，棋盘中有一些位置不能放皇后。现在要向棋盘中放入n个黑皇后和n个白皇后，使任意的两个黑皇后都不在同一行、同一列或同一条对角线上，任意的两个白皇后都不在同一行、同一列或同一条对角线上。问总共有多少种放法？n小于等于8。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行为一个整数n，表示棋盘的大小。<br>接下来n行，每行n个0或1的整数，如果一个整数为1，表示对应的位置可以放皇后，如果一个整数为0，表示对应的位置不可以放皇后。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数，表示总共有多少种放法。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4<br>1 1 1 1<br>1 1 1 1<br>1 1 1 1<br>1 1 1 1</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>2</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4<br>1 0 1 1<br>1 1 1 1<br>1 1 1 1<br>1 1 1 1</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>0</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先放置白皇后, cur代表当前行，从0开始一行行遍历</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">w_queen</span>(<span class="params">cur=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="comment"># 判断上行放置的棋子是否有问题，如果有则回退</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(cur-<span class="number">1</span>): </span><br><span class="line">        <span class="comment"># 由于是一行行遍历肯定不存在同行，只需检测是否同列和同对角线</span></span><br><span class="line">        <span class="comment"># 若在该列或对角线上存在其他皇后</span></span><br><span class="line">        <span class="keyword">if</span> w_pos[row] - w_pos[cur-<span class="number">1</span>] == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">abs</span>(w_pos[row] - w_pos[cur-<span class="number">1</span>]) == cur - <span class="number">1</span> - row: </span><br><span class="line">            <span class="comment"># 该位置不能放</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 当前颜色皇后都正确放置完毕</span></span><br><span class="line">    <span class="keyword">if</span> cur == n: </span><br><span class="line">        <span class="comment"># 放置另一种颜色的皇后</span></span><br><span class="line">        b_queen(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 遍历每列</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 如果该位置为1，则可以放置其子</span></span><br><span class="line">        <span class="keyword">if</span> chessboard[cur][col] == <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 记录该棋子存放位置</span></span><br><span class="line">            w_pos[cur] = col</span><br><span class="line">            <span class="comment"># 继续放下一个皇后</span></span><br><span class="line">            w_queen(cur+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再放置黑皇后，与白皇后同理</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">b_queen</span>(<span class="params">cur=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(cur-<span class="number">1</span>): </span><br><span class="line">        <span class="keyword">if</span> b_pos[row] - b_pos[cur-<span class="number">1</span>] == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">abs</span>(b_pos[row] - b_pos[cur-<span class="number">1</span>]) == cur - <span class="number">1</span> - row: </span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> cur == n: </span><br><span class="line">        <span class="comment"># 两种颜色皇后放置完毕，记录次数</span></span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 如果该位置为1且没有放白皇后，则可以放置其子</span></span><br><span class="line">        <span class="keyword">if</span> chessboard[cur][col] == <span class="number">1</span> <span class="keyword">and</span> w_pos[cur] != col:</span><br><span class="line">            b_pos[cur] = col</span><br><span class="line">            b_queen(cur+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>()) </span><br><span class="line"><span class="comment"># 初始化棋盘</span></span><br><span class="line">chessboard = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    arr = <span class="built_in">input</span>().split()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        chessboard[i].append(<span class="built_in">int</span>(arr[j]))</span><br><span class="line"><span class="comment"># 用于记录白皇后位置</span></span><br><span class="line">w_pos = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 用于记录黑皇后位置</span></span><br><span class="line">b_pos = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 初始化多少种放法</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 开始放置皇后</span></span><br><span class="line">w_queen(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 输出多少种放法</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="sin之舞"><a href="#sin之舞" class="headerlink" title="sin之舞"></a>sin之舞</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>最近FJ为他的奶牛们开设了数学分析课，FJ知道若要学好这门课，必须有一个好的三角函数基本功。所以他准备和奶牛们做一个“Sine之舞”的游戏，寓教于乐，提高奶牛们的计算能力。<br>不妨设<br>An=sin(1–sin(2+sin(3–sin(4+…sin(n))…)<br>Sn=(…(A1+n)A2+n-1)A3+…+2)An+1<br>FJ想让奶牛们计算Sn的值，请你帮助FJ打印出Sn的完整表达式，以方便奶牛们做题。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>仅有一个数：N&lt;201。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>请输出相应的表达式Sn，以一个换行符结束。输出中不得含有多余的空格或换行、回车符。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>((sin(1)+3)sin(1–sin(2))+2)sin(1–sin(2+sin(3)))+1</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">A</span>(<span class="params">k, n</span>):</span></span><br><span class="line">    <span class="keyword">if</span> k == n:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;sin(%d&#x27;</span> % (k + <span class="number">1</span>), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 若后边还有式子，判断是输出+号还是-号</span></span><br><span class="line">    <span class="keyword">if</span> k + <span class="number">1</span> != n:  </span><br><span class="line">        <span class="keyword">if</span> k % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;+&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 若到底了，则输出n个&#x27;)&#x27;结束</span></span><br><span class="line">    <span class="keyword">else</span>:  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;)&#x27;</span>*n, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    k += <span class="number">1</span></span><br><span class="line">    A(k, n)  <span class="comment"># 递归调用自身</span></span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="comment"># 第一项n-1个括号开始</span></span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;(&#x27;</span>*(n-<span class="number">1</span>), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 后续An+n-i)</span></span><br><span class="line">    A(<span class="number">0</span>, i+<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;+%d&#x27;</span> % (n-i), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="comment"># 最后一项加完整数之和不必再输出右括号</span></span><br><span class="line">    <span class="keyword">if</span> i != n - <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;)&#x27;</span>, end=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="不同子串"><a href="#不同子串" class="headerlink" title="不同子串"></a>不同子串</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>一个字符串的非空子串是指字符串中长度至少为1的连续的一段字符组成的串。例如，字符串aaab有非空子串a, b, aa, ab, aaa, aab, aaab，一共7个。 注意在计算时，只算本质不同的串的个数。请问，字符串0100110001010001有多少个不同的非空子串？           </p>
</blockquote>
<p>答案</p>
<blockquote>
<p>100</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str1 = <span class="string">&#x27;0100110001010001&#x27;</span></span><br><span class="line">var = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(str1)+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str1) - i + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> str1[j:j+i] <span class="keyword">not</span> <span class="keyword">in</span> var:</span><br><span class="line">            var.append(str1[j:j+i])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(var))</span><br></pre></td></tr></table></figure>
<h3 id="成绩排名"><a href="#成绩排名" class="headerlink" title="成绩排名"></a>成绩排名</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明刚经过了一次数学考试，老师由于忙碌忘记排名了，于是老师把这个光荣的任务交给了小明，小明则找到了聪明的你，希望你能帮他解决这个问题。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行包含一个正整数N，表示有个人参加了考试。接下来N行，每行有一个字符串和一个正整数，分别表示人名和对应的成绩，用一个空格分隔。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一共有N行，每行一个字符串，第i行的字符串表示成绩从高到低排在第i位的人的名字，若分数一样则按人名的字典序顺序从小到大。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3<br>aaa 47<br>bbb 90<br>ccc 70</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>bbb<br>ccc<br>aaa </p>
</blockquote>
<p>人数&lt;=100,分数&lt;=100,人名仅包含小写字母。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">inf = [<span class="built_in">list</span>(<span class="built_in">input</span>().split()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">information.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])  <span class="comment"># 先排姓名，按字母顺序</span></span><br><span class="line">information.sort(key=<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x[<span class="number">1</span>]), reverse=<span class="literal">True</span>)  <span class="comment"># 后排成绩，从大到小</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="built_in">print</span>(information[i][<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="承压计算"><a href="#承压计算" class="headerlink" title="承压计算"></a>承压计算</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>X星球的高科技实验室中整齐地堆放着某批珍贵金属原料。</p>
<p>每块金属原料的外形、尺寸完全一致，但重量不同。<br>金属材料被严格地堆放成金字塔形。</p>
<p>其中的数字代表金属块的重量（计量单位较大）。<br>最下一层的X代表30台极高精度的电子秤。</p>
<p>假设每块原料的重量都十分精确地平均落在下方的两个金属块上，<br>最后，所有的金属块的重量都严格精确地平分落在最底层的电子秤上。<br>电子秤的计量单位很小，所以显示的数字很大。</p>
<p>工作人员发现，其中读数最小的电子秤的示数为：2086458231</p>
<p>请你推算出：读数最大的电子秤的示数为多少？</p>
<p>注意：需要提交的是一个<strong>整数</strong>，不要填写任何多余的内容。</p>
</blockquote>
<p><code>pyramid.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                             7 </span><br><span class="line">                            5 8 </span><br><span class="line">                           7 8 8 </span><br><span class="line">                          9 2 7 2 </span><br><span class="line">                         8 1 4 9 1 </span><br><span class="line">                        8 1 8 8 4 1 </span><br><span class="line">                       7 9 6 1 4 5 4 </span><br><span class="line">                      5 6 5 5 6 9 5 6 </span><br><span class="line">                     5 5 4 7 9 3 5 5 1 </span><br><span class="line">                    7 5 7 9 7 4 7 3 3 1 </span><br><span class="line">                   4 6 4 5 5 8 8 3 2 4 3 </span><br><span class="line">                  1 1 3 3 1 6 6 5 5 4 4 2 </span><br><span class="line">                 9 9 9 2 1 9 1 9 2 9 5 7 9 </span><br><span class="line">                4 3 3 7 7 9 3 6 1 3 8 8 3 7 </span><br><span class="line">               3 6 8 1 5 3 9 5 8 3 8 1 8 3 3 </span><br><span class="line">              8 3 2 3 3 5 5 8 5 4 2 8 6 7 6 9 </span><br><span class="line">             8 1 8 1 8 4 6 2 2 1 7 9 4 2 3 3 4 </span><br><span class="line">            2 8 4 2 2 9 9 2 8 3 4 9 6 3 9 4 6 9 </span><br><span class="line">           7 9 7 4 9 7 6 6 2 8 9 4 1 8 1 7 2 1 6 </span><br><span class="line">          9 2 8 6 4 2 7 9 5 4 1 2 5 1 7 3 9 8 3 3 </span><br><span class="line">         5 2 1 6 7 9 3 2 8 9 5 5 6 6 6 2 1 8 7 9 9 </span><br><span class="line">        6 7 1 8 8 7 5 3 6 5 4 7 3 4 6 7 8 1 3 2 7 4 </span><br><span class="line">       2 2 6 3 5 3 4 9 2 4 5 7 6 6 3 2 7 2 4 8 5 5 4 </span><br><span class="line">      7 4 4 5 8 3 3 8 1 8 6 3 2 1 6 2 6 4 6 3 8 2 9 6 </span><br><span class="line">     1 2 4 1 3 3 5 3 4 9 6 3 8 6 5 9 1 5 3 2 6 8 8 5 3 </span><br><span class="line">    2 2 7 9 3 3 2 8 6 9 8 4 4 9 5 8 2 6 3 4 8 4 9 3 8 8 </span><br><span class="line">   7 7 7 9 7 5 2 7 9 2 5 1 9 2 6 5 3 9 3 5 7 3 5 4 2 8 9 </span><br><span class="line">  7 7 6 6 8 7 5 5 8 2 4 7 7 4 7 2 6 9 2 1 8 2 9 8 5 7 3 6 </span><br><span class="line"> 5 9 4 5 5 7 5 5 6 3 5 3 9 5 8 9 5 4 1 2 6 1 4 3 5 3 2 4 1 </span><br><span class="line">X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = []</span><br><span class="line">k = <span class="number">0</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;pyramid.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</span><br><span class="line">    arr.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, line.split())))</span><br><span class="line">arr.append([<span class="number">0</span>]*<span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">30</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">        arr[i][j] += arr[i - <span class="number">1</span>][j] / <span class="number">2</span></span><br><span class="line">        arr[i][j + <span class="number">1</span>] += arr[i - <span class="number">1</span>][j] / <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="number">2086458231</span> / <span class="built_in">min</span>(arr[-<span class="number">1</span>]) * <span class="built_in">max</span>(arr[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<h3 id="乘积尾零"><a href="#乘积尾零" class="headerlink" title="乘积尾零"></a>乘积尾零</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>如下的10行数据，每行有10个整数，请你求出它们的乘积的末尾有多少个零？注意：需要提交的是一个整数，表示末尾零的个数。不要填写任何多余内容。</p>
</blockquote>
<p><code>num.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">5650 4542 3554 473 946 4114 3871 9073 90 4329</span><br><span class="line">2758 7949 6113 5659 5245 7432 3051 4434 6704 3594</span><br><span class="line">9937 1173 6866 3397 4759 7557 3070 2287 1453 9899</span><br><span class="line">1486 5722 3135 1170 4014 5510 5120 729 2880 9019</span><br><span class="line">2049 698 4582 4346 4427 646 9742 7340 1230 7683</span><br><span class="line">5693 7015 6887 7381 4172 4341 2909 2027 7355 5649</span><br><span class="line">6701 6645 1671 5978 2704 9926 295 3125 3878 6785</span><br><span class="line">2066 4247 4800 1578 6652 4616 1113 6205 3264 2915</span><br><span class="line">3966 5291 2904 1285 2193 1428 2265 8730 9436 7074</span><br><span class="line">689 5510 8243 6114 337 4096 8199 7313 3685 211</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;num.txt&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    lines = file.readlines()</span><br><span class="line">file.close</span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> line.split():</span><br><span class="line">        <span class="keyword">if</span> res == <span class="number">0</span>:</span><br><span class="line">            res = <span class="built_in">int</span>(num)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res *= <span class="built_in">int</span>(num)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">str</span>(res)[::-<span class="number">1</span>]:</span><br><span class="line">    <span class="keyword">if</span> i != <span class="string">&#x27;0&#x27;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="单词分析"><a href="#单词分析" class="headerlink" title="单词分析"></a>单词分析</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小蓝正在学习一门神奇的语言，这门语言中的单词都是由小写字母组成，<br>有些单词很长，远远超过正常英文单词的长度。小蓝学了很长时间也记不住一些单词，<br>他准备不再完全记忆这些单词，而是根据单词中哪个字母出现的最多来分辨单词。<br>请你帮助小蓝，给了一些单词后，帮助他找到出现最多的字母和这个字母出现的次数。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行包含一个单词，单词只有小写英文字母组成。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出两行，第一行包含一个英文字母，表示单词中出现最多的字母是哪个。 如果有多个字母出现的次数相等，输出字典序最小的那个。 第二行包含一个整数，表示出现的最多的那个字母在单词中出现的次数。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>lanqiao</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>a<br>2</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>longlonglongistoolong</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>o<br>6</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">word = <span class="built_in">input</span>()</span><br><span class="line">mapNum = &#123;&#125;</span><br><span class="line"><span class="comment"># 次数最多的字母</span></span><br><span class="line">maxV = <span class="literal">None</span></span><br><span class="line"><span class="comment"># 最多次数</span></span><br><span class="line">maxNum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> word:</span><br><span class="line">    <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> mapNum:</span><br><span class="line">        mapNum[v] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        mapNum[v] += <span class="number">1</span></span><br><span class="line">keys = <span class="built_in">sorted</span>(mapNum.keys())</span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> keys:</span><br><span class="line">    <span class="keyword">if</span> mapNum[key] &gt; maxNum:</span><br><span class="line">        maxV = key</span><br><span class="line">        maxNum = mapNum[key]</span><br><span class="line"><span class="built_in">print</span>(maxV)</span><br><span class="line"><span class="built_in">print</span>(maxNum)</span><br></pre></td></tr></table></figure>
<h3 id="等差数列"><a href="#等差数列" class="headerlink" title="等差数列"></a>等差数列</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>数学老师给小明出了一道等差数列求和的题目。但是粗心的小明忘记了一部分的数列，只记得其中N个整数。<br>现在给出这N个整数，小明想知道包含这N个整数的最短的等差数列有几项？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含一个整数N。<br>第二行包含N个整数A1，A2，···，AN。（注意A1~AN并不一定是按等差数列中的顺序给出）</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数表示答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5<br>2 6 4 10 20</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>10</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>包含2、6、4、10、20的最短的等差数列是2、4、6、8、10、12、14、16、18、20。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split()))</span><br><span class="line">min_gap = <span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)</span><br><span class="line"><span class="comment"># 先排序</span></span><br><span class="line">arr.sort()</span><br><span class="line"><span class="comment"># 找出等差数列的步长（各相邻数差值最小的）</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">    <span class="keyword">if</span> arr[i] - arr[i-<span class="number">1</span>] &lt; min_gap:</span><br><span class="line">        min_gap = arr[i] - arr[i-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 等差数列长度为(某项-首项)/步长+1</span></span><br><span class="line">res = (arr[-<span class="number">1</span>] - arr[<span class="number">0</span>]) // min_gap + <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="等差素数列"><a href="#等差素数列" class="headerlink" title="等差素数列"></a>等差素数列</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>2,3,5,7,11,13,…是素数序列。</p>
<p>类似：7,37,67,97,127,157 这样完全由素数组成的等差数列，叫等差素数数列。<br>上边的数列公差为30，长度为6。</p>
<p>2004年，格林与华人陶哲轩合作证明了：存在任意长度的素数等差数列。<br>这是数论领域一项惊人的成果！</p>
<p>有这一理论为基础，请你借助手中的计算机，满怀信心地搜索：</p>
<p>长度为10的等差素数列，其公差最小值是多少？</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 判断是否为素数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isprimy</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">int</span>(<span class="built_in">float</span>(n)**<span class="number">0.5</span>) + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> n % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"><span class="comment"># 在一个范围里查找起点</span></span><br><span class="line"><span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">4000</span>):</span><br><span class="line">    <span class="comment"># 不是素数则跳过</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isprimy(start):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># 查找公差</span></span><br><span class="line">    <span class="keyword">for</span> diff <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">400</span>):</span><br><span class="line">        <span class="comment"># 记录数列长度</span></span><br><span class="line">        count = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 下一个数值</span></span><br><span class="line">        <span class="built_in">next</span> = start + diff</span><br><span class="line">        <span class="comment"># 若仍为素数</span></span><br><span class="line">        <span class="keyword">while</span>(isprimy(<span class="built_in">next</span>)):</span><br><span class="line">            <span class="comment"># 长度加1</span></span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 继续判断下一个数</span></span><br><span class="line">            <span class="built_in">next</span> += diff</span><br><span class="line">            <span class="comment"># 若长度大等10，则找到</span></span><br><span class="line">            <span class="keyword">if</span> count &gt;= <span class="number">10</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;起点:&#x27;</span>, start,<span class="string">&#x27;公差:&#x27;</span>, diff)</span><br><span class="line">                exit()</span><br></pre></td></tr></table></figure>
<h3 id="递归倒置字符数组"><a href="#递归倒置字符数组" class="headerlink" title="递归倒置字符数组"></a>递归倒置字符数组</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>完成一个递归程序，倒置字符数组，并打印实现过程。<br>递归逻辑为：<br>当字符长度等于1时，直接返回<br>否则，调换首尾两个字符，再递归地倒置字符数组的剩下部分</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>字符数组长度及该数组</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>在求解过程中，打印字符数组的变化情况。<br>最后空一行，在程序结尾处打印倒置后该数组的各个元素。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5 abcde</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>ebcda<br>edcba<br>edcba</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>1 a</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>a</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n, string = <span class="built_in">input</span>().split()</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">int</span>(n) &gt; <span class="number">1</span>:</span><br><span class="line">    l = <span class="number">0</span></span><br><span class="line">    r = <span class="built_in">int</span>(n) - <span class="number">1</span></span><br><span class="line">    string = <span class="built_in">list</span>(string)</span><br><span class="line">    <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">        string[l], string[r] = string[r], string[l]</span><br><span class="line">        l += <span class="number">1</span></span><br><span class="line">        r -= <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(string))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(string)</span><br></pre></td></tr></table></figure>
<h3 id="递增三元组"><a href="#递增三元组" class="headerlink" title="递增三元组"></a>递增三元组</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>在数列 a[1], a[2], …, a[n] 中，如果对于下标 i, j, k 满足 0&lt;i&lt;j&lt;k&lt;n+1 且 a[i]&lt;a[j]&lt;a[k]，则称 a[i], a[j], a[k] 为一组递增三元组，a[j]为递增三元组的中心。<br>给定一个数列，请问数列中有多少个元素可能是递增三元组的中心。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含一个整数 n。<br>第二行包含 n 个整数 a[1], a[2], …, a[n]，相邻的整数间用空格分隔，表示给定的数列。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行包含一个整数，表示答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5<br>1 2 5 3 5</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>2</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>a[2]和a[4]可能是三元组的中心。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split()))</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录该中心是否用过</span></span><br><span class="line">data = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, n):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(j + <span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> arr[i] &lt; arr[j] &lt; arr[k]:</span><br><span class="line">                <span class="keyword">if</span> arr[j] <span class="keyword">not</span> <span class="keyword">in</span> data:</span><br><span class="line">                    data.append(arr[j])</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="第几个幸运数"><a href="#第几个幸运数" class="headerlink" title="第几个幸运数"></a>第几个幸运数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>到x星球旅行的游客都被发给一个整数，作为游客编号。<br>x星的国王有个怪癖，他只喜欢数字3,5和7。<br>国王规定，游客的编号如果只含有因子：3,5,7,就可以获得一份奖品。<br>前10个幸运数字是：3 5 7 9 15 21 25 27 35 45，因而第11个幸运数字是：49<br>小明领到了一个幸运数字 59084709587505。<br>去领奖的时候，人家要求他准确说出这是第几个幸运数字，否则领不到奖品。<br>请你帮小明计算一下，59084709587505是第几个幸运数字。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数表示答案。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MAX = <span class="number">59084709587505</span></span><br><span class="line"><span class="comment"># MAX = 49</span></span><br><span class="line">a = [<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>]</span><br><span class="line">s = <span class="built_in">set</span>()</span><br><span class="line">tou = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">       t = tou * i</span><br><span class="line">       <span class="keyword">if</span> t &lt;= MAX:</span><br><span class="line">        s.add(t)</span><br><span class="line">    lst = <span class="built_in">sorted</span>(s)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lst:</span><br><span class="line">        <span class="keyword">if</span> i &gt; tou:</span><br><span class="line">            tou = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> tou &gt;= MAX:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(s))  <span class="comment"># 1905</span></span><br></pre></td></tr></table></figure>
<h3 id="调手表"><a href="#调手表" class="headerlink" title="调手表"></a>调手表</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明买了块高端大气上档次的电子手表，他正准备调时间呢。在 M78 星云，时间的计量单位和地球上不同，M78 星云的一个小时有 n 分钟。大家都知道，手表只有一个按钮可以把当前的数加一。在调分钟的时候，如果当前显示的数是 0 ，那么按一下按钮就会变成 1，再按一次变成 2 。如果当前的数是 n - 1，按一次后会变成 0 。作为强迫症患者，小明一定要把手表的时间调对。如果手表上的时间比当前时间多1，则要按 n - 1 次加一按钮才能调回正确时间。</p>
<p>小明想，如果手表可以再添加一个按钮，表示把当前的数加 k 该多好啊……<br>他想知道，如果有了这个 +k 按钮，按照最优策略按键，从任意一个分钟数调到另外任意一个分钟数最多要按多少次。</p>
<p>注意，按 +k 按钮时，如果加k后数字超过n-1,则会对n取模。比如，n=10, k=6 的时候，假设当前时间是0，连按2次 +k 按钮，则调为2。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>一行两个整数 n, k，意义如题。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一行一个整数。表示：按照最优策略按键，从一个时间调到另一个时间最多要按多少次。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5 3</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>2</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>如果时间正确则按0次。否则要按的次数和操作系列之间的关系如下：<br>1：+1<br>2：+1, +1<br>3：+3<br>4：+3, +1</p>
</blockquote>
<p>对于 30% 的数据 0 &lt; k &lt; n &lt;= 5<br>对于 60% 的数据 0 &lt; k &lt; n &lt;= 100<br>对于 100% 的数据 0 &lt; k &lt; n &lt;= 100000<br>资源约定：<br>峰值内存消耗（含虚拟机） &lt; 256M<br>CPU消耗 &lt; 1000ms</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n, k = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">    tmp = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &gt;= k:</span><br><span class="line">        tmp += i // k</span><br><span class="line">        i %= k</span><br><span class="line">    tmp += i</span><br><span class="line">    <span class="keyword">if</span> tmp &gt; res:</span><br><span class="line">        res = tmp</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="队列操作"><a href="#队列操作" class="headerlink" title="队列操作"></a>队列操作</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>队列操作题。根据输入的操作命令，操作队列（1）入队、（2）出队并输出、（3）计算队中元素个数并输出。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行一个数字N。<br>下面N行，每行第一个数字为操作命令：（1）入队、（2）出队并输出、（3）计算队中元素个数并输出。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>若干行每行显示一个2或3命令的输出结果。注意：2.出队命令可能会出现空队出队（下溢），请输出“no”，并退出。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>7<br>1 19<br>1 56<br>2<br>3<br>2<br>3<br>2</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>19<br>1<br>56<br>0<br>no</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">command = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">queue = []</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;输出：&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> command:</span><br><span class="line">    <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">        queue.append(i[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(queue) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;no&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            <span class="built_in">print</span>(queue.pop(<span class="number">0</span>))</span><br><span class="line">    <span class="keyword">if</span> i[<span class="number">0</span>] == <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(queue) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            <span class="built_in">print</span>(<span class="built_in">len</span>(queue))</span><br></pre></td></tr></table></figure>
<h3 id="方格分割"><a href="#方格分割" class="headerlink" title="方格分割"></a>方格分割</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>6x6的方格，沿着格子的边线剪开成两部分。要求这两部分的形状完全相同。如图，就是可行的分割法。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/image-20220302142250156.png" alt></p>
<p>试计算： 包括这3种分法在内，一共有多少种不同的分割方法。</p>
<p>注意：旋转对称的属于同一种分割法。</p>
<p>请提交该整数，不要填写任何多余的内容或说明文字。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">因为两部分形状相同，则必定经过中间点</span></span><br><span class="line"><span class="string">从中间点（3，3）出发，向两边按格点走，行走的方式有向上、向下、向左、向右</span></span><br><span class="line"><span class="string">当其中一边达到边界，根据对称性，另一边也到达边界，则所有走过点的连线为一种分割方式</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">global</span> ans</span><br><span class="line">    <span class="comment"># 到达边界，分割完成</span></span><br><span class="line">    <span class="keyword">if</span> x == <span class="number">0</span> <span class="keyword">or</span> x == <span class="number">6</span> <span class="keyword">or</span> y == <span class="number">0</span> <span class="keyword">or</span> y == <span class="number">6</span>:</span><br><span class="line">        ans += <span class="number">1</span> </span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">    <span class="comment"># 4个出行可能性</span></span><br><span class="line">    <span class="keyword">for</span> xy <span class="keyword">in</span> dirs:</span><br><span class="line">        <span class="comment"># 出发后的新索引</span></span><br><span class="line">        tx = x + xy[<span class="number">0</span>]</span><br><span class="line">        ty = y + xy[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 当前位置未走过</span></span><br><span class="line">        <span class="keyword">if</span> arr_map[tx][ty] == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 标记为走过</span></span><br><span class="line">            arr_map[tx][ty] = <span class="number">1</span></span><br><span class="line">            <span class="comment"># 两边出发，根据对称性，另一边也标记为走过</span></span><br><span class="line">            arr_map[<span class="number">6</span>-tx][<span class="number">6</span>-ty] = <span class="number">1</span></span><br><span class="line">            <span class="comment"># 到达新位置后, 继续搜寻下一步可能</span></span><br><span class="line">            dfs(tx, ty)</span><br><span class="line">            <span class="comment"># 当进行到这步，则代表一种分割可能已经搜寻完，因此跳出了递归</span></span><br><span class="line">            <span class="comment"># 则要将方格还原，进行下一种可能的搜寻</span></span><br><span class="line">            arr_map[tx][ty] = <span class="number">0</span></span><br><span class="line">            arr_map[<span class="number">6</span>-tx][<span class="number">6</span>-ty] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 初始化方格代表(0,0)到(6,6)的位置</span></span><br><span class="line">arr_map = [[<span class="number">0</span>] * <span class="number">7</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>)]</span><br><span class="line"><span class="comment"># 4个方向</span></span><br><span class="line">dirs = [(<span class="number">1</span>,<span class="number">0</span>), (-<span class="number">1</span>,<span class="number">0</span>), (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>,-<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 中间点置1 代表走过</span></span><br><span class="line">arr_map[<span class="number">3</span>][<span class="number">3</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 分割方法</span></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"><span class="comment"># 从中间点索引往两边走</span></span><br><span class="line">dfs(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 由于旋转对称的属于同一种分割方法,故最终结果要除以4</span></span><br><span class="line"><span class="built_in">print</span>(ans//<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h3 id="分解质因数"><a href="#分解质因数" class="headerlink" title="分解质因数"></a>分解质因数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>求出区间[a,b]中所有整数的质因数分解。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入两个整数a，b。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>每行输出一个数的分解，形如k=a1*a2*a3…(a1&lt;=a2&lt;=a3…，k也是从小到大的)</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3 10</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3=3<br>4=2*2<br>5=5<br>6=2*3<br>7=7<br>8=2*2*2<br>9=3*3<br>10=2*5</p>
</blockquote>
<p>2&lt;=a&lt;=b&lt;=10000</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">factor</span>(<span class="params">num</span>):</span></span><br><span class="line">    <span class="comment"># 遍历该数的可能因子</span></span><br><span class="line">    <span class="comment"># 最大因子只到该数的开方</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">int</span>(<span class="built_in">float</span>(num)**<span class="number">0.5</span>)+<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 若能找到因子</span></span><br><span class="line">        <span class="keyword">if</span> num % i == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 输出该因子</span></span><br><span class="line">            <span class="built_in">print</span>((<span class="string">&#x27;%d*&#x27;</span>) % i, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">            <span class="comment"># 继续分解</span></span><br><span class="line">            factor(num // i)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 若找不到，返回本身</span></span><br><span class="line">    <span class="built_in">print</span>(num, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">a, b = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line"><span class="comment"># 遍历该区间的数</span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(a, b+<span class="number">1</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%d=&#x27;</span>%num, end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    factor(num)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>
<h3 id="分数"><a href="#分数" class="headerlink" title="分数"></a>分数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>1/1 + 1/2 + 1/4 + 1/8 + 1/16 + …<br>每项是前一项的一半，如果一共有20项,<br>求这个和是多少，结果用分数表示出来。<br>类似：<br>3/2<br>当然，这只是加了前2项而已。分子分母要求互质。</p>
<p>注意：<br>需要提交的是已经约分过的分数，中间任何位置不能含有空格。<br>请不要填写任何多余的文字或符号</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 最大公约数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    <span class="keyword">while</span> b != <span class="number">0</span>:</span><br><span class="line">        c = a % b</span><br><span class="line">        a = b</span><br><span class="line">        b = c</span><br><span class="line">    <span class="keyword">return</span> a</span><br><span class="line"><span class="comment"># 分子</span></span><br><span class="line">molecule = <span class="number">0</span></span><br><span class="line"><span class="comment"># 因为1/1 + 1/2 + ... + 1/2^19通分后</span></span><br><span class="line"><span class="comment"># = 2^19/2^19 + 2^18/2^19 + ... + 1/2^19</span></span><br><span class="line"><span class="comment"># 则分子和为2^19 + 2^18 + ... + 1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    molecule += <span class="number">2</span> ** i</span><br><span class="line"><span class="comment"># 分母为2^19</span></span><br><span class="line">gc = gcd(molecule, <span class="number">2</span> ** <span class="number">19</span>)</span><br><span class="line"><span class="comment"># 输出约分后的结果</span></span><br><span class="line"><span class="built_in">print</span>(molecule // gc , <span class="string">&#x27;/&#x27;</span>, <span class="number">2</span> ** <span class="number">19</span> // gc, sep=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="复数求和"><a href="#复数求和" class="headerlink" title="复数求和"></a>复数求和</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>从键盘读入n个复数（实部和虚部都为整数）用链表存储，遍历链表求出n个复数的和并输出。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3<br>3 4<br>5 2<br>1 3</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>9+9i</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>7<br>1 2<br>3 4<br>2 5<br>1 8<br>6 4<br>7 9<br>3 7</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>23+39i</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">real = <span class="number">0</span></span><br><span class="line">imaginary = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    real += arr[i][<span class="number">0</span>]</span><br><span class="line">    imaginary += arr[i][<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(real,<span class="string">&#x27;+&#x27;</span>,imaginary,<span class="string">&#x27;i&#x27;</span>, sep=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="购物单"><a href="#购物单" class="headerlink" title="购物单"></a>购物单</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明刚刚找到工作，老板人很好，只是老板夫人很爱购物。老板忙的时候经常让小明帮忙到商场代为购物。小明很厌烦，但又不好推辞。</p>
<p>这不，XX大促销又来了！老板夫人开出了长长的购物单，都是有打折优惠的。<br>小明也有个怪癖，不到万不得已，从不刷卡，直接现金搞定。<br>现在小明很心烦，请你帮他计算一下，需要从取款机上取多少现金，才能搞定这次购物。</p>
<p>取款机只能提供100元面额的纸币。小明想尽可能少取些现金，够用就行了。<br>你的任务是计算出，小明最少需要取多少现金。<br>以下是让人头疼的购物单，为了保护隐私，物品名称被隐藏了。<br>****     180.90       88折<br>****      10.25       65折<br>****      56.14        9折<br>****     104.65        9折<br>****     100.30       88折<br>****     297.15       半价<br>****     26.75       65折<br>****     130.62       半价<br>****     240.28       58折<br>****     270.62        8折<br>****     115.87       88折<br>****     247.34       95折<br>****      73.21        9折<br>****     101.00       半价<br>****      79.54       半价<br>****     278.44        7折<br>****     199.26       半价<br>****      12.97        9折<br>****     166.30       78折<br>****     125.50       58折<br>****      84.98        9折<br>****     113.35       68折<br>****     166.57       半价<br>****      42.56        9折<br>****      81.90       95折<br>****     131.78        8折<br>****     255.89       78折<br>****     109.17        9折<br>****     146.69       68折<br>****     139.33       65折<br>****     141.16       78折<br>****     154.74        8折<br>****      59.42        8折<br>****      85.44       68折<br>****     293.70       88折<br>****     261.79       65折<br>****      11.30       88折<br>****     268.27       58折<br>****     128.29       88折<br>****     251.03        8折<br>****     208.39       75折<br>****     128.88       75折<br>****      62.06        9折<br>****     225.87       75折<br>****      12.89       75折<br>****      34.28       75折<br>****      62.16       58折<br>****     129.12       半价<br>****     218.37       半价<br>****     289.69       8折</p>
<p>需要说明的是，88折指的是按标价的88%计算，而8折是按80%计算，余者类推。<br>特别地，半价是按50%计算。</p>
<p>请提交小明要从取款机上提取的金额，单位是元。<br>答案是一个整数，类似4300的样子，结尾必然是00，不要填写任何多余的内容。</p>
</blockquote>
<p>首先在把数据复制到记事本中，用Ctrl+H键替换，把<code>****</code>用空格替换，把7折、8折、9折替换为70、80、90，半价替换为50。<br><code>item.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">180.90  88  </span><br><span class="line"> 10.25  65  </span><br><span class="line"> 56.14   90  </span><br><span class="line">104.65   90  </span><br><span class="line">100.30  88  </span><br><span class="line">297.15  50  </span><br><span class="line"> 26.75  65  </span><br><span class="line">130.62  50  </span><br><span class="line">240.28  58  </span><br><span class="line">270.62   80  </span><br><span class="line">115.87  88  </span><br><span class="line">247.34  95  </span><br><span class="line"> 73.21   90  </span><br><span class="line">101.00  50  </span><br><span class="line"> 79.54  50  </span><br><span class="line">278.44   70  </span><br><span class="line">199.26  50  </span><br><span class="line"> 12.97   90  </span><br><span class="line">166.30  78  </span><br><span class="line">125.50  58  </span><br><span class="line"> 84.98   90  </span><br><span class="line">113.35  68  </span><br><span class="line">166.57  50  </span><br><span class="line"> 42.56   90  </span><br><span class="line"> 81.90  95  </span><br><span class="line">131.78   80  </span><br><span class="line">255.89  78  </span><br><span class="line">109.17   90  </span><br><span class="line">146.69  68  </span><br><span class="line">139.33  65  </span><br><span class="line">141.16  78  </span><br><span class="line">154.74   80  </span><br><span class="line"> 59.42   80  </span><br><span class="line"> 85.44  68  </span><br><span class="line">293.70  88  </span><br><span class="line">261.79  65  </span><br><span class="line"> 11.30  88  </span><br><span class="line">268.27  58  </span><br><span class="line">128.29  88  </span><br><span class="line">251.03   80  </span><br><span class="line">208.39  75  </span><br><span class="line">128.88  75  </span><br><span class="line"> 62.06   90  </span><br><span class="line">225.87  75  </span><br><span class="line"> 12.89  75  </span><br><span class="line"> 34.28  75  </span><br><span class="line"> 62.16  58  </span><br><span class="line">129.12  50  </span><br><span class="line">218.37  50  </span><br><span class="line">289.69  80 </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;item.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</span><br><span class="line">    price, rate = <span class="built_in">map</span>(<span class="built_in">float</span>, line.split())</span><br><span class="line">    ans += price * rate / <span class="number">100</span></span><br><span class="line">file.close()</span><br><span class="line"><span class="built_in">print</span>(ans)</span><br></pre></td></tr></table></figure>
<h3 id="龟兔赛跑预测"><a href="#龟兔赛跑预测" class="headerlink" title="龟兔赛跑预测"></a>龟兔赛跑预测</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>话说这个世界上有各种各样的兔子和乌龟，但是研究发现，所有的兔子和乌龟都有一个共同的特点——喜欢赛跑。于是世界上各个角落都不断在发生着乌龟和兔子的比赛，小华对此很感兴趣，于是决定研究不同兔子和乌龟的赛跑。他发现，兔子虽然跑比乌龟快，但它们有众所周知的毛病——骄傲且懒惰，于是在与乌龟的比赛中，一旦任一秒结束后兔子发现自己领先t米或以上，它们就会停下来休息s秒。对于不同的兔子，t，s的数值是不同的，但是所有的乌龟却是一致——它们不到终点决不停止。</p>
<p>然而有些比赛相当漫长，全程观看会耗费大量时间，而小华发现只要在每场比赛开始后记录下兔子和乌龟的数据——兔子的速度v1（表示每秒兔子能跑v1米），乌龟的速度v2，以及兔子对应的t，s值，以及赛道的长度l——就能预测出比赛的结果。但是小华很懒，不想通过手工计算推测出比赛的结果，于是他找到了你——清华大学计算机系的高才生——请求帮助，请你写一个程序，对于输入的一场比赛的数据v1，v2，t，s，l，预测该场比赛的结果。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入只有一行，包含用空格隔开的五个正整数v1，v2，t，s，l，其中(v1, v2&lt;=100; t&lt;=300; s&lt;=10; l&lt;=10000且为v1, v2的公倍数)</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出包含两行，第一行输出比赛结果——一个大写字母“T”或“R”或“D”，分别表示乌龟获胜，兔子获胜，或者两者同时到达终点。<br>第二行输出一个正整数，表示获胜者（或者双方同时）到达终点所耗费的时间（秒数）。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>10 5 5 2 20</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>D<br>4</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>10 5 5 1 20</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>R<br>3</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>10 5 5 3 20</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>T<br>4</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">v1, v2, t, s, l = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">rabbit = <span class="number">0</span></span><br><span class="line">tortoise = <span class="number">0</span></span><br><span class="line">time = <span class="number">0</span></span><br><span class="line">flag = <span class="literal">False</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">if</span> rabbit == l <span class="keyword">or</span> tortoise == l:  <span class="comment"># 如果兔子或乌龟到达终点，结束</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> rabbit - tortoise &gt;= t:  <span class="comment"># 兔子达到领先条件，休息</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(s):  <span class="comment"># 休息时间按秒增加，乌龟路程按秒增加</span></span><br><span class="line">            tortoise += v2</span><br><span class="line">            time += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> tortoise == l:  </span><br><span class="line">                <span class="comment"># 兔子休息时，乌龟到达了终点，结束。</span></span><br><span class="line">                <span class="comment"># 注意：有可能兔子在休息中，乌龟就到达了终点</span></span><br><span class="line">                <span class="comment"># 所以休息时间未必循环完</span></span><br><span class="line">                <span class="comment"># 如：兔子要休息10s，乌龟可能在兔子休息的第9s就到达了终点</span></span><br><span class="line">                <span class="comment"># 这里的flag就起到提前结束的功能</span></span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> flag:  <span class="comment"># 如果提前结束，则全部结束</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    time += <span class="number">1</span>  <span class="comment"># 每走一秒，兔子和乌龟按相应速度增加相应距离</span></span><br><span class="line">    rabbit += v1</span><br><span class="line">    tortoise += v2</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rabbit &gt; tortoise:  <span class="comment"># 谁先到达终点，谁的距离大</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;R&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> rabbit &lt; tortoise:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;T&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:  <span class="comment"># 相等则平局</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(time)</span><br></pre></td></tr></table></figure>
<h3 id="合根植物"><a href="#合根植物" class="headerlink" title="合根植物"></a>合根植物</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>w星球的一个种植园，被分成 m * n 个小格子（东西方向m行，南北方向n列）。每个格子里种了一株合根植物。<br>这种植物有个特点，它的根可能会沿着南北或东西方向伸展，从而与另一个格子的植物合成为一体。</p>
<p>如果我们告诉你哪些小格子间出现了连根现象，你能说出这个园中一共有多少株合根植物吗？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行，两个整数m，n，用空格分开，表示格子的行数、列数（1&lt;m,n&lt;1000）。<br>接下来一行，一个整数k，表示下面还有k行数据(0&lt;k&lt;100000)<br>接下来k行，第行两个整数a，b，表示编号为a的小格子和编号为b的小格子合根了。</p>
<p>格子的编号一行一行，从上到下，从左到右编号。<br>比如：5 * 4 的小格子，编号：<br>1 2 3 4<br>5 6 7 8<br>9 10 11 12<br>13 14 15 16<br>17 18 19 20</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5 4<br>16<br>2 3<br>1 5<br>5 9<br>4 8<br>7 8<br>9 10<br>10 11<br>11 12<br>10 14<br>12 16<br>14 18<br>17 18<br>15 19<br>19 20<br>9 13<br>13 17</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>5</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>其合根情况参考下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/RequireFile.do" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">并查集算法</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 用于找到x的父节点</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rootFind</span>(<span class="params">x</span>):</span></span><br><span class="line">    p = x </span><br><span class="line">    <span class="comment">#如果x的父节点不是他本身，就一直循坏到找到父节点为之</span></span><br><span class="line">    <span class="keyword">while</span> x != pre[x]: </span><br><span class="line">        x = pre[x]</span><br><span class="line">    <span class="comment"># 压缩路径，这个是优化的，所以可加可不加</span></span><br><span class="line">    <span class="keyword">while</span> p != x: <span class="comment"># 若当前节点不是父节点，找到父节点后，把沿途每个节点的根节点都设成父节点，使树变得扁平，以减小深度</span></span><br><span class="line">       p, pre[p] = pre[p], x</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">m, n = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">cnt = m * n</span><br><span class="line"><span class="comment"># pre列表中存储的是每个节点的父节点</span></span><br><span class="line">pre = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cnt+<span class="number">1</span>)]</span><br><span class="line">k = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    a,b = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">    roota = rootFind(a)</span><br><span class="line">    rootb = rootFind(b)</span><br><span class="line">    <span class="keyword">if</span> roota != rootb: </span><br><span class="line">        <span class="comment"># 如果父节点不一样就合并, 选任意一方为父</span></span><br><span class="line">        pre[roota] = pre[rootb]</span><br><span class="line">        <span class="comment">#同时合并的话，集合就会少一个</span></span><br><span class="line">        cnt -= <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(cnt)</span><br></pre></td></tr></table></figure>
<h3 id="换钞票"><a href="#换钞票" class="headerlink" title="换钞票"></a>换钞票</h3><p><strong>题目描述</strong></p>
<blockquote>
<p>x星球的钞票的面额只有：100元，5元，2元，1元，共4种。<br>小明去x星旅游，他手里只有2张100元的x星币，太不方便，恰好路过x星银行就去换零钱。<br>小明有点强迫症，他坚持要求200元换出的零钞中2元的张数刚好是1元的张数的10倍，<br>剩下的当然都是5元面额的。</p>
<p>银行的工作人员有点为难，你能帮助算出：在满足小明要求的前提下，最少要换给他多少张钞票吗？<br>（5元，2元，1元面额的必须都有，不能是0）</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 总共200元</span></span><br><span class="line">total = <span class="number">200</span></span><br><span class="line"><span class="comment"># 由于2元是1元的10倍，即扣掉5元钞票的钱数，应为21的倍数</span></span><br><span class="line"><span class="comment"># 要使换的钱数最少，则5元的钞票要多</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">200</span> // <span class="number">21</span>):</span><br><span class="line">    total -= <span class="number">21</span></span><br><span class="line">    <span class="keyword">if</span> total % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 共换了多少张钞票</span></span><br><span class="line">        count = <span class="number">10</span> * i + i + total // <span class="number">5</span></span><br><span class="line">        <span class="built_in">print</span>(count)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h3 id="回形取数"><a href="#回形取数" class="headerlink" title="回形取数"></a>回形取数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>回形取数就是沿矩阵的边取数，若当前方向上无数可取或已经取过，则左转90度。一开始位于矩阵左上角，方向向下。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入第一行是两个不超过200的正整数m, n，表示矩阵的行和列。接下来m行每行n个整数，表示这个矩阵。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出只有一行，共mn个数，为输入矩阵回形取数得到的结果。数之间用一个空格分隔，行末不要有多余的空格。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3 3<br>1 2 3<br>4 5 6<br>7 8 9</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1 4 7 8 9 6 3 2 5</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3 2<br>1 2<br>3 4<br>5 6</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1 3 5 6 4 2</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m, n = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">matrix = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    arr = <span class="built_in">input</span>().split()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        matrix[i].append(<span class="built_in">int</span>(arr[j]))</span><br><span class="line"><span class="comment"># 初始位置</span></span><br><span class="line">x, y = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="comment"># 外框到里框的个数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(m, n)//<span class="number">2</span>+<span class="number">1</span>):</span><br><span class="line">     <span class="comment"># 向下取数</span></span><br><span class="line">    <span class="keyword">while</span> x &lt; m <span class="keyword">and</span> matrix[x][y] != -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(matrix[x][y], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        matrix[x][y] = -<span class="number">1</span>  <span class="comment"># 将去过的位置置为-1</span></span><br><span class="line">        x += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 上个循环结束后x多加一次要减回来</span></span><br><span class="line">    x -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 列值加1，因为第零列在上个循环已经输出，往右推一行</span></span><br><span class="line">    y += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 向右取数</span></span><br><span class="line">    <span class="keyword">while</span>  y &lt; n <span class="keyword">and</span> matrix[x][y] != -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(matrix[x][y], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        matrix[x][y] = -<span class="number">1</span>  <span class="comment"># 将去过的位置置为-1</span></span><br><span class="line">        y += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 上个循环多加一次减回来</span></span><br><span class="line">    y -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 往上推一行</span></span><br><span class="line">    x -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 向上取数</span></span><br><span class="line">    <span class="keyword">while</span> x &gt;= <span class="number">0</span> <span class="keyword">and</span> matrix[x][y] != -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(matrix[x][y], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        matrix[x][y] = -<span class="number">1</span>  <span class="comment"># 将去过的位置置为-1</span></span><br><span class="line">        x -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 上个循环使多减一次加回来</span></span><br><span class="line">    x += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 往左推一行</span></span><br><span class="line">    y -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 向左取数</span></span><br><span class="line">    <span class="keyword">while</span> y &gt;= <span class="number">0</span> <span class="keyword">and</span> matrix[x][y] != -<span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(matrix[x][y], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        matrix[x][y] = -<span class="number">1</span>  <span class="comment"># 将去过的位置置为-1</span></span><br><span class="line">        y -= <span class="number">1</span></span><br><span class="line">    <span class="comment"># 上个循环多加一次减回来</span></span><br><span class="line">    y += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 向下推一行</span></span><br><span class="line">    x += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="金陵十三钗"><a href="#金陵十三钗" class="headerlink" title="金陵十三钗"></a>金陵十三钗</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>在电影《金陵十三钗》中有十二个秦淮河的女人要自我牺牲代替十二个女学生去赴日本人的死亡宴会。为了不让日本人发现，自然需要一番乔装打扮。但由于天生材质的原因，每个人和每个人之间的相似度是不同的。由于我们这是编程题，因此情况就变成了金陵n钗。给出n个女人和n个学生的相似度矩阵，求她们之间的匹配所能获得的最大相似度。</p>
<p>所谓相似度矩阵是一个n*n的二维数组<code>like[i][j]</code>。其中i, j分别为女人的编号和学生的编号，皆从0到n-1编号。<code>like[i][j]</code>是一个0到100的整数值，表示第i个女人和第j个学生的相似度，值越大相似度越大，比如0表示完全不相似，100表示百分之百一样。每个女人都需要找一个自己代替的女学生。</p>
<p>最终要使两边一一配对，形成一个匹配。请编程找到一种匹配方案，使各对女人和女学生之间的相似度之和最大。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行一个正整数n表示有n个秦淮河女人和n个女学生<br>接下来n行给出相似度，每行n个0到100的整数，依次对应二维矩阵的n行n列。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>仅一行，一个整数，表示可获得的最大相似度。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4<br>97 91 68 14<br>8 33 27 92<br>36 32 98 53<br>73 7 17 82</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>354</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>最大相似度为91+92+98+73=354</p>
</blockquote>
<p>对于70%的数据，n&lt;=10<br>对于100%的数据，n&lt;=13</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 本题类似n皇后问题，先列举出所有可能，在求其中和最大</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">queen</span>(<span class="params">cur=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">global</span> maxSum</span><br><span class="line">    <span class="comment"># 判断上行的棋子放置是否有问题</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(cur-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 若该女学生已被其他女人匹配</span></span><br><span class="line">        <span class="keyword">if</span> res[row] == res[cur-<span class="number">1</span>]:</span><br><span class="line">            <span class="comment"># 向上回溯</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 若匹配完毕</span></span><br><span class="line">    <span class="keyword">if</span> cur == n:</span><br><span class="line">        <span class="comment"># 算出当前排列的和</span></span><br><span class="line">        cur_sum = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            cur_sum += matrix[i][res[i]]</span><br><span class="line">        <span class="comment"># 储存最大和</span></span><br><span class="line">        <span class="keyword">if</span> cur_sum &gt; maxSum:</span><br><span class="line">            maxSum = cur_sum</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每列</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 设置秦淮河女人匹配的女学生</span></span><br><span class="line">        res[cur] = col</span><br><span class="line">        <span class="comment"># 对下一个秦淮河女人进行匹配</span></span><br><span class="line">        queen(cur+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 相似度矩阵</span></span><br><span class="line">matrix = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">res = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">maxSum = <span class="number">0</span></span><br><span class="line">queen()</span><br><span class="line"><span class="built_in">print</span>(maxSum)</span><br></pre></td></tr></table></figure>
<h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定一个N阶矩阵A，输出A的M次幂（M是非负整数）<br>例如：<br>A =<br>1 2<br>3 4<br>A的2次幂<br>7 10<br>15 22</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行是一个正整数N、M（1&lt;=N&lt;=30, 0&lt;=M&lt;=5），表示矩阵A的阶数和要求的幂数<br>接下来N行，每行N个绝对值不超过10的非负整数，描述矩阵A的值</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出共N行，每行N个整数，表示A的M次幂所对应的矩阵。相邻的数之间用一个空格隔开</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>2 2<br>1 2<br>3 4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>7 10<br>15 22</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 矩阵乘法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mul_matrix</span>(<span class="params">matrix1, matrix2, n</span>):</span></span><br><span class="line">    <span class="comment"># 存放乘法后的矩阵</span></span><br><span class="line">    res = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="comment"># 遍历每个元素</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            pos = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 乘法后所得结果该位置的值等于两个数组该行和该列的加权</span></span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                pos += matrix1[i][c] * matrix2[c][j]</span><br><span class="line">            res[i].append(pos)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">n, m = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">matrix = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    arr = <span class="built_in">input</span>().split()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        matrix[i].append(<span class="built_in">int</span>(arr[j]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化单位矩阵</span></span><br><span class="line">res = [[<span class="number">1</span> <span class="keyword">if</span> i == j <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># m次幂</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m+<span class="number">1</span>):</span><br><span class="line">    res = mul_matrix(res, matrix, n)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="built_in">print</span>(res[i][j], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>
<h3 id="矩阵面积交"><a href="#矩阵面积交" class="headerlink" title="矩阵面积交"></a>矩阵面积交</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>平面上有两个矩形，它们的边平行于直角坐标系的X轴或Y轴。对于每个矩形，我们给出它的一对相对顶点的坐标，请你编程算出两个矩形的交的面积。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入仅包含两行，每行描述一个矩形。<br>在每行中，给出矩形的一对相对顶点的坐标，每个点的坐标都用两个绝对值不超过$10^7$的实数表示。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出仅包含一个实数，为交的面积。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>1  1  3  3<br>2  2  4  4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rect1 = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, <span class="built_in">input</span>().split()))</span><br><span class="line">rect2 = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, <span class="built_in">input</span>().split()))</span><br><span class="line">x1 = <span class="built_in">max</span>(<span class="built_in">min</span>(rect1[<span class="number">0</span>], rect1[<span class="number">2</span>]), <span class="built_in">min</span>(rect2[<span class="number">0</span>], rect2[<span class="number">2</span>]))</span><br><span class="line">y1 = <span class="built_in">max</span>(<span class="built_in">min</span>(rect1[<span class="number">1</span>], rect1[<span class="number">3</span>]), <span class="built_in">min</span>(rect2[<span class="number">1</span>], rect2[<span class="number">3</span>]))</span><br><span class="line">x2 = <span class="built_in">min</span>(<span class="built_in">max</span>(rect1[<span class="number">0</span>], rect1[<span class="number">2</span>]), <span class="built_in">max</span>(rect2[<span class="number">0</span>], rect2[<span class="number">2</span>]))</span><br><span class="line">y2 = <span class="built_in">min</span>(<span class="built_in">max</span>(rect1[<span class="number">1</span>], rect1[<span class="number">3</span>]), <span class="built_in">max</span>(rect2[<span class="number">1</span>], rect2[<span class="number">3</span>]))</span><br><span class="line"><span class="comment"># 交集的面积</span></span><br><span class="line">inter = <span class="built_in">max</span>(x2-x1, <span class="number">0</span>) * <span class="built_in">max</span>(y2-y1, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(inter)</span><br></pre></td></tr></table></figure>
<h3 id="矩阵求和"><a href="#矩阵求和" class="headerlink" title="矩阵求和"></a>矩阵求和</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>今天小明的任务是填满这么一张表： 表有n行n列，行和列的编号都从1算起。 其中第i行第j个元素的值是gcd(i, j)的平方，gcd表示最大公约数，以下是这个表的前四行的前四列： </p>
<p>1 1 1 1<br>1 4 1 4<br>1 1 9 1<br>1 4 1 16</p>
<p>小明突然冒出一个奇怪的想法，他想知道这张表中所有元素的和。 由于表过于庞大，他希望借助计算机的力量。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>一行一个正整数n意义见题。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一行一个数，表示所有元素的和。由于答案比较大，请输出模 (10^9 + 7)后的结果。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>48</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%92%8C.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; 方法一：暴力求解会超时</span></span><br><span class="line"><span class="string"># 求最大公约数</span></span><br><span class="line"><span class="string">def gcd(i, j):</span></span><br><span class="line"><span class="string">    while j !=0:</span></span><br><span class="line"><span class="string">        k = i % j</span></span><br><span class="line"><span class="string">        i, j = j, k</span></span><br><span class="line"><span class="string">    return i</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">n = int(input())</span></span><br><span class="line"><span class="string">sum_arr = 0</span></span><br><span class="line"><span class="string">mod = 10 ** 9 + 7</span></span><br><span class="line"><span class="string">for i in range(1, n+1):</span></span><br><span class="line"><span class="string">    for j in range(1, n+1):</span></span><br><span class="line"><span class="string">        t = gcd(i, j) ** 2</span></span><br><span class="line"><span class="string">        sum_arr += t % mod</span></span><br><span class="line"><span class="string">print(sum_arr)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;方法二：欧拉函数（线性筛法）推荐&#x27;&#x27;&#x27;</span></span><br><span class="line">MOD = <span class="number">10</span> ** <span class="number">9</span> + <span class="number">7</span></span><br><span class="line"><span class="comment"># 欧拉函数</span></span><br><span class="line">phi = []</span><br><span class="line"><span class="comment"># 存放[1, n/d]中，所有互质对的个数</span></span><br><span class="line">sum_ = []</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euler_table</span>(<span class="params">n</span>):</span></span><br><span class="line">    <span class="comment"># 初始化</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n + <span class="number">1</span>):</span><br><span class="line">        phi.append(<span class="number">0</span>)</span><br><span class="line">        sum_.append(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># n=1时的欧拉函数为1</span></span><br><span class="line">    phi[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 求到n为止的欧拉函数(线性筛法)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># ph[i]为0时代表没遍历过，则此时i为素数</span></span><br><span class="line">        <span class="keyword">if</span> phi[i] == <span class="number">0</span>:</span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> j &lt;= n:</span><br><span class="line">                <span class="comment"># 先令phi[j] = j,则ph[j] / i = j / i = i^(k-1)</span></span><br><span class="line">                <span class="keyword">if</span> phi[j] == <span class="number">0</span>:</span><br><span class="line">                    phi[j] = j</span><br><span class="line">                <span class="comment"># 当i是素数时 phi(i) = i-1</span></span><br><span class="line">                <span class="comment"># phi(i^k) = i^(k-1) * (i-1) </span></span><br><span class="line">                <span class="comment"># 这里j = i^k</span></span><br><span class="line">                phi[j] = phi[j] // i * (i - <span class="number">1</span>)</span><br><span class="line">                <span class="comment"># 进行递推，求得相应的phi[j]，使phi[j]上的值不再为0，那么下次遍历i时，若为0，则代表i为素数</span></span><br><span class="line">                j += i</span><br><span class="line">    sum_[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 递推，求互质对的个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">        sum_[i] = sum_[i - <span class="number">1</span>] + phi[i] * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">euler_table(n)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n + <span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 将问题转化成了count(d)*d*d</span></span><br><span class="line">    ans = (ans + sum_[n // i] * i % MOD * i) % MOD</span><br><span class="line"><span class="built_in">print</span>(ans)</span><br></pre></td></tr></table></figure>
<h3 id="门牌制作"><a href="#门牌制作" class="headerlink" title="门牌制作"></a>门牌制作</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小蓝要为一条街的住户制作门牌号。</p>
<p>这条街一共有 2020 位住户，门牌号从 1 到 2020 编号。</p>
<p>小蓝制作门牌的方法是先制作 0 到 9 这几个数字字符，最后根据需要将字符粘贴到门牌上，例如门牌 1017 需要依次粘贴字符 1、0、1、7，即需要 1 个字符 0，2 个字符 1，1 个字符 7。</p>
<p>请问要制作所有的 1 到 2020 号门牌，总共需要多少个字符 2？</p>
<p>这是一道结果填空的题，你只需要算出结果后提交即可。<br>本题的结果为一个整数，在提交答案时只填写这个整数，填写多余的内容将无法得分。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2021</span>):</span><br><span class="line">    count += <span class="built_in">str</span>(num).count(<span class="string">&quot;2&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="迷宫"><a href="#迷宫" class="headerlink" title="迷宫"></a>迷宫</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>下图给出了一个迷宫的平面图，其中标记为 1 的为障碍，标记为 0 的为可 以通行的地方。</p>
<p>010000<br>000100<br>001001<br>110000</p>
<p>迷宫的入口为左上角，出口为右下角，在迷宫中，只能从一个位置走到这 个它的上、下、左、右四个方向之一。 对于上面的迷宫，从入口开始，可以按DRRURRDDDR 的顺序通过迷宫， 一共 10 步。其中 D、U、L、R 分别表示向下、向上、向左、向右走。</p>
<p> 对于下面这个更复杂的迷宫（30 行 50 列），请找出一种通过迷宫的方式， 其使用的步数最少，在步数最少的前提下，请找出字典序最小的一个作为答案。 请注意在字典序中D&lt;L&lt;R&lt;U。</p>
</blockquote>
<p><code>data.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">01010101001011001001010110010110100100001000101010</span><br><span class="line">00001000100000101010010000100000001001100110100101</span><br><span class="line">01111011010010001000001101001011100011000000010000</span><br><span class="line">01000000001010100011010000101000001010101011001011</span><br><span class="line">00011111000000101000010010100010100000101100000000</span><br><span class="line">11001000110101000010101100011010011010101011110111</span><br><span class="line">00011011010101001001001010000001000101001110000000</span><br><span class="line">10100000101000100110101010111110011000010000111010</span><br><span class="line">00111000001010100001100010000001000101001100001001</span><br><span class="line">11000110100001110010001001010101010101010001101000</span><br><span class="line">00010000100100000101001010101110100010101010000101</span><br><span class="line">11100100101001001000010000010101010100100100010100</span><br><span class="line">00000010000000101011001111010001100000101010100011</span><br><span class="line">10101010011100001000011000010110011110110100001000</span><br><span class="line">10101010100001101010100101000010100000111011101001</span><br><span class="line">10000000101100010000101100101101001011100000000100</span><br><span class="line">10101001000000010100100001000100000100011110101001</span><br><span class="line">00101001010101101001010100011010101101110000110101</span><br><span class="line">11001010000100001100000010100101000001000111000010</span><br><span class="line">00001000110000110101101000000100101001001000011101</span><br><span class="line">10100101000101000000001110110010110101101010100001</span><br><span class="line">00101000010000110101010000100010001001000100010101</span><br><span class="line">10100001000110010001000010101001010101011111010010</span><br><span class="line">00000100101000000110010100101001000001000000000010</span><br><span class="line">11010000001001110111001001000011101001011011101000</span><br><span class="line">00000110100010001000100000001000011101000000110011</span><br><span class="line">10101000101000100010001111100010101001010000001000</span><br><span class="line">10000010100101001010110000000100101010001011101000</span><br><span class="line">00111100001000010000000110111000000001000000001011</span><br><span class="line">10000001100111010111010001000110111010101101111000</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">path = [[0,1,0,0,0,0],</span></span><br><span class="line"><span class="string">[0,0,0,1,0,0],</span></span><br><span class="line"><span class="string">[0,0,1,0,0,1],</span></span><br><span class="line"><span class="string">[1,1,0,0,0,0]]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">path =[]</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data.txt&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    contents = file.readlines()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> contents:</span><br><span class="line">    path.append(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">list</span>(i.strip()))))</span><br><span class="line"><span class="comment"># 迷宫的实质就是一个矩阵，即用（x，y）即可表示迷宫内的任意一点，再用一个字符串w来表示路径。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x, y, w</span>):</span></span><br><span class="line">        self.x = x	<span class="comment"># 记录横坐标</span></span><br><span class="line">        self.y = y	<span class="comment"># 记录纵坐标</span></span><br><span class="line">        self.w = w	<span class="comment"># 记录路径</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span> </span><br><span class="line">        <span class="keyword">return</span> self.w	<span class="comment"># 输出路径</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">up</span>(<span class="params">node</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Node(node.x - <span class="number">1</span>, node.y, node.w+<span class="string">&quot;U&quot;</span>)	<span class="comment"># 上的情况</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">down</span>(<span class="params">node</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Node(node.x + <span class="number">1</span>, node.y, node.w+<span class="string">&quot;D&quot;</span>)	<span class="comment"># 下的情况</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">left</span>(<span class="params">node</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Node(node.x, node.y - <span class="number">1</span>, node.w+<span class="string">&quot;L&quot;</span>)	<span class="comment"># 左的情况</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">right</span>(<span class="params">node</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Node(node.x, node.y + <span class="number">1</span>, node.w+<span class="string">&quot;R&quot;</span>)	<span class="comment"># 右的情况</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    row, col = <span class="built_in">len</span>(path), <span class="built_in">len</span>(path[<span class="number">0</span>]) <span class="comment"># 矩阵的长和宽</span></span><br><span class="line">    visited = <span class="built_in">set</span>() <span class="comment"># 记录访问过的点</span></span><br><span class="line">    queue = []</span><br><span class="line">    node = Node(<span class="number">0</span>, <span class="number">0</span>, <span class="string">&quot;&quot;</span>) <span class="comment"># 设置起点</span></span><br><span class="line">    <span class="comment"># 存放进队列</span></span><br><span class="line">    queue.append(node)</span><br><span class="line">    <span class="comment"># 由于每次开始移动前先弹出，若后续没步走，则队列为0，结束</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(queue) != <span class="number">0</span>:</span><br><span class="line">        moveNode = queue[<span class="number">0</span>] <span class="comment"># 设置当前移动点为moveNode</span></span><br><span class="line">        <span class="comment"># 开始移动前先弹出</span></span><br><span class="line">        queue.pop(<span class="number">0</span>)				</span><br><span class="line">        moveStr = <span class="built_in">str</span>(moveNode.x) + <span class="string">&quot; &quot;</span>+ <span class="built_in">str</span>(moveNode.y) <span class="comment"># 用于记录当前坐标是否走过</span></span><br><span class="line">        <span class="comment"># 若没走过则进行记录</span></span><br><span class="line">        <span class="keyword">if</span> moveStr <span class="keyword">not</span> <span class="keyword">in</span> visited:</span><br><span class="line">            visited.add(moveStr)</span><br><span class="line">            <span class="keyword">if</span> moveNode.x == row - <span class="number">1</span> <span class="keyword">and</span> moveNode.y == col - <span class="number">1</span>: <span class="comment"># 若到达终点则输出且退出循环</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">len</span>(moveNode.__str__()))	<span class="comment"># 输出步数</span></span><br><span class="line">                <span class="built_in">print</span>(moveNode)	<span class="comment"># 打印路径</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">                </span><br><span class="line">            <span class="keyword">if</span> moveNode.x &lt; row - <span class="number">1</span> :	<span class="comment"># 首先顺序为下,不能超出边界</span></span><br><span class="line">                <span class="comment"># 若没有障碍物，则可以通行</span></span><br><span class="line">                <span class="keyword">if</span> path[moveNode.x + <span class="number">1</span>][moveNode.y] == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># 添加进队列</span></span><br><span class="line">                    queue.append(down(moveNode))</span><br><span class="line">            <span class="keyword">if</span> moveNode.y &gt; <span class="number">0</span>:	<span class="comment"># 第二顺序是左</span></span><br><span class="line">                <span class="keyword">if</span> path[moveNode.x][moveNode.y - <span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">                    queue.append(left(moveNode))</span><br><span class="line">            <span class="keyword">if</span> moveNode.y &lt; col - <span class="number">1</span>: <span class="comment"># 第三顺序是右</span></span><br><span class="line">                <span class="keyword">if</span> path[moveNode.x][moveNode.y + <span class="number">1</span>] == <span class="number">0</span>:</span><br><span class="line">                    queue.append(right(moveNode))</span><br><span class="line">            <span class="keyword">if</span> moveNode.x &gt; <span class="number">0</span>:	<span class="comment"># 最后顺序是上</span></span><br><span class="line">                <span class="keyword">if</span> path[moveNode.x - <span class="number">1</span>][moveNode.y] == <span class="number">0</span>:</span><br><span class="line">                    queue.append(up(moveNode))</span><br></pre></td></tr></table></figure>
<h3 id="迷宫2"><a href="#迷宫2" class="headerlink" title="迷宫2"></a>迷宫2</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>X星球的一处迷宫游乐场建在某个小山坡上。它是由10x10相互连通的小房间组成的。房间的地板上写着一个很大的字母。</p>
<p>我们假设玩家是面朝上坡的方向站立，则：L表示走到左边的房间，R表示走到右边的房间，U表示走到上坡方向的房间，D表示走到下坡方向的房间。</p>
<p>X星球的居民有点懒，不愿意费力思考。他们更喜欢玩运气类的游戏。这个游戏也是如此！</p>
<p>开始的时候，直升机把100名玩家放入一个个小房间内。玩家一定要按照地上的字母移动。</p>
<p>请你计算一下，最后，有多少玩家会走出迷宫?而不是在里边兜圈子。</p>
<p>如果你还没明白游戏规则，可以参看一个简化的4x4迷宫的解说图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/aHR0cHM6Ly9pbWctYmxvZy5jc2RuLm5ldC8yMDE4MDMxNzE0NTk1OTk1" alt></p>
</blockquote>
<p>迷宫地图<code>迷宫2.txt</code>如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UDDLUULRUL</span><br><span class="line">UURLLLRRRU</span><br><span class="line">RRUURLDLRD</span><br><span class="line">RUDDDDUUUU</span><br><span class="line">URUDLLRRUU</span><br><span class="line">DURLRLDLRL</span><br><span class="line">ULLURLLRDU</span><br><span class="line">RDLULLRDDD</span><br><span class="line">UUDDUDUDLL</span><br><span class="line">ULRDLUURRR</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    <span class="keyword">global</span> rows</span><br><span class="line">    <span class="keyword">global</span> cols</span><br><span class="line">    <span class="comment"># 走出迷宫，计数+1</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">or</span> x &gt; rows-<span class="number">1</span> <span class="keyword">or</span> y &lt; <span class="number">0</span> <span class="keyword">or</span> y &gt; cols-<span class="number">1</span>:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 若当前位置未走过，则标记为走过</span></span><br><span class="line">    <span class="keyword">if</span> paths[x][y] == <span class="number">0</span>:</span><br><span class="line">        paths[x][y] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 若已走过，则代表回到原路，走不出迷宫，退出</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 获取方向</span></span><br><span class="line">    direction = dataMap[x][y]</span><br><span class="line">    <span class="comment"># 上</span></span><br><span class="line">    <span class="keyword">if</span> direction == <span class="string">&#x27;U&#x27;</span>:</span><br><span class="line">        dfs(x-<span class="number">1</span>, y)</span><br><span class="line">    <span class="comment"># 下</span></span><br><span class="line">    <span class="keyword">if</span> direction == <span class="string">&#x27;D&#x27;</span>:</span><br><span class="line">        dfs(x+<span class="number">1</span>, y)</span><br><span class="line">    <span class="comment"># 左</span></span><br><span class="line">    <span class="keyword">if</span> direction == <span class="string">&#x27;L&#x27;</span>:</span><br><span class="line">        dfs(x, y-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 右</span></span><br><span class="line">    <span class="keyword">if</span> direction == <span class="string">&#x27;R&#x27;</span>:</span><br><span class="line">        dfs(x, y+<span class="number">1</span>)    </span><br><span class="line"><span class="comment"># 存储地图</span></span><br><span class="line">dataMap = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;迷宫2.txt&#x27;</span>, mode=<span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        dataMap.append(<span class="built_in">list</span>(line.strip()))</span><br><span class="line">rows = <span class="built_in">len</span>(dataMap)</span><br><span class="line">cols = <span class="built_in">len</span>(dataMap[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># 记录走出人数</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">        <span class="comment"># 用于记录走过的轨迹，未走过为0，走过为1</span></span><br><span class="line">        paths = [[<span class="number">0</span>]*cols <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rows)]</span><br><span class="line">        dfs(x, y)</span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="年号字串"><a href="#年号字串" class="headerlink" title="年号字串"></a>年号字串</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明用字母A 对应数字1，B 对应2，以此类推，用Z 对应26。对于27以上的数字，小明用两位或更长位的字符串来对应，例如AA 对应27，AB 对应28，AZ 对应52，LQ 对应329。请问2019 对应的字符串是什么？</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ans = <span class="string">&#x27;&#x27;</span></span><br><span class="line">n = <span class="number">2019</span></span><br><span class="line"><span class="keyword">while</span> n != <span class="number">0</span>:</span><br><span class="line">    t = n % <span class="number">26</span></span><br><span class="line">    n = n // <span class="number">26</span></span><br><span class="line">    ans += <span class="built_in">chr</span>(<span class="number">64</span>+t)</span><br><span class="line"><span class="built_in">print</span>(ans[::-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h3 id="跑步锻炼"><a href="#跑步锻炼" class="headerlink" title="跑步锻炼"></a>跑步锻炼</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小蓝每天都锻炼身体。<br>正常情况下，小蓝每天跑1千米。如果某天是周一或者月初（1日），为了激励自己，小蓝要跑2千米。如果同时是周一或月初，小蓝也是跑2千米。<br>小蓝跑步已经坚持了很长时间，从2000年1月1日周六（含）到2020年10月1日周四（含）。请问这段时间小蓝总共跑步多少千米</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 遍历日期可以用到datetime这个内置库</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 一个是初始日期，一个是结束日期，因为range函数是半开半闭，所以结束日期要比要求的大一天</span></span><br><span class="line">start = datetime.datetime(<span class="number">2000</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">end = datetime.datetime(<span class="number">2020</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line"><span class="comment"># 用结束日期-初始日期就能得到之间相差的天数。也就是遍历次数</span></span><br><span class="line"><span class="keyword">for</span> day <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">int</span>((end -  start).days)):</span><br><span class="line">    <span class="comment"># 再用初始天数，加上每次遍历的天数，就可以得到当前日期</span></span><br><span class="line">    <span class="comment"># 使用timedelta可以很方便的在日期上做天days，小时hour，分钟，秒，毫秒，微妙的时间计算</span></span><br><span class="line">    cur_date = start +  datetime.timedelta(days=day)</span><br><span class="line">    <span class="comment"># 用.strftime()方法可以访问这一天的各种参数</span></span><br><span class="line">    <span class="comment"># 获取天数和星期,为1日或星期1跑2km</span></span><br><span class="line">    <span class="keyword">if</span> (cur_date.strftime(<span class="string">&#x27;%d&#x27;</span>)) == <span class="string">&#x27;01&#x27;</span> <span class="keyword">or</span>  (cur_date.strftime(<span class="string">&#x27;%w&#x27;</span>)) == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">        <span class="built_in">sum</span> += <span class="number">2</span></span><br><span class="line">    <span class="comment"># 否则为1km</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">sum</span> += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>)</span><br></pre></td></tr></table></figure>
<h3 id="平面切分"><a href="#平面切分" class="headerlink" title="平面切分"></a>平面切分</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>平面上有 N条直线，其中第i条直线是 y = Ai*x + B。</p>
<p>请计算这些直线将平面分成了几个部分。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行包含一个整数N。<br>以下N行，每行包含两个整数Ai, Bi。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一个整数代表答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3<br>1 1<br>2 2<br>3 3</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>6</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在同一个平面内，如果添加的每一条直线互不相交，则每添加一条直线，就会增加一个平面；</span></span><br><span class="line"><span class="comment"># 当添加一条直线时，这条直线与当前平面内已有直线每产生一个不同位置的交点时</span></span><br><span class="line"><span class="comment"># 这条直线对平面总数量的贡献会额外增多一个</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">lines = [<span class="built_in">tuple</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment">#这里是去掉重复直线</span></span><br><span class="line">lines = <span class="built_in">list</span>(<span class="built_in">set</span>(lines))</span><br><span class="line">n = <span class="built_in">len</span>(lines)</span><br><span class="line"><span class="comment">#得到两条直线交点，若平行，返回None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getnode</span>(<span class="params">lines1, lines2</span>):</span></span><br><span class="line">    A1 = lines1[<span class="number">0</span>]</span><br><span class="line">    B1 = lines1[<span class="number">1</span>]</span><br><span class="line">    A2 = lines2[<span class="number">0</span>]</span><br><span class="line">    B2 = lines2[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> A1 - A2 == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">    x = (B2 - B1) / (A1 - A2)</span><br><span class="line">    y = A1 * x + B1</span><br><span class="line">    <span class="keyword">return</span> (x, y)</span><br><span class="line"><span class="comment"># 每条线对分割平面的贡献 默认为1，即两两平行</span></span><br><span class="line">ci = [<span class="number">1</span>] * n</span><br><span class="line"><span class="comment"># 交点去重</span></span><br><span class="line">node = <span class="built_in">set</span>()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">    node.clear()</span><br><span class="line">    <span class="comment"># 判断新增加的线与之前线是否有交点</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">        tmp = getnode(lines[i], lines[j])</span><br><span class="line">        <span class="keyword">if</span> tmp == <span class="literal">None</span>: <span class="keyword">continue</span></span><br><span class="line">        node.add(tmp)</span><br><span class="line">    <span class="comment"># 每有个交点贡献多1</span></span><br><span class="line">    ci[i] += <span class="built_in">len</span>(node)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sum</span>(ci) + <span class="number">1</span>) </span><br></pre></td></tr></table></figure>
<h3 id="全球变暖"><a href="#全球变暖" class="headerlink" title="全球变暖"></a>全球变暖</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>你有一张某海域NxN像素的照片，”.”表示海洋、”#”表示陆地，如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.......</span><br><span class="line">.##....</span><br><span class="line">.##....</span><br><span class="line">....##.</span><br><span class="line">..####.</span><br><span class="line">...###.</span><br><span class="line">.......</span><br></pre></td></tr></table></figure>
<p>其中”上下左右”四个方向上连在一起的一片陆地组成一座岛屿。例如上图就有2座岛屿。 </p>
<p>由于全球变暖导致了海面上升，科学家预测未来几十年，岛屿边缘一个像素的范围会被海水淹没。具体来说如果一块陆地像素与海洋相邻(上下左右四个相邻像素中有海洋)，它就会被淹没。 </p>
<p>例如上图中的海域未来会变成如下样子：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.......</span><br><span class="line">.......</span><br><span class="line">.......</span><br><span class="line">.......</span><br><span class="line">....#..</span><br><span class="line">.......</span><br><span class="line">.......</span><br></pre></td></tr></table></figure>
<p>请你计算：依照科学家的预测，照片中有多少岛屿会被完全淹没。  </p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行包含一个整数N。  (1 &lt;= N &lt;= 1000)  </p>
<p>以下N行N列代表一张海域照片。  </p>
<p>照片保证第1行、第1列、第N行、第N列的像素都是海洋。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一个整数表示答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>7<br>…….<br>.##….<br>.##….<br>….##.<br>..####.<br>…###.<br>……. </p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">思路:</span></span><br><span class="line"><span class="string">在接收初始图之后，首先搜索查找初始岛屿数，在找到一个岛屿后，对整个岛屿进行标记，防止重复计数。</span></span><br><span class="line"><span class="string">随后再次进行搜索，如果有四周均为陆地的坐标，则标记此坐标未被淹没。</span></span><br><span class="line"><span class="string">最后查找所有未被淹没的坐标，并将坐标所处的整个岛标记，防止重复计数。</span></span><br><span class="line"><span class="string">初始岛屿数量减去未被淹没岛的数量，即为被淹没的岛的数量。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;例子1：</span></span><br><span class="line"><span class="string">输入：</span></span><br><span class="line"><span class="string">7</span></span><br><span class="line"><span class="string">.......</span></span><br><span class="line"><span class="string">.##....</span></span><br><span class="line"><span class="string">.##....</span></span><br><span class="line"><span class="string">....##.</span></span><br><span class="line"><span class="string">..####.</span></span><br><span class="line"><span class="string">...###.</span></span><br><span class="line"><span class="string">.......</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出：</span></span><br><span class="line"><span class="string">1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;例子2：</span></span><br><span class="line"><span class="string">输入：</span></span><br><span class="line"><span class="string">5</span></span><br><span class="line"><span class="string">.....</span></span><br><span class="line"><span class="string">.#.#.</span></span><br><span class="line"><span class="string">..#..</span></span><br><span class="line"><span class="string">.#.#.</span></span><br><span class="line"><span class="string">.....</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">输出：</span></span><br><span class="line"><span class="string">5</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 用于搜寻岛屿的数量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="comment"># 如果该点是海洋或者已被访问过则跳过</span></span><br><span class="line">    <span class="keyword">if</span> maps[x][y] == <span class="string">&#x27;.&#x27;</span> <span class="keyword">or</span>  maps[x][y] == <span class="string">&#x27;1&#x27;</span>:</span><br><span class="line">	    <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 否则将该点标记为1，代表已访问过</span></span><br><span class="line">    maps[x][y] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line">    <span class="comment"># 搜索该点四周的点</span></span><br><span class="line">    dfs(x+<span class="number">1</span>, y)</span><br><span class="line">    dfs(x-<span class="number">1</span>, y)</span><br><span class="line">    dfs(x, y+<span class="number">1</span>)</span><br><span class="line">    dfs(x, y-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 初始海洋照片</span></span><br><span class="line">maps = [<span class="built_in">list</span>(<span class="built_in">input</span>()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 初始岛屿个数</span></span><br><span class="line">first_num = <span class="number">0</span></span><br><span class="line"><span class="comment"># 剩余岛屿个数</span></span><br><span class="line">res_num = <span class="number">0</span></span><br><span class="line"><span class="comment"># 初始岛屿个数</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> maps[x][y] == <span class="string">&#x27;#&#x27;</span>:</span><br><span class="line">                dfs(x, y)</span><br><span class="line">                first_num += <span class="number">1</span></span><br><span class="line"><span class="comment"># 海域未来模样</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 照片保证第1行、第1列、第N行、第N列的像素都是海洋。</span></span><br><span class="line">        <span class="keyword">if</span> x == <span class="number">0</span> <span class="keyword">or</span> x == n-<span class="number">1</span> <span class="keyword">or</span> y == <span class="number">0</span> <span class="keyword">or</span> y == n-<span class="number">1</span> <span class="keyword">or</span> maps[x][y] == <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 四周都是陆地则标记为2，代表该岛屿不会被淹没</span></span><br><span class="line">        <span class="keyword">if</span> maps[x+<span class="number">1</span>][y] != <span class="string">&#x27;.&#x27;</span> <span class="keyword">and</span> maps[x-<span class="number">1</span>][y] != <span class="string">&#x27;.&#x27;</span> <span class="keyword">and</span> maps[x][y+<span class="number">1</span>] != <span class="string">&#x27;.&#x27;</span> <span class="keyword">and</span> maps[x][y-<span class="number">1</span>] != <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">            maps[x][y] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">        <span class="comment"># 否则标记为3代表将被淹没</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            maps[x][y] = <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="comment"># 最后查找剩余多少个岛屿</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> maps[x][y] == <span class="string">&#x27;2&#x27;</span>:</span><br><span class="line">                dfs(x, y)</span><br><span class="line">                res_num += <span class="number">1</span></span><br><span class="line"><span class="comment"># 输出淹没了多少座岛</span></span><br><span class="line"><span class="built_in">print</span>(first_num - res_num)</span><br></pre></td></tr></table></figure>
<h3 id="蛇形填数"><a href="#蛇形填数" class="headerlink" title="蛇形填数"></a>蛇形填数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>如下图所示，小明用从1开始的正整数“蛇形”填充无限大的矩阵。<br>1 2 6 7 15 …<br>3 5 8 14 …<br>4 9 13 …<br>10 12 …<br>11 …<br>…<br>容易看出矩阵第二行第二列中的数是5。请你计算矩阵中第20行第20列的数是多少？</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">lis = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>)]</span><br><span class="line">num = <span class="number">1</span>  <span class="comment"># 记录当前的数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>):  <span class="comment"># 层数</span></span><br><span class="line">    <span class="keyword">for</span> j, k <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">list</span>(<span class="built_in">range</span>(i)), <span class="built_in">list</span>(<span class="built_in">range</span>(num, num + i))):</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>:  <span class="comment"># 偶数层</span></span><br><span class="line">            lis[j][i-j-<span class="number">1</span>] = k</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            lis[i-j-<span class="number">1</span>][j] = k</span><br><span class="line">    num += i</span><br><span class="line"><span class="built_in">print</span>(lis[<span class="number">19</span>][<span class="number">19</span>])</span><br></pre></td></tr></table></figure>
<h3 id="石子游戏"><a href="#石子游戏" class="headerlink" title="石子游戏"></a>石子游戏</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>石子游戏的规则如下：</p>
<p>地上有n堆石子，每次操作可选取两堆石子（石子个数分别为x和y）并将它们合并，操作的得分记为(x+1)×(y+1)，对地上的石子堆进行操作直到只剩下一堆石子时停止游戏。</p>
<p>请问在整个游戏过程中操作的总得分的最大值是多少？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入数据的第一行为整数n，表示地上的石子堆数；第二行至第n+1行是每堆石子的个数。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>程序输出一行，为游戏总得分的最大值。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>10<br>5105<br>19400<br>27309<br>19892<br>27814<br>25129<br>19272<br>12517<br>25419<br>4053</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>15212676150</p>
</blockquote>
<p>1≤n≤1000，1≤一堆中石子数≤50000</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 堆数</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 每堆石子的个数</span></span><br><span class="line">data = [<span class="built_in">int</span>(<span class="built_in">input</span>()) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 先排序</span></span><br><span class="line">data.sort()</span><br><span class="line"><span class="comment"># 分数</span></span><br><span class="line">result = <span class="number">0</span></span><br><span class="line"><span class="comment"># 贪心算法，每次取最大两堆合并</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(data) != <span class="number">1</span>:</span><br><span class="line">    result += (data[-<span class="number">1</span>] + <span class="number">1</span>) * (data[-<span class="number">2</span>] + <span class="number">1</span>)</span><br><span class="line">    data[-<span class="number">2</span>] += data[-<span class="number">1</span>]</span><br><span class="line">    data.pop(-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="时间转换"><a href="#时间转换" class="headerlink" title="时间转换"></a>时间转换</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定一个以秒为单位的时间t，要求用H:M:S的格式来表示这个时间。H表示时间，M表示分钟，而S表示秒，它们都是整数且没有前导的“0”。例如，若t=0，则应输出是“0:0:0”；若t=3661，则输出“1:1:1”。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入只有一行，是一个整数t（0&lt;=t&lt;=86399）。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出只有一行，是以“H:M:S”的格式所表示的时间，不包括引号。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>0</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>0:0:0</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5436</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1:30:36</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%d:%d:%d&#x27;</span>%(t//<span class="number">3600</span>, t%<span class="number">3600</span>//<span class="number">60</span>, t%<span class="number">3600</span>%<span class="number">60</span>))</span><br></pre></td></tr></table></figure>
<h3 id="数的读法"><a href="#数的读法" class="headerlink" title="数的读法"></a>数的读法</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>Tom教授正在给研究生讲授一门关于基因的课程，有一件事情让他颇为头疼：一条染色体上有成千上万个碱基对，它们从0开始编号，到几百万，几千万，甚至上亿。比如说，在对学生讲解第1234567009号位置上的碱基时，光看着数字是很难准确的念出来的。</p>
<p>所以，他迫切地需要一个系统，然后当他输入1234567009时，会给出相应的念法：十二亿三千四百五十六万七千零九，用汉语拼音表示为shi er yi san qian si bai wu shi liu wan qi qian ling jiu，这样他只需要照着念就可以了。</p>
<p>你的任务是帮他设计这样一个系统：给定一个阿拉伯数字串，你帮他按照中文读写的规范转为汉语拼音字串，相邻的两个音节用一个空格符格开。</p>
<p>注意必须严格按照规范，比如说“10010”读作“yi wan ling yi shi”而不是“yi wan ling shi”，“100000”读作“shi wan”而不是“yi shi wan”，“2000”读作“er qian”而不是“liang qian”。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>有一个数字串，数值大小不超过2,000,000,000。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>是一个由小写英文字母，逗号和空格组成的字符串，表示该数的英文读法。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>1234567009</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>shi er yi san qian si bai wu shi liu wan qi qian ling jiu</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">input</span>()</span><br><span class="line"><span class="comment"># 数值读法</span></span><br><span class="line">pin_yin = &#123;<span class="string">&#x27;0&#x27;</span>: <span class="string">&#x27;ling&#x27;</span>, <span class="string">&#x27;1&#x27;</span>: <span class="string">&#x27;yi&#x27;</span>, <span class="string">&#x27;2&#x27;</span>: <span class="string">&#x27;er&#x27;</span>, <span class="string">&#x27;3&#x27;</span>: <span class="string">&#x27;san&#x27;</span>, <span class="string">&#x27;4&#x27;</span>: <span class="string">&#x27;si&#x27;</span>, <span class="string">&#x27;5&#x27;</span>: <span class="string">&#x27;wu&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;6&#x27;</span>: <span class="string">&#x27;liu&#x27;</span>, <span class="string">&#x27;7&#x27;</span>: <span class="string">&#x27;qi&#x27;</span>, <span class="string">&#x27;8&#x27;</span>: <span class="string">&#x27;ba&#x27;</span>, <span class="string">&#x27;9&#x27;</span>: <span class="string">&#x27;jiu&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 特殊位置读法</span></span><br><span class="line">pin_yin_2 = &#123;<span class="number">0</span>: <span class="string">&#x27;&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;shi&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;bai&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;qian&#x27;</span>, <span class="number">4</span>: <span class="string">&#x27;wan&#x27;</span>, <span class="number">5</span>: <span class="string">&#x27;shi&#x27;</span>,</span><br><span class="line">             <span class="number">6</span>: <span class="string">&#x27;bai&#x27;</span>, <span class="number">7</span>: <span class="string">&#x27;qian&#x27;</span>, <span class="number">8</span>: <span class="string">&#x27;yi&#x27;</span>, <span class="number">9</span>: <span class="string">&#x27;shi&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 个位的索引</span></span><br><span class="line">l = <span class="built_in">len</span>(n) - <span class="number">1</span></span><br><span class="line"><span class="comment"># 从最高位开始遍历</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(n)):</span><br><span class="line">    <span class="comment"># 当前位的值</span></span><br><span class="line">    cur = <span class="built_in">int</span>(n[i])</span><br><span class="line">    <span class="comment"># 当前位的值不为0时的读法</span></span><br><span class="line">    <span class="keyword">if</span> cur != <span class="number">0</span>:  </span><br><span class="line">        <span class="comment"># 个位与当前位索引相差1,、5、9，即在十位，十万位，十亿位置且开头为1时</span></span><br><span class="line">        <span class="comment"># 不读出1</span></span><br><span class="line">        <span class="comment"># 如10， shi ; 100000, shi wan; 1000000000, shi yi</span></span><br><span class="line">        <span class="keyword">if</span> cur == <span class="number">1</span> <span class="keyword">and</span> i == <span class="number">0</span> <span class="keyword">and</span> (l - i == <span class="number">1</span> <span class="keyword">or</span> l - i == <span class="number">5</span> <span class="keyword">or</span> l - i == <span class="number">9</span>):</span><br><span class="line">            <span class="built_in">print</span>(pin_yin_2[l - i], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 输出当前数的读法</span></span><br><span class="line">        <span class="built_in">print</span>(pin_yin[n[i]], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="comment"># 输出指定位置的读法</span></span><br><span class="line">        <span class="built_in">print</span>(pin_yin_2[l - i], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="comment"># 处理当前位的值为0的读法问题</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        <span class="comment"># 如果此0是在万位或亿位，则读出万或亿</span></span><br><span class="line">        <span class="comment"># 如shi wan, shi yi</span></span><br><span class="line">        <span class="keyword">if</span> l - i == <span class="number">4</span> <span class="keyword">or</span> l - i == <span class="number">8</span>:  </span><br><span class="line">            <span class="built_in">print</span>(pin_yin_2[l - i], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        <span class="comment"># 如果后一位仍然为0，或者，当前是最后一位，则不读此0</span></span><br><span class="line">        <span class="keyword">elif</span> (i &lt; l <span class="keyword">and</span> n[i + <span class="number">1</span>] == <span class="string">&#x27;0&#x27;</span>) <span class="keyword">or</span> i == l:  </span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则才读出这个零</span></span><br><span class="line">            <span class="built_in">print</span>(pin_yin[<span class="string">&#x27;0&#x27;</span>], end=<span class="string">&#x27; &#x27;</span>)  </span><br></pre></td></tr></table></figure>
<h3 id="数的分解"><a href="#数的分解" class="headerlink" title="数的分解"></a>数的分解</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>把 2019 分解成 3 个各不相同的正整数之和，并且要求每个正整数都不包含数字 2 和 4，一共有多少种不同的分解方法？注意交换 3 个整数的顺序被视为同一种方法，例如 1000+1001+18 和 1001+1000+18 被视为同一种。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 因为三个数要各不相同 i从小到大 j从小到大并比i大，则为了保证不重,k也因比j大</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2019</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(i) <span class="keyword">and</span> <span class="string">&#x27;4&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(i):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="number">2019</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(j) <span class="keyword">and</span> <span class="string">&#x27;4&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(j):</span><br><span class="line">                k = <span class="number">2019</span> - i - j</span><br><span class="line">                <span class="keyword">if</span> k &gt; j <span class="keyword">and</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(k) <span class="keyword">and</span> <span class="string">&#x27;4&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="built_in">str</span>(k):</span><br><span class="line">                    count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="数列求值"><a href="#数列求值" class="headerlink" title="数列求值"></a>数列求值</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>本题为填空题，只需要算出结果后，在代码中使用输出语句将所填结果输出即可。</p>
<p>给定数列 1, 1, 1, 3, 5, 9, 17,⋯，从第 4 项开始，每项都是前 3 项的和。求第 20190324 项的最后 4 位数字。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">f0=<span class="number">1</span></span><br><span class="line">f1=<span class="number">1</span></span><br><span class="line">f2=<span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, <span class="number">20190324</span>):</span><br><span class="line">    result = (f0 + f1 + f2) % <span class="number">10000</span></span><br><span class="line">    f0 = f1</span><br><span class="line">    f1 = f2</span><br><span class="line">    f2 = result</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="数位递增的数"><a href="#数位递增的数" class="headerlink" title="数位递增的数"></a>数位递增的数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>一个正整数如果任何一个数位不大于右边相邻的数位，则称为一个数位递增的数，例如1135是一个数位递增的数，而1024不是一个数位递增的数。<br>给定正整数 n，请问在整数 1 至 n 中有多少个数位递增的数？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含一个整数n。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行包含一个整数，表示答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>30</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>26</p>
</blockquote>
<p>对于 40% 的评测用例，1 &lt;= n &lt;= 1000。<br>对于 80% 的评测用例，1 &lt;= n &lt;= 100000。<br>对于所有评测用例，1 &lt;= n &lt;= 1000000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">    num = <span class="built_in">str</span>(i)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(num) == <span class="number">1</span>:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        flag = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> num[j] &gt; num[j+<span class="number">1</span>]:</span><br><span class="line">                flag = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="数字9"><a href="#数字9" class="headerlink" title="数字9"></a>数字9</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>在1至2019中，有多少个数的数位中包含数字9？</p>
<p>注意，有的数中的数位中包含多个9，这个数只算一次。例如，1999这个数包含数字9，在计算只是算一个数。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2020</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;9&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(num):</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="数字三角形"><a href="#数字三角形" class="headerlink" title="数字三角形"></a>数字三角形</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/tri.png" alt></p>
<p>图为一个数字三角形。 请编一个程序计算从顶至底的某处的一条路径，使该路径所经过的数字的总和最大。<br>● 每一步可沿左斜线向下或右斜线向下走；<br>● 1＜三角形行数≤100；<br>● 三角形中的数字为整数0，1，…99；</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>首先读到的是三角形的行数。</p>
<p>接下来描述整个三角形</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>最大总和（整数）</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5<br>7<br>3 8<br>8 1 0<br>2 7 4 4<br>4 5 2 6 5</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>30</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pathMax</span>(<span class="params">path, x, y, leftNum, rightNum</span>):</span></span><br><span class="line">    <span class="keyword">global</span> n</span><br><span class="line">    <span class="comment"># 添加当前路径</span></span><br><span class="line">    path.append(pyramid[x][y])</span><br><span class="line">    <span class="comment"># 如果走到底返回</span></span><br><span class="line">    <span class="keyword">if</span> x == n-<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 左下和右下次数相差不超过1，记录路径</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(leftNum - rightNum) &lt;= <span class="number">1</span>:</span><br><span class="line">            paths.append(path)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    pleft = []</span><br><span class="line">    pright = []</span><br><span class="line">    pleft += path</span><br><span class="line">    pright += path</span><br><span class="line">    <span class="comment"># 左下走</span></span><br><span class="line">    pathMax(pleft, x+<span class="number">1</span>, y, leftNum+<span class="number">1</span>, rightNum)</span><br><span class="line">    <span class="comment"># 右下走</span></span><br><span class="line">    pathMax(pright, x+<span class="number">1</span>, y+<span class="number">1</span>, leftNum, rightNum+<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">pyramid = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 用于所有可能路径</span></span><br><span class="line">paths = []</span><br><span class="line">pathMax([], <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="comment"># 返回最大路径</span></span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> paths:</span><br><span class="line">    tmp = <span class="built_in">sum</span>(path)</span><br><span class="line">    <span class="keyword">if</span> tmp &gt; res:</span><br><span class="line">        res = tmp</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="特别数的和"><a href="#特别数的和" class="headerlink" title="特别数的和"></a>特别数的和</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明对数位中含有2 、 0 、 1 、 9 的数字很感兴趣（不包括前导 0 ），在 1 到 40 中这样的数包括 1 、 2 、 9 、 10 至 32 、 39 和 40 ，共 28 个，他们的和是 574 。请问，在1 到 n 中，所有这样的数的和是多少？</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行包含一个整数n。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行，包含一个整数，表示满足条件的数的和。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>40</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>574</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">int</span>(<span class="built_in">input</span>())+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;2&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(i) <span class="keyword">or</span> <span class="string">&#x27;0&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(i) <span class="keyword">or</span> <span class="string">&#x27;1&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(i) <span class="keyword">or</span> <span class="string">&#x27;9&#x27;</span> <span class="keyword">in</span> <span class="built_in">str</span>(i):</span><br><span class="line">        res += i</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="特殊回文数"><a href="#特殊回文数" class="headerlink" title="特殊回文数"></a>特殊回文数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>123321是一个非常特殊的数，它从左边读和从右边读是一样的。</p>
<p>输入一个正整数n， 编程求所有这样的五位和六位十进制数，满足各位数字之和等于n 。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行，包含一个正整数n。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>按从小到大的顺序输出满足条件的整数，每个整数占一行。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>52</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>899998<br>989989<br>998899</p>
</blockquote>
<p>1&lt;=n&lt;=54</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">start = time.perf_counter()</span><br><span class="line"><span class="comment">#6位数，n一定为偶数</span></span><br><span class="line"><span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">0</span>):</span><br><span class="line">    s = n // <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> s &lt;= <span class="number">27</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">                <span class="keyword">if</span> (s - i - j) &lt; <span class="number">10</span> <span class="keyword">and</span> (s - i - j) &gt;= <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="built_in">int</span>(<span class="built_in">str</span>(i)+<span class="built_in">str</span>(j)+<span class="built_in">str</span>(s-i-j)*<span class="number">2</span>+<span class="built_in">str</span>(j)+<span class="built_in">str</span>(i)))</span><br><span class="line"><span class="comment">#5位数，n减去中间那个数一定为偶数  </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> (n - i) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        s = (n - i) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">if</span> s &lt;= <span class="number">18</span>:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">                <span class="keyword">if</span> (s - j) &gt;= <span class="number">0</span> <span class="keyword">and</span> (s - j) &lt; <span class="number">10</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="built_in">int</span>(<span class="built_in">str</span>(j)+<span class="built_in">str</span>(s-j)+<span class="built_in">str</span>(i)+<span class="built_in">str</span>(s-j)+<span class="built_in">str</span>(j)))</span><br><span class="line">               </span><br><span class="line">end = time.perf_counter()</span><br><span class="line"><span class="built_in">print</span>(end - start)</span><br></pre></td></tr></table></figure>
<h3 id="完美的代价"><a href="#完美的代价" class="headerlink" title="完美的代价"></a>完美的代价</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>回文串，是一种特殊的字符串，它从左往右读和从右往左读是一样的。小龙龙认为回文串才是完美的。现在给你一个串，它不一定是回文的，请你计算最少的交换次数使得该串变成一个完美的回文串。</p>
<p>交换的定义是：交换两个相邻的字符，例如mamad</p>
<p>第一次交换 ad : mamda</p>
<p>第二次交换 md : madma</p>
<p>第三次交换 ma : madam (回文！完美！)</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行是一个整数N，表示接下来的字符串的长度(N &lt;= 8000)<br>第二行是一个字符串，长度为N.只包含小写字母</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>如果可能，输出最少的交换次数。<br>否则输出Impossible</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5<br>mamad</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = <span class="built_in">list</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 统计出现奇数次的字符的个数</span></span><br><span class="line">flag = <span class="number">0</span></span><br><span class="line"><span class="comment"># 交换次数</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 由于最后形成回文，只需遍历一半即可</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n//<span class="number">2</span>):</span><br><span class="line">    <span class="comment"># 从另一半寻找是否有字符与之相等</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>, i - <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 没找到</span></span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            <span class="comment"># 记录奇数个数的字符</span></span><br><span class="line">            flag += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 如果有一个字符出现的次数是奇数次数，而且n是偶数，那么不可能构成回文</span></span><br><span class="line">            <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">and</span> flag == <span class="number">1</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Impossible&#x27;</span>)</span><br><span class="line">                exit()</span><br><span class="line">            <span class="comment"># 如果奇数次数的字符出现两个以上，那么不可能构成回文</span></span><br><span class="line">            <span class="keyword">if</span>  flag &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Impossible&#x27;</span>)</span><br><span class="line">                exit() </span><br><span class="line">        <span class="comment"># 若找到</span></span><br><span class="line">        <span class="keyword">elif</span> arr[j] == arr[i]:</span><br><span class="line">            <span class="comment"># 一直将其交换到对应位置</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(j, n-<span class="number">1</span>-i):</span><br><span class="line">                arr[j], arr[j+<span class="number">1</span>] = arr[j+<span class="number">1</span>], arr[j]</span><br><span class="line">                <span class="comment"># 记录交换次数</span></span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="完全二叉树的权值"><a href="#完全二叉树的权值" class="headerlink" title="完全二叉树的权值"></a>完全二叉树的权值</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定一棵包含 N 个节点的完全二叉树，树上每个节点都有一个权值，按从上到下、从左到右的顺序依次是 A1, A2, · · · AN，如下图所示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/image-20220302170648228.png" alt></p>
<p>现在小明要把相同深度的节点的权值加在一起，他想知道哪个深度的节点权值之和最大？如果有多个深度的权值和同为最大，请你输出其中最小的深度。</p>
<p>注：根的深度是 1。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行包含一个整数 N。<br>第二行包含 N 个整数 A1, A2, · · · AN 。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数代表答案。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>7<br>1 6 5 4 3 2 1</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>2</p>
</blockquote>
<p>对于所有评测用例， 1 ≤ N ≤ 100000， −100000 ≤ Ai ≤ 100000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">data = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split()))</span><br><span class="line"><span class="comment"># 二叉树深度</span></span><br><span class="line">deep = <span class="number">1</span></span><br><span class="line"><span class="comment"># 用于记录权值最大的深度</span></span><br><span class="line">max_deep = deep</span><br><span class="line"><span class="comment"># 记录最大权重</span></span><br><span class="line">max_sum = <span class="number">0</span></span><br><span class="line"><span class="comment"># 深度为deep的完全二叉树节点个数为(2^n)-1</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">2</span> ** deep - <span class="number">1</span> &lt;= n:</span><br><span class="line">    <span class="comment"># 当前深度的节点个数 = 当前深度完全二叉树的总个数-上层深度完全二叉树的总个数</span></span><br><span class="line">    data_sum = <span class="built_in">sum</span>(data[<span class="number">2</span> ** (deep - <span class="number">1</span>) - <span class="number">1</span>: <span class="number">2</span> ** deep - <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 记录最大权重所在深度</span></span><br><span class="line">    <span class="keyword">if</span> max_sum &lt; data_sum:</span><br><span class="line">        max_sum = data_sum</span><br><span class="line">        max_deep = deep</span><br><span class="line">    deep += <span class="number">1</span></span><br><span class="line"><span class="comment"># 输出最大权重所在深度</span></span><br><span class="line"><span class="built_in">print</span>(max_deep)</span><br></pre></td></tr></table></figure>
<h3 id="晚会节目单"><a href="#晚会节目单" class="headerlink" title="晚会节目单"></a>晚会节目单</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明要组织一台晚会，总共准备了 n 个节目。然后晚会的时间有限，他只能最终选择其中的 m 个节目。</p>
<p>这 n个节目是按照小明设想的顺序给定的，顺序不能改变。</p>
<p>小明发现，观众对于晚会的喜欢程度与前几个节目的好看程度有非常大的关系，他希望选出的第一个节目尽可能好看，在此前提下希望第二个节目尽可能好看，依次类推。</p>
<p>小明给每个节目定义了一个好看值，请你帮助小明选择出 m 个节目，满足他的要求。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含两个整数 n, m ，表示节目的数量和要选择的数量。<br>第二行包含 n 个整数，依次为每个节目的好看值。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行包含 m 个整数，为选出的节目的好看值。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5 3<br>3 1 2 5 4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3 5 4</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>选择了第1, 4, 5个节目。</p>
</blockquote>
<p>对于 30% 的评测用例，1 &lt;= n &lt;= 20；<br>对于 60% 的评测用例，1 &lt;= n &lt;= 100；<br>对于所有评测用例，1 &lt;= n&lt;= 100000，0 &lt;= 节目的好看值 &lt;= 100000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n, m = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">tvlist = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split()))</span><br><span class="line"><span class="comment"># 选最大</span></span><br><span class="line">res = []</span><br><span class="line"><span class="comment"># 开始索引</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="comment"># 当前个数为0</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 直到选满m个</span></span><br><span class="line"><span class="keyword">while</span> count &lt; m:</span><br><span class="line">    <span class="comment"># 从选出的值对应的索引序号后开始到n - m + count中选</span></span><br><span class="line">    res.append(<span class="built_in">max</span>(tvlist[index: n - m + count + <span class="number">1</span>]))</span><br><span class="line">    index = tvlist[index: n - m + count + <span class="number">1</span>].index(res[count]) + index + <span class="number">1</span></span><br><span class="line">    <span class="comment"># 计数</span></span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="built_in">print</span>(*res)</span><br><span class="line"><span class="comment"># n,m =map(int,input().split())</span></span><br><span class="line"><span class="comment"># tvlist = list(map(int, input().split()))</span></span><br><span class="line"><span class="comment"># maxTv= tvlist.copy()</span></span><br><span class="line"><span class="comment"># maxTv.sort(reverse=True)</span></span><br><span class="line"><span class="comment"># maxTv = maxTv[:m]</span></span><br><span class="line"><span class="comment"># count = 0</span></span><br><span class="line"><span class="comment"># for tv in tvlist:</span></span><br><span class="line"><span class="comment">#     if tv in maxTv:</span></span><br><span class="line"><span class="comment">#         print(tv, end=&#x27; &#x27;)</span></span><br><span class="line"><span class="comment">#         count += 1</span></span><br><span class="line"><span class="comment">#         if count == m:</span></span><br><span class="line"><span class="comment">#             break</span></span><br></pre></td></tr></table></figure>
<h3 id="芯片测试"><a href="#芯片测试" class="headerlink" title="芯片测试"></a>芯片测试</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>有n（2≤n≤20）块芯片，有好有坏，已知好芯片比坏芯片多。</p>
<p>每个芯片都能用来测试其他芯片。用好芯片测试其他芯片时，能正确给出被测试芯片是好还是坏。而用坏芯片测试其他芯片时，会随机给出好或是坏的测试结果（即此结果与被测试芯片实际的好坏无关）。</p>
<p>给出所有芯片的测试结果，问哪些芯片是好芯片。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入数据第一行为一个整数n，表示芯片个数。<br>第二行到第n+1行为n*n的一张表，每行n个数据。表中的每个数据为0或1，在这n行中的第i行第j列（1≤i, j≤n）的数据表示用第i块芯片测试第j块芯片时得到的测试结果，1表示好，0表示坏，i=j时一律为1（并不表示该芯片对本身的测试结果。芯片不能对本身进行测试）。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>按从小到大的顺序输出所有好芯片的编号</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>3<br>1 0 1<br>0 1 0<br>1 0 1</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1 3</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    arr_ = <span class="built_in">input</span>().split()</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        arr[i].append(<span class="built_in">int</span>(arr_[j]))</span><br><span class="line"><span class="comment"># 既然好芯片比坏芯片多，那么我们只需记录每一列0的个数就行了，若个数超过n/2，则此芯片为坏芯片</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> arr[i][j] == <span class="number">0</span>:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count &gt; n / <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="built_in">print</span>(j+<span class="number">1</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="幸运顾客"><a href="#幸运顾客" class="headerlink" title="幸运顾客"></a>幸运顾客</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>为了吸引更多的顾客，某商场决定推行有奖抽彩活动。“本商场每日将产生一名幸运顾客，凡购买30元以上商品者均有机会获得本商场提供的一份精美礼品。”该商场的幸运顾客产生方式十分奇特：每位顾客可至抽奖台抽取一个幸运号码，该商场在抽奖活动推出的第i天将从所有顾客中（包括不在本日购物满30元者）挑出幸运号第i小的顾客作为当日的幸运顾客。该商场的商品本就价廉物美，自从有奖活动推出后，顾客更是络绎不绝，因此急需你编写一个程序，为他解决幸运顾客的产生问题。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第1行一个整数N，表示命令数。<br>第2~N+1行，每行一个数，表示命令。如果x&gt;=0，表示有一顾客抽取了号码x；如果x=-1，表示傍晚抽取该日的幸运号码。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>对应各命令-1输出幸运号码；每行一个号码。(两个相同的幸运号看作两个号码)</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>6<br>3<br>4<br>-1<br>-1<br>3<br>-1</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3<br>4<br>4</p>
</blockquote>
<p>共10组数据。<br>对100%的数据，N=$10^6$所有命令为-1或int范围内的非负数，前i的命令中-1的数量不超过[i/2]（向下取整）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 存放号码</span></span><br><span class="line">consumer = []</span><br><span class="line"><span class="comment"># 统计-1的个数</span></span><br><span class="line">ans = <span class="number">0</span></span><br><span class="line"><span class="comment"># 存放结果</span></span><br><span class="line">res = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    data = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">    <span class="keyword">if</span> data != -<span class="number">1</span>:</span><br><span class="line">        consumer.append(data)</span><br><span class="line">        <span class="comment"># 排序</span></span><br><span class="line">        consumer.sort()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        res.append(consumer[ans])</span><br><span class="line">        ans += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="序列计数"><a href="#序列计数" class="headerlink" title="序列计数"></a>序列计数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明想知道，满足以下条件的正整数序列的数量：</p>
<ol>
<li><p>第一项为n；</p>
</li>
<li><p>第二项不超过n；</p>
</li>
<li><p>从第三项开始，每一项小于前两项的差的绝对值。</p>
<p>请计算，对于给定的n，有多少种满足条件的序列。</p>
</li>
</ol>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行包含一个整数n。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一个整数，表示答案。答案可能很大，请输出答案除以10000的余数。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>7</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>以下是满足条件的序列：<br>4 1<br>4 1 1<br>4 1 2<br>4 2<br>4 2 1<br>4 3<br>4 4</p>
</blockquote>
<p>对于 20% 的评测用例，1 &lt;= n &lt;= 5；<br>对于 50% 的评测用例，1 &lt;= n &lt;= 10；<br>对于 80% 的评测用例，1 &lt;= n &lt;= 100；<br>对于所有评测用例，1 &lt;= n &lt;= 1000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用于派生下一项</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">next_item</span>(<span class="params">res</span>):</span></span><br><span class="line">    new_res = []</span><br><span class="line">    <span class="comment"># 当前序列最后两项的绝对差</span></span><br><span class="line">    ab = <span class="built_in">abs</span>(res[-<span class="number">2</span>] - res[-<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 若能派生出下一项</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, ab):</span><br><span class="line">        <span class="comment"># 则新序列为当前序列加下一项</span></span><br><span class="line">        new_res.append(res + [i])</span><br><span class="line">    <span class="keyword">return</span> new_res</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一项</span></span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 用于记录序列</span></span><br><span class="line">res_list = []</span><br><span class="line"><span class="comment"># 用于记录可派生项</span></span><br><span class="line">accept_list = []</span><br><span class="line"><span class="comment"># 用于循环</span></span><br><span class="line">temp_list = []</span><br><span class="line"><span class="comment"># 计数</span></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 第二项</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 记录此时的第一项和第二项</span></span><br><span class="line">    res_list.append([n, i])</span><br><span class="line"><span class="comment"># 记录此时的序列用于循环</span></span><br><span class="line">temp_list += res_list</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(temp_list) &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="keyword">for</span> res <span class="keyword">in</span> temp_list:  <span class="comment"># 判断temp_list的每一项</span></span><br><span class="line">        next_ = next_item(res)  <span class="comment"># 判断这项可以再派生下一项</span></span><br><span class="line">        <span class="comment"># 添加记录到accept_list</span></span><br><span class="line">        accept_list += next_</span><br><span class="line">    temp_list.clear()  <span class="comment"># 清空</span></span><br><span class="line">    res_list = accept_list + res_list  <span class="comment"># 把新派生出的项加到res_list，res_list此时已包含两项加新派生的项</span></span><br><span class="line">    temp_list += accept_list  <span class="comment"># 新派生的项加到temp_list进行下次循环用</span></span><br><span class="line">    accept_list.clear() <span class="comment"># 清空</span></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> res_list:</span><br><span class="line">    <span class="built_in">print</span>(i, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(res_list) % <span class="number">10000</span>)</span><br></pre></td></tr></table></figure>
<h3 id="寻找2020"><a href="#寻找2020" class="headerlink" title="寻找2020"></a>寻找2020</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小蓝有一个数字矩阵，里面只包含数字 0 和 2。小蓝很喜欢 2020，他想找到这个数字矩阵中有多少个 2020 。</p>
<p>小蓝只关注三种构成 2020 的方式：<br>• 同一行里面连续四个字符从左到右构成 2020。<br>• 同一列里面连续四个字符从上到下构成 2020。<br>• 在一条从左上到右下的斜线上连续四个字符，从左上到右下构成 2020。</p>
<p>例如，对于下面的矩阵：<br>220000<br>000000<br>002202<br>000000<br>000022<br>002020<br>一共有 5 个 2020。其中 1 个是在同一行里的，1 个是在同一列里的，3 个是斜线上的。</p>
<p>小蓝的矩阵比上面的矩阵要大，由于太大了，他只好将这个矩阵放在了一个文件里面，在试题目录下有一个文件<code>2020.txt</code>，里面给出了小蓝的矩阵。</p>
<p>请帮助小蓝确定在他的矩阵中有多少个 2020。</p>
</blockquote>
<p><code>2020.txt</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">220000</span><br><span class="line">000000</span><br><span class="line">002202</span><br><span class="line">000000</span><br><span class="line">000022</span><br><span class="line">002020</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums, result=[], <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;2020.txt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines():</span><br><span class="line">        nums.append(<span class="built_in">list</span>(line.strip()))</span><br><span class="line">move=[[<span class="number">0</span>, <span class="number">1</span>],[<span class="number">1</span>, <span class="number">0</span>],[<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums[<span class="number">0</span>])):       </span><br><span class="line">        <span class="keyword">for</span> xx, yy <span class="keyword">in</span> move:</span><br><span class="line">            num = <span class="built_in">str</span>(nums[x][y])</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">                x_, y_= x + xx * m, y + yy * m</span><br><span class="line">                <span class="keyword">if</span> <span class="number">0</span> &lt;= x_ &lt; <span class="built_in">len</span>(nums) <span class="keyword">and</span> <span class="number">0</span> &lt;= y_ &lt;<span class="built_in">len</span>(nums[<span class="number">0</span>]):</span><br><span class="line">                    num += <span class="built_in">str</span>(nums[x_][y_])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> num == <span class="string">&#x27;2020&#x27;</span>:</span><br><span class="line">                result += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h3 id="杨辉三角"><a href="#杨辉三角" class="headerlink" title="杨辉三角"></a>杨辉三角</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>杨辉三角形又称Pascal三角形，它的一个重要性质是：三角形中的每个数字等于它两肩上的数字相加。</p>
<p>下面给出了杨辉三角形的前4行：</p>
<p>1</p>
<p>1 1</p>
<p>1 2 1</p>
<p>1 3 3 1</p>
<p>给出n，输出它的前n行。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入包含一个数n。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出杨辉三角形的前n行。每一行从这一行的第一个数开始依次输出，中间使用一个空格分隔。请不要在前面输出多余的空格。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1<br>1 1<br>1 2 1<br>1 3 3 1</p>
</blockquote>
<p>1 &lt;= n &lt;= 34。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">triangle_yang = [[<span class="number">0</span> <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">triangle_yang[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">    <span class="comment"># 每一行的第一列和最后一列为1</span></span><br><span class="line">    triangle_yang[i][<span class="number">0</span>], triangle_yang[i][-<span class="number">1</span>] = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">    <span class="comment"># 其余为两肩数值之和</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, i):</span><br><span class="line">        triangle_yang[i][j] = triangle_yang[i-<span class="number">1</span>][j-<span class="number">1</span>] + triangle_yang[i-<span class="number">1</span>][j]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 输出杨辉三角</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(triangle_yang[i][j], end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>
<h3 id="叶节点数"><a href="#叶节点数" class="headerlink" title="叶节点数"></a>叶节点数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>一棵包含有2019个结点的二叉树，最多包含多少个叶结点？</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># n为深度</span></span><br><span class="line">n = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> <span class="number">2</span> ** n - <span class="number">1</span> &lt; <span class="number">2019</span>:</span><br><span class="line">    n += <span class="number">1</span></span><br><span class="line"><span class="comment"># 2019节点多于深度为n-1的二叉树，小于深度为n的二叉树，通过普通的数学计算，可得最后层的叶子节点数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="number">2</span> ** n - <span class="number">1</span> - (<span class="number">2</span> ** (n - <span class="number">1</span>) - <span class="number">1</span>) - (<span class="number">2</span> ** n - <span class="number">1</span> - <span class="number">2019</span>) // <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h3 id="音节判断"><a href="#音节判断" class="headerlink" title="音节判断"></a>音节判断</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明对类似于 hello 这种单词非常感兴趣，这种单词可以正好分为四段，第一段由一个或多个辅音字母组成，第二段由一个或多个元音字母组成，第三段由一个或多个辅音字母组成，第四段由一个或多个元音字母组成。</p>
<p>给定一个单词，请判断这个单词是否也是这种单词，如果是请输出yes，否则请输出no。</p>
<p>元音字母包括 a, e, i, o, u，共五个，其他均为辅音字母。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行，包含一个单词，单词中只包含小写英文字母。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出答案，或者为yes，或者为no。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>lanqiao</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>yes</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>world</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>no</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str1 = <span class="built_in">input</span>()</span><br><span class="line">alpha = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;u&#x27;</span>]</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line">flag = <span class="literal">True</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str1)):</span><br><span class="line">    <span class="keyword">if</span> str1[i] <span class="keyword">in</span> alpha <span class="keyword">and</span> str1[i-<span class="number">1</span>] <span class="keyword">not</span> <span class="keyword">in</span> alpha:</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">2</span> <span class="keyword">and</span> str1[i] <span class="keyword">not</span> <span class="keyword">in</span> alpha:</span><br><span class="line">        flag = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span>(flag <span class="keyword">and</span> count == <span class="number">2</span>): </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;yes&#x27;</span>) </span><br><span class="line"><span class="keyword">else</span>: </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;no&#x27;</span>) </span><br></pre></td></tr></table></figure>
<h3 id="预测身高"><a href="#预测身高" class="headerlink" title="预测身高"></a>预测身高</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>生理卫生老师在课堂上娓娓道来：<br>你能看见你未来的样子吗？显然不能。但你能预测自己成年后的身高，有公式：<br>男孩成人后身高=（父亲身高+母亲身高）/ 2 * 1.08<br>女孩成人后身高=(父亲身高*0.923+母亲身高）/ 2<br>数学老师听见了，回头说：这是大样本统计拟合公式，准确性不错。<br>生物老师听见了，回头说：结果不是绝对的，影响身高的因素很多，比如营养、疾病、体育锻炼、睡眠、情绪、环境因素等。<br>老师们齐回头，看见同学们都正在预测自己的身高。<br>毛老师见此情形，推推眼镜说：何必手算，编程又快又简单…<br>约定：<br>身高的单位用米表示，所以自然是会有小数的。<br>男性用整数1表示，女性用整数0表示。<br>预测的身高保留三位小数</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>用空格分开的三个数，整数 小数 小数<br>分别表示：性别 父亲身高 母亲身高</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一个小数，表示根据上述表示预测的身高（保留三位小数）</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>1 1.91 1.70</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1.949</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>0 1.00 2.077</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>1.500</p>
</blockquote>
<p>父母身高范围（0，3]<br>时间限制1.0秒</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sex, dad, mom = <span class="built_in">map</span>(<span class="built_in">float</span>, <span class="built_in">input</span>().split())</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">int</span>(sex) == <span class="number">0</span>:</span><br><span class="line">    height = (dad * <span class="number">0.923</span> + mom) / <span class="number">2</span> </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    height = (dad + mom) / <span class="number">2</span>*<span class="number">1.08</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;%.3f&#x27;</span> % height)</span><br></pre></td></tr></table></figure>
<h3 id="约数个数"><a href="#约数个数" class="headerlink" title="约数个数"></a>约数个数</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>1200000有多少个约数（只计算正约数）。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="comment"># 根据对称，只要到根号即可</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">int</span>(<span class="built_in">float</span>(<span class="number">1200000</span>)**<span class="number">0.5</span>) + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="number">1200000</span> % i == <span class="number">0</span>:</span><br><span class="line">        count += <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(count)</span><br></pre></td></tr></table></figure>
<h3 id="长草"><a href="#长草" class="headerlink" title="长草"></a>长草</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小明有一块空地，他将这块空地划分为 n 行 m 列的小块，每行和每列的长度都为 1。<br>小明选了其中的一些小块空地，种上了草，其他小块仍然保持是空地。<br>这些草长得很快，每个月，草都会向外长出一些，如果一个小块种了草，则它将向自己的上、下、左、右四小块空地扩展，这四小块空地都将变为有草的小块。<br>请告诉小明，k 个月后空地上哪些地方有草。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含两个整数 n, m。<br>接下来 n 行，每行包含 m 个字母，表示初始的空地状态，字母之间没有空格。如果为小数点，表示为空地，如果字母为 g，表示种了草。<br>接下来包含一个整数 k。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出 n 行，每行包含 m 个字母，表示 k 个月后空地的状态。如果为小数点，表示为空地，如果字母为 g，表示长了草。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>4 5<br>.g…<br>…..<br>..g..<br>…..<br>2</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>gggg.<br>gggg.<br>ggggg<br>.ggg.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grow</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">for</span> offset <span class="keyword">in</span> R:</span><br><span class="line">        x1 = x + offset[<span class="number">0</span>]</span><br><span class="line">        y1 = y + offset[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> y1 &gt;= <span class="number">0</span> <span class="keyword">and</span> y1 &lt; m <span class="keyword">and</span> x1 &gt;= <span class="number">0</span> <span class="keyword">and</span> x1 &lt; n <span class="keyword">and</span> area[x1][y1] == <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">            area[x1][y1] = <span class="string">&#x27;g&#x27;</span></span><br><span class="line">            flag[x1][y1] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n, m = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">area = [<span class="built_in">list</span>(<span class="built_in">input</span>()) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">k = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 上下左右</span></span><br><span class="line">R = [(-<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, <span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 长草月数</span></span><br><span class="line"><span class="keyword">for</span> month <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    <span class="comment"># 记录已经生长过的草位置</span></span><br><span class="line">    flag = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">if</span> area[i][j] == <span class="string">&#x27;g&#x27;</span> <span class="keyword">and</span> flag[i][j] == <span class="number">0</span>:</span><br><span class="line">                flag[i][j] = <span class="number">1</span></span><br><span class="line">                grow(i, j)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出第k月长草情况</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> area:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(row))</span><br></pre></td></tr></table></figure>
<h3 id="长整数加法"><a href="#长整数加法" class="headerlink" title="长整数加法"></a>长整数加法</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>输入两个整数a和b，输出这两个整数的和。a和b都不超过100位。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入包括两行，第一行为一个非负整数a，第二行为一个非负整数b。两个整数都不超过100位，两数的最高位都不是0。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行，表示a + b的值。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>20100122201001221234567890<br>2010012220100122</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>20100122203011233454668012</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = <span class="built_in">input</span>()</span><br><span class="line">arr2 = <span class="built_in">input</span>()</span><br><span class="line"><span class="comment"># 比较两者长度，进行补0</span></span><br><span class="line">length = <span class="built_in">len</span>(arr1) - <span class="built_in">len</span>(arr2)</span><br><span class="line"><span class="keyword">if</span> length &gt; <span class="number">0</span>:</span><br><span class="line">    arr2 = <span class="string">&#x27;0&#x27;</span> * length + arr2</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    arr1 = <span class="string">&#x27;0&#x27;</span> * (-length) + arr1</span><br><span class="line"><span class="comment"># 存放结果</span></span><br><span class="line">result = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr1)+<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 进位</span></span><br><span class="line">k = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr1)):</span><br><span class="line">    <span class="comment"># 从个位开始加，同时加上进位</span></span><br><span class="line">    <span class="built_in">sum</span> = k + <span class="built_in">int</span>(arr1[<span class="built_in">len</span>(arr1)-i-<span class="number">1</span>]) + <span class="built_in">int</span>(arr2[<span class="built_in">len</span>(arr1)-i-<span class="number">1</span>]) </span><br><span class="line">    <span class="comment"># 从个位开始存放结果</span></span><br><span class="line">    result[<span class="built_in">len</span>(arr1) - i] = <span class="built_in">sum</span> % <span class="number">10</span></span><br><span class="line">    <span class="comment"># 设置进位</span></span><br><span class="line">    k = <span class="built_in">sum</span> // <span class="number">10</span></span><br><span class="line"><span class="comment"># 最高位进位</span></span><br><span class="line"><span class="keyword">if</span> k != <span class="number">0</span>:</span><br><span class="line">    result[<span class="number">0</span>] = k</span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr1)+<span class="number">1</span>):</span><br><span class="line">    <span class="comment"># 排除最高位为0的情况</span></span><br><span class="line">    <span class="keyword">if</span> result[<span class="number">0</span>] == <span class="number">0</span> <span class="keyword">and</span> i == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="built_in">print</span>(result[i], end=<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="装饰珠"><a href="#装饰珠" class="headerlink" title="装饰珠"></a>装饰珠</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>在怪物猎人这一款游戏中，玩家可以通过给装备镶嵌不同的装饰珠来获取 相应的技能，以提升自己的战斗能力。</p>
<p>已知猎人身上一共有 6 件装备，每件装备可能有若干个装饰孔，每个装饰孔有各自的等级，可以镶嵌一颗小于等于自身等级的装饰珠 (也可以选择不镶嵌)。</p>
<p>装饰珠有 M 种，编号 1 至 M，分别对应 M 种技能，第 i 种装饰珠的等级为 $L_i$，只能镶嵌在等级大于等于 $L_i$ 的装饰孔中。<br>对第 i 种技能来说，当装备相应技能的装饰珠数量达到 $K_i$个时，会产生$W_i(K_i)$的价值，镶嵌同类技能的数量越多，产生的价值越大，即$W_i(K_{i-1})&lt;W_i(K_i)$。但每个技能都有上限$P_i$(1≤$P_i$≤7)，当装备的珠子数量超过$P_i$时，只会产生$W_i(P_i)$的价值。</p>
<p>对于给定的装备和装饰珠数据，求解如何镶嵌装饰珠，使得 6 件装备能得到的总价值达到最大。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第 1 至 6 行，包含 6 件装备的描述。其中第i行的第一个整数$N_i$表示第i件装备的装饰孔数量。后面紧接着$N_i$个整数，分别表示该装备上每个装饰孔的等级L(1≤ L ≤4)。<br>第 7 行包含一个正整数 M，表示装饰珠 (技能) 种类数量。<br>第 8 至 M + 7 行，每行描述一种装饰珠 (技能) 的情况。每行的前两个整数$L_j$(1≤ $L_j$ ≤4)和$P_j$(1≤ $P_j$ ≤7)分别表示第 j 种装饰珠的等级和上限。接下来$P_j$个整数，其中第 k 个数表示装备该中装饰珠数量为 k 时的价值$W_j(k)$。<br>其中1 ≤ $N_i$ ≤ 50，1 ≤ M ≤ $10^4$，1 ≤ $W_j(k)$ ≤ $10^4$。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出一行包含一个整数，表示能够得到的最大价值。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>1 1<br>2 1 2<br>1 1<br>2 2 2<br>1 1<br>1 3<br>3<br>1 5 1 2 3 5 8<br>2 4 2 4 8 15<br>3 2 5 10</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>20</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>按照如下方式镶嵌珠子得到最大价值 20，括号内表示镶嵌的装饰珠的种类编号：<br>1: (1)<br>2: (1) (2)<br>3: (1)<br>4: (2) (2)<br>5: (1)<br>6: (2)</p>
<p>4 颗技能 1 装饰珠，4 颗技能 2 装饰珠$W_1(4) + W_2(4) = 5 + 15 = 20$。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># curItem表示当前装备索引</span></span><br><span class="line"><span class="comment"># curHole表示当前孔洞索引</span></span><br><span class="line"><span class="comment"># holeNum表示当前装备孔洞总数量</span></span><br><span class="line"><span class="comment"># skillNums记录孔洞装备情况</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">holeValue</span>(<span class="params">skillNums, curItem, curHole, holeNum, phole</span>):</span></span><br><span class="line">    <span class="comment"># 遍历完所有孔，记录数据退出</span></span><br><span class="line">    <span class="keyword">if</span> curHole == holeNum:</span><br><span class="line">        phole.append(skillNums)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 当前孔位的装备容量</span></span><br><span class="line">    maxLimit = items[curItem][curHole+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 如果技能等级小等容量，则可以装备</span></span><br><span class="line">        <span class="keyword">if</span> skills[j][<span class="number">0</span>] &lt;= maxLimit:</span><br><span class="line">            tmp = []</span><br><span class="line">            tmp += skillNums</span><br><span class="line">            tmp[j] += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 记录当前孔装备技能</span></span><br><span class="line">            holeValue(tmp, curItem, curHole+<span class="number">1</span>, holeNum, phole)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搜索所有的可能价值</span></span><br><span class="line"><span class="comment"># skillNums用于封装各个技能的数量</span></span><br><span class="line"><span class="comment"># cur代表当前是第几号装备</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">allValue</span>(<span class="params">skillNums, cur</span>):</span></span><br><span class="line">    <span class="comment"># 遍历完所有装备，记录数据退出</span></span><br><span class="line">    <span class="keyword">if</span> cur == <span class="number">6</span>:</span><br><span class="line">        values.append(skillNums)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 用于记录每个孔位的可能装备情况</span></span><br><span class="line">    phole = []</span><br><span class="line">    <span class="comment"># 所需该装备的所有可能装备情况</span></span><br><span class="line">    holeValue(skillNums, cur, <span class="number">0</span>, items[cur][<span class="number">0</span>], phole)</span><br><span class="line">    <span class="comment"># 进行下一个装备的搜索</span></span><br><span class="line">    <span class="keyword">for</span> arr <span class="keyword">in</span> phole:</span><br><span class="line">        allValue(arr, cur+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 装备</span></span><br><span class="line">items = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>)]</span><br><span class="line">n = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line"><span class="comment"># 技能</span></span><br><span class="line">skills = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line"><span class="comment"># 用于记录所有的可能价值</span></span><br><span class="line">values = []</span><br><span class="line"><span class="comment"># 搜寻所有可能</span></span><br><span class="line">allValue([<span class="number">0</span>]*n, <span class="number">0</span>)</span><br><span class="line"><span class="comment"># 存放最大价值</span></span><br><span class="line">maxValue = <span class="number">0</span></span><br><span class="line"><span class="comment"># 遍历每种可能</span></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> values:</span><br><span class="line">    tmp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个技能的可能存放数量</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(value)):</span><br><span class="line">        <span class="comment"># 求取价值</span></span><br><span class="line">        index = <span class="built_in">min</span>(value[i], skills[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> index &gt; <span class="number">0</span>:</span><br><span class="line">            tmp += skills[i][index+<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> tmp &gt; maxValue:</span><br><span class="line">        maxValue = tmp</span><br><span class="line"><span class="built_in">print</span>(maxValue)</span><br></pre></td></tr></table></figure>
<h3 id="字符串操作"><a href="#字符串操作" class="headerlink" title="字符串操作"></a>字符串操作</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给出一个字符串和多行文字，在这些文字中找到字符串出现的那些行。你的程序还需支持大小写敏感选项：当选项打开时，表示同一个字母的大写和小写看作不同的字符；当选项关闭时，表示同一个字母的大写和小写看作相同的字符。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行包含一个字符串S，由大小写英文字母组成。<br>第二行包含一个数字，表示大小写敏感的选项，当数字为0时表示大小写不敏感，当数字为1时表示大小写敏感。<br>第三行包含一个整数n，表示给出的文字的行数。<br>接下来n行，每行包含一个字符串，字符串由大小写英文字母组成，不含空格和其他字符。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出多行，每行包含一个字符串，按出现的顺序依次给出那些包含了字符串S的行。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>Hello<br>1<br>5<br>HelloWorld<br>HiHiHelloHiHi<br>GrepIsAGreatTool<br>HELLO<br>HELLOisNOTHello</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>HelloWorld<br>HiHiHelloHiHi<br>HELLOisNOTHello</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>在上面的样例中，第四个字符串虽然也是Hello，但是大小写不正确。如果将输入的第二行改为0，则第四个字符串应该输出。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="built_in">input</span>()</span><br><span class="line">buttom = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">rows = <span class="built_in">int</span>(<span class="built_in">input</span>())</span><br><span class="line">arr = [<span class="built_in">input</span>() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(rows)]</span><br><span class="line">res = []</span><br><span class="line"><span class="keyword">if</span> buttom == <span class="number">1</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="keyword">if</span> s <span class="keyword">in</span> i:</span><br><span class="line">            res.append(i)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    s = s.lower()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        <span class="keyword">if</span> s <span class="keyword">in</span> i.lower():</span><br><span class="line">            res.append(i)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(res)):</span><br><span class="line">    <span class="built_in">print</span>(res[i])</span><br></pre></td></tr></table></figure>
<h3 id="字符串对比"><a href="#字符串对比" class="headerlink" title="字符串对比"></a>字符串对比</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定两个仅由大写字母或小写字母组成的字符串(长度介于1到10之间)，它们之间的关系是以下4中情况之一：<br>1：两个字符串长度不等。比如 Beijing 和 Hebei<br>2：两个字符串不仅长度相等，而且相应位置上的字符完全一致(区分大小写)，比如 Beijing 和 Beijing<br>3：两个字符串长度相等，相应位置上的字符仅在不区分大小写的前提下才能达到完全一致（也就是说，它并不满足情况2）。比如 beijing 和 BEIjing<br>4：两个字符串长度相等，但是即使是不区分大小写也不能使这两个字符串一致。比如 Beijing 和 Nanjing<br>编程判断输入的两个字符串之间的关系属于这四类中的哪一类，给出所属的类的编号。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>包括两行，每行都是一个字符串</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>仅有一个数字，表明这两个字符串的关系编号</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>BEIjing<br>beiJing</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str1 = <span class="built_in">input</span>()</span><br><span class="line">str2 = <span class="built_in">input</span>()</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(str1) != <span class="built_in">len</span>(str2):</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> str1 == str2:</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">elif</span> str1.lower() == str2.lower():</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h3 id="字符串跳步"><a href="#字符串跳步" class="headerlink" title="字符串跳步"></a>字符串跳步</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定一个字符串，你需要从第start位开始每隔step位输出字符串对应位置上的字符。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>第一行：一个只包含小写字母的字符串。<br>第二行：两个非负整数start和step，意义见上。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>一行，表示对应输出。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>abcdefg<br>2 2</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>ceg</p>
</blockquote>
<p>start从0开始计数。<br>字符串长度不超过100000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="built_in">input</span>()</span><br><span class="line">start, step = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line"><span class="built_in">print</span>(s[start::step])</span><br></pre></td></tr></table></figure>
<h3 id="最长公共子序列-LCS）"><a href="#最长公共子序列-LCS）" class="headerlink" title="最长公共子序列(LCS）"></a>最长公共子序列(LCS）</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>给定两个字符串，寻找这两个字串之间的最长公共子序列。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入两行，分别包含一个字符串，仅含有小写字母。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>最长公共子序列的长度。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>abcdgh<br>aedfhb</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>3</p>
</blockquote>
<p><strong>样例说明</strong></p>
<blockquote>
<p>最长公共子序列为a，d，h。</p>
</blockquote>
<p>字串长度1~1000。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">str1 = <span class="built_in">input</span>()</span><br><span class="line">str2 = <span class="built_in">input</span>()</span><br><span class="line"><span class="comment"># res[i][j]代表长度str1长度为i,str2长度为j时的最长公共子序列的长度</span></span><br><span class="line">res = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str2)+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str1)+<span class="number">1</span>)]</span><br><span class="line"><span class="comment"># 从零开始递归</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str1)+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(str2)+<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 其中一个字符串长度为0时，最长公共子序列的长度为0</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">or</span> j == <span class="number">0</span>:</span><br><span class="line">            res[i][j] = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 否则若当前长度位置i和j的字符相等，则最长公共子序列的长度更新为i-1和j-1长度时最长公共子序列的长度+1</span></span><br><span class="line">        <span class="keyword">elif</span> str1[i-<span class="number">1</span>] == str2[j-<span class="number">1</span>]:</span><br><span class="line">            res[i][j] = res[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="comment"># 若当前长度位置i和j的字符不相等，则最长公共子序列的长度为最长的(i-1和j长度时的最长公共子序列长度，i和j-1长度时的最长公共子序列长度)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res[i][j] = <span class="built_in">max</span>(res[i - <span class="number">1</span>][j], res[i][j - <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 返回最终长度时的最长公共子序列的长度</span></span><br><span class="line"><span class="built_in">print</span>(res[-<span class="number">1</span>][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h3 id="最长滑雪道"><a href="#最长滑雪道" class="headerlink" title="最长滑雪道"></a>最长滑雪道</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>小袁非常喜欢滑雪， 因为滑雪很刺激。为了获得速度，滑的区域必须向下倾斜，而且当你滑到坡底，你不得不再次走上坡或者等待升降机来载你。 小袁想知道在某个区域中最长的一个滑坡。区域由一个二维数组给出。数组的每个数字代表点的高度。如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/lanqiao/image-20220302190226582.png" alt></p>
<p>一个人可以从某个点滑向上下左右相邻四个点之一，当且仅当高度减小。在上面的例子中，一条可滑行的滑坡为24-17-16-1。当然25-24-23-…-3-2-1更长。事实上，这是最长的一条。<br>你的任务就是找到最长的一条滑坡，并且将滑坡的长度输出。 滑坡的长度定义为经过点的个数，例如滑坡24-17-16-1的长度是4。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入的第一行表示区域的行数R和列数C(1&lt;=R, C&lt;=10)。下面是R行，每行有C个整数，依次是每个点的高度h（0&lt;= h &lt;=10000）。</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>只有一行，为一个整数，即最长区域的长度。</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>5 5<br>1 2 3 4 5<br>16 17 18 19 6<br>15 24 25 20 7<br>14 23 22 21 8<br>13 12 11 10 9</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>25</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#递归搜索， 求该位置出发的最长路径</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="comment"># 初始化为1</span></span><br><span class="line">    maxHeight = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 该位置周边的四个点</span></span><br><span class="line">    offset = [[-<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> offset:</span><br><span class="line">        <span class="comment"># 下一个搜索点的横坐标</span></span><br><span class="line">        tx = x + i[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 下一个搜索点的纵坐标</span></span><br><span class="line">        ty = y + i[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 若超出边界，跳过</span></span><br><span class="line">        <span class="keyword">if</span> tx &lt; <span class="number">0</span> <span class="keyword">or</span> tx &gt; R - <span class="number">1</span> <span class="keyword">or</span> ty &lt; <span class="number">0</span> <span class="keyword">or</span> ty &gt; C - <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 若不满足高度差，跳过</span></span><br><span class="line">        <span class="keyword">if</span> arr[tx][ty] &gt;= arr[x][y]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 当前位置出发的最长路径只有两种情况</span></span><br><span class="line">        <span class="comment"># 1.找不到满足条件的搜索点为它自身 2.下一个搜索点的最长路径+1</span></span><br><span class="line">        maxHeight = <span class="built_in">max</span>(maxHeight, dfs(tx, ty) + <span class="number">1</span>) </span><br><span class="line">    <span class="keyword">return</span> maxHeight</span><br><span class="line"></span><br><span class="line"><span class="comment">#输入</span></span><br><span class="line">R, C = <span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())</span><br><span class="line">arr = [<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">input</span>().split())) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(R)]</span><br><span class="line"><span class="comment"># 存放最长路径的结果</span></span><br><span class="line">res = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(R):</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(C):</span><br><span class="line">        res = <span class="built_in">max</span>(res, dfs(x, y))</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<h3 id="最长字符序列-同LCS"><a href="#最长字符序列-同LCS" class="headerlink" title="最长字符序列(同LCS)"></a>最长字符序列(同LCS)</h3><p><strong>题目描述</strong> </p>
<blockquote>
<p>设x(i), y(i), z(i)表示单个字符，则X={x(1)x(2)……x(m)}，Y={y(1)y(2)……y(n)}，Z={z(1)z(2)……z(k)},我们称其为字符序列，其中m,n和k分别是字符序列X，Y，Z的长度，括号()中的数字被称作字符序列的下标。<br>如果存在一个严格递增而且长度大于0的下标序列{i1,i2……ik}，使得对所有的j=1,2,……k，有x(ij)=z(j)，那么我们称Z是X的字符子序列。而且，如果Z既是X的字符子序列又是Y的字符子序列，那么我们称Z为X和Y的公共字符序列。<br>在我们今天的问题中，我们希望计算两个给定字符序列X和Y的最大长度的公共字符序列，这里我们只要求输出这个最大长度公共子序列对应的长度值。<br>举例来说，字符序列X=abcd，Y=acde，那么它们的最大长度为3，相应的公共字符序列为acd。</p>
</blockquote>
<p><strong>输入描述</strong></p>
<blockquote>
<p>输入一行，用空格隔开的两个字符串</p>
</blockquote>
<p><strong>输出描述</strong></p>
<blockquote>
<p>输出这两个字符序列对应的最大长度公共字符序列的长度值</p>
</blockquote>
<p><strong>输入样例</strong></p>
<blockquote>
<p>aAbB aabb</p>
</blockquote>
<p><strong>输出样例</strong></p>
<blockquote>
<p>2</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a, b = <span class="built_in">input</span>().split()</span><br><span class="line">arr = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(b)+<span class="number">1</span>)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)+<span class="number">1</span>)]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(b)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">or</span> j == <span class="number">0</span>:</span><br><span class="line">            arr[i][j] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> a[i-<span class="number">1</span>] == b[j-<span class="number">1</span>]:</span><br><span class="line">            arr[i][j] = arr[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            arr[i][j] = <span class="built_in">max</span>(arr[i][j-<span class="number">1</span>], arr[i-<span class="number">1</span>][j])</span><br><span class="line"><span class="built_in">print</span>(arr[-<span class="number">1</span>][-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>资源</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode刷题(Python3及Java实现)</title>
    <url>/2021/03/09/Leetcode%E5%88%B7%E9%A2%98/</url>
    <content><![CDATA[<blockquote>
<p>本系列是本人在刷题过程中，参考<a href="https://www.geekxh.com/0.0.%E5%AD%A6%E4%B9%A0%E9%A1%BB%E7%9F%A5/01.html">《小浩算法》</a>的题型分类所做。由于小浩在大多数题目并未使用统一的语言实现，这里本人给出了Python和Java的实现。目前Python实现已完成，Java实现仍在更新中。若有错误或者更好的解决方法，欢迎提出。</p>
</blockquote>
<h2 id="数组系列"><a href="#数组系列" class="headerlink" title="数组系列"></a>数组系列</h2><h3 id="1-交集"><a href="#1-交集" class="headerlink" title="1.交集"></a>1.交集</h3><blockquote>
<p>此题可以看成是一道传统的映射题（map映射），为什么可以这样看呢，因为我们需找出两个数组的交集元素，同时应与两个数组中出现的次数一致。这样就导致了我们需要知道每个值出现的次数，所以映射关系就成了&lt;元素,出现次数&gt;</p>
</blockquote>
<p><strong>[第349题]</strong>    给定两个数组，编写一个函数来计算它们的交集。 </p>
<ul>
<li><p>示例 1：<br>输入：nums1 = [1,2,2,1], nums2 = [2,2]<br>输出：[2]</p>
</li>
<li><p>示例 2：<br>输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4]<br>输出：[9,4] </p>
</li>
</ul>
<p>说明： <strong>输出结果中的每个元素一定是唯一的。</strong> 我们可以不考虑输出结果的顺序。 </p>
<p><strong>方法一：映射字典</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        key = &#123;&#125;</span><br><span class="line">        result=[]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> nums1:</span><br><span class="line">        	<span class="comment">#遍历nums1，初始化字典key</span></span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> key:</span><br><span class="line">                key[v] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> nums2:</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">in</span> key:</span><br><span class="line">            	<span class="comment">#如果元素相同，将其存入result中，并将出现次数减1</span></span><br><span class="line">                <span class="keyword">if</span> key[v] &gt; <span class="number">0</span>:</span><br><span class="line">                    key[v] -= <span class="number">1</span></span><br><span class="line">                    result.append(v)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:60 ms,击败了74.80% 的Python3用户<br>内存消耗:13.4 MB,击败了70.92% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] intersection(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums2.length];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//getOrDefault()，当Map集合中有这个key时，就使用这个key值，如果没有就使用默认值defaultValue</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums1) map.put(num, map.getOrDefault(num, <span class="number">1</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums2)&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.getOrDefault(num, -<span class="number">1</span>) &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                map.put(num, map.get(num)-<span class="number">1</span>);</span><br><span class="line">                res[count++] = num;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//返回指定长度的新数组对象</span></span><br><span class="line">        <span class="keyword">return</span> Arrays.copyOf(res, count);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了84.57% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了7.70% 的用户</p>
<p><strong>方法二：set函数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    	<span class="comment">#set转化成无重复元素的集合取交集</span></span><br><span class="line">        result = <span class="built_in">set</span>(nums1).intersection(<span class="built_in">set</span>(nums2))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(result)</span><br></pre></td></tr></table></figure>
<p>执行耗时:64 ms,击败了57.06% 的Python3用户<br>内存消耗:13.3 MB,击败了88.25% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] intersection(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2) &#123;</span><br><span class="line">        Set&lt;Integer&gt; map = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums2.length];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums1) map.add(num);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums2)&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.contains(num))&#123;</span><br><span class="line">                res[count++] = num;</span><br><span class="line">                map.remove(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//返回指定长度的新数组对象</span></span><br><span class="line">        <span class="keyword">return</span> Arrays.copyOf(res, count);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了94.86% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了58.09% 的用户</p>
<p><strong>[第350题]</strong>    给定两个数组，编写一个函数来计算它们的交集。 </p>
<ul>
<li><p>示例 1：<br>输入：nums1 = [1,2,2,1], nums2 = [2,2]<br>输出：[2]</p>
</li>
<li><p>示例 2：<br>输入：nums1 = [4,9,5], nums2 = [9,4,9,8,4]<br>输出：[9,4] </p>
</li>
</ul>
<p>说明：<strong>输出结果中每个元素出现的次数，应与元素在两个数组中出现次数的最小值一致。</strong>我们可以不考虑输出结果的顺序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        key = &#123;&#125;</span><br><span class="line">        result = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> nums1:</span><br><span class="line">            <span class="comment">#遍历nums1，初始化字典key</span></span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> key:</span><br><span class="line">                key[v] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                key[v] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> nums2:</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">in</span> key:</span><br><span class="line">                <span class="comment">#如果元素相同，将其存入result中，并将出现次数减1</span></span><br><span class="line">                <span class="keyword">if</span> key[v] &gt; <span class="number">0</span>:</span><br><span class="line">                    key[v] -= <span class="number">1</span></span><br><span class="line">                    result.append(v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了97.73% 的Python3用户<br>内存消耗:13.5 MB,击败了36.24% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] intersect(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums2.length];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> num : nums1) map.put(num,map.getOrDefault(num,<span class="number">0</span>) + <span class="number">1</span>) ;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> num : nums2)&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.getOrDefault(num, -<span class="number">1</span>) &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                res[count++] = num ;</span><br><span class="line">                map.put(num,map.get(num) -<span class="number">1</span>) ;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//返回指定长度的新数组对象</span></span><br><span class="line">        <span class="keyword">return</span> Arrays.copyOf(res, count);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了73.45% 的用户<br>内存消耗：38.8 MB, 在所有 Java 提交中击败了16.45% 的用户</p>
<p><strong>[题目进阶]</strong>   如果给定的数组已经排好序呢？你将如何优化你的算法？假如两个数组都是有序的，分别为：arr1 = [1,2,3,4,4,13]，arr2 = [1,2,3,9,10]</p>
<blockquote>
<p>对于两个已经排序好数组的题，我们可以很容易想到使用双指针的解法</p>
<p>设定两个为0的指针，比较两个指针的元素是否相等。如果指针的元素相等，我们将两个指针一起<br>向后移动，并且将相等的元素放入空白数组。</p>
<p>如果两个指针的元素不相等，我们将小的元素的指针后移。继续进行判断。</p>
<p>反复以上步骤，直到任意一个数组终止。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        nums1.sort()</span><br><span class="line">        nums2.sort()</span><br><span class="line">        result = []</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(nums1) <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(nums2):</span><br><span class="line">            <span class="keyword">if</span> nums1[i] == nums2[j]:</span><br><span class="line">                result.append(nums1[i])</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums1[i] &lt; nums2[j]:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:68 ms,击败了46.68% 的Python3用户<br>内存消耗:13.4 MB,击败了44.53% 的Python3用户</p>
<h3 id="2-最长公共前缀"><a href="#2-最长公共前缀" class="headerlink" title="2.最长公共前缀"></a>2.最长公共前缀</h3><blockquote>
<p>我们要想寻找最长公共前缀，那么首先这个前缀是公共的，我们可以从任意一个元素中找到它。<br>假定我们现在就从一个数组中寻找最长公共前缀，那么首先，我们可以将第一个元素设置为基准<br>元素x0。假如数组为[“flow”,”flower”,”flight”]，flow就是我们的基准元素x0。</p>
<p>然后我们只需要依次将基准元素和后面的元素进行比较（假定后面的元素依次为x1,x2,x3….），不断更<br>新基准元素，直到基准元素和所有元素都满足最长公共前缀的条件，就可以得到最长公共前缀。</p>
<p>具体比对过程如下：</p>
<p>如果strings.Index(x1,x) == 0，则直接跳过（因为此时x就是x1的最长公共前缀），对比下一个元<br>素。（如flower和flow进行比较）</p>
<p>如果strings.Index(x1,x) != 0, 则截取掉基准元素x的最后一个元素，再次和x1进行比较，直至满足<br>string.Index(x1,x) == 0，此时截取后的x为x和x1的最长公共前缀。（如flight和flow进行比较，依<br>次截取出flow-flo-fl，直到fl被截取出，此时fl为flight和flow的最长公共前缀）</p>
</blockquote>
<p><strong>[第14题]</strong>   编写一个函数来查找字符串数组中的最长公共前缀。 如果不存在公共前缀，返回空字符串 “”。 </p>
<ul>
<li><p>示例 1:<br>输入: [“flower”,”flow”,”flight”]<br>输出: “fl”</p>
</li>
<li><p>示例 2:<br>输入: [“dog”,”racecar”,”car”]<br>输出: “”<br>解释: 输入不存在公共前缀。</p>
</li>
</ul>
<p>说明: 所有输入只包含小写字母 a-z 。 </p>
<p><strong>方法一：比对基准元素</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestCommonPrefix</span>(<span class="params">self, strs: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(strs) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#基准元素</span></span><br><span class="line">            result = strs[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#基准元素和后面的元素进行比较</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> strs[<span class="number">1</span>:]:</span><br><span class="line">            <span class="comment"># find:在[beg, end]范围内查找substring，找到返回substr的起始下标，否则返回-1。</span></span><br><span class="line">            <span class="comment"># 前缀起始坐标必须为0开始，中间不算</span></span><br><span class="line">            <span class="keyword">while</span> k.find(result) != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(result) == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment">#调整基准元素</span></span><br><span class="line">                    result = result[:-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了98.27% 的Python3用户<br>内存消耗:13.4 MB,击败了56.76% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">longestCommonPrefix</span><span class="params">(String[] strs)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//设置基准元素</span></span><br><span class="line">        <span class="keyword">if</span>(strs.length &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">        String res = strs[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">//与后续字符串比较</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;strs.length; i++)&#123;</span><br><span class="line">            <span class="comment">//若不包含，则缩小范围</span></span><br><span class="line">             <span class="keyword">while</span>(!strs[i].startsWith(res))&#123;</span><br><span class="line">                <span class="keyword">if</span>(res.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">                res = res.substring(<span class="number">0</span>, res.length()-<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.7 MB, 在所有 Java 提交中击败了30.89% 的用户</p>
<p><strong>方法二：利用ASCII码</strong></p>
<blockquote>
<p>利用python的max()和min()，在Python里字符串是可以比较的，按照ascII值排，举例abb， aba，abac，最大为abb，最小为aba。所以只需要比较最大最小的公共前缀就是整个数组的公共前缀</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestCommonPrefix</span>(<span class="params">self, strs: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> strs:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        s1 = <span class="built_in">min</span>(strs)</span><br><span class="line">        s2 = <span class="built_in">max</span>(strs)</span><br><span class="line">        <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(s1):</span><br><span class="line">            <span class="keyword">if</span> x != s2[i]:</span><br><span class="line">                <span class="keyword">return</span> s2[:i]</span><br><span class="line">        <span class="keyword">return</span> s1</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了61.62% 的Python3用户<br>内存消耗:13.3 MB,击败了85.07% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">longestCommonPrefix</span><span class="params">(String[] strs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(strs.length &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">        String min = strs[<span class="number">0</span>];</span><br><span class="line">        String max = strs[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(String s: strs)&#123;</span><br><span class="line">            <span class="comment">//若字符串等于参数字符串、则返回0，字符串小于参数字符串、则返回值小于0，字符串大于参数字符串、返回值大于0。</span></span><br><span class="line">            <span class="keyword">if</span>(s.compareTo(max) &gt; <span class="number">0</span>) max = s;</span><br><span class="line">            <span class="keyword">if</span>(s.compareTo(min) &lt; <span class="number">0</span>) min = s;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;min.length(); i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(min.charAt(i) != max.charAt(i)) <span class="keyword">return</span> min.substring(<span class="number">0</span>, i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> min;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了85.32% 的用户<br>内存消耗：36.8 MB, 在所有 Java 提交中击败了20.75% 的用户</p>
<p><strong>方法三：利用zip函数</strong></p>
<blockquote>
<p>利用python的zip函数，把str看成list然后把输入看成二维数组，左对齐纵向压缩，然后把每项利用集合去重，之后遍历list中找到元素长度大于1之前的就是公共前缀</p>
<p>比如strs=[“flow”,”flower”,”flight”]，则zip(*strs)将依次取出[‘f’,’f’,’f’]、[‘l’,’l’,’l’]、……、[‘’, ‘r’,’t’]，通过set去重，则[‘f’]、[‘l’]、……、[‘’, ‘r’,’t’]，长度大于1之前的就是公共前缀</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">longestCommonPrefix</span>(<span class="params">self, strs: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> strs:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        ss = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">set</span>, <span class="built_in">zip</span>(*strs)))</span><br><span class="line">        res = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> i, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(ss):</span><br><span class="line">            x = <span class="built_in">list</span>(x)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(x) &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            res = res + x[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了81.85% 的Python3用户<br>内存消耗:13.4 MB,击败了50.03% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">longestCommonPrefix</span><span class="params">(String[] strs)</span> </span>&#123;</span><br><span class="line">        String res = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        List&lt;Set&lt;Character&gt;&gt; ss = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> maxLength = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(String s: strs)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s.length() &gt; maxLength) maxLength = s.length();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;maxLength; i++)&#123;</span><br><span class="line">            Set&lt;Character&gt; set = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span>(String s: strs)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i &lt; s.length()) set.add(s.charAt(i));</span><br><span class="line">                <span class="keyword">else</span> set.add(<span class="string">&#x27; &#x27;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            ss.add(set);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(Set&lt;Character&gt; set: ss)&#123;</span><br><span class="line">            <span class="keyword">if</span>(set.size() &gt; <span class="number">1</span>) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">char</span> s: set) res += s;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：16 ms, 在所有 Java 提交中击败了5.83% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了5.05% 的用户</p>
<h3 id="3-买卖股票的最佳时机"><a href="#3-买卖股票的最佳时机" class="headerlink" title="3.买卖股票的最佳时机"></a>3.买卖股票的最佳时机</h3><p><strong>[第122题]</strong>   给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以<strong>尽可能地完成更多的交易（多次买卖一支股票）。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 </strong></p>
<ul>
<li><p>示例 1: 输入: [7,1,5,3,6,4]<br>输出: 7<br>解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。</p>
</li>
<li><p>示例 2:<br>输入: [1,2,3,4,5]<br>输出: 4<br>解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。</p>
</li>
<li><p>示例 3:<br>输入: [7,6,4,3,1]<br>输出: 0<br>解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 </p>
</li>
</ul>
<blockquote>
<p>1、不能参与多笔交易。换句话讲，我们只能在手上没有股票的时候买入，也就是必须在再次购买前出<br>售掉之前的股票。像我们平时买股票时的追涨杀跌是不可以的。</p>
<p>2、尽可能地多进行交易。这个非常好理解。像是黄金，一年基本上都有2-3次涨跌。我们只要把握住机<br>会，在每一次涨跌的时候，低价卖入高价卖出，就可以使利益达到最大化。这个条件也是相当重要的，<br>如果我们把这里变成，最多完成两笔交易，就变成另一道题。</p>
<p>假设给定的数组为：[7, 1, 5, 3, 6, 4] 我们将其绘制成折线图，，我们要在满足1和2的条件下获取最大利益，其实就是尽可能多的低价买入高价卖出。而每一次上升波段，其实就是一次低价买入高价卖出。而我们没有限制交易次数，也就是我们需要求出所有的上升波段的和。如图里就是A+B，也就是（5-1）+（6-3） = 7，就是我们能获取到的最大利益。</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/1.jpg" alt></p>
<p><strong>方法一：贪心算法</strong></p>
<blockquote>
<p>只要今天价格小于明天价格就在今天买入然后明天卖出</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        profit = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prices)-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> prices[i] &lt; prices[i+<span class="number">1</span>]:</span><br><span class="line">                profit += (prices[i+<span class="number">1</span>] - prices[i])</span><br><span class="line">        <span class="keyword">return</span>  profit</span><br></pre></td></tr></table></figure>
<p>执行耗时:84 ms,击败了53.70% 的Python3用户<br>内存消耗:14.7 MB,击败了38.34% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfit</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> profit=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;prices.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(prices[i]&lt;prices[i+<span class="number">1</span>]) profit+=(prices[i+<span class="number">1</span>]-prices[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> profit;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了99.57% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了79.49% 的用户</p>
<p><strong>方法二：DP动态规划</strong></p>
<blockquote>
<p>第i天只有两种状态，不持有或持有股票，当天不持有股票的状态可能来自昨天卖出或者昨天也不持有，同理，当天持有股票的状态可能来自昨天买入或者昨天也持有中，取最后一天的不持有股票状态就是问题的解</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span>(<span class="params">self, prices: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(prices) &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [[<span class="number">0</span>]*<span class="number">2</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prices))]</span><br><span class="line">        <span class="comment"># dp[i][0]表示第i天不持有股票, dp[i][1]表示第i天持有股票</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(prices)):</span><br><span class="line">            <span class="comment">#不持有股票分为：1.1一直都不买入仍是昨天的未持有 2.今天卖出，即昨天加今天卖出的钱</span></span><br><span class="line">            dp[i][<span class="number">0</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">0</span>], dp[i-<span class="number">1</span>][<span class="number">1</span>]+prices[i])</span><br><span class="line">            <span class="comment">#持有股票分为：1.昨天没有持有，今天买入 2.昨天已买入一直持有着</span></span><br><span class="line">            dp[i][<span class="number">1</span>] = <span class="built_in">max</span>(dp[i-<span class="number">1</span>][<span class="number">0</span>]-prices[i], dp[i-<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span>  dp[-<span class="number">1</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:136 ms,击败了5.26% 的Python3用户<br>内存消耗:16.4 MB,击败了5.02% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProfit</span><span class="params">(<span class="keyword">int</span>[] prices)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[prices.length][<span class="number">2</span>];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">1</span>] = -prices[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i&lt; prices.length; i++)&#123;</span><br><span class="line">            dp[i][<span class="number">0</span>] = Math.max(dp[i-<span class="number">1</span>][<span class="number">0</span>], dp[i-<span class="number">1</span>][<span class="number">1</span>]+prices[i]); </span><br><span class="line">            dp[i][<span class="number">1</span>] = Math.max(dp[i-<span class="number">1</span>][<span class="number">1</span>], dp[i-<span class="number">1</span>][<span class="number">0</span>]-prices[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[prices.length-<span class="number">1</span>][<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了19.71% 的用户<br>内存消耗：38 MB, 在所有 Java 提交中击败了91.41% 的用户</p>
<h3 id="4-旋转数组"><a href="#4-旋转数组" class="headerlink" title="4.旋转数组"></a>4.旋转数组</h3><p><strong>[第189题]</strong>   给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。 </p>
<ul>
<li>示例 1:<br>输入: [1,2,3,4,5,6,7] 和 k = 3<br>输出: [5,6,7,1,2,3,4]<br>解释:向右旋转 1 步: [7,1,2,3,4,5,6]，向右旋转 2 步: [6,7,1,2,3,4,5]，向右旋转 3 步: [5,6,7,1,2,3,4]</li>
<li>示例 2:<br>输入: [-1,-100,3,99] 和 k = 2<br>输出: [3,99,-1,-100]<br>解释: 向右旋转 1 步: [99,-1,-100,3]，向右旋转 2 步: [3,99,-1,-100] </li>
</ul>
<p>说明: 尽可能想出更多的解决方案，至少有三种不同的方法可以解决这个问题。 <strong>要求使用空间复杂度为 O(1) 的原地算法。</strong> </p>
<blockquote>
<p>这个方法基于这个事实：若我们需要将数组中的元素向右移动 k 个位置， 那么 k%l (l为数组长<br>度) 的尾部元素会被移动到头部，剩下的元素会被向后移动。</p>
<p>通过观察我们可以得到，我们只需要将所有元素反转，然后反转前 k 个元素，再反转后面l-k个元素，就能得到想要的结果。</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/2.jpg" alt></p>
<p><strong>方法一：翻转三次</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotate</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        k %= n</span><br><span class="line">        <span class="comment"># 定义反转函数</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">switch</span>(<span class="params">a, b</span>):</span></span><br><span class="line">            <span class="keyword">while</span> (a&lt;b):    <span class="comment"># 从两头往中间交换</span></span><br><span class="line">                nums[a], nums[b] = nums[b], nums[a]</span><br><span class="line">                a += <span class="number">1</span></span><br><span class="line">                b -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># 三次反转</span></span><br><span class="line">        switch(<span class="number">0</span>, n-<span class="number">1</span>)  <span class="comment"># 反转整体</span></span><br><span class="line">        switch(<span class="number">0</span>, k-<span class="number">1</span>)    <span class="comment"># 反转前k个元素</span></span><br><span class="line">        switch(k, n-<span class="number">1</span>)    <span class="comment"># 反转后面元素</span></span><br><span class="line">        <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了94.96% 的Python3用户<br>内存消耗:13.5 MB,击败了76.57% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rotate</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        k = k % nums.length;</span><br><span class="line">        reverse(nums, <span class="number">0</span>, nums.length-<span class="number">1</span>);</span><br><span class="line">        reverse(nums, <span class="number">0</span>, k-<span class="number">1</span>);</span><br><span class="line">        reverse(nums, k, nums.length-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(start &lt; end)&#123;</span><br><span class="line">                <span class="keyword">int</span> tmp = nums[start];</span><br><span class="line">                nums[start] = nums[end];</span><br><span class="line">                nums[end] = tmp;</span><br><span class="line">                start++;</span><br><span class="line">                end--;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：39 MB, 在所有 Java 提交中击败了45.62% 的用户</p>
<p><strong>方法二：利用切片翻转</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotate</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        k = k % <span class="built_in">len</span>(nums)</span><br><span class="line">        nums.reverse()</span><br><span class="line">        nums[:k] = <span class="built_in">reversed</span>(nums[:k])</span><br><span class="line">        nums[k:] = <span class="built_in">reversed</span>(nums[k:])</span><br><span class="line">        <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了85.56% 的Python3用户<br>内存消耗:13.6 MB,击败了27.15% 的Python3用户</p>
<p><strong>方法三：利用切片移位（不考虑原地算法）</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotate</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        k = k % <span class="built_in">len</span>(nums)</span><br><span class="line">        nums[:] = nums[-k:] + nums[:-k]</span><br><span class="line">        <span class="keyword">return</span> nums</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了85.56% 的Python3用户<br>内存消耗:13.6 MB,击败了44.31% 的Python3用户</p>
<h3 id="5-原地删除"><a href="#5-原地删除" class="headerlink" title="5.原地删除"></a>5.原地删除</h3><p><strong>[第27题]</strong>   给你一个数组nums和一个值val，你需要原地移除所有数值等于val的元素，并返回移除后数组的新长度。 <strong>不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并原地修改输入数组。</strong> 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 </p>
<ul>
<li>示例 1:<br>给定 nums = [3,2,2,3], val = 3, 函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。<br>你不需要考虑数组中超出新长度后面的元素。</li>
<li>示例 2:<br>给定 nums = [0,1,2,2,3,0,4,2], val = 2,函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。<br>注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeElement</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], val: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 应使用逆序</span></span><br><span class="line">        <span class="comment"># 如果是正序的话，删除一个索引所对应的值后</span></span><br><span class="line">        <span class="comment"># python会自动吧删除的位置补上来</span></span><br><span class="line">        <span class="comment"># 这样就会导致从删除位位置到最后一位的索引和原索引相差1个</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == val:</span><br><span class="line">                <span class="keyword">del</span> nums[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了72.46% 的Python3用户<br>内存消耗:13.4 MB,击败了33.88% 的Python3用户</p>
<blockquote>
<p>因为题目说了不需要考虑数组中超出新长度后面的元素，所以不需要真的移除，只要将其值覆盖即可</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">removeElement</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=val)&#123;</span><br><span class="line">                nums[count]=nums[i];</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.3 MB, 在所有 Java 提交中击败了8.49% 的用户</p>
<p><strong>[第26题]</strong>   给定一个<strong>排序数组</strong>，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。<strong>不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。</strong></p>
<ul>
<li>示例 1:<br>给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。 </li>
<li>示例 2:<br>给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组nums的前五个元素被修改为 0, 1, 2, 3, 4。<br>你不需要考虑数组中超出新长度后面的元素。</li>
</ul>
<blockquote>
<p>这道题的重点是原地两个字，也就是要求必须在 O(1) 的空间下完成。并且题中已经告知了数组为有序数组，这样重复的元素一定是连在一起的，我们只需要一个一个移除重复的元素即可</p>
</blockquote>
<p><strong>方法一：循环移除</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeDuplicates</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == nums[i-<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">del</span> nums[i]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了88.67% 的Python3用户<br>内存消耗:14.2 MB,击败了96.20% 的Python3用户</p>
<blockquote>
<p>与27题同理</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">removeDuplicates</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; nums.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=nums[i+<span class="number">1</span>]) nums[++count] = nums[i+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ++count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了80.44% 的用户<br>内存消耗：40.4 MB, 在所有 Java 提交中击败了19.16% 的用户</p>
<p><strong>方法二：set函数（不考虑原地算法）</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeDuplicates</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        nums[:] = <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(nums)))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(nums)</span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了99.68% 的Python3用户<br>内存消耗:14.4 MB,击败了64.71% 的Python3用户</p>
<h3 id="6-加一"><a href="#6-加一" class="headerlink" title="6.加一"></a>6.加一</h3><p><strong>[第66题]</strong>   给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。最高位数字存放在数组的首位，数组中每个元素只存储单个数字。 你可以假设除了整数 0 之外，这个整数不会以零开头。 </p>
<ul>
<li><p>示例 1:<br>输入: [1,2,3]<br>输出: [1,2,4]<br>解释: 输入数组表示数字 123。</p>
</li>
<li><p>示例 2:<br>输入: [4,3,2,1]<br>输出: [4,3,2,2]<br>解释: 输入数组表示数字 4321。</p>
</li>
</ul>
<blockquote>
<p>根据题目，我们需要加一！没错，加一很重要。因为它只是加一，所以我们会考虑到两种情况：</p>
<p>普通情况，除9之外的数字加1。<br>特殊情况，9加1。（因为9加1需要进位）</p>
<p>所以我们只需要模拟这两种运算，就可以顺利进行求解！</p>
</blockquote>
<p><strong>方法一：模拟运算</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plusOne</span>(<span class="params">self, digits: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        addon = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(digits)-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            digits[i] += addon</span><br><span class="line">            <span class="comment"># 将进位归0</span></span><br><span class="line">            addon = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 个位加1</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">len</span>(digits) - <span class="number">1</span>:</span><br><span class="line">                digits[i] += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 逢十进一</span></span><br><span class="line">            <span class="keyword">if</span> digits[i] == <span class="number">10</span>:</span><br><span class="line">                addon = <span class="number">1</span></span><br><span class="line">                digits[i] = <span class="number">0</span></span><br><span class="line">        <span class="comment">#类似99，或者999，我们需要进行扩充数组</span></span><br><span class="line">        <span class="keyword">if</span> addon == <span class="number">1</span>:</span><br><span class="line">            digits.insert(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> digits</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了70.94% 的Python3用户<br>内存消耗:13.4 MB,击败了46.46% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] plusOne(<span class="keyword">int</span>[] digits) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[digits.length+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span> addon = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=digits.length-<span class="number">1</span>; i&gt;=<span class="number">0</span>; i--)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i==digits.length-<span class="number">1</span>) digits[i]++;</span><br><span class="line">            res[i+<span class="number">1</span>] = digits[i] + addon;</span><br><span class="line">            addon = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span>(res[i+<span class="number">1</span>]==<span class="number">10</span>)&#123;</span><br><span class="line">                addon = <span class="number">1</span>;</span><br><span class="line">                res[i+<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(addon==<span class="number">1</span>) res[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> addon==<span class="number">1</span>?res: Arrays.copyOfRange(res, <span class="number">1</span>, res.length);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37 MB, 在所有 Java 提交中击败了29.28% 的用户</p>
<p><strong>方法二：利用Python特性</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plusOne</span>(<span class="params">self, digits: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="comment"># 整形转字符</span></span><br><span class="line">        digits = [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> digits]</span><br><span class="line">        <span class="comment"># 拼接字符转数字</span></span><br><span class="line">        digits = <span class="built_in">int</span>(<span class="string">&quot;&quot;</span>.join(digits))</span><br><span class="line">        <span class="comment"># 加1</span></span><br><span class="line">        digits += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 数字转列表</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">int</span>, <span class="built_in">str</span>(digits)))</span><br></pre></td></tr></table></figure>
<p>执行耗时:48 ms,击败了18.72% 的Python3用户<br>内存消耗:13.4 MB,击败了33.38% 的Python3用户</p>
<h3 id="7-两数之和"><a href="#7-两数之和" class="headerlink" title="7.两数之和"></a>7.两数之和</h3><p><strong>[第1题]</strong>   给定一个整数数组nums和一个目标值target，请你在该数组中找出和为目标值的那两个整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。 </p>
<ul>
<li>示例:<br>给定 nums = [2, 7, 11, 15], target = 9<br>因为 nums[0] + nums[1] = 2 + 7 = 9<br>所以返回 [0, 1]</li>
</ul>
<p><strong>方法一：暴力解法</strong></p>
<blockquote>
<p>首先我们拿到题目一看，马上可以想到暴力题解。我们只需要 “遍历每个元素 x，并查找是否存在一个值与 target - x 相等的目标元素。”</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> target-nums[i] <span class="keyword">in</span> nums[i+<span class="number">1</span>:]:</span><br><span class="line">                <span class="keyword">return</span> i, nums[i+<span class="number">1</span>:].index(target-nums[i])+i+<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure>
<p>执行耗时:964 ms,击败了38.87% 的Python3用户<br>内存消耗:14.1 MB,击败了85.75% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; nums.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> tmp = target - nums[i];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>; j &lt; nums.length; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[j]==tmp) <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;i, j&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了44.60% 的用户</p>
<blockquote>
<p>可以看到该种解题方式的时间复杂度过高，达到了O(n²)。为了对运行时间复杂度进行优化，我们需要一种更有效的方法来检查数组中是否存在目标元素。我们可以想到用哈希表的方式，通过以空间换取时间的方式来进行。</p>
</blockquote>
<p><strong>方法二：哈希表</strong></p>
<blockquote>
<p>首先先遍历数组nums，i 为当前下标。将每一个遍历的值放入字典中作为key。</p>
<p>同时，对每个值都判断字典中是否存在target-nums[i]的key值。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        hashmap = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> index, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums):</span><br><span class="line">            another_num = target - num</span><br><span class="line">            <span class="keyword">if</span> another_num <span class="keyword">in</span> hashmap:</span><br><span class="line">                <span class="keyword">return</span> [hashmap[another_num], index]</span><br><span class="line">            hashmap[num] = index</span><br><span class="line">        <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了91.51% 的Python3用户<br>内存消耗:14.6 MB,击败了37.49% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(target-nums[i])) <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;map.get(target-nums[i]), i&#125;;</span><br><span class="line">            map.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了34.68% 的用户</p>
<h3 id="8-三数之和"><a href="#8-三数之和" class="headerlink" title="8.三数之和"></a>8.三数之和</h3><p><strong>[第15题]</strong> 给你一个包含n个整数的数组nums，判断nums中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 </p>
<ul>
<li>示例：<br>给定数组 nums = [-1, 0, 1, 2, -1, -4]，<br>满足要求的三元组集合为：<br>[<br> [-1, 0, 1],<br> [-1, -1, 2]<br>]</li>
</ul>
<blockquote>
<p>本题的暴力题解可以仿照二数之和，直接三层遍历，取和为0的三元组，并记录下来，最后再去重。但是作为一个有智慧的人，我们不能这么去做。</p>
<p>假若我们的数组为：[-1, 0, 1, 2, -1, -4]<br>首先我们先把数组排个序，因为我们要同时找三个数，所以<strong>采取固定一个数，同时用双指针来查找另外两个数的方式。</strong>所以初始化时，我们选择固定第一个元素（当然，这一轮走完了，这个蓝框框我们就要也往前移动），同时将下一个元素和末尾元素分别设上 left 和 right 指针。画出图来就是下面这个样子：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/37.png" alt><br>因为我们已经排好了序，如果<strong>固定下来的数（上面蓝色框框）本身就大于 0，那三数之和必然无法等于 0。</strong><br>现在我们的排序就发挥出用处了，<strong>如果和大于0，那就说明 right 的值太大，需要左移。如果和小于0，那就说明 left 的值太小，需要右移。</strong><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/38.png" alt><br>其中：在第6行时，因为三数之和大于0，所以right进行了左移。最后一行，跳过了重复的-1。<br><strong>除了固定下来的i值（蓝框框），left 和 right 当然也是需要处理重复的情况。</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">threeSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt; <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        <span class="comment"># 进行排序</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="comment"># 固定值大于0退出循环</span></span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="comment"># 过滤固定值重复</span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 左指针</span></span><br><span class="line">            L = i + <span class="number">1</span></span><br><span class="line">            <span class="comment"># 右指针</span></span><br><span class="line">            R = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> L &lt; R:</span><br><span class="line">                <span class="comment"># 满足条件添加res</span></span><br><span class="line">                <span class="keyword">if</span> nums[i] + nums[L] + nums[R] == <span class="number">0</span>:</span><br><span class="line">                    res.append([nums[i], nums[L], nums[R]])</span><br><span class="line">                    <span class="comment">#满足条件后，移动双指针，跳过重复的</span></span><br><span class="line">                    <span class="keyword">while</span> L &lt; R <span class="keyword">and</span> nums[L] == nums[L + <span class="number">1</span>]:</span><br><span class="line">                        L = L + <span class="number">1</span></span><br><span class="line">                    <span class="keyword">while</span> L &lt; R <span class="keyword">and</span> nums[R] == nums[R - <span class="number">1</span>]:</span><br><span class="line">                        R = R - <span class="number">1</span></span><br><span class="line">                    L = L + <span class="number">1</span></span><br><span class="line">                    R = R - <span class="number">1</span></span><br><span class="line">                <span class="comment"># 三数之和大于0,右指针左移</span></span><br><span class="line">                <span class="keyword">elif</span> nums[i] + nums[L] + nums[R] &gt; <span class="number">0</span>:</span><br><span class="line">                    R = R - <span class="number">1</span></span><br><span class="line">                <span class="comment"># 三数之和小于0,左指针右移</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    L = L + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:836 ms,击败了79.07% 的Python3用户<br>内存消耗:16 MB,击败了43.03% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; threeSum(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;nums.length-<span class="number">2</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; nums[i] == nums[i-<span class="number">1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">int</span> l = i + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> r = nums.length - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] + nums[l] + nums[r] == <span class="number">0</span>)&#123;</span><br><span class="line">                    res.add(<span class="keyword">new</span> ArrayList&lt;Integer&gt;(Arrays.asList(nums[i], nums[l], nums[r])));</span><br><span class="line">                    <span class="keyword">while</span>(l &lt; r &amp;&amp; nums[l] == nums[l+<span class="number">1</span>]) l++;</span><br><span class="line">                    <span class="keyword">while</span>(l &lt; r &amp;&amp; nums[r] == nums[r-<span class="number">1</span>]) r--;</span><br><span class="line">                    l++;</span><br><span class="line">                    r--;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(nums[i] + nums[l] + nums[r] &gt; <span class="number">0</span>) r--;</span><br><span class="line">                <span class="keyword">else</span> l++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：29 ms, 在所有 Java 提交中击败了31.84% 的用户<br>内存消耗：42.5 MB, 在所有 Java 提交中击败了48.86% 的用户</p>
<h3 id="9-Z字形变换"><a href="#9-Z字形变换" class="headerlink" title="9.Z字形变换"></a>9.Z字形变换</h3><p><strong>[第6题]</strong> 将一个给定字符串根据给定的行数，以从上往下、从左到右进行 Z 字形排列。 比如输入字符串为 “LEETCODEISHIRING” 行数为 3 时，排列如下：<br>L   C   I   R<br>E T O E S I I G<br>E   D   H   N<br>之后，你的输出需要从左往右逐行读取，产生出一个新的字符串，比如：”LCIRETOESIIGEDHN”。 请你实现这个将字符串进行指定行数变换的函数： string convert(string s, int numRows); </p>
<ul>
<li>示例 1:<br>输入: s = “LEETCODEISHIRING”, numRows = 3<br>输出: “LCIRETOESIIGEDHN”</li>
<li>示例 2:<br>输入: s = “LEETCODEISHIRING”, numRows = 4<br>输出: “LDREOEIIECIHNTSG”<br>解释:<br>L     D     R<br>E   O E   I I<br>E C   I H   N<br>T     S     G </li>
</ul>
<blockquote>
<p><strong>根据 numRows 的大小来回进行放置即可</strong>（即从0到n-1，再从n-1到0）。具体的请看下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/39.png" alt><br>我们能看出来，<strong>每 2n-2 即为一个周期</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert</span>(<span class="params">self, s: <span class="built_in">str</span>, numRows: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        <span class="keyword">if</span> numRows == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> s</span><br><span class="line">        temp = [<span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(numRows)]</span><br><span class="line">        period = numRows * <span class="number">2</span> - <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> index, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="comment"># 每2n-2为周期</span></span><br><span class="line">            mod = index % period</span><br><span class="line">            <span class="comment"># 0到n-1</span></span><br><span class="line">            <span class="keyword">if</span> mod &lt; numRows:</span><br><span class="line">                temp[mod] += value</span><br><span class="line">            <span class="comment"># n-1到0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp[period - mod] += value</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(temp)</span><br></pre></td></tr></table></figure>
<p>执行耗时:56 ms,击败了95.52% 的Python3用户<br>内存消耗:13.6 MB,击败了16.18% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">convert</span><span class="params">(String s, <span class="keyword">int</span> numRows)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(numRows &lt; <span class="number">2</span>) <span class="keyword">return</span> s;</span><br><span class="line">        String[] tmp = <span class="keyword">new</span> String[numRows];</span><br><span class="line">        Arrays.fill(tmp, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="keyword">int</span> period = numRows * <span class="number">2</span> - <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; s.length(); i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> mod = i % period;</span><br><span class="line">            <span class="keyword">if</span>(mod &lt; numRows) tmp[mod] += s.charAt(i);</span><br><span class="line">            <span class="keyword">else</span> tmp[period-mod] += s.charAt(i);</span><br><span class="line">        &#125;</span><br><span class="line">        String res = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(String str: tmp)&#123;</span><br><span class="line">            res += str;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：18 ms, 在所有 Java 提交中击败了20.92% 的用户<br>内存消耗：39.5 MB, 在所有 Java 提交中击败了13.73% 的用户</p>
<h2 id="链表系列"><a href="#链表系列" class="headerlink" title="链表系列"></a>链表系列</h2><h3 id="1-删除链表倒数第N个节点"><a href="#1-删除链表倒数第N个节点" class="headerlink" title="1.删除链表倒数第N个节点"></a>1.删除链表倒数第N个节点</h3><blockquote>
<p>在链表的题目中，十道有九道会用到哨兵节点，所以我们先讲一下什么是哨兵节点。<br>哨兵节点，其实就是一个附加在原链表最前面用来简化边界条件的附加节点，它的值域不存储任何东<br>西，只是为了操作方便而引入。比如原链表为 a -&gt; b -&gt; c，则加了哨兵节点的链表即为 x -&gt; a -&gt; b &gt; c。</p>
<p>那我们为什么需要引入哨兵节点呢?举个例子，比如我们要删除某链表的第一个元素，常见的删除链表<br>的操作是找到要删元素的前一个元素，假如我们记为pre。我们通过：</p>
<p>pre.Next = pre.Next.Next</p>
<p>来进行删除链表的操作。但是此时若是删除第一个元素的话，你就很难进行了，因为按道理来讲，此时<br>第一个元素的前一个元素就是nil（空的），如果使用pre就会报错。那如果此时你设置了哨兵节点的<br>话，此时的pre就是哨兵节点了。这样对于链表中的任何一个元素，你要删除都可以通过 pre.Next =<br>pre.Next.Next 的方式来进行，这就是哨兵节点的作用。</p>
</blockquote>
<p><strong>[第19题]</strong>  给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。 </p>
<ul>
<li>示例：<br>给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 n = 2.<br>当删除了倒数第二个节点后，链表变为 1-&gt;2-&gt;3-&gt;5.</li>
</ul>
<p>说明： 给定的 n 保证是有效的。<br>进阶： 你能尝试使用一趟扫描实现吗？ </p>
<blockquote>
<p>首先我们思考，让我们删除倒数第N个元素，那我们只要找到倒数第N个元素就可以了，那怎么找<br>呢？我们只需要设置两个指针变量，中间间隔N-1元素。当后面的指针遍历完所有元素指向nil<br>时，前面的指针就指向了我们要删除的元素。</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/3.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeNthFromEnd</span>(<span class="params">self, head: ListNode, n: <span class="built_in">int</span></span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="comment"># 思路：双指针法。</span></span><br><span class="line">        slow = fast = head</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):  <span class="comment"># 先让fast走n步</span></span><br><span class="line">            fast = fast.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">if</span> fast == <span class="literal">None</span>:  <span class="comment"># 若走了n步后为None，则表明删除的为head节点</span></span><br><span class="line">            <span class="keyword">return</span> head.<span class="built_in">next</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> fast.<span class="built_in">next</span> != <span class="literal">None</span>:  <span class="comment"># slow和fast同时往前走</span></span><br><span class="line">            slow = slow.<span class="built_in">next</span>  <span class="comment"># 当fast走到头时，second即是要删除节点的前一个节点位置</span></span><br><span class="line">            fast = fast.<span class="built_in">next</span></span><br><span class="line">        slow.<span class="built_in">next</span> = slow.<span class="built_in">next</span>.<span class="built_in">next</span>  <span class="comment"># 删除该节点</span></span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了82.68% 的Python3用户<br>内存消耗:13.4 MB,击败了31.27% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">removeNthFromEnd</span><span class="params">(ListNode head, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        ListNode res = <span class="keyword">new</span> ListNode(<span class="number">0</span>, head);</span><br><span class="line">        ListNode fast = head;</span><br><span class="line">        ListNode slow = res;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(fast.next!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            fast=fast.next;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="keyword">if</span>(i &gt;= n) slow = slow.next;   </span><br><span class="line">        &#125;</span><br><span class="line">        slow.next = slow.next.next;</span><br><span class="line">        <span class="keyword">return</span> res.next;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.5 MB, 在所有 Java 提交中击败了33.64% 的用户</p>
<h3 id="2-合并两个有序链表"><a href="#2-合并两个有序链表" class="headerlink" title="2.合并两个有序链表"></a>2.合并两个有序链表</h3><p><strong>[第21题]</strong> 将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 </p>
<ul>
<li>示例：<br>输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4<br>输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4</li>
</ul>
<blockquote>
<p>首先我们维护一个prehead的哨兵节点。我们其实只需要调整它的next指针。让它总是指向l1或者l2中较小的一个，直到l1或者l2任一指向null。这样到了最后，如果l1还是l2中任意一方还有余下元素没有用到，那余下的这些元素一定大于prehead已经合并完的链表（因为是有序链表）。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mergeTwoLists</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="comment"># 创建一个新链表</span></span><br><span class="line">        cur = ListNode()</span><br><span class="line">        <span class="comment"># 设置哨兵节点</span></span><br><span class="line">        result = cur</span><br><span class="line">        <span class="comment"># 指向两者中小的</span></span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">and</span> l2:</span><br><span class="line">            <span class="keyword">if</span> l1.val &lt; l2.val:</span><br><span class="line">                cur.<span class="built_in">next</span> = l1</span><br><span class="line">                l1 = l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                cur.<span class="built_in">next</span> = l2</span><br><span class="line">                l2 = l2.<span class="built_in">next</span></span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="comment"># 将其中一方剩余的添加进来</span></span><br><span class="line">        <span class="keyword">if</span> l1 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cur.<span class="built_in">next</span> = l1</span><br><span class="line">        <span class="keyword">if</span> l2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cur.<span class="built_in">next</span> = l2</span><br><span class="line">        <span class="keyword">return</span> result.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了48.83% 的Python3用户<br>内存消耗:13.3 MB,击败了79.52% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">mergeTwoLists</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        ListNode res = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        ListNode p = res;</span><br><span class="line">        <span class="keyword">while</span>(l1!=<span class="keyword">null</span> &amp;&amp; l2!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(l1.val&lt;=l2.val)&#123;</span><br><span class="line">                p.next = l1;</span><br><span class="line">                l1 = l1.next;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                p.next = l2;</span><br><span class="line">                l2 = l2.next;</span><br><span class="line">            &#125;</span><br><span class="line">            p = p.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(l1!=<span class="keyword">null</span>) p.next = l1;</span><br><span class="line">        <span class="keyword">if</span>(l2!=<span class="keyword">null</span>) p.next = l2;</span><br><span class="line">        <span class="keyword">return</span> res.next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了10.58% 的用户</p>
<h3 id="3-环形链表"><a href="#3-环形链表" class="headerlink" title="3.环形链表"></a>3.环形链表</h3><p><strong>[第141题]</strong> 给定一个链表，判断链表中是否有环。如果链表中有某个节点，可以通过连续跟踪next指针再次到达，则链表中存在环。 为了表示给定链表中的环，我们使用整数pos来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果pos是 -1，则在该链表中没有环。注意：pos不作为参数进行传递，仅仅是为了标识链表的实际情况。 如果链表中存在环，则返回true 。 否则，返回false 。 </p>
<ul>
<li>示例 1：输入：head = [3,2,0,-4], pos = 1<br>输出：true<br>解释：链表中有一个环，其尾部连接到第二个节点。</li>
<li>示例 2：输入：head = [1,2], pos = 0<br>输出：true<br>解释：链表中有一个环，其尾部连接到第一个节点。</li>
<li>示例 3：输入：head = [1], pos = -1<br>输出：false<br>解释：链表中没有环。</li>
</ul>
<p>进阶：你能用O(1)（即，常量）内存解决此问题吗？</p>
<p><strong>方法一：哈希表判定</strong></p>
<blockquote>
<p>思路：通过hash表来检测节点之前是否被访问过，来判断链表是否成环。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasCycle</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="built_in">hash</span> = &#123;&#125;</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            <span class="keyword">if</span> head <span class="keyword">in</span> <span class="built_in">hash</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="built_in">hash</span>[head] = <span class="number">1</span></span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:64 ms,击败了58.42% 的Python3用户<br>内存消耗:16.4 MB,击败了32.63% 的Python3用户</p>
<p><strong>方法二：双指针</strong></p>
<blockquote>
<p>本题标准解法！常识内容，必须掌握！</p>
<p>思路来源：先想象一下，两名运动员以不同速度在跑道上进行跑步会怎么样？相遇！好了，这道题你会<br>了。</p>
<p>解题方法：通过使用具有不同速度的快、慢两个指针遍历链表，空间复杂度可以被降低至 O(1)。慢指<br>针每次移动一步，而快指针每次移动两步。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hasCycle</span>(<span class="params">self, head: ListNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        slow, fast = head, head</span><br><span class="line">        <span class="keyword">while</span> fast <span class="keyword">and</span> fast.<span class="built_in">next</span>:</span><br><span class="line">            <span class="comment"># 慢指针，每次走一步; 快指针，每次走两步</span></span><br><span class="line">            slow, fast = slow.<span class="built_in">next</span>, fast.<span class="built_in">next</span>.<span class="built_in">next</span></span><br><span class="line">            <span class="comment"># 快慢指针相遇，表示有环</span></span><br><span class="line">            <span class="keyword">if</span> fast <span class="keyword">is</span> slow:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:48 ms,击败了99.09% 的Python3用户<br>内存消耗:16.3 MB,击败了77.10% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasCycle</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">       ListNode fast = head;</span><br><span class="line">       ListNode slow = head;</span><br><span class="line">       <span class="keyword">while</span>(fast!=<span class="keyword">null</span> &amp;&amp; fast.next!=<span class="keyword">null</span>)&#123;</span><br><span class="line">           slow = slow.next;</span><br><span class="line">           fast = fast.next.next;</span><br><span class="line">           <span class="keyword">if</span>(fast==slow) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">false</span>;  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：39.7 MB, 在所有 Java 提交中击败了13.26% 的用户</p>
<h3 id="4-两数相加"><a href="#4-两数相加" class="headerlink" title="4.两数相加"></a>4.两数相加</h3><p><strong>[第2题]</strong> 给出两个非空的链表用来表示两个非负的整数。其中，它们各自的位数是按照逆序的方式存储的，并且它们的每个节点只能存储一位数字。如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。您可以假设除了数字 0 之外，这两个数都不会以 0 开头。</p>
<ul>
<li>示例：<br>输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)<br>输出：7 -&gt; 0 -&gt; 8<br>原因：342 + 465 = 807</li>
</ul>
<blockquote>
<p>加法肯定是从最低位到最高位进行相加，也就是这里的<strong>链表头到链表尾进行相加，所以需要遍历链表</strong>。</p>
<p>令 l1 和 l2 指向两个链表的头，用一个tmp值来存储同一位相加的结果，以及一个新的链表来存储tmp的值。</p>
<p><strong>所有模拟运算的题目，都需要考虑进位</strong>。<strong>我们使用tmp携带进位的值到下一位的运算</strong>。自然，这里的链表也不能直接存储tmp的值了，而是要存储tmp%10的值。重复这个步骤，<strong>直到两个链表都遍历完成，并且 tmp 没有进位值</strong>。</p>
<p><strong>因为我们没有构造哨兵节点，所以此时不太容易直接返回新链表</strong>。所以在整个流程的第一步，我们还需要用一个哨兵节点指向我们的新链表。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addTwoNumbers</span>(<span class="params">self, l1: ListNode, l2: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        <span class="built_in">list</span> = ListNode()</span><br><span class="line">        result = <span class="built_in">list</span></span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> l1 <span class="keyword">or</span> l2 <span class="keyword">or</span> tmp != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> l1:</span><br><span class="line">                tmp += l1.val</span><br><span class="line">                l1 = l1.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">if</span> l2:</span><br><span class="line">                tmp += l2.val</span><br><span class="line">                l2 = l2.<span class="built_in">next</span></span><br><span class="line">            <span class="built_in">list</span>.<span class="built_in">next</span> = ListNode(tmp % <span class="number">10</span>)</span><br><span class="line">            tmp //= <span class="number">10</span></span><br><span class="line">            <span class="built_in">list</span> = <span class="built_in">list</span>.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> result.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:72 ms,击败了84.37% 的Python3用户<br>内存消耗:13.6 MB,击败了6.12% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        ListNode res = <span class="keyword">new</span> ListNode();</span><br><span class="line">        ListNode p = res;</span><br><span class="line">        <span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l1!=<span class="keyword">null</span> || l2!=<span class="keyword">null</span> || tmp != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(l1!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                tmp += l1.val;</span><br><span class="line">                l1 = l1.next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(l2!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                tmp += l2.val;</span><br><span class="line">                l2 = l2.next;</span><br><span class="line">            &#125;</span><br><span class="line">            p.next = <span class="keyword">new</span> ListNode(tmp % <span class="number">10</span>);</span><br><span class="line">            tmp /= <span class="number">10</span>;</span><br><span class="line">            p = p.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res.next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了49.86% 的用户</p>
<h2 id="动态规划系列"><a href="#动态规划系列" class="headerlink" title="动态规划系列"></a>动态规划系列</h2><blockquote>
<p>关于动态规划的资料很多，官方的定义是指把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解。概念中的各阶段之间的关系，其实指的就是状态转移方程。很多人觉得DP难（下文统称动态规划为DP），根本原因是因为DP跟一些固定形式的算法不同（比如DFS、二分法、KMP），它没有实际的步骤规定第一步、第二步来做什么，所以准确来说，DP其实是一种解决问题的思想。</p>
<p>这种思想的本质是：一个规模比较大的问题（可以用两三个参数表示的问题），可以通过若干规模较小的问题的结果来得到的（通常会寻求到一些特殊的计算逻辑，如求最值等）。</p>
<p>那么我们应该如何通过子问题去得到大规模问题呢？这就用到了状态转移方程，我们一般看到的状态转移方程，基本都是这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;opt ：指代特殊的计算逻辑，通常为 max or min。</span><br><span class="line">&gt;i,j,k 都是在定义DP方程中用到的参数。</span><br><span class="line">&gt;dp[i] = opt(dp[i-1])+1</span><br><span class="line">&gt;dp[i][j] = w(i,j,k) + opt(dp[i-1][k])</span><br><span class="line">&gt;dp[i][j] = opt(dp[i-1][j] + xi, dp[i][j-1] + yj, ...)</span><br></pre></td></tr></table></figure>
<p>每一个状态转移方程，多少都有一些细微的差别。这个其实很容易理解，世间的关系多了去了，不可能抽象出完全可以套用的公式。所以我个人其实不建议去死记硬背各种类型的状态转移方程。</p>
</blockquote>
<h3 id="1-爬楼梯"><a href="#1-爬楼梯" class="headerlink" title="1.爬楼梯"></a>1.爬楼梯</h3><p><strong>[第70题]</strong> 假设你正在爬楼梯。需要n阶你才能到达楼顶。每次你可以爬1或2个台阶。你有多少种不同的方法可以爬到楼顶呢？注意：给定n是一个正整数。 </p>
<ul>
<li>示例 1：<br>输入： 2<br>输出： 2<br>解释： 有两种方法可以爬到楼顶。</li>
</ul>
<ol>
<li>1 阶 + 1 阶 </li>
<li>2 阶 </li>
</ol>
<ul>
<li>示例 2：<br>输入： 3<br>输出： 3<br>解释： 有三种方法可以爬到楼顶。</li>
</ul>
<ol>
<li>1 阶 + 1 阶 + 1 阶</li>
<li>1 阶 + 2 阶</li>
<li>2 阶 + 1 阶</li>
</ol>
<blockquote>
<p>通过分析我们可以明确，该题可以被分解为一些包含最优子结构的子问题，即它的最优解可以从其子问题的最优解来有效地构建。满足“将大问题分解为若干个规模较小的问题”的条件。所我们令dp[n]表示能到达第n阶的方法总数，可以得到如下状态转移方程：</p>
<p>dp[n]=dp[n-1]+dp[n-2]</p>
<p>上 1 阶台阶：有1种方式。<br>上 2 阶台阶：有1+1和2两种方式。<br>上 3 阶台阶：到达第3阶的方法总数就是到第1阶和第2阶的方法数之和。<br>上 n 阶台阶，到达第n阶的方法总数就是到第 (n-1) 阶和第 (n-2) 阶的方法数之和。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">climbStairs</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        dp = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> n &gt;= <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>, n+<span class="number">1</span>):</span><br><span class="line">                dp.append(dp[i-<span class="number">1</span>] + dp[i-<span class="number">2</span>])</span><br><span class="line">        <span class="keyword">return</span> dp[n]</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了87.16% 的Python3用户<br>内存消耗:13.4 MB,击败了50.33% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">climbStairs</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=n; i++) dp[i] = dp[i-<span class="number">1</span>] + dp[i-<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">return</span> dp[n]; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.3 MB, 在所有 Java 提交中击败了38.13% 的用户</p>
<h3 id="2-最大子序和"><a href="#2-最大子序和" class="headerlink" title="2.最大子序和"></a>2.最大子序和</h3><p><strong>[第53题]</strong> 给定一个整数数组nums，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 </p>
<ul>
<li>示例:<br>输入: [-2,1,-3,4,-1,2,1,-5,4]<br>输出: 6<br>解释: 连续子数组 [4,-1,2,1] 的和最大，为6。</li>
</ul>
<blockquote>
<p>首先我们分析题目，一个连续子数组一定要以一个数作为结尾，那么我们可以将状态定义成如下：</p>
<p>dp[i]：表示以nums[i]结尾的连续子数组的最大和。</p>
<p>根据状态的定义，我们继续进行分析：如果要得到dp[i]，那么nums[i]一定会被选取。并且dp[i]所表示的连续子序列与dp[i-1]所表示的连续子序列很可能就差一个nums[i] 。即：</p>
<p>dp[i] = dp[i-1]+nums[i] , if (dp[i-1] &gt;= 0)</p>
<p>但是这里我们遇到一个问题，很有可能dp[i-1]本身是一个负数。那这种情况的话，如果dp[i]通过dp[i-1]+nums[i] 来推导，那么结果其实反而变小了，因为我们dp[i]要求的是最大和。所以在这种情况下，如果dp[i-1] &lt; 0，那么dp[i]其实就是nums[i]的值。即</p>
<p>dp[i] = nums[i] , if (dp[i-1] &lt; 0)</p>
<p>综上分析，我们可以得到：</p>
<p>dp[i]=max(nums[i], dp[i−1]+nums[i])</p>
<p>得到了状态转移方程，但是我们还需要通过一个已有的状态的进行推导，我们可以想到dp[0]一定是以nums[0]进行结尾，所以</p>
<p>dp[i] = dp[i-1]+nums[i] , if (dp[i-1] &gt;= 0)<br>dp[0] = nums[0]</p>
<p>在很多题目中，因为dp[i]本身就定义成了题目中的问题，所以dp[i]最终就是要的答案。但是这里状态中的定义，并不是题目中要的问题，不能直接返回最后的一个状态 (这一步经常有初学者会摔跟头)。所以最终的答案，其实我们是寻找：</p>
<p>max(dp[0], dp[1], …, d[i-1], dp[i])</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSubArray</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [nums[<span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> dp[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            dp.append(<span class="built_in">max</span>(nums[i], dp[i-<span class="number">1</span>]+nums[i]))</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp)</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了90.97% 的Python3用户<br>内存消耗:14.2 MB,击败了24.24% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">        dp[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> res = dp[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;nums.length;i++)&#123;</span><br><span class="line">            dp[i] = Math.max(dp[i-<span class="number">1</span>]+nums[i], nums[i]);</span><br><span class="line">            res = Math.max(res, dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了94.84% 的用户<br>内存消耗：38.3 MB, 在所有 Java 提交中击败了76.68% 的用户</p>
<h3 id="3-最长上升子序列"><a href="#3-最长上升子序列" class="headerlink" title="3.最长上升子序列"></a>3.最长上升子序列</h3><p><strong>[第300题]</strong> 给定一个无序的整数数组，找到其中最长上升子序列的长度。 </p>
<ul>
<li>示例:<br>输入: [10,9,2,5,3,7,101,18]<br>输出: 4<br>解释: 最长的上升子序列是 [2,3,7,101]，它的长度是 4。 </li>
</ul>
<p>说明: 可能会有多种最长上升子序列的组合，你只需要输出对应的长度即可。 </p>
<blockquote>
<p>首先我们分析题目，要找的是最长上升子序列（Longest Increasing Subsequence，LIS）。因为题目中没有要求连续，所以LIS可能是连续的，也可能是非连续的。同时，LIS符合可以从其子问题的最优解来进行构建的条件。所以我们可以尝试用动态规划来进行求解。首先我们定义状态：</p>
<p>dp[i] ：表示以nums[i]结尾的最长上升子序列的长度</p>
<p>我们分两种情况进行讨论：</p>
<p>如果nums[i]比前面的所有元素都小，那么dp[i]等于1（即它本身）（该结论正确）</p>
<p>如果nums[i]前面存在比他小的元素，那么dp[i]就等于dp[i] = max(dp[j]+1，dp[k]+1，dp[p]+1，…..)<br>只要满足：<br>nums[i] &gt; nums[j]<br>nums[i] &gt; nums[k]<br>nums[i] &gt; nums[p]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLIS</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [<span class="number">1</span>]</span><br><span class="line">        result = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(nums)):</span><br><span class="line">            dp.append(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                <span class="keyword">if</span> nums[i] &gt; nums[j]:</span><br><span class="line">                    dp[i] = <span class="built_in">max</span>(dp[j]+<span class="number">1</span>, dp[i])</span><br><span class="line">            result = <span class="built_in">max</span>(result, dp[i])</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:1344 ms,击败了26.36% 的Python3用户<br>内存消耗:13.6 MB,击败了5.92% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> maxLen = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;i; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] &gt; nums[j]) maxLen = Math.max(maxLen, dp[j]+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            dp[i] = maxLen;</span><br><span class="line">            res = Math.max(res, dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：67 ms, 在所有 Java 提交中击败了75.12% 的用户<br>内存消耗：38.3 MB, 在所有 Java 提交中击败了15.62% 的用户</p>
<h3 id="4-三角形最小路径和"><a href="#4-三角形最小路径和" class="headerlink" title="4.三角形最小路径和"></a>4.三角形最小路径和</h3><p><strong>[第120题]</strong> 给定一个三角形，找出自顶向下的最小路径和。每一步只能移动到下一行中相邻的结点上。 相邻的结点在这里指的是下标与上一层结点下标相同或者等上一层结点下标 + 1的两个点。 </p>
<ul>
<li>例如，给定三角形： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[	[2],     </span><br><span class="line">   [3,4],    </span><br><span class="line">  [6,5,7],   </span><br><span class="line"> [4,1,8,3]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
自顶向下的最小路径和为11（即，2 + 3 + 5 + 1 = 11）。 </li>
</ul>
<blockquote>
<p>我们根据题目中给出的条件：每一步只能移动到下一行中相邻的结点上。其实也就等同于，每一步我们只能往下移动一格或者右下移动一格。将其转化成代码，假如2所在的元素位置为[0,0]，那我们往下移动就只能移动到[1,0]或者[1,1]的位置上。假如5所在的位置为[2,1]，同样也只能移动到[3,1]和[3,2]的位置上。</p>
<p>所以我们通过动态规划进行求解。首先，我们定义状态：<br><code>dp[i][j] : 表示包含第i行j列元素的最小路径和</code><br>我们很容易想到可以自顶向下进行分析。并且，无论最后的路径是哪一条，它一定要经过最顶上的元<br>素，即<code>[0,0]</code>。所以我们需要对<code>dp[0][0]</code>进行初始化。<br><code>dp[0][0] = [0][0]位置所在的元素值</code><br>继续分析，如果我们要求<code>dp[i][j]</code>，那么其一定会从自己头顶上的两个元素移动而来。<br>得到状态转移方程：<br><code>dp[i][j] = min(dp[i-1][j-1],dp[i-1][j]) + triangle[i][j]</code><br>但是，我们这里会遇到一个问题！除了最顶上的元素之外，<br><strong>最左边的元素只能从自己头顶而来</strong><br><strong>最右边的元素只能从自己左上角而来</strong><br>然后，我们观察发现，位于第2行的元素，都是特殊元素（因为都只能从[0,0]的元素走过来）<br>我们可以直接将其特殊处理，得到：<br><code>dp[1][0] = triangle[1][0] + triangle[0][0]</code><br><code>dp[1][1] = triangle[1][1] + triangle[0][0]</code><br>最后，我们只要找到最后一行元素中，路径和最小的一个，就是我们的答案。即：<br><code>l：dp数组长度</code><br><code>result = min(dp[l-1,0]，dp[l-1,1]，dp[l-1,2]....)</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minimumTotal</span>(<span class="params">self, triangle: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(triangle) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(triangle)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(triangle[i])):</span><br><span class="line">                <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                    triangle[i][j] = triangle[i - <span class="number">1</span>][j] + triangle[i][j]</span><br><span class="line">                <span class="keyword">elif</span> j == <span class="built_in">len</span>(triangle[i]) - <span class="number">1</span>:</span><br><span class="line">                    triangle[i][j] = triangle[i - <span class="number">1</span>][j - <span class="number">1</span>] + triangle[i][j]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    triangle[i][j] = <span class="built_in">min</span>(triangle[i - <span class="number">1</span>][j], triangle[i - <span class="number">1</span>][j - <span class="number">1</span>]) + triangle[i][j]</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">min</span>(triangle[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了96.02% 的Python3用户<br>内存消耗:14 MB,击败了39.84% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minimumTotal</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; triangle)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = triangle.size();</span><br><span class="line">        <span class="keyword">if</span>(n &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n][n];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = triangle.get(<span class="number">0</span>).get(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span>(n &lt; <span class="number">2</span>) <span class="keyword">return</span> dp[<span class="number">0</span>][<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> res = Integer.MAX_VALUE;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; triangle.get(i).size(); j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j == <span class="number">0</span>) dp[i][j] = triangle.get(i).get(j) + dp[i - <span class="number">1</span>][j];</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(j == triangle.get(i).size()-<span class="number">1</span>)&#123;</span><br><span class="line">                    dp[i][j] = triangle.get(i).get(j) + dp[i - <span class="number">1</span>][j-<span class="number">1</span>];</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    dp[i][j] = triangle.get(i).get(j) + Math.min(dp[i - <span class="number">1</span>][j], dp[i - <span class="number">1</span>][j - <span class="number">1</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(i == n-<span class="number">1</span>) res = Math.min(res, dp[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：5 ms, 在所有 Java 提交中击败了21.88% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了5.22% 的用户</p>
<p><strong>优化：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minimumTotal</span><span class="params">(List&lt;List&lt;Integer&gt;&gt; triangle)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = triangle.size();</span><br><span class="line">        <span class="comment">//因为当前状态只与上一行的列有关，因此可以压缩空间</span></span><br><span class="line">        <span class="comment">//dp[j]代表第j列的最小路径和</span></span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        dp[<span class="number">0</span>] = triangle.get(<span class="number">0</span>).get(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">            <span class="comment">//更新最后一列</span></span><br><span class="line">            dp[i] = dp[i - <span class="number">1</span>] + triangle.get(i).get(i);</span><br><span class="line">            <span class="comment">//更新中间列</span></span><br><span class="line">            <span class="comment">//需要逆序，否则上一列的值会被覆盖</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i - <span class="number">1</span>; j &gt; <span class="number">0</span>; --j) &#123;</span><br><span class="line">                dp[j] = Math.min(dp[j - <span class="number">1</span>], dp[j]) + triangle.get(i).get(j);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//更新第0列</span></span><br><span class="line">            dp[<span class="number">0</span>] += triangle.get(i).get(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> minTotal = dp[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; ++i) &#123;</span><br><span class="line">            minTotal = Math.min(minTotal, dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> minTotal;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了94.30% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了5.22% 的用户</p>
<h3 id="5-最小路径和"><a href="#5-最小路径和" class="headerlink" title="5.最小路径和"></a>5.最小路径和</h3><p><strong>[第64题]</strong> 给定一个包含非负整数的m x n网格，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。 说明：每次只能向下或者向右移动一步。 </p>
<ul>
<li>示例:<br>输入:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">[1,3,1],</span><br><span class="line">[1,5,1],</span><br><span class="line">[4,2,1]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
输出: 7<br>解释: 因为路径 1→3→1→1→1 的总和最小。</li>
</ul>
<blockquote>
<p>该题与上一道求三角形最小路径和一样，题目明显符合可以从子问题的最优解进行构建，所以我们考虑使用动态规划进行求解。首先，我们定义状态：<br><code>dp[i][j] : 表示包含第i行j列元素的最小路径和</code><br>同样，因为任何一条到达右下角的路径，都会经过<code>[0,0]</code>这个元素。所以我们需要对<code>dp[0][0]</code>进行初始化。<br><code>dp[0][0] = [0][0]位置所在的元素值</code><br>如果我们要求<code>dp[i][j]</code> ，那么它一定是从自己的上方或者左边移动而来<br>进而我们得到状态转移方程：<br><code>dp[i][j] = min(dp[i-1][j],dp[i][j-1]) + grid[i][j]</code><br>同样我们需要考虑两种特殊情况：<br><strong>最上面一行，只能由左边移动而来</strong><br><strong>最左边一列，只能由上面移动而来</strong><br>最后，因为我们的目标是从左上角走到右下角，整个网格的最小路径和其实就是包含右下角元素的最小路径和。即：<br><code>最终结果就是：dp[l-1][len(dp[l-1])-1]</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minPathSum</span>(<span class="params">self, grid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(grid)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(grid[i])):</span><br><span class="line">                <span class="keyword">if</span> (i == <span class="number">0</span>) <span class="keyword">and</span> (j == <span class="number">0</span>):</span><br><span class="line">                    grid[i][j] = grid[i][j]</span><br><span class="line">                <span class="keyword">elif</span> (i == <span class="number">0</span>) <span class="keyword">and</span> (j != <span class="number">0</span>):</span><br><span class="line">                    grid[i][j] = grid[i][j-<span class="number">1</span>] + grid[i][j]</span><br><span class="line">                <span class="keyword">elif</span> (i != <span class="number">0</span>) <span class="keyword">and</span> (j == <span class="number">0</span>):</span><br><span class="line">                    grid[i][j] = grid[i-<span class="number">1</span>][j] + grid[i][j]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    grid[i][j] = <span class="built_in">min</span>(grid[i][j-<span class="number">1</span>], grid[i-<span class="number">1</span>][j]) + grid[i][j]</span><br><span class="line">        <span class="keyword">return</span> grid[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:72 ms,击败了19.09% 的Python3用户<br>内存消耗:14.8 MB,击败了23.49% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minPathSum</span><span class="params">(<span class="keyword">int</span>[][] grid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; grid.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j &lt; grid[<span class="number">0</span>].length; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span> &amp;&amp; j==<span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(i==<span class="number">0</span> &amp;&amp; j != <span class="number">0</span>) grid[i][j] = grid[i][j-<span class="number">1</span>] + grid[i][j];</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(i!=<span class="number">0</span> &amp;&amp; j == <span class="number">0</span>) grid[i][j] = grid[i-<span class="number">1</span>][j] + grid[i][j];</span><br><span class="line">                <span class="keyword">else</span> grid[i][j] = Math.min(grid[i-<span class="number">1</span>][j], grid[i][j-<span class="number">1</span>]) + grid[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> grid[grid.length-<span class="number">1</span>][grid[<span class="number">0</span>].length-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了15.82% 的用户<br>内存消耗：41 MB, 在所有 Java 提交中击败了86.60% 的用户</p>
<h3 id="6-打家劫舍"><a href="#6-打家劫舍" class="headerlink" title="6.打家劫舍"></a>6.打家劫舍</h3><p><strong>[第198题]</strong> 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。给定一个代表每个房屋存放金额的非负整数数组，计算你不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 </p>
<ul>
<li>示例 1：<br>输入：[1,2,3,1]<br>输出：4<br>解释：偷窃1号房屋 (金额 = 1) ，然后偷窃3号房屋 (金额 = 3)。偷窃到的最高金额 = 1 + 3 = 4 。 </li>
<li>示例 2：<br>输入：[2,7,9,3,1]#<br>输出：12<br>解释：偷窃1号房屋 (金额 = 2), 偷窃3号房屋 (金额 = 9)，接着偷窃5号房屋 (金额 = 1)。偷窃到的最高金额 = 2 + 9 + 1 = 12 。</li>
</ul>
<blockquote>
<p>定义出状态:<br><code>dp[i] : 偷盗至第i个房子时，所获取的最大利益</code><br>因为小偷一定会从前偷到最后（强调：偷盗至第i个房间，不代表小偷要从第i个房间中获取财物）。所以我们的最终答案很容易确定。即：<code>dp[i]</code><br>由于不可以在相邻的房屋闯入，所以至i房屋可盗窃的最大值，要么就是至i-1房屋可盗窃的最大值，要么就是至i-2房屋可盗窃的最大值加上当前房屋的值，二者之间取最大值，即：<br><code>dp[i] = max(dp[i-2]+nums[i], dp[i-1])</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rob</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) &lt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                nums[i] = nums[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">elif</span> i == <span class="number">1</span>:</span><br><span class="line">                nums[i] = <span class="built_in">max</span>(nums[<span class="number">0</span>], nums[<span class="number">1</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                nums[i] = <span class="built_in">max</span>(nums[i-<span class="number">2</span>]+nums[i], nums[i-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> nums[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了96.55% 的Python3用户<br>内存消耗:13.5 MB,击败了5.36% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rob</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length &lt; <span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i==<span class="number">0</span>) dp[<span class="number">0</span>] = nums[<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(i==<span class="number">1</span>) dp[<span class="number">1</span>] = Math.max(nums[<span class="number">0</span>], nums[<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">else</span> dp[i] = Math.max(dp[i-<span class="number">1</span>], dp[i-<span class="number">2</span>] + nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[nums.length-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.8 MB, 在所有 Java 提交中击败了61.62% 的用户</p>
<h2 id="字符串系列"><a href="#字符串系列" class="headerlink" title="字符串系列"></a>字符串系列</h2><h3 id="1-反转字符串"><a href="#1-反转字符串" class="headerlink" title="1.反转字符串"></a>1.反转字符串</h3><p><strong>[第344题]</strong> 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组char[]的形式给出。不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用O(1)的额外空间解决这一问题。你可以假设数组中的所有字符都是ASCII码表中的可打印字符。 </p>
<ul>
<li>示例 1：<br>输入：[“h”,”e”,”l”,”l”,”o”]<br>输出：[“o”,”l”,”l”,”e”,”h”]</li>
<li>示例 2：<br>输入：[“H”,”a”,”n”,”n”,”a”,”h”]<br>输出：[“h”,”a”,”n”,”n”,”a”,”H”] </li>
</ul>
<blockquote>
<p>这是一道相当简单的经典题目，直接上题解：使用双指针进行反转字符串。<br>假设输入字符串为[“h”,”e”,”l”,”l”,”0”]<br>定义left和right分别指向首元素和尾元素<br>当left &lt; right ，进行交换。<br>交换完毕，left++，right—<br>直至left == right</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverseString</span>(<span class="params">self, s: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify s in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            s[left], s[right] = s[right], s[left]</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">            right -= <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:48 ms,击败了77.38% 的Python3用户<br>内存消耗:14.6 MB,击败了7.10% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reverseString</span><span class="params">(<span class="keyword">char</span>[] s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = s.length-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (left &lt; right)&#123;</span><br><span class="line">            swap(s, left, right);</span><br><span class="line">            left++;</span><br><span class="line">            right--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">char</span>[] ch,<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">        <span class="keyword">char</span> temp = ch[i];</span><br><span class="line">        ch[i] = ch[j];</span><br><span class="line">        ch[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：45.2 MB, 在所有 Java 提交中击败了33.90% 的用户</p>
<h3 id="2-字符串中的第一个唯一字符"><a href="#2-字符串中的第一个唯一字符" class="headerlink" title="2.字符串中的第一个唯一字符"></a>2.字符串中的第一个唯一字符</h3><p><strong>[第387题]</strong> 给定一个字符串，找到它的第一个不重复的字符，并返回它的索引。如果不存在，则返回 -1。</p>
<ul>
<li>示例：<br>s = “leetcode” 返回 0<br>s = “loveleetcode” 返回 2</li>
</ul>
<p>提示：你可以假定该字符串只包含小写字母。</p>
<p><strong>方法一：用字典</strong></p>
<blockquote>
<p>在数组中记录每个字母的最后一次出现的所在索引。然后再通过一次循环，比较各个字母第一次出现的索引是否为最后一次的索引。如果是，我们就找到了我们的目标，如果不是我们将其设为 -1（标示该元素非目标元素）如果第二次遍历最终没有找到目标，直接返回 -1即可。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">firstUniqChar</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="built_in">dict</span> = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="built_in">dict</span>[s[i]] = i</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="built_in">dict</span>[s[i]]:</span><br><span class="line">                <span class="keyword">return</span> i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">dict</span>[s[i]] = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:128 ms,击败了61.83% 的Python3用户<br>内存消耗:13.7 MB,击败了5.07% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">firstUniqChar</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        Map&lt;Character, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.length(); i++) map.put(s.charAt(i), i);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.length(); i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (i == map.get(s.charAt(i))) <span class="keyword">return</span> i;</span><br><span class="line">            <span class="keyword">else</span> map.put(s.charAt(i), -<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：35 ms, 在所有 Java 提交中击败了27.69% 的用户<br>内存消耗：39.1 MB, 在所有 Java 提交中击败了27.58% 的用户</p>
<p><strong>方法二：用集合</strong></p>
<blockquote>
<p>集合的特性为集合中每个元素都是独一无二的，我们可以利用这特性，将列表转换为集合。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">firstUniqChar</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 转为集合, 将去重后的集合再转化为列表</span></span><br><span class="line">        unique = <span class="built_in">list</span>(<span class="built_in">set</span>(s))</span><br><span class="line">        <span class="comment"># 按原列表索引排序，不改变顺序</span></span><br><span class="line">        unique.sort(key=s.index)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> unique:</span><br><span class="line">            <span class="keyword">if</span> s.count(i) == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> s.index(i)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:76 ms,击败了94.58% 的Python3用户<br>内存消耗:13.7 MB,击败了5.07% 的Python3用户</p>
<h3 id="3-实现Sunday匹配"><a href="#3-实现Sunday匹配" class="headerlink" title="3.实现Sunday匹配"></a>3.实现Sunday匹配</h3><p><strong>[第28题]</strong> 实现strStr()函数。给定一个haystack字符串和一个needle字符串，在haystack字符串中找出needle字符串出现的第一个位置 (从0开始)。如果不存在，则返回-1。 </p>
<ul>
<li>示例 1:<br>输入: haystack = “hello”, needle = “ll”<br>输出: 2</li>
<li>示例 2:<br>输入: haystack = “aaaaa”, needle = “bba”<br>输出: -1</li>
</ul>
<p>说明:<br>当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。 </p>
<p>对于本题而言，当needle是空字符串时我们应当返回0 。这与C语言的strstr()以及Java的indexOf()定义相符。 </p>
<blockquote>
<p>先普及几个概念：</p>
<ul>
<li>串：串是字符串的简称</li>
<li>空串：长度为零的串称为空串</li>
<li>主串：包含子串的串相应地称为主串</li>
<li>子串：串中任意个连续字符组成的子序列称为该串的子串</li>
<li>模式串：子串的定位运算又称为串的模式匹配，是一种求子串第一个字符在主串中序号的运算。被匹配的主串称为目标串，子串称为模式串。</li>
</ul>
<p>对于SUNDAY算法，我们<strong>从头部开始比较，一旦发现不匹配，直接找到主串中位于模式串后面的第一个字符</strong>，即下面绿色的 “s”。（因为，无论模式串移动多少步，模式串后的第一个字符都要参与下一次比较，也就是这里的 “s”）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/53.png" alt></p>
<p>找到了模式串后的第一个字符 “s”，接下来该怎么做？我们需要<strong>查看模式串中是否包含这个元素，如果不包含那就可以跳过一大片，从该字符的下一个字符开始比较。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/54.png" alt></p>
<p>因为仍然不匹配（空格和l），我们继续重复上面的过程。找到模式串的下一个元素：t</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/55.png" alt></p>
<p>现在有意思了，我们发现t被包含于模式串中，并且t出现在模式串倒数第3个。所以我们把模式串向前移动3个单位：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/56.png" alt></p>
<p>捞干货，这个过程里我们做了一些什么：</p>
<ul>
<li>对齐目标串和模式串，从前向后匹配</li>
<li><strong>关注主串中位于模式串后面的第一个元素（核心）</strong></li>
<li>如果关注的字符没有在子串中出现则直接跳过</li>
<li>否则开始移动模式串，移动位数 = 子串长度 - 该字符最右出现的位置(以0开始)</li>
</ul>
</blockquote>
<p>然而这种方法，我这里用Python写会超时，估计原因在于查找索引太耗时，还是用子串逐一比较来的实在<img src="file:///C:\Users\Qiyuan-Z\AppData\LocalLow\Baidu\BAIDUP~1\dict\Default\0F25D2~1.PNG" alt="img"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">strStr</span>(<span class="params">self, haystack: <span class="built_in">str</span>, needle: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        L, n = <span class="built_in">len</span>(needle), <span class="built_in">len</span>(haystack)</span><br><span class="line">        <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(n - L + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> haystack[start: start + L] == needle:</span><br><span class="line">                <span class="keyword">return</span> start</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了97.51% 的Python3用户<br>内存消耗:13.7 MB,击败了17.10% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">strStr</span><span class="params">(String haystack, String needle)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (haystack == <span class="keyword">null</span> || needle == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">if</span> (haystack.length() &lt; needle.length()) &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>; </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//目标串匹配索</span></span><br><span class="line">        <span class="keyword">int</span> originIndex = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//模式串匹配索引</span></span><br><span class="line">        <span class="keyword">int</span> aimIndex = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 成功匹配完终止条件：所有needle均成功匹配</span></span><br><span class="line">        <span class="keyword">while</span> (aimIndex &lt; needle.length()) &#123;</span><br><span class="line">            <span class="comment">// 针对origin匹配完，但needle未匹配完情况处理</span></span><br><span class="line">            <span class="keyword">if</span> (originIndex &gt; haystack.length() - <span class="number">1</span>) <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (haystack.charAt(originIndex) == needle.charAt(aimIndex)) &#123;</span><br><span class="line">                <span class="comment">// 匹配则index均加1</span></span><br><span class="line">                originIndex++;</span><br><span class="line">                aimIndex++;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">//下一个目标字符索引</span></span><br><span class="line">                <span class="keyword">int</span> nextCharIndex = originIndex - aimIndex + needle.length();</span><br><span class="line">                <span class="comment">//判断下一个目标字符（图里的那个绿框框）是否存在。</span></span><br><span class="line">                <span class="keyword">if</span> (nextCharIndex &lt; haystack.length()) &#123;</span><br><span class="line">                    <span class="comment">// 判断目标字符在模式串中匹配到，返回最后一个匹配的index</span></span><br><span class="line">                    <span class="keyword">int</span> step = needle.lastIndexOf(haystack.charAt(nextCharIndex));</span><br><span class="line">                    <span class="keyword">if</span> (step == -<span class="number">1</span>) &#123;</span><br><span class="line">                        <span class="comment">// 不存在的话，设置到目标字符的下一个元素</span></span><br><span class="line">                        originIndex = nextCharIndex + <span class="number">1</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// 存在的话，移动对应的数字（参考上文中的存在公式）</span></span><br><span class="line">                        originIndex = nextCharIndex - step;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">//模式串总是从第一个开始匹配</span></span><br><span class="line">                    aimIndex = <span class="number">0</span>;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> originIndex - aimIndex;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了28.87% 的用户<br>内存消耗：37 MB, 在所有 Java 提交中击败了68.02% 的用户</p>
<h3 id="4-大数打印"><a href="#4-大数打印" class="headerlink" title="4.大数打印"></a>4.大数打印</h3><div class="table-container">
<table>
<thead>
<tr>
<th>剑指offer 17：大数打印</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入数字n，按顺序打印出从1到最大的n位十进制数。比如输入3，则打印出 1、2、3 一直到最大的3位数 999。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: n = 1 </span><br><span class="line">输出: [1,2,3,4,5,6,7,8,9]</span><br></pre></td></tr></table></figure>
<p><strong>说明：</strong></p>
<ul>
<li>用返回一个整数列表来代替打印</li>
<li>n 为正整数</li>
</ul>
<p><strong>题目升级</strong>： <strong>这道题目的名字叫做大数打印，如果阈值超出long类型，该怎么办呢？请手动实现一下！</strong></p>
<blockquote>
<p><strong>采用数组进行存储</strong>。</p>
<ul>
<li>对最低位nSum的值递增（也就是字符串加1运算），当大于等于10时，我们把进位标识改为1，同时恢复对nSum减10（29-31）</li>
<li>通过判断首位是否进位来判断到达最大的n位数情况。比如n=4，只有对9999加1，才会对第一个字符进位。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printNumbers</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        result = []</span><br><span class="line">        num = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        isBegin = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">while</span> isBegin:</span><br><span class="line">            <span class="comment"># tmp用于存储进位，初始值为1代表加1</span></span><br><span class="line">            tmp = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(num)-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="comment"># python divmod() 函数把除数和余数运算结果结合起来，返回一个包含商和余数的元组(a // b, a % b)。</span></span><br><span class="line">                tmp, num[i] = <span class="built_in">divmod</span>(num[i] + tmp, <span class="number">10</span>)</span><br><span class="line">                <span class="keyword">if</span> tmp &gt; <span class="number">0</span> <span class="keyword">and</span> i != <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">elif</span> tmp == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 直到最后一位仍进位就结束</span></span><br><span class="line">                    isBegin = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">if</span> isBegin:</span><br><span class="line">                result.append(<span class="built_in">int</span>(<span class="string">&#x27;&#x27;</span>.join(<span class="built_in">map</span>(<span class="built_in">str</span>, num))))</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行用时：200 ms, 在所有 Python3 提交中击败了5.22% 的用户<br>内存消耗：20.3 MB, 在所有 Python3 提交中击败了18.63% 的用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] printNumbers(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">int</span> max = (<span class="keyword">int</span>)Math.pow(<span class="number">10</span>, n)-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[max];</span><br><span class="line">        <span class="keyword">char</span>[] num  = <span class="keyword">new</span> <span class="keyword">char</span>[n];</span><br><span class="line">        Arrays.fill(num, <span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">        <span class="keyword">boolean</span> isBegin = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(isBegin)&#123;</span><br><span class="line">            <span class="keyword">int</span> tmp = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i =n-<span class="number">1</span>; i&gt;=<span class="number">0</span>; i--)&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = num[i] - <span class="string">&#x27;0&#x27;</span> + tmp;</span><br><span class="line">                num[i] = (<span class="keyword">char</span>) (sum % <span class="number">10</span> + <span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">                tmp = sum / <span class="number">10</span>;</span><br><span class="line">                <span class="keyword">if</span>(tmp &gt; <span class="number">0</span> &amp;&amp; i != <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(tmp == <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">                <span class="keyword">else</span> isBegin = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(isBegin) res[index++] = saveNumber(num);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">saveNumber</span><span class="params">(<span class="keyword">char</span>[] number)</span> </span>&#123;</span><br><span class="line">        String res = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">boolean</span> isBegin = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> c : number) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!isBegin &amp;&amp; c != <span class="string">&#x27;0&#x27;</span>) isBegin = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (isBegin) res += c;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Integer.valueOf(res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：60 ms, 在所有 Java 提交中击败了5.31% 的用户<br>内存消耗：46.3 MB, 在所有 Java 提交中击败了91.10% 的用户</p>
<h3 id="5-验证回文串"><a href="#5-验证回文串" class="headerlink" title="5.验证回文串"></a>5.验证回文串</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第125题：验证回文串</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>说明：</strong> 本题中，我们将空字符串定义为有效的回文串。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: &quot;A man, a plan, a canal: Panama&quot;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: &quot;race a car&quot;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<blockquote>
<p>“回文串”是一个正读和反读都一样的字符串，比如“level”或者“noon”等等就是回文串。</p>
<p>当然，对于本题而言，因为原字符串还包括了除字母，数字之外的一些幺蛾子，所以我们可以考虑将其替换或跳过。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isPalindrome</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="comment"># 转换成小写</span></span><br><span class="line">        s = s.lower()</span><br><span class="line">        <span class="comment"># 两头遍历比对</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; j:</span><br><span class="line">        	<span class="comment"># 跳过特殊符号</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ((s[i] &gt;= <span class="string">&#x27;0&#x27;</span> <span class="keyword">and</span> s[i] &lt;= <span class="string">&#x27;9&#x27;</span>) <span class="keyword">or</span> (s[i] &gt;= <span class="string">&#x27;a&#x27;</span> <span class="keyword">and</span> s[i] &lt;= <span class="string">&#x27;z&#x27;</span>)):</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> ((s[j] &gt;= <span class="string">&#x27;0&#x27;</span> <span class="keyword">and</span> s[j] &lt;= <span class="string">&#x27;9&#x27;</span>) <span class="keyword">or</span> (s[j] &gt;= <span class="string">&#x27;a&#x27;</span> <span class="keyword">and</span> s[j] &lt;= <span class="string">&#x27;z&#x27;</span>)):</span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> s[i] != s[j]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:60 ms,击败了61.53% 的Python3用户<br>内存消耗:13.8 MB,击败了53.68% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        String str = s.toLowerCase();</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> r = str.length()-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">            <span class="keyword">if</span> (!((str.charAt(l) &gt;= <span class="string">&#x27;0&#x27;</span> &amp;&amp; str.charAt(l) &lt;= <span class="string">&#x27;9&#x27;</span>) || (str.charAt(l) &gt;= <span class="string">&#x27;a&#x27;</span> &amp;&amp; str.charAt(l) &lt;= <span class="string">&#x27;z&#x27;</span>)))&#123;</span><br><span class="line">                l++;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!((str.charAt(r) &gt;= <span class="string">&#x27;0&#x27;</span> &amp;&amp; str.charAt(r) &lt;= <span class="string">&#x27;9&#x27;</span>) || (str.charAt(r) &gt;= <span class="string">&#x27;a&#x27;</span> &amp;&amp; str.charAt(r) &lt;= <span class="string">&#x27;z&#x27;</span>)))&#123;</span><br><span class="line">                r--;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(str.charAt(l) != str.charAt(r)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            l++;</span><br><span class="line">            r--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了64.94% 的用户<br>内存消耗：38.4 MB, 在所有 Java 提交中击败了73.12% 的用户</p>
<h3 id="6-KMP"><a href="#6-KMP" class="headerlink" title="6.KMP"></a>6.KMP</h3><blockquote>
<p>KMP 算法常被称为“看毛片算法”，由一个姓K的，一个姓M的，一个姓P 一起提出。<strong>是一种由暴力匹配改进的字符串匹配算法</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/57.png" alt></p>
<p>暴力匹配，就是目标串和模式串一个一个的对比。假若我们目标串长度为m，模式串长度为n。模式串与目标串至少比较m次，又因其自身长度为n，所以理论的时间复杂度为<strong>O(m*n)。</strong> 但因为途中遇到不能匹配的字符时，就可以停止，并不需要完全对比（比如上图第2行）<strong>。所以虽然理论时间复杂度为 </strong>O(m*n) ，但其实大部分情况效率高很多。</p>
<p>下面直接给出 <strong>KMP算法</strong> 的操作流程：</p>
<ul>
<li>假设现在文本串 S 匹配到 i 位置，模式串 P 匹配到 j 位置</li>
<li>如果 j = -1，或者当前字符匹配成功（即 S[i] == P[j] ），都令 i++，j++，继续匹配下一个字符；   如果 j !=  -1，且当前字符匹配失败（即 S[i] != P[j] ），则令 i 不变，j = next[j]。此举意味着失配时，模式串 P相对于文本串 S 向右移动了 j - next [j]  位</li>
<li>换言之，将模式串 P 失配位置的 next 数组的值对应的模式串 P 的索引位置移动到失配处</li>
</ul>
<p>以下图文本串 S 与模式串 P 为例：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/58.jpg" alt><br>求得每一个子串的所有前缀与后缀。<br><strong>前缀</strong>指除了最后一个字符以外，一个字符串的全部头部组合；<strong>后缀</strong>指除了第一个字符以外，一个字符串的全部尾部组合。</p>
<p>求得原模式串 P 的子串对应的各个前缀后缀的公共元素的<strong>最大长度表</strong>下图。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/59.jpg" alt></p>
<p>根据<strong>最大长度表</strong>去求<strong>next数组</strong>：<strong>next数组相当于“最大长度值” 整体向右移动一位，然后初始值赋为-1</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/60.jpg" alt></p>
<p>好了，获取了<strong>next 数组</strong>后，<strong>KMP 算法</strong>的操作就很清晰了。</p>
<p>将模式串 P 与文本串 S 的字母一个个进行匹配，当失配的时候，模式串向右移动。比如模式串的 <strong>b</strong> 与文本串的 <strong>c</strong> 失配了，找出失配处模式串的<strong>next数组</strong>里面对应的值，这里为 <strong>0</strong>，然后将索引为 <strong>0</strong> 的位置移动到失配处。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/61.jpg" alt></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/62.jpg" alt></p>
</blockquote>
<p>例子：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/156.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/154.png" alt><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/155.png" alt></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KMPAlgorithm</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String str1 = <span class="string">&quot;BBC ABCDAB ABCDABCDABDE&quot;</span>;</span><br><span class="line">        String str2 = <span class="string">&quot;ABCDABD&quot;</span>;</span><br><span class="line">        <span class="comment">//得到目标子串的部分匹配值</span></span><br><span class="line">        <span class="keyword">int</span>[] next = kmpNext(str2);</span><br><span class="line">        System.out.println(<span class="string">&quot;next=&quot;</span>+ Arrays.toString(next));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> index = kmpSearch(str1, str2, next);</span><br><span class="line">        System.out.println(<span class="string">&quot;index= &quot;</span> +index);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> str1 源字符串</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> str2 子串</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> next 部分匹配表，是子串对应的部分匹配表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 如果是-1就是没有匹配到，否则返回第一个匹配的位置</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">kmpSearch</span><span class="params">(String str1, String str2, <span class="keyword">int</span>[] next)</span></span>&#123;</span><br><span class="line">        <span class="comment">//遍历</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>, j=<span class="number">0</span>; i&lt; str1.length(); i++) &#123;</span><br><span class="line">            <span class="comment">//若匹配不成功，目标子串偏移, 移动位数为（已匹配字符数-部分匹配值）相当于next右移</span></span><br><span class="line">            <span class="comment">//因此j = j - next[j-1]或j = next[j-1]都可</span></span><br><span class="line">            <span class="keyword">if</span> (j &gt; <span class="number">0</span> &amp;&amp; str1.charAt(i) != str2.charAt(j)) j= next[j-<span class="number">1</span>];</span><br><span class="line">            <span class="comment">//记录已匹配的字符数</span></span><br><span class="line">            <span class="keyword">if</span> (str1.charAt(i) == str2.charAt(j)) j++;</span><br><span class="line">            <span class="comment">//匹配成功, 返回索引</span></span><br><span class="line">            <span class="keyword">if</span> (j == str2.length()) <span class="keyword">return</span> i-j+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//匹配不成功，返回-1</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取到一个字符串（子串）的部分匹配值表</span></span><br><span class="line">    <span class="keyword">public</span>  <span class="keyword">static</span> <span class="keyword">int</span>[] kmpNext(String dest)&#123;</span><br><span class="line">        <span class="comment">//创建一个next数组保存部分匹配值</span></span><br><span class="line">        <span class="keyword">int</span>[] next = <span class="keyword">new</span> <span class="keyword">int</span>[dest.length()];</span><br><span class="line">        next[<span class="number">0</span>] = <span class="number">0</span>;<span class="comment">//如果字符串是长度为1部分匹配值就是0</span></span><br><span class="line">        <span class="comment">// i相当于后缀，一步步遍历目标串的子串, j代表公共前缀长</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>, j=<span class="number">0</span>; i&lt; dest.length(); i++)&#123;</span><br><span class="line">            <span class="comment">//若后缀不等于前缀，则公共前缀长归0</span></span><br><span class="line">            <span class="keyword">if</span> (j &gt; <span class="number">0</span> &amp;&amp; dest.charAt(i) != dest.charAt(j)) j = <span class="number">0</span>;</span><br><span class="line">            <span class="comment">//随着后缀长度增加 若后缀一直等于前缀，公共前缀长+1</span></span><br><span class="line">            <span class="keyword">if</span> (dest.charAt(i) == dest.charAt(j)) j++;</span><br><span class="line">            <span class="comment">//部分匹配值为公共前缀长</span></span><br><span class="line">            next[i] = j;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="7-旋转字符串"><a href="#7-旋转字符串" class="headerlink" title="7.旋转字符串"></a>7.旋转字符串</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第796题：旋转字符串</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定两个字符串, A 和 B。A 的旋转操作就是将 A 最左边的字符移动到最右边。例如, 若 A = ‘abcde’，在移动一次之后结果就是’bcdea’ 。如果在若干次旋转操作之后，A 能变成B，那么返回True。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: A = &#x27;abcde&#x27;, B = &#x27;cdeab&#x27;</span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: A = &#x27;abcde&#x27;, B = &#x27;abced&#x27;</span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong> A 和 B 长度不超过 100。</p>
<blockquote>
<p>无论它怎样旋转，最终的 A + A包含了所有可以通过旋转操作从 A 得到的字符串：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/63.png" alt><br>那我们只需要判断 B 是否为 A + A 的子串就可以了。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotateString</span>(<span class="params">self, A: <span class="built_in">str</span>, B: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(A) == <span class="built_in">len</span>(B) <span class="keyword">and</span> (B <span class="keyword">in</span> (A + A))</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了35.30% 的Python3用户<br>内存消耗:13.4 MB,击败了48.35% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">rotateString</span><span class="params">(String A, String B)</span> </span>&#123;</span><br><span class="line">        String s = A + A;</span><br><span class="line">        <span class="keyword">return</span> A.length()==B.length() &amp;&amp; s.contains(B)?<span class="keyword">true</span>: <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.5 MB, 在所有 Java 提交中击败了37.20% 的用户</p>
<h3 id="8-最后一个单词的长度"><a href="#8-最后一个单词的长度" class="headerlink" title="8.最后一个单词的长度"></a>8.最后一个单词的长度</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第58题：最后一个单词的长度</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个仅包含大小写字母和空格 ‘ ‘ 的字符串 s，返回其最后一个单词的长度。如果字符串从左向右滚动显示，那么最后一个单词就是最后出现的单词。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: &quot;Hello World&quot; </span><br><span class="line">输出: 5</span><br></pre></td></tr></table></figure>
<p><strong>说明：</strong> 一个单词是指仅由字母组成、不包含任何空格字符的 <strong>最大子字符串</strong>。</p>
<blockquote>
<p>题中的陷阱在于，<strong>结尾处仍然可能有空格</strong>。</p>
<p>所以一般的解题思路为，先去掉末尾的空格，然后从尾向前开始遍历，直到遇到第一个空格处结束。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLastWord</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 去除字符串开头或者结尾的空格,再按空格划分</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(s.strip().split(<span class="string">&#x27; &#x27;</span>)[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了94.69% 的Python3用户<br>内存消耗:13.6 MB,击败了12.63% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLastWord</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        String[] str = s.trim().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> str[str.length-<span class="number">1</span>].length();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了38.46% 的用户<br>内存消耗：37.2 MB, 在所有 Java 提交中击败了8.91% 的用户</p>
<h2 id="二叉树系列"><a href="#二叉树系列" class="headerlink" title="二叉树系列"></a>二叉树系列</h2><h3 id="1-最大深度与DFS"><a href="#1-最大深度与DFS" class="headerlink" title="1.最大深度与DFS"></a>1.最大深度与DFS</h3><blockquote>
<p>在计算机科学中，二叉树是每个结点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。二叉树常被用于实现二叉查找树和二叉堆。树比链表稍微复杂，因为链表是线性数据结构，而树不是。树的问题很多都可以由广度优先搜索或深度优先搜索解决。</p>
</blockquote>
<p><strong>[第104题]</strong> 给定一个二叉树，找出其最大深度。二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。说明: 叶子节点是指没有子节点的节点。 </p>
<ul>
<li>示例：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">给定二叉树 [3,9,20,null,null,15,7]，</span><br><span class="line">    3</span><br><span class="line">   / \</span><br><span class="line">  9  20</span><br><span class="line">     / \</span><br><span class="line">    15  7</span><br></pre></td></tr></table></figure>
返回它的最大深度 3 。</li>
</ul>
<p><strong>方法一：递归求解</strong></p>
<blockquote>
<p>每个节点的深度与它左右子树的深度有关，且等于其左右子树最大深度值加上1，即<br><code>maxDepth(root) = max(maxDepth(root.left), maxDepth(root.right)) + 1</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(self.maxDepth(root.left), self.maxDepth(root.right)) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:56 ms,击败了54.54% 的Python3用户<br>内存消耗:15.4 MB,击败了12.04% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> Math.max(maxDepth(root.left), maxDepth(root.right)) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.6 MB, 在所有 Java 提交中击败了12.93% 的用户</p>
<p><strong>方法二：非递归DFS</strong></p>
<blockquote>
<p>DFS：深度优先搜索算法（Depth First Search），对于二叉树而言，它沿着<strong>树的深度遍历树的节点，尽可能深的搜索树的分支，这一过程一直进行到已发现从源节点可达的所有节点为止。</strong><br>如下图二叉树，它的访问顺序为：A-B-D-E-C-F-G<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    a</span><br><span class="line">   / \</span><br><span class="line">  b    c</span><br><span class="line"> / \  / \</span><br><span class="line">d   e f  g</span><br></pre></td></tr></table></figure><br>虽然我们用递归的方式根据DFS的思想顺利完成了题目。但是这种方式的缺点却显而易见。因为在递归中，如果层级过深，我们很可能保存过多的临时变量，导致栈溢出。这也是为什么我们一般不在后台代码中使用递归的原因。<br>事实上，函数调用的参数是通过栈空间来传递的，在调用过程中会占用线程的栈资源。而递归调用，只有走到最后的结束点后函数才能依次退出，而未到达最后的结束点之前，占用的栈空间一直没有释放，如果递归调用次数过多，就可能导致占用的栈资源超过线程的最大值，从而导致栈溢出，导致程序的异常退出。<br>如何将递归的代码转化成非递归的形式。这里请记住，<strong>99%的递归转非递归，都可以通过栈来进行实现。</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment">#stack记录的是节点</span></span><br><span class="line">        <span class="comment">#是同时入栈同时出栈，level记录的是节点在第几层</span></span><br><span class="line">        stack = []</span><br><span class="line">        level = [<span class="number">1</span>]</span><br><span class="line">        maxdepth = <span class="number">0</span></span><br><span class="line">        stack.append(root)</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            <span class="comment">#stack中的元素和level中的元素同时出栈</span></span><br><span class="line">            node = stack.pop()</span><br><span class="line">            temp = level.pop()</span><br><span class="line">            maxdepth = <span class="built_in">max</span>(temp, maxdepth)</span><br><span class="line">            <span class="keyword">if</span> node.right:</span><br><span class="line">                <span class="comment"># 同时入栈</span></span><br><span class="line">                stack.append(node.right)</span><br><span class="line">                level.append(temp + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> node.left:</span><br><span class="line">                <span class="comment"># 同时入栈</span></span><br><span class="line">                stack.append(node.left)</span><br><span class="line">                level.append(temp + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> maxdepth</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了97.17% 的Python3用户<br>内存消耗:14.6 MB,击败了81.81% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        Stack&lt;TreeNode&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        Stack&lt;Integer&gt; level = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> maxdepth = <span class="number">0</span>;</span><br><span class="line">        stack.push(root);</span><br><span class="line">        level.push(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">while</span>(!stack.empty())&#123;</span><br><span class="line">            TreeNode node = stack.pop();</span><br><span class="line">            <span class="keyword">int</span> tmp = level.pop();</span><br><span class="line">            maxdepth = Math.max(maxdepth, tmp);</span><br><span class="line">            <span class="keyword">if</span>(node.right!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(node.right);</span><br><span class="line">                level.push(tmp+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(node.left!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(node.left);</span><br><span class="line">                level.push(tmp+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxdepth;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了16.83% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了94.17% 的用户</p>
<p>如果不理解代码，请看下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/4.jpg" alt></p>
<p>1：首先将a压入栈<br>2：a弹栈，将c、b压入栈（注意顺序）<br>3：b弹栈，将e、d压入栈<br>4：d、e、c弹栈，将g、f压入栈<br>5：f、g弹栈</p>
<p><strong>唯一需要强调的是，为什么需要先右后左压入数据？是因为我们需要将先访问的数据，后压入栈（请思考栈的特点）。</strong></p>
<h3 id="2-层次遍历与BFS"><a href="#2-层次遍历与BFS" class="headerlink" title="2.层次遍历与BFS"></a>2.层次遍历与BFS</h3><blockquote>
<p>在上一节中，我们通过例题学习了二叉树的DFS（深度优先搜索），其实就是沿着一个方向一直<br>向下遍历。那我们可不可以按照高度一层一层的访问树中的数据呢？当然可以，就是本节中我们<br>要讲的BFS（宽度优先搜索），同时也被称为广度优先搜索。</p>
<p>其实就是从上到下，先把每一层遍历完之后再遍历一下一层。假如我们的树如下：<br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    a</span><br><span class="line">   / \</span><br><span class="line">  b    c</span><br><span class="line"> / \  / \</span><br><span class="line">d   e f  g</span><br></pre></td></tr></table></figure><br>按照BFS，访问顺序如下：<br><code>a-&gt;b-&gt;c-&gt;d-&gt;e-&gt;f-&gt;g</code></p>
</blockquote>
<p><strong>[第102题]</strong> 给你一个二叉树，请你返回其按层序遍历得到的节点值。（即逐层地，从左到右访问所有节点）。 </p>
<ul>
<li>示例：<br>二叉树：[3,9,20,null,null,15,7]<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  3</span><br><span class="line"> / \</span><br><span class="line">9  20</span><br><span class="line">  /  \</span><br><span class="line"> 15   7</span><br></pre></td></tr></table></figure>
返回其层次遍历结果： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  [3],</span><br><span class="line">  [9,20],</span><br><span class="line">  [15,7]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>方法一：DFS递归求解</strong></p>
<blockquote>
<p>想到递归，我们一般先想到DFS。我们可以对该二叉树进行先序遍历（根左右的顺序），同时，记录节点所在的层次level，并且对每一层都定义一个数组，然后将访问到的节点值放入对应层的数组中。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        self.result = []</span><br><span class="line">        self._dfs(root, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dfs</span>(<span class="params">self, node, level</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> node:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.result) &lt; level + <span class="number">1</span>:</span><br><span class="line">            self.result.append([])</span><br><span class="line">        self.result[level].append(node.val)</span><br><span class="line">        self._dfs(node.left, level + <span class="number">1</span>)</span><br><span class="line">        self._dfs(node.right, level + <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了94.65% 的Python3用户<br>内存消耗:14 MB,击败了11.12% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">     <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; result = <span class="keyword">new</span> ArrayList();</span><br><span class="line">        levelOrder(root, result, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">levelOrder</span><span class="params">(TreeNode root, List&lt;List&lt;Integer&gt;&gt; result, <span class="keyword">int</span> level)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">while</span> (result.size() &lt; level + <span class="number">1</span>) &#123;</span><br><span class="line">            List&lt;Integer&gt; item = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            result.add(item);</span><br><span class="line">        &#125;</span><br><span class="line">        result.get(level).add(root.val);</span><br><span class="line">        levelOrder(root.left, result, level + <span class="number">1</span>);</span><br><span class="line">        levelOrder(root.right, result, level + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.8 MB, 在所有 Java 提交中击败了14.02% 的用户</p>
<p><strong>方法二：BFS求解</strong></p>
<blockquote>
<p>上面的解法，其实相当于是用DFS的方法实现了二叉树的BFS。那我们能不能直接使用BFS的方式进行解题呢？当然，我们可以使用Queue的数据结构。我们将root节点初始化进队列，通过消耗尾部，插入头部的方式来完成BFS。</p>
</blockquote>
<p>具体步骤如下图：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/5.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">levelOrder</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        result = []</span><br><span class="line">        <span class="comment"># 初始化队列</span></span><br><span class="line">        queue = collections.deque()</span><br><span class="line">        queue.append(root)</span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            current_level = []</span><br><span class="line">            <span class="comment"># 同一层从右进，从左出</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(queue)):</span><br><span class="line">                node = queue.popleft()</span><br><span class="line">                current_level.append(node.val)</span><br><span class="line">                <span class="keyword">if</span> node.left:</span><br><span class="line">                    queue.append(node.left)</span><br><span class="line">                <span class="keyword">if</span> node.right:</span><br><span class="line">                    queue.append(node.right)</span><br><span class="line">            <span class="comment"># 添加每层的节点</span></span><br><span class="line">            result.append(current_level)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了84.08% 的Python3用户<br>内存消耗:13.7 MB,击败了32.49% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">     <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            List&lt;Integer&gt; tmp = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">int</span> size = queue.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>; i&lt;size; i++) &#123;</span><br><span class="line">                TreeNode node = queue.poll();</span><br><span class="line">                tmp.add(node.val);</span><br><span class="line">                <span class="keyword">if</span>(node.left!=<span class="keyword">null</span>) queue.offer(node.left);</span><br><span class="line">                <span class="keyword">if</span>(node.right!=<span class="keyword">null</span>) queue.offer(node.right);</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(tmp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了94.76% 的用户<br>内存消耗：38.6 MB, 在所有 Java 提交中击败了68.05% 的用户</p>
<h3 id="3-BST与其验证"><a href="#3-BST与其验证" class="headerlink" title="3.BST与其验证"></a>3.BST与其验证</h3><blockquote>
<p>先看定义：二叉搜索树（Binary Search Tree），（又：二叉查找树，二叉排序树）它或者是一棵空树，或者是具有下列性质的二叉树：若<strong>它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值</strong>；它的左、右子树也分别为二叉搜索树。</p>
<p>这里强调一下子树的概念：设T是有根树，a是T中的一个顶点，由<strong>a以及a的所有后裔（后代）</strong>导出的子图称为有向树T的子树。具体来说，<strong>子树就是树的其中一个节点以及其下面的所有的节点</strong>所构成的树。</p>
<p>比如下面这就是一颗二叉搜索树：</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/6.jpg" alt></p>
<blockquote>
<p>下面这两个都不是：</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/7.jpg" alt></p>
<blockquote>
<p><1>图中4节点位置的数值应该大于根节点</1></p>
<p><2>图中3节点位置的数值应该大于根节点</2></p>
</blockquote>
<p><strong>[第98题]</strong> 给定一个二叉树，判断其是否是一个有效的二叉搜索树。假设一个二叉搜索树具有如下特征：节点的左子树只包含小于当前节点的数。节点的右子树只包含大于当前节点的数。所有左子树和右子树自身必须也是二叉搜索树。 </p>
<ul>
<li>示例 1:<br>输入:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  2</span><br><span class="line"> / \</span><br><span class="line">1   3</span><br></pre></td></tr></table></figure>
输出: true</li>
<li>示例 2:<br>输入:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  5</span><br><span class="line"> / \</span><br><span class="line">1   4</span><br><span class="line">   / \</span><br><span class="line">     3   6</span><br></pre></td></tr></table></figure>
输出: false<br>解释: 输入为: [5,1,4,null,null,3,6]。根节点的值为 5 ，但是其右子节点值为 4 。</li>
</ul>
<blockquote>
<p>首先看完题目，我们很容易想到遍历整棵树，比较所有节点，通过左节点值&lt;节点值，右节点值&gt;节点值的方式来进行求解。但是这种解法是错误的，因为对于任意一个节点，我们不光需要左节点值小于该节点，并且左子树上的所有节点值都需要小于该节点。（右节点一致）所以我们在此引入上界与下界，用以保存之前的节点中出现的最大值与最小值。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidBST</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> self.isBST(root, -inf, inf)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBST</span>(<span class="params">self, root, <span class="built_in">min</span>, <span class="built_in">max</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">min</span> &gt;= root.val) <span class="keyword">or</span> (<span class="built_in">max</span> &lt;= root.val):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> self.isBST(root.left, <span class="built_in">min</span>, root.val) <span class="keyword">and</span> self.isBST(root.right, root.val, <span class="built_in">max</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了88.67% 的Python3用户<br>内存消耗:15.8 MB,击败了38.48% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidBST</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> isBST(root, Long.MIN_VALUE, Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isBST</span><span class="params">(TreeNode root, <span class="keyword">long</span> min, <span class="keyword">long</span> max)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span>(root.val &lt;= min || root.val &gt;= max) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> isBST(root.left, min, root.val) &amp;&amp; isBST(root.right, root.val, max);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.4 MB, 在所有 Java 提交中击败了7.36% 的用户</p>
<h3 id="4-BST的查找"><a href="#4-BST的查找" class="headerlink" title="4.BST的查找"></a>4.BST的查找</h3><p><strong>[第700题]</strong> 给定二叉搜索树（BST）的根节点和一个值。 你需要在BST中找到节点值等于给定值的节点。 返回以该节点为根的子树。 如果节点不存在，则返回 NULL。 </p>
<ul>
<li>例如，<br>给定二叉搜索树:<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    4</span><br><span class="line">   / \</span><br><span class="line">  2   7</span><br><span class="line"> / \</span><br><span class="line">1   3</span><br></pre></td></tr></table></figure>
和值: 2<br>你应该返回如下子树: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  2     </span><br><span class="line"> / \   </span><br><span class="line">1   3</span><br></pre></td></tr></table></figure>
在上述示例中，如果要找的值是 5，但因为没有节点值为 5，我们应该返回 NULL。 </li>
</ul>
<blockquote>
<p>假设目标值为 val，根据BST的特性，我们可以很容易想到查找过程<br>如果val小于当前结点的值，转向其左子树继续搜索；<br>如果val大于当前结点的值，转向其右子树继续搜索；<br>如果已找到，则返回当前结点。</p>
</blockquote>
<p><strong>方法一：递归</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchBST</span>(<span class="params">self, root: TreeNode, val: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> root.val &gt; val:</span><br><span class="line">            <span class="keyword">return</span> self.searchBST(root.left, val)</span><br><span class="line">        <span class="keyword">elif</span> root.val &lt; val:</span><br><span class="line">            <span class="keyword">return</span> self.searchBST(root.right, val)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<p>执行耗时:116 ms,击败了10.76% 的Python3用户<br>内存消耗:15.5 MB,击败了33.59% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">searchBST</span><span class="params">(TreeNode root, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(root.val &gt; val) <span class="keyword">return</span> searchBST(root.left, val);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(root.val &lt; val) <span class="keyword">return</span> searchBST(root.right, val);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：39.2 MB, 在所有 Java 提交中击败了83.28% 的用户</p>
<p><strong>方法二：迭代</strong></p>
<blockquote>
<p>递归与迭代的区别<br>递归：重复调用函数自身实现循环称为递归；<br>迭代：利用变量的原值推出新值称为迭代，或者说迭代是函数内某段代码实现循环；</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchBST</span>(<span class="params">self, root: TreeNode, val: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">while</span> root:</span><br><span class="line">            <span class="keyword">if</span> root.val &gt; val:</span><br><span class="line">                root = root.left</span><br><span class="line">            <span class="keyword">elif</span> root.val &lt; val:</span><br><span class="line">                root = root.right</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> root</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:76 ms,击败了99.39% 的Python3用户<br>内存消耗:15.6 MB,击败了6.14% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">searchBST</span><span class="params">(TreeNode root, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(root!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(root.val &gt; val) root = root.left;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(root.val &lt; val) root = root.right;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> root;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：39.6 MB, 在所有 Java 提交中击败了8.04% 的用户</p>
<h3 id="5-BST的删除"><a href="#5-BST的删除" class="headerlink" title="5.BST的删除"></a>5.BST的删除</h3><p><strong>[第450题]</strong> 给定一个二叉搜索树的根节点root和一个值key，删除二叉搜索树中的key对应的节点，并保证二叉搜索树的性质不变。返回二叉搜索树（有可能被更新）的根节点的引用。一般来说，删除节点可分为两个步骤：首先找到需要删除的节点；如果找到了，删除它。<br>说明： 要求算法时间复杂度为O(h)，h为树的高度。 </p>
<ul>
<li>示例:<br>root = [5,3,6,2,4,null,7]<br>key = 3<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    5</span><br><span class="line">   / \</span><br><span class="line">  3   6</span><br><span class="line"> / \   \</span><br><span class="line">2   4   7</span><br></pre></td></tr></table></figure>
给定需要删除的节点值是 3，所以我们首先找到 3 这个节点，然后删除它。<br>一个正确的答案是 [5,4,6,2,null,null,7], 如下图所示。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    5</span><br><span class="line">   / \</span><br><span class="line">  4   6</span><br><span class="line"> /     \</span><br><span class="line">2       7</span><br></pre></td></tr></table></figure>
另一个正确答案是 [5,2,6,null,4,null,7]。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  5</span><br><span class="line"> / \</span><br><span class="line">2   6</span><br><span class="line"> \   \</span><br><span class="line">  4   7</span><br></pre></td></tr></table></figure>
</li>
</ul>
<blockquote>
<p>我们要删除BST的一个节点，首先需要找到该节点。而找到之后，会出现三种情况。</p>
<p>1、待删除的节点左子树为空，让待删除节点的右子树替代自己。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/8.jpg" alt><br>2、待删除的节点右子树为空，让待删除节点的左子树替代自己。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/9.jpg" alt><br>3、如果待删除的节点的左右子树都不为空。我们需要找到<strong>比当前节点小的最大节点（前驱）</strong>，来替换自己</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/10.jpg" alt></p>
<p>或者<strong>比当前节点大的最小节点（后继）</strong>，来替换自己。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/11.jpg" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteNode</span>(<span class="params">self, root: TreeNode, key: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> root.val &gt; key:</span><br><span class="line">            root.left = self.deleteNode(root.left, key)</span><br><span class="line">        <span class="keyword">elif</span> root.val &lt; key:</span><br><span class="line">            root.right = self.deleteNode(root.right, key)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#第一种和第二种情况</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">or</span> <span class="keyword">not</span> root.right:</span><br><span class="line">                root = root.left <span class="keyword">if</span> root.left <span class="keyword">else</span> root.right</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 第三种情况，查找后继</span></span><br><span class="line">                cur = root.right</span><br><span class="line">                <span class="keyword">while</span> cur.left:</span><br><span class="line">                    cur = cur.left</span><br><span class="line">                root.val = cur.val</span><br><span class="line">                <span class="comment"># 找到右子树最小值，再通过主递归函数删除最小值</span></span><br><span class="line">                <span class="comment"># 出口就是 if not root.left or not root.right: root = root.left if root.left else root.right</span></span><br><span class="line">                root.right = self.deleteNode(root.right, cur.val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<p>执行耗时:72 ms,击败了99.85% 的Python3用户<br>内存消耗:17.6 MB,击败了24.40% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">deleteNode</span><span class="params">(TreeNode root, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(root.val &gt; key) root.left = deleteNode(root.left, key);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(root.val &lt; key) root.right = deleteNode(root.right, key);</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">if</span>(root.left==<span class="keyword">null</span> || root.right==<span class="keyword">null</span> )&#123;</span><br><span class="line">                root = root.left!=<span class="keyword">null</span>?root.left: root.right;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                TreeNode cur = root.right;</span><br><span class="line">                <span class="keyword">while</span>(cur.left!=<span class="keyword">null</span>) cur = cur.left;</span><br><span class="line">                root.val = cur.val;</span><br><span class="line">                root.right = deleteNode(root.right, cur.val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了62.43% 的用户</p>
<h3 id="6-平衡二叉树"><a href="#6-平衡二叉树" class="headerlink" title="6.平衡二叉树"></a>6.平衡二叉树</h3><p><strong>[第110题]</strong> 给定一个二叉树，判断它是否是高度平衡的二叉树。<br>本题中，一棵高度平衡二叉树定义为：一个二叉树每个节点的左右两个子树的高度差的绝对值不超过1。 </p>
<ul>
<li>示例 1:<br>给定二叉树 [3,9,20,null,null,15,7] <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  3</span><br><span class="line"> / \</span><br><span class="line">9  20</span><br><span class="line">  /  \</span><br><span class="line"> 15   7 </span><br></pre></td></tr></table></figure>
返回 true 。  </li>
<li>示例 2:<br>给定二叉树 [1,2,2,3,3,null,null,4,4] <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">      1</span><br><span class="line">     / \</span><br><span class="line">    2   2</span><br><span class="line">   / \</span><br><span class="line">  3   3</span><br><span class="line"> / \</span><br><span class="line">4   4</span><br></pre></td></tr></table></figure>
返回 false 。 </li>
</ul>
<blockquote>
<p>我们想判断一棵树是否满足平衡二叉树，无非就是判断当前结点的两个孩子是否满足平衡，同时两个孩子的高度差是否超过1。那只要我们可以得到高度，再基于高度进行判断即可。</p>
<p>这里唯一要注意的是，当我们判定其中任意一个节点如果不满足平衡二叉树时，那说明整棵树已经不是一颗平衡二叉树，我们可以对其进行阻断，不需要继续递归下去。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isBalanced</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 不平衡的情况有3种：左树不平衡、右树不平衡、左树和右树差的绝对值大于1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.isBalanced(root.left) <span class="keyword">or</span> <span class="keyword">not</span> self.isBalanced(root.right):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        leftH = self.maxDepth(root.left) + <span class="number">1</span></span><br><span class="line">        rightH = self.maxDepth(root.right) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">abs</span>(leftH - rightH) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxDepth</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 树的深度为左右俩子树最大深度 + 1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(self.maxDepth(root.left), self.maxDepth(root.right)) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:64 ms,击败了73.12% 的Python3用户<br>内存消耗:17.3 MB,击败了66.69% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isBalanced</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(!isBalanced(root.left) || !isBalanced(root.right)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">int</span> leftH = maxDepth(root.left) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> rightH = maxDepth(root.right) + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(Math.abs(leftH - rightH) &gt; <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxDepth</span><span class="params">(TreeNode root)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> Math.max(maxDepth(root.left), maxDepth(root.right)) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了99.97% 的用户<br>内存消耗：39.2 MB, 在所有 Java 提交中击败了5.03% 的用户</p>
<h3 id="7-完全二叉树"><a href="#7-完全二叉树" class="headerlink" title="7.完全二叉树"></a>7.完全二叉树</h3><blockquote>
<p>如果<strong>二叉树中除了叶子结点，每个结点的度都为 2</strong>，则此二叉树称为<strong>满二叉树</strong>。（<strong>二叉树的度代表某个结点的孩子或者说直接后继的个数</strong>。对于二叉树而言，1度是只有一个孩子或者说单子树,2度是有两个孩子或者说左右子树都有。）</p>
<p>满二叉树如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/12.jpg" alt><br>如果<strong>二叉树中除去最后一层节点为满二叉树，且最后一层的结点依次从左到右分布，则此二叉树被称为<br>完全二叉树</strong>。</p>
<p>比如下面这颗：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/13.jpg" alt><br>而这颗就不是：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/14.jpg" alt></p>
</blockquote>
<p><strong>[第222题]</strong> 给出一个完全二叉树，求出该树的节点个数。<br>说明：<br>完全二叉树的定义如下：在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第h层，则该层包含1~ 2h个节点。 </p>
<ul>
<li>示例:<br>输入: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    1</span><br><span class="line">   / \</span><br><span class="line">  2   3</span><br><span class="line"> / \  /</span><br><span class="line">4  5 6</span><br></pre></td></tr></table></figure>
输出: 6 </li>
</ul>
<p><strong>方法一：递归求解</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> + self.countNodes(root.left) + self.countNodes(root.right)</span><br></pre></td></tr></table></figure>
<p>执行耗时:88 ms,击败了91.26% 的Python3用户<br>内存消耗:20.5 MB,击败了6.22% 的Python3用户</p>
<p>但是很明显，出题者肯定不是要这种答案。因为这种答案和完全二叉树一毛钱关系都没有。所以我们继<br>续思考。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">countNodes</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> countNodes(root.left) + countNodes(root.right) + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：41.1 MB, 在所有 Java 提交中击败了23.37% 的用户</p>
<p><strong>方法二：经典解法</strong></p>
<blockquote>
<p>由于题中已经告诉我们这是一颗完全二叉树，我们又已知了完全二叉树除了最后一层，其他层都是满的，并且最后一层的节点全部靠向了左边。那我们可以想到，可以将该完全二叉树可以分割成<strong>若干满二叉树和完全二叉树，满二叉树直接根据层高h计算出节点为2^h-1，然后继续计算子树中完全二叉树节点</strong>。那如何分割成若干满二叉树和完全二叉树呢？<strong>对任意一个子树，遍历其左子树层高left，右子树层高right，相等左子树则是满二叉树，否则右子树是满二叉树</strong>。</p>
<p>如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/15.jpg" alt><br>左子树为满二叉树<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/16.jpg" alt><br>右子树为满二叉树</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">countNodes</span>(<span class="params">self, root: TreeNode</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 计算左右子树高度</span></span><br><span class="line">        lh, rh = self.__getHeight(root.left), self.__getHeight(root.right)</span><br><span class="line">        <span class="keyword">if</span> lh == rh:  <span class="comment"># 左右子树高度相同，说明左子树必满 则节点数=左子树节点 + root节点(=1) + 递归找右子树</span></span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">pow</span>(<span class="number">2</span>, lh) - <span class="number">1</span>) + <span class="number">1</span> + self.countNodes(root.right)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 左子树比右子树高，说明右子树必满 同理</span></span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">pow</span>(<span class="number">2</span>, rh) - <span class="number">1</span>) + <span class="number">1</span> + self.countNodes(root.left)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getHeight</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        level = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> root:</span><br><span class="line">            level += <span class="number">1</span></span><br><span class="line">            root = root.left</span><br><span class="line">        <span class="keyword">return</span> level</span><br></pre></td></tr></table></figure>
<p>执行耗时:88 ms,击败了91.26% 的Python3用户<br>内存消耗:20.4 MB,击败了47.22% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">countNodes</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> lh = getHeight(root.left);</span><br><span class="line">        <span class="keyword">int</span> rh = getHeight(root.right);</span><br><span class="line">        <span class="keyword">if</span>(lh == rh) <span class="keyword">return</span> (<span class="keyword">int</span>)(Math.pow(<span class="number">2</span>, lh) - <span class="number">1</span>) + <span class="number">1</span> + countNodes(root.right);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> (<span class="keyword">int</span>)(Math.pow(<span class="number">2</span>, rh) - <span class="number">1</span>) + <span class="number">1</span> + countNodes(root.left);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getHeight</span><span class="params">(TreeNode root)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> level = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(root != <span class="keyword">null</span>)&#123;</span><br><span class="line">            level++;</span><br><span class="line">            root = root.left;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> level;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：41 MB, 在所有 Java 提交中击败了50.61% 的用户</p>
<h3 id="8-二叉树的剪枝"><a href="#8-二叉树的剪枝" class="headerlink" title="8.二叉树的剪枝"></a>8.二叉树的剪枝</h3><blockquote>
<p>假设有一棵树，最上层的是root节点，而<strong>父节点会依赖子节点</strong>。如果现在有一些节点已经标记为无效，我们要删除这些无效节点。<strong>如果无效节点的依赖的节点还有效，那么不应该删除</strong>，如果无效节点和它的子节点都无效，则可以删除。剪掉这些节点的过程，称为剪枝，目的是<strong>用来处理二叉树模型中的依赖问题</strong>。</p>
</blockquote>
<p><strong>[第814题]</strong> 给定二叉树根结点root，此外树的每个结点的值要么是0，要么是1。返回移除了所有不包含 1 的子树的原二叉树。( 节点 X 的子树为 X 本身，以及所有 X 的后代。) </p>
<ul>
<li><p>示例1:<br>输入: [1,null,0,0,1]<br>输出: [1,null,0,null,1]<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/17.jpg" alt><br>解释:<br>只有红色节点满足条件“所有不包含 1 的子树”。<br>右图为返回的答案。</p>
</li>
<li><p>示例2:<br>输入: [1,0,1,0,0,0,1]<br>输出: [1,null,1,null,1]<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/18.jpg" alt></p>
</li>
<li><p>示例3:<br>输入: [1,1,0,1,1,0,1,0]<br>输出: [1,1,0,1,1,null,1]<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/19.jpg" alt></p>
</li>
</ul>
<p>说明:<br>给定的二叉树最多有100个节点。<br>每个节点的值只会为0或1。 </p>
<blockquote>
<p>剪什么大家应该都能理解。那关键是怎么剪？过程也很简单，<strong>在递归的过程中，如果当前结点的左右节点皆为空，且当前结点为0，我们就将当前节点剪掉即可</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pruneTree</span>(<span class="params">self, root: TreeNode</span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        root.left = self.pruneTree(root.left)</span><br><span class="line">        root.right = self.pruneTree(root.right)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root.left <span class="keyword">and</span> <span class="keyword">not</span> root.right <span class="keyword">and</span> root.val == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了78.18% 的Python3用户<br>内存消耗:13.5 MB,击败了5.40% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">pruneTree</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        root.left = pruneTree(root.left);</span><br><span class="line">        root.right = pruneTree(root.right);</span><br><span class="line">        <span class="keyword">if</span>(root.left == <span class="keyword">null</span> &amp;&amp; root.right == <span class="keyword">null</span> &amp;&amp; root.val == <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.1 MB, 在所有 Java 提交中击败了37.22% 的用户</p>
<h2 id="回溯系列"><a href="#回溯系列" class="headerlink" title="回溯系列"></a>回溯系列</h2><h3 id="1-全排列算法"><a href="#1-全排列算法" class="headerlink" title="1.全排列算法"></a>1.全排列算法</h3><blockquote>
<p>什么是全排列？从 n 个不同元素中任取 m（m≤n）个元素，按照一定的顺序排列起来，叫做从 n 个不同元素中取出 m 个元素的一个排列。当 m=n 时所有的排列情况叫全排列。</p>
</blockquote>
<p><strong>[第46题]</strong> 给定一个没有重复数字的序列，返回其所有可能的全排列。 </p>
<ul>
<li>示例:<br>输入: [1,2,3]<br>输出:<br>[<br>[1,2,3],<br>[1,3,2],<br>[2,1,3],<br>[2,3,1],<br>[3,1,2],<br>[3,2,1]<br>] </li>
</ul>
<blockquote>
<p>回溯法（探索与回溯法）是一种选优搜索法，又称为试探法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。</p>
<p>比如我们选择三个数字：</p>
<ul>
<li>在枚举第一位的时候，就有三种情况</li>
<li>在枚举第二位的时候，就只有两种情况（前面已经出现的一个数字不可以再出现）</li>
<li>在枚举第三位的时候，就只有一种情况（前面已经出现的两个数字不可以再出现）</li>
</ul>
<p>整个代码其实就干了这么一件事！其实就是说<strong>当枚举到最后一位的时候，这个就是我们要的排列结果，所以我们要放入到全排列结果集中。</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permute</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        self.result = []</span><br><span class="line">        tmp = []</span><br><span class="line">        self.dfs(nums, tmp)</span><br><span class="line">        <span class="keyword">return</span> self.result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">self, nums, tmp</span>):</span></span><br><span class="line">        <span class="comment"># 若长度相等，则添加到结果</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(tmp) == <span class="built_in">len</span>(nums):</span><br><span class="line">            self.result.append(tmp[:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">                <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> tmp:</span><br><span class="line">                    <span class="comment"># 枚举第一位</span></span><br><span class="line">                    tmp.append(i)</span><br><span class="line">                    <span class="comment"># 找出第一位固定后的排列情况</span></span><br><span class="line">                    self.dfs(nums, tmp)</span><br><span class="line">                    <span class="comment"># 清除选择过的数字</span></span><br><span class="line">                    tmp.pop(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了94.22% 的Python3用户<br>内存消耗:13.5 MB,击败了67.02% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; permute(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; ans = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        dfs(nums, <span class="number">0</span>, ans);</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> level, List&lt;List&lt;Integer&gt;&gt; ans)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(level == nums.length-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="comment">//数组转列表</span></span><br><span class="line">            ans.add(Arrays.stream(nums).boxed().collect(Collectors.toList()));</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=level; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="comment">//与当前level交换的可能</span></span><br><span class="line">            <span class="comment">//i = level时不动, i &gt; level时交换</span></span><br><span class="line">            swap(nums, i, level);</span><br><span class="line">            <span class="comment">//与下一level交换的可能</span></span><br><span class="line">            <span class="comment">//同理level+1可能不动，可能与大于level+1的数交换</span></span><br><span class="line">            dfs(nums, level + <span class="number">1</span>, ans);</span><br><span class="line">            <span class="comment">//恢复</span></span><br><span class="line">            swap(nums, i, level);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> i ,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> temp = nums[i];</span><br><span class="line">        nums[i] = nums[j];</span><br><span class="line">        nums[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="滑动窗口系列"><a href="#滑动窗口系列" class="headerlink" title="滑动窗口系列"></a>滑动窗口系列</h2><h3 id="1-滑动窗口最大值"><a href="#1-滑动窗口最大值" class="headerlink" title="1.滑动窗口最大值"></a>1.滑动窗口最大值</h3><p><strong>[第239题]</strong> 给定一个数组nums，有一个大小为k的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的k个数字。滑动窗口每次只向右移动一位。返回滑动窗口中的最大值。 </p>
<ul>
<li>示例:<br>输入: nums = [1,3,-1,-3,5,3,6,7], 和k = 3<br>输出: [3,3,5,5,6,7]<br>解释: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  滑动窗口的位置                最大值</span><br><span class="line">---------------               -----</span><br><span class="line">[1  3  -1] -3  5  3  6  7       3</span><br><span class="line"> 1 [3  -1  -3] 5  3  6  7       3</span><br><span class="line"> 1  3 [-1  -3  5] 3  6  7       5</span><br><span class="line"> 1  3  -1 [-3  5  3] 6  7       5</span><br><span class="line"> 1  3  -1  -3 [5  3  6] 7       6</span><br><span class="line"> 1  3  -1  -3  5 [3  6  7]      7 </span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>方法一：暴力求解</strong></p>
<blockquote>
<p>可以<strong>通过遍历所有的滑动窗口，找到每一个窗口的最大值，来进行暴力求解</strong>。那一共有多少个滑动窗口呢，小学题目，可以得到共有L-k+1个窗口。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - k + <span class="number">1</span>):</span><br><span class="line">            result.append(<span class="built_in">max</span>(nums[i: k + i]))</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>运行失败:<br>Time Limit Exceeded<br>运行速度不行，会超时。。。。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] maxSlidingWindow(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length &lt; k) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length - k + <span class="number">1</span>]; </span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>, r = k-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(r &lt; nums.length)&#123;</span><br><span class="line">            res[index++] = maxArray(nums, l, r);</span><br><span class="line">            l++;</span><br><span class="line">            r++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxArray</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> maxValue = nums[l];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = l + <span class="number">1</span>; i &lt;= r; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; maxValue) maxValue = nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Java也超时。。。。</p>
<p><strong>方法二：线性题解</strong></p>
<blockquote>
<p>最典型的解法还是使用双端队列，只要遍历该数组，同时在双端队列的头去维护当前窗口的最大值（在遍历过程中，发现当前元素比队列中的元素大，就将原来队列中的元素祭天），在整个遍历的过程中我们再记录下每一个窗口的最大值到结果数组中。最终结果数组就是我们想要的</p>
<p>假设nums = [1,3,-1,-3,5,3,6,7]，和k = 3</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/20.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        queue = collections.deque()</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="keyword">while</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> (<span class="built_in">len</span>(queue) &gt; <span class="number">0</span>) <span class="keyword">and</span> (nums[i] &gt; queue[-<span class="number">1</span>]):</span><br><span class="line">                <span class="comment"># 将比当前元素小的元素祭天</span></span><br><span class="line">                queue.pop()</span><br><span class="line">            queue.append(nums[i])</span><br><span class="line">            <span class="keyword">if</span> i &gt;= k <span class="keyword">and</span> nums[i - k] == queue[<span class="number">0</span>]:</span><br><span class="line">                <span class="comment"># 维护队列，保证其头元素为当前窗口最大值, 而不是之前窗口</span></span><br><span class="line">                <span class="comment"># 即当前窗口恰好与之前窗口的最大值分离时，要舍去之前窗口的最大值</span></span><br><span class="line">                queue.popleft()</span><br><span class="line">            <span class="keyword">if</span> i &gt;= k-<span class="number">1</span>:</span><br><span class="line">                <span class="comment"># 放入结果数组</span></span><br><span class="line">                result.append(queue[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:416 ms,击败了22.57% 的Python3用户<br>内存消耗:25.4 MB,击败了7.76% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] maxSlidingWindow(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length &lt; k) <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length - k + <span class="number">1</span>]; </span><br><span class="line">        <span class="comment">//Queue窄化了LinkedList的访问,由于需要从右边弹出，这里使用LinkedList</span></span><br><span class="line">        LinkedList&lt;Integer&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(i &gt; <span class="number">0</span> &amp;&amp; !queue.isEmpty() &amp;&amp; queue.peekLast() &lt; nums[i]) queue.pollLast();</span><br><span class="line">            queue.offer(nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(i &gt;= k &amp;&amp; nums[i-k] == queue.peek()) queue.poll();</span><br><span class="line">            <span class="keyword">if</span>(i &gt;= k-<span class="number">1</span>) res[i - k + <span class="number">1</span>] = queue.peek();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：38 ms, 在所有 Java 提交中击败了50.52% 的用户<br>内存消耗：52.7 MB, 在所有 Java 提交中击败了52.71% 的用户</p>
<h3 id="2-无重复字符的最长子串"><a href="#2-无重复字符的最长子串" class="headerlink" title="2.无重复字符的最长子串"></a>2.无重复字符的最长子串</h3><blockquote>
<p>对于大部分滑动窗口类型的题目，一般是<strong>考察字符串的匹配</strong>。比较标准的题目，会给出一个<strong>模式串B</strong>，以及一个<strong>目标串A</strong>。然后提出问题，找到<strong>A中符合对B一些限定规则的子串或者对A一些限定规则的结果</strong>，最终<strong>再将搜索出的子串完成题意中要求的组合或者其他</strong>。</p>
<p>而对于这一类题目，我们常用的解题思路，是去<strong>维护一个可变长度的滑动窗口</strong>。无论是使用<strong>双指针</strong>，还是使用<strong>双端队列</strong>，又或者用<strong>游标</strong>等其他奇技淫巧，目的都是一样的。</p>
</blockquote>
<p><strong>[第3题]</strong> 给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。 </p>
<ul>
<li>示例 1:<br>输入: “abcabcbb”<br>输出: 3<br>解释: 因为无重复字符的最长子串是 “abc”，所以其长度为 3。</li>
<li>示例 2:<br>输入: “bbbbb”<br>输出: 1<br>解释: 因为无重复字符的最长子串是 “b”，所以其长度为 1。 </li>
<li>示例 3:<br>输入: “pwwkew”<br>输出: 3<br>解释: 因为无重复字符的最长子串是 “wke”，所以其长度为 3。<br>请注意，你的答案必须是子串的长度，”pwke” 是一个子序列，不是子串。</li>
</ul>
<p><strong>方法一：双指针</strong></p>
<blockquote>
<p>假设我们的输入为“abcabcbb”，我们只需要维护一个窗口在输入字符串中进行移动。如下图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/21.jpg" alt><br>当下一个元素在窗口没有出现过时，我们扩大窗口。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/22.jpg" alt><br>当下一个元素在窗口中出现过时，我们缩小窗口，将<strong>出现过的元素以及其左边的元素</strong>统统移出：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/23.jpg" alt><br>在整个过程中，我们<strong>记录下窗口出现过的最大值</strong>即可。而我们唯一要做的，只需要尽可能扩大窗口。</p>
<p>那我们代码中通过什么来维护这样的一个窗口呢？anyway~ 不管是队列，双指针，甚至通过map来<br>做，都可以。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        result = []</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        maxlen = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; <span class="built_in">len</span>(s) <span class="keyword">and</span> right &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">if</span> s[right] <span class="keyword">not</span> <span class="keyword">in</span> result:</span><br><span class="line">                result.append(s[right])</span><br><span class="line">                right += <span class="number">1</span></span><br><span class="line">                maxlen = <span class="built_in">max</span>(maxlen, right-left)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.remove(s[left])</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> maxlen</span><br></pre></td></tr></table></figure>
<p>执行耗时:136 ms,击败了21.58% 的Python3用户<br>内存消耗:13.7 MB,击败了5.01% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        Set&lt;Character&gt; set = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(right &lt; s.length())&#123;</span><br><span class="line">            <span class="keyword">if</span>(set.contains(s.charAt(right))) set.remove(s.charAt(left++));</span><br><span class="line">            <span class="keyword">else</span> set.add(s.charAt(right++));</span><br><span class="line">            maxLen = Math.max(set.size(), maxLen);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxLen;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：12 ms, 在所有 Java 提交中击败了23.70% 的用户<br>内存消耗：38.9 MB, 在所有 Java 提交中击败了23.38% 的用户</p>
<p><strong>方法二：字典</strong></p>
<blockquote>
<p>通过观察，我们能看出来。如果是最坏情况的话，我们每一个字符都可能会访问两次，left一次，right一次，时间复杂度达到了O(2N)</p>
<p>假设我们的字符串为“abcdc”，对于abc我们都访问了2次。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/24.jpg" alt><br>那如何来进一步优化呢？其实我们可以定义<strong>字符到索引的映射</strong>，而不是简单通过一个集合来判断字符是否存在。这样的话，当我们<strong>找到重复的字符时，我们可以立即跳过该窗口</strong>，而不需要对之前的元素进行再次访问。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/25.jpg" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="built_in">map</span> = &#123;&#125;</span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        maxlen = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> right &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="comment"># 如果有重复字符直接跳过该窗口</span></span><br><span class="line">            <span class="keyword">if</span> s[right] <span class="keyword">in</span> <span class="built_in">map</span>:</span><br><span class="line">                left = <span class="built_in">max</span>(<span class="built_in">map</span>[s[right]], left)</span><br><span class="line">            maxlen = <span class="built_in">max</span>(maxlen, right-left+<span class="number">1</span>)</span><br><span class="line">            <span class="built_in">map</span>[s[right]] = right + <span class="number">1</span></span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> maxlen</span><br></pre></td></tr></table></figure>
<p>执行耗时:68 ms,击败了86.27% 的Python3用户<br>内存消耗:13.5 MB,击败了34.59% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        Map&lt;Character, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(right &lt; s.length())&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(s.charAt(right))) left = Math.max(left, map.get(s.charAt(right)));</span><br><span class="line">            maxLen = Math.max(right-left+<span class="number">1</span>, maxLen);</span><br><span class="line">            map.put(s.charAt(right), right+<span class="number">1</span>);</span><br><span class="line">            right++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxLen;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：9 ms, 在所有 Java 提交中击败了40.45% 的用户<br>内存消耗：38.6 MB, 在所有 Java 提交中击败了61.39% 的用户</p>
<p><strong>方法三：利用ASCII映射，数组代替字典</strong></p>
<blockquote>
<p>我们可以使用一个128位的数组来替代字典。（因为ASCII码表里的字符总共有128个。ASCII码的长度是一个字节，8位，理论上可以表示256个字符，但是许多时候只谈128个。具体原因可以下去自行学习~）</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLongestSubstring</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        charIndex = [<span class="number">0</span>]*<span class="number">128</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        maxlen = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> right &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="comment"># 如果有重复字符直接跳过该窗口</span></span><br><span class="line">            <span class="comment"># ord()将字符转ASCII码</span></span><br><span class="line">            left = <span class="built_in">max</span>(charIndex[<span class="built_in">ord</span>(s[right])], left)</span><br><span class="line">            maxlen = <span class="built_in">max</span>(maxlen, right-left+<span class="number">1</span>)</span><br><span class="line">            charIndex[<span class="built_in">ord</span>(s[right])] = right + <span class="number">1</span></span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> maxlen</span><br></pre></td></tr></table></figure>
<p>执行耗时:68 ms,击败了86.27% 的Python3用户<br>内存消耗:13.5 MB,击败了11.53% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.length() == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[] charIndex = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">128</span>];</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> maxLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(right &lt; s.length())&#123;</span><br><span class="line">            left = Math.max(left, charIndex[s.charAt(right) + <span class="number">0</span>]);</span><br><span class="line">            maxLen = Math.max(right-left+<span class="number">1</span>, maxLen);</span><br><span class="line">            charIndex[s.charAt(right) + <span class="number">0</span>] = right + <span class="number">1</span>;</span><br><span class="line">            right++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxLen;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了88.31% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了40.58% 的用户</p>
<h3 id="3-找到字符串中所有字母异位词"><a href="#3-找到字符串中所有字母异位词" class="headerlink" title="3.找到字符串中所有字母异位词"></a>3.找到字符串中所有字母异位词</h3><p><strong>[第438题]</strong> 给定一个字符串s和一个非空字符串p，找到s中所有是p的字母异位词的子串，返回这些子串的起始索引。字符串只包含小写英文字母，并且字符串 s 和 p 的长度都不超过20100。<br>说明：<br>字母异位词指字母相同，但排列不同的字符串。<br>不考虑答案输出的顺序。 </p>
<ul>
<li>示例 1:<br>输入: s: “cbaebabacd” p: “abc”<br>输出: [0, 6]<br>解释:<br>起始索引等于 0 的子串是 “cba”, 它是 “abc” 的字母异位词。<br>起始索引等于 6 的子串是 “bac”, 它是 “abc” 的字母异位词。</li>
<li>示例 2:<br>输入: s: “abab” p: “ab”<br>输出: [0, 1, 2]<br>解释:<br>起始索引等于 0 的子串是 “ab”, 它是 “ab” 的字母异位词。<br>起始索引等于 1 的子串是 “ba”, 它是 “ab” 的字母异位词。<br>起始索引等于 2 的子串是 “ab”, 它是 “ab” 的字母异位词。</li>
</ul>
<blockquote>
<p>我们通过双指针维护一个窗口，由于我们只需要判断字母异位词，我们可以将窗口初始化大小和目标串保持一致。</p>
<p>而判断字母异位词，我们需要<strong>保证窗口中的字母出现次数与目标串中的字母出现次数一致</strong>。</p>
<p>我们通过移动窗口，来更新窗口数组，进而和目标数组匹配，匹配成功进行记录。每一次窗口移动，<strong>左指针前移</strong>，原来<strong>左指针位置处的数值减1，表示字母移出</strong>；<strong>同时右指针前移，右指针位置处的数值加1，表示字母移入</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findAnagrams</span>(<span class="params">self, s: <span class="built_in">str</span>, p: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="comment"># 思路:</span></span><br><span class="line">        <span class="comment"># 想象一个窗口在s上向右移动,窗口宽度为len(p)</span></span><br><span class="line">        <span class="comment"># 只要窗口内的字符串各字符数量与p中一致,则匹配成功</span></span><br><span class="line">        <span class="comment"># 窗口在向右移动的时候,只需要将最左端的值从字典中删除,将最右端+1的值加入字典即可.</span></span><br><span class="line"></span><br><span class="line">        pmap = &#123;&#125;</span><br><span class="line">        <span class="comment"># 初始化目标窗口</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> p:</span><br><span class="line">            <span class="comment">#  get() 函数返回指定键的值, 如果键不在字典中返回默认值 None 或者设置的默认值。</span></span><br><span class="line">            pmap[i] = pmap.get(i, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        plenth = <span class="built_in">len</span>(p)</span><br><span class="line"></span><br><span class="line">        rlist = []</span><br><span class="line">        rmap = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(s):</span><br><span class="line">            <span class="comment"># 每次移动窗口，右指针值加1</span></span><br><span class="line">            rmap[v] = rmap.get(v, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">            <span class="comment"># 与目标窗口匹配，返回左指针索引</span></span><br><span class="line">            <span class="keyword">if</span> rmap == pmap:</span><br><span class="line">                rlist.append(i - plenth + <span class="number">1</span>)</span><br><span class="line">            <span class="comment"># 每次移动窗口，左指针值减1，当为0时删除</span></span><br><span class="line">            <span class="keyword">if</span> i - plenth + <span class="number">1</span> &gt;= <span class="number">0</span>:</span><br><span class="line">                rmap[s[i - plenth + <span class="number">1</span>]] = rmap.get(s[i - plenth + <span class="number">1</span>]) - <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> rmap[s[i - plenth + <span class="number">1</span>]] == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">del</span> rmap[s[i - plenth + <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rlist</span><br></pre></td></tr></table></figure>
<p>执行耗时:144 ms,击败了48.40% 的Python3用户<br>内存消耗:14.2 MB,击败了87.61% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">findAnagrams</span><span class="params">(String s, String p)</span> </span>&#123;</span><br><span class="line">        Map&lt;Character, Integer&gt; pmap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> pLength = p.length();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;pLength; i++) pmap.put(p.charAt(i), pmap.getOrDefault(p.charAt(i), <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line">        Map&lt;Character, Integer&gt; rList = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.length(); i++)&#123;</span><br><span class="line">            rList.put(s.charAt(i), rList.getOrDefault(s.charAt(i), <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span>(rList.equals(pmap)) res.add(i-pLength+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span>((i - pLength + <span class="number">1</span>) &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">                rList.put(s.charAt(i - pLength + <span class="number">1</span>), rList.get(s.charAt(i - pLength + <span class="number">1</span>))-<span class="number">1</span>);</span><br><span class="line">                <span class="keyword">if</span> (rList.get(s.charAt(i - pLength + <span class="number">1</span>)) == <span class="number">0</span>) rList.remove(s.charAt(i - pLength + <span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：118 ms, 在所有 Java 提交中击败了15.26% 的用户<br>内存消耗：39.8 MB, 在所有 Java 提交中击败了21.13% 的用户</p>
<h3 id="4-和为S的连续正数序列"><a href="#4-和为S的连续正数序列" class="headerlink" title="4.和为S的连续正数序列"></a>4.和为S的连续正数序列</h3><p><strong>[剑指57-II]</strong> 输入一个正整数target ，输出所有和为target的连续正整数序列（至少含有两个数）。序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。 </p>
<ul>
<li>示例 1：<br>输入：target = 9<br>输出：[[2,3,4],[4,5]]</li>
<li>示例 2：<br>输入：target = 15<br>输出：[[1,2,3,4,5],[4,5,6],[7,8]]</li>
</ul>
<blockquote>
<p>假若我们输入的target为9，大脑中应该有下面这么个玩意：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/40.png" alt><br>然后我们通过左右指针来维护一个滑动窗口，同时计算窗口内的值是否是目标值：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/41.png" alt><br>如果窗口的值过小，我们就移动右边界。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/42.png" alt><br>如果窗口的值过大，我们就移动左边界。<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/43.png" alt><br>剩下的就是反复上面的操作就可以了。<strong>对于任意一个正整数，总是小于它的中值与中值+1的和。</strong><br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/44.png" alt><br>比如这里的100，就一定小于50+51，换成其他数也一样。换句话说，<strong>一旦窗口左边界超过中值，窗口内的和一定会大于target</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findContinuousSequence</span>(<span class="params">self, target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        j = <span class="number">1</span></span><br><span class="line">        tmp = <span class="number">0</span></span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">while</span> i &lt;= target // <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">if</span> tmp &lt; target:</span><br><span class="line">                tmp += j</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> tmp &gt; target:</span><br><span class="line">                tmp -= i</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.append([x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(i, j)])</span><br><span class="line">                tmp -= i</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:104 ms,击败了84.47% 的Python3用户<br>内存消耗:13.5 MB,击败了19.37% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[][] findContinuousSequence(<span class="keyword">int</span> target) &#123;</span><br><span class="line">        List&lt;<span class="keyword">int</span>[]&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">1</span>, right = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(left &lt;= target / <span class="number">2</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(tmp &lt; target) tmp += right++;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(tmp &gt; target) tmp -= left++;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">int</span>[] temp = <span class="keyword">new</span> <span class="keyword">int</span>[right - left];</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; temp.length; i++) temp[i] = left + i;</span><br><span class="line">                list.add(temp);</span><br><span class="line">                tmp -= left++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span>[][] res = <span class="keyword">new</span> <span class="keyword">int</span>[list.size()][];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; res.length; i++) &#123;</span><br><span class="line">            res[i] = list.get(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了79.58% 的用户<br>内存消耗：36.6 MB, 在所有 Java 提交中击败了47.66% 的用户</p>
<h2 id="博弈论系列"><a href="#博弈论系列" class="headerlink" title="博弈论系列"></a>博弈论系列</h2><blockquote>
<p>本系列将为大家带来一整套的博弈论问题。因为在面试的过程中，除了常规的算法题目，我们经<br>常也会被问到一些趣味题型来考察思维，而这类问题中，很多都有博弈论的影子存在。这些公司里以FLAG（Facebook, LinkedIn, Amazon, Google）为典型，特别喜欢考察本类题型。同时，本系列将不一定都是算法问题，不是IT行业的小伙伴也可以进行学习，来提高分析问题的能力~</p>
</blockquote>
<h3 id="1-囚徒困境"><a href="#1-囚徒困境" class="headerlink" title="1.囚徒困境"></a>1.囚徒困境</h3><p>一件严重的纵火案发生后，警察在现场抓到两个犯罪嫌疑人。事实上，正是他们一起放火烧了这座仓库。但是，警方没有掌握足够的证据，只得把他们分开囚禁起来，要求他们坦白交代。</p>
<p>在分开囚禁后，警察对其分别告知：<br>如果你坦白，而对方不坦白，则将你释放，判对方8年。<br>如果你不坦白，而对方坦白，则将对方释放，而判你8年。<br>如果你两都坦白了，则判你两各自4年。<br>那么两个囚犯应该如何做，是互相背叛还是一起合作？</p>
<p><strong>题目分析</strong> 从表面上看，其实囚犯最应该的就是一起合作，都不坦白，这样因为证据不足，会将两人都进行释放。<br>但是！因为事实确实是两人放的火，所以他们<strong>不得不进行思考，另一人采取了什么样的行为？</strong></p>
<p>犯人甲当然不傻，他根本无法相信同伙不会向警方提供任何信息！因为如果同伙一旦坦白，而自己这边如果什么都没说的话，就可以潇洒而去。但他同时也意识到，他的同伙也不傻，也会同样来这样设想他。</p>
<p>所以犯人甲的结论是，<strong>唯一理性的选择就是背叛同伙</strong>，把一切都告诉警方！这样的话，如果他的同伙笨得只会保持沉默，那么他就会是那个离开的人。而如果他的同伙也根据这个逻辑向警方交代了，那么也没有关系，起码他不必服最重的刑！</p>
<p>这场博弈的过程，<strong>显然不是顾及团体利益的最优解决方案</strong>。以全体利益而言，如果两个参与者都合作保持沉默，两人都可以无罪释放，总体利益更高！但根据假设（人性），二人<strong>均为理性的个人</strong>，且只追求自己的个人利益。均衡状况会是两个囚徒都选择背叛，这就是“困境”所在！</p>
<p>事实上，这种<strong>两人都选择坦白的策略以及因此被判4年的结局</strong>被称作“<strong>纳什均衡</strong>”（也叫非合作均衡），换言之，在此情况下，<strong>无一参与者可以“独自行动”（即单方面改变决定）而增加收获</strong>。</p>
<p>我们看一下官方释意是多么难懂“所谓纳什均衡，指的是参与人的一种策略组合，在该策略组合上，<strong>任何参与人单独改变策略都不会得到好处</strong>。”简单点讲，如果在一个策略组合上，当所有其他人都不改变策略时，没有人会改变自己的策略，则该策略组合就是一个纳什均衡。</p>
<h3 id="2-辛普森悖论"><a href="#2-辛普森悖论" class="headerlink" title="2.辛普森悖论"></a>2.辛普森悖论</h3><p>羊羊医院里统计了两种胆结石治疗方案的治愈率。在统计过程中，医生将病人分为大胆结石和小胆结石两组。统计结果如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/26.jpg" alt></p>
<ul>
<li>对于小胆结石而言，手术A的治愈率（93%）高于手术B（87%）</li>
<li>对于大胆结石而言，手术A的治愈率（73%）高于手术B（69%）</li>
</ul>
<p><strong>羊羊医院的医生得出结论：</strong></p>
<p>无论是对于大小胆结石，手术A的治愈率都胜过手术B。</p>
<p>但是真的是这样吗？当然不是，我们根据样本统计出大小胆结石总计的治愈率，发现<strong>手术B(治愈率83%)其实是要高于手术A(治愈率78%)</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/27.jpg" alt></p>
<p>为什么会出现这样的结果？这就是著名的<strong>辛普森悖论</strong>。</p>
<p><strong>题目分析</strong> 得到了结论，我们来思考背后的东西。在我们的直觉里有这样一个逻辑：<strong>如果一个事物的各部分都分别大于另一个事物的各部分，那么这个事物大于另一个事物</strong>。比如：我们的直觉告诉我们如果手术A在两组病人中都更好，那么在所有病人中也应该更好。<br>我们可以将其公式化（<strong>该公式错误</strong>），假设：</p>
<p>A=A1+A2+….+An<br>B=B1+B2+….+Bn<br>如果对i=1,2…,n都有Ai&gt;Bi，则A&gt;B</p>
<p>乍一看，我们觉得该公式没有问题，所以这个公式也就代表了我们大部分人的思维工作。其实在这个公式中，隐藏掉了一个很重要的条件：<strong>A1、A2、An 以及 B1、B2、Bn 并不能简单的通过“加”来得到 A或者B</strong>。这就是<strong>可加性</strong>的前提。在大脑的思维过程中，因为我们很难直接看到这个前提，进而就导致了我们错误的思考！</p>
<p>下面我们举一些在生活中常见的辛普森悖论例子：</p>
<ul>
<li>打麻将的时候，把把都赢小钱，造成赢钱的假象，其实不如别人赢一把大的。</li>
<li>在苹果和安卓的竞争中，你听见身边的人都在逃离苹果，奔向安卓。但是其实苹果的流入率还是要高于安卓。（有数据证明，很经典的案例）</li>
<li>你男票，这里比别人差，那里比别人差，但是其实他真的比别的男生差吗？（这个纯属本人胡扯了..）</li>
</ul>
<h3 id="3-红眼睛和蓝眼睛"><a href="#3-红眼睛和蓝眼睛" class="headerlink" title="3.红眼睛和蓝眼睛"></a>3.红眼睛和蓝眼睛</h3><p>一个岛上有100个人，其中有5个红眼睛，95个蓝眼睛。这个岛有三个奇怪的宗教规则。</p>
<p>1.他们不能照镜子，不能看自己眼睛的颜色。<br>2.他们不能告诉别人对方的眼睛是什么颜色。<br>3.一旦有人知道了自己是红眼睛，他就必须在当天夜里自杀。</p>
<p>某天，有个旅行者到了这个岛上。由于不知道这里的规矩，所以他在和全岛人一起狂欢的时候，不留神就说了一句话：【你们这里有红眼睛的人。】</p>
<p>问题：假设这个岛上的人每天都可以看到其他所有人，每个人都可以做出缜密的逻辑推理，请问岛上会发生什么？</p>
<p><strong>题目分析</strong> 题目乍看之下，没有任何逻辑可言！以目测条件，基本无法完成任何正常的推理。但是在仔细推敲之后，我们可以将问题简化，从假设只有1个红眼睛开始分析。</p>
<p>我们假设岛上只有1个红眼睛的人，还有99个都是蓝眼睛。因为这个旅行者说了“这里有红眼睛的人”，<strong>那么在第一天的时候，这个红眼睛会发现其他的人都是蓝眼睛</strong>（与此同时，其他人因为看到了这个红眼睛的人，所以都确认了自己的安全）<strong>那么这天晚上，这个红眼睛的人一定会自杀！</strong></p>
<p>继续分析，假设这个岛上有2个红眼睛，那么当旅行者说“这里有红眼睛的人”之后的第一天，这两个红眼睛分别发现还有别的红眼睛存在，所以他们当天晚上认为自己是安全的。但是到了第二天，红眼睛惊讶的发现，<strong>另一个红眼睛的人竟然没有自杀（说明岛上有不止一个红眼睛），并且当天他们也没有发现有别的红眼睛存在（说明另一个红眼睛就是自己）</strong>WTF，那肯定另一个红眼睛就是自己了，所以<strong>在第二天夜里，两个红眼睛的人会同时自杀！</strong></p>
<p>继续分析，假如岛上红眼睛有3个。那么在第一天，红眼睛发现了岛上还有另外两个红眼睛，红眼睛呵呵一笑，“反正不是我”。到了第二天，红眼睛仍然看到了另外两个红眼睛，红眼睛心想，”这下你两该完蛋了吧”，毕竟你两都知道了自己是红眼睛，晚上回去统统自杀吧！（根据上面的推论得出）但是惊奇的是，<strong>到了第三天，红眼睛发现另外两个红眼睛竟然都没有自杀。（说明岛上红眼睛的人不止两个）</strong>并且当天红眼睛也没发现新的红眼睛（<strong>说明还有一个红眼睛就是自己</strong>）所以在第三天的夜里，三个红眼睛会同时自杀。</p>
<p>根据上面的推论，<strong>假设有N个红眼睛，那么到了第N天，这N个红眼睛就会自杀</strong>。所以最终这个岛上红眼睛的人会统统自杀！这就是答案，生活就是这么朴实无华，且枯燥。</p>
<p><strong>旅客的挽回</strong><br>上面的分析大家应该都看懂了。但若是在旅客说完这句话后，其并没有离开这个岛。同时他也看到了周围人眼里的惊慌和失措，这个时候，旅客为自己的行为感到了懊恼和悔恨！旅客决定对自己的话进行挽回，旅客又该怎么做呢？</p>
<p>这里我提供一种思路，<strong>旅客可以在第N次集会上杀掉N个红眼睛</strong>，让这N个红眼睛 “GO TO SLEEP”，就可以中断事件的推理。事实上，基于人道主义，旅客并不需要手动杀人，她只需要在第N天的时候告诉这N个人，你们是红眼睛，那么这天晚上，这N个人就会自杀。”All RETURN”，一切将回归秩序~</p>
<h3 id="4-海盗分金币"><a href="#4-海盗分金币" class="headerlink" title="4.海盗分金币"></a>4.海盗分金币</h3><p>在大海上，有5个海盗抢得100枚金币，他们决定每一个人按顺序依次提出自己的分配方案，如果提出的方案没有获得半数或半数以上的人的同意，则这个提出方案的人就被扔到海里喂鲨鱼。那么第一个提出方案的人要怎么做，才能使自己的利益最大化？</p>
<p>海盗们有如下特点：<br>1.足智多谋，总是采取最优策略。<br>2.贪生怕死，尽量保全自己性命。<br>3.贪得无厌，希望自己得到越多宝石越好<br>4.心狠手辣，在自己利益最大的情况下希望越多人死越好。<br>5.疑心多虑，不信任彼此，尽量确保自身利益不寄希望与别人给自己更大利益。</p>
<p><strong>题目分析</strong> 首先我们很容易会觉得，抽签到第一个提方案的海盗会很吃亏！因为只要死的人够多，那么平均每个人获取的金币就最多，而第一个提方案的人是最容易死的。但是事实是，在满足海盗特点的基础上，<strong>第一个提方案的海盗是最赚的</strong>，我们一起来分析一下。</p>
<p>假如我们设想只有两个海盗。那么不管第一个说什么，只要第二个人不同意，第二个人就可以得到全部的金币！所以第一个海盗必死无疑，这个大家都能理解。（当然，这样的前提是一号提出方案后不可以马上自己同意，不然如果自己提出给自己全部金币的方案，然后自己支持，这样就是二号必死无疑）</p>
<p>假如现在我们加入第三个海盗，这时候原来的一号成为了二号，二号成为了三号。这时候现在的二号心里会清楚，<strong>如果他投死了一号，那么自己必死无疑！</strong>所以根据贪生怕死的原则，二号肯定会让一号存活。而此时一号心理也清楚，无论自己提出什么样的方案，二号都会让自己存活，而这时只要加上自己的一票，就有半数通过，所以一号提出方案：把金币都给我。</p>
<p>现在又继续加入了新的海盗！原来的1,2,3号，成为了现在的2,3,4号。这时候新的一号海盗洞悉了奥秘，知道了<strong>如果自己死了，二号就可以获取全部的金币</strong>，所以提出给三号和四号一人一个金币，一起投死2号。而与此同时，现在的3号和4号获取的要比三个人时多（三个人时自己获取不了任何金币），所以他们会同意这个方案！</p>
<p>现在加入我们的大Boss，最后一个海盗。根据分析，大Boss海盗1号推知出2号的方案后就可以提出(97,0,1,2,0)或者(97,0,1,0,2)的方案。这样的分配方案对现在的3号海盗相比现在的2号的分配方案还多了一枚金币，就会投赞成票，4号或者5号因为得到了2枚金币，相比2号的一枚多，也会支持1号，加上1号自己的赞成票，方案就会通过，即1号提出(97,0,1,2,0)或(97,0,1,0,2)的分配方案，大Boss成功获得了97枚金币。</p>
<p><strong>思考</strong> 最终，大Boss一号海盗得到97枚金币，投死了老二和老五，这竟然是我们分析出的最佳方案！这个答案明显是反直觉的，如果你是老大，你敢这样分金币，必死无疑。可是，推理过程却非常严谨，无懈可击，那么问题出在哪里呢？</p>
<p>其实，在”海盗分赃”模型中，任何”分配者”想让自己的方案获得通过的关键是，事先考虑清楚”对手”的分配方案是什么，<strong>并用最小的代价获取最大收益，拉拢”对手”分配方案中最不得意的人们</strong>。1号看起来最有可能喂鲨鱼，但他牢牢地把握住先发优势，结果不但消除了死亡威胁，还收益最大。而5号，看起来最安全，没有死亡的威胁，甚至还能坐收渔人之利，却因不得不看别人脸色行事而只能分得一小杯羹。</p>
<p>不过，模型任意改变一个假设条件，最终结果都不一样。而现实世界远比模型复杂。<strong>因为假定所有人都理性，本身就是不理性的。</strong>回到“海盗分金”的模型中，只要3号、4号或5号中有一个人偏离了绝对聪明的假设，海盗1号无论怎么分都可能会被扔到海里去了。所以，1号首先要考虑的就是他的海盗兄弟们的聪明和理性究竟靠得住靠不住，否则先分者必定倒霉。</p>
<p>如果某人和一号本身不对眼，就想丢他喂鲨鱼。果真如此，1号自以为得意的方案岂不成了自掘坟墓。再就是俗话所说的“人心隔肚皮”。由于信息不对称，谎言和虚假承诺就大有用武之地，而阴谋也会像杂草般疯长，并借机获益。如果2号对3、4、5号大放烟幕弹，宣称对于1号所提出任何分配方案，他一定会再多加上一个金币给他们。这样，结果又当如何？</p>
<p>通常，现实中人人都有自认的公平标准，因而时常会嘟嚷：“<strong>谁动了我的奶酪？</strong>”可以料想，一旦1号所提方案和其所想的不符，就会有人大闹。当大家都闹起来的时候，1号能拿着97枚金币毫发无损、镇定自若地走出去吗？最大的可能就是，海盗们会要求修改规则，然后重新分配。当然，大家也可以讲清楚下次再得100枚金币时，先由2号海盗来分…然后是3号……颇有点像美国总统选举，轮流主政。说白了，其实是民主形式下的分赃制。</p>
<p>最可怕的是其他四人形成一个反1号的大联盟并制定出新规则：四人平分金币，将1号扔进大海。这就颇有点阿Q式的革命理想：高举平均主义的旗帜，将富人扔进死亡深渊。</p>
<h3 id="5-智猪博弈"><a href="#5-智猪博弈" class="headerlink" title="5.智猪博弈"></a>5.智猪博弈</h3><p>假设猪圈里有一头大猪、一头小猪。猪圈的一头有猪食槽，另一头安装着控制猪食供应的按钮，按一下按钮会有10个单位的猪食进槽，,但是按按钮以后跑到食槽所需要付出的劳动量，加起来要消耗相当于2个单位的猪食。并且因为按钮和食槽分置笼子的两端，等到按按钮的猪付出劳动跑到食槽的时候，坐享其成的另一头猪早已吃了不少。如果大猪先到（小猪按），大猪吃掉9个单位，小猪只能吃到1个单位；如果同时到达（也就是一起按），大猪吃掉7个单位，小猪吃到3个单位；如果小猪先到（大猪按），小猪可以吃到4个单位，而大猪吃到6个单位。那么，在两头猪都足够聪明的前提下，最终的结果是什么？</p>
<blockquote>
<p>首先小猪如果去按按钮，然后再回来的话，只能吃到一份猪食，直接就嗝屁了，这种可能性肯定是不行的。自然，这时大猪也就只有去按按钮这一个选项了。所以最终的结果会是：<strong>小猪选择等待，大猪去按按钮</strong>。</p>
<ul>
<li><p>如果小猪和大猪同时行动的话，则它们同时到达食槽，分别得到1个单位和5个单位的纯收益（付出4个单位的成本）</p>
</li>
<li><p>如果大猪行动，小猪等待，小猪可得到4个单位的纯收益，大猪得到的6个单位，付出2个单位的成本，实得4个单位；</p>
</li>
<li><p>如果大猪等待，小猪行动，小猪只能吃到1个单位，则小猪的收入将不抵成本，纯收益为-1。</p>
</li>
<li><p>如果大猪等待，小猪也等待，那么小猪的收益为零，成本也为零，总之，小猪等待还是要优于行动。</p>
</li>
</ul>
<p>这道题目是一个很经典的“<strong>劣势策略”下的可预测问题</strong>，其在各高校经济学课程中也被放在一个举足轻重的地位上。原因无他，正是大猪做出这样一个“决策”，目的不是出于对小猪的爱，<strong>而是基于“自利”的原则</strong>。</p>
</blockquote>
<h3 id="6-生男生女问题"><a href="#6-生男生女问题" class="headerlink" title="6.生男生女问题"></a>6.生男生女问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>题目：国家为了调控男女比例，制定了一个政策：新婚夫妇都必须生娃（接地气），如果生出的是男娃就不能再生了，如果生出的是女娃就必须继续生下去，直到生出第一个男娃为止（出题人牛P）。</th>
</tr>
</thead>
<tbody>
<tr>
<td>问题是：若干年后，该国的男女比例会发生怎样的变化？</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>其实这个问题答案是比较反直觉的：<strong>没有变化</strong>。原因是因为：<strong>生男生女的概率永远都是百分之50</strong>。</p>
<p>或者我们也可以换一种思路：我们不妨假设把一大批新婚夫妇关在一个超大的屋子里，逼着他们进行一轮一轮的生孩子游戏。第一轮里，有一半的夫妇生了男娃，退出了游戏；另一半夫妇得到的是女娃，进入第二轮。在第二轮里面，又有一半由于生出男娃而退出，自然，另一半生出女娃的夫妇进入第三轮……注意到，在每一轮里，新生男娃和新生女娃都是一样多的，因此把所有轮数合在一起看，男娃的总数和女娃的总数也一定是相同的。</p>
</blockquote>
<h3 id="7-硬币问题"><a href="#7-硬币问题" class="headerlink" title="7.硬币问题"></a>7.硬币问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>题目：A和B两人为了竞价一个拍卖品，决定用抛掷硬币的办法来判断谁有资格。为了让游戏过程更加刺激，A提出了这样一个方案：连续抛掷硬币，直到最近三次硬币抛掷结果是“正反反”或者“反反正”。如果是前者，那么A获胜；如果是后者，那么B获胜</th>
</tr>
</thead>
<tbody>
<tr>
<td>问题是：B应该接受A的提议吗？换句话说，这个游戏是公平的吗？</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>事实，该游戏并不公平。虽然“正反反”和“反反正”在频率上出现的一样，但是其之间却有一个竞争关系：<strong>一旦抛硬币产生其中一种序列，游戏即结束</strong>。所以不论何时，只要抛出一个正面，也就意味着B必输无疑。换句话说，在整个游戏的前两次抛掷中，只要出现“正正”，“正反”，“反正”其中任一，A则一定会取得胜利。A和B的概率比达到3:1，优势不言而喻。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/45.png" alt></p>
</blockquote>
<h3 id="8-画圈圈的问题"><a href="#8-画圈圈的问题" class="headerlink" title="8.画圈圈的问题"></a>8.画圈圈的问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>面试题：小浩出去面试时，面试官拿出一张纸，在纸上从左到右画了一百个小圆圈（手速快，没办法）接下来，面试官要求两人轮流涂掉其中一个或者两个相邻的小圆圈。</th>
</tr>
</thead>
<tbody>
<tr>
<td>规定：谁涂掉最后一个小圆圈谁就赢了（换句话说，谁没有涂的了谁就输了）。问题是：小浩应该选取先涂还是后涂？如何才能有必胜策略？</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p> 作为聪明机智的小浩（没见过这么夸自己的），最后当然是小浩获胜。获胜的方法：<strong>小浩强烈要求先手进行游戏，并且在游戏开始时，先把正中间的两个小圆圈涂黑，于是左右两边各剩下了49个圆圈</strong>。像是下面这样：</p>
<p> <img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/46.png" alt><br> 然后小浩开始模仿（逼死）面试官，面试官在左边涂掉哪些圆圈，小浩就对称地在右边涂掉哪些圆圈；面试官在右边涂掉哪些圆圈， 小浩就对称地在左边涂掉哪些圆圈。因此，只要面试官有走的，小浩就一定有走的，最终保证能获胜。</p>
<p> 在博弈论中，这类游戏就叫做“<strong>无偏博弈</strong>”（impartial game）。<strong>在无偏博弈中，如果对于某个棋局状态，谁遇到了它谁就有办法必胜，我们就把它叫做“必胜态”；如果对于某个棋局状态，谁遇到了它对手就会有办法必胜，我们就把它叫做“必败态”</strong>。</p>
</blockquote>
<h3 id="9-巧克力问题"><a href="#9-巧克力问题" class="headerlink" title="9.巧克力问题"></a>9.巧克力问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>面试题：小浩出去面试时，面试官掏出一块10×10个小块的巧克力。首先，面试官把巧克力掰成两大块，并且吃掉其中一块，把另一块交给小浩。小浩再把剩下的巧克力掰成两大块，吃掉其中一块，把另一块交回给面试官。两个人就这样无聊且枯燥的掰呀掰。。。</th>
</tr>
</thead>
<tbody>
<tr>
<td>规定：谁没办法往下继续掰，谁就输了。如果面试官先开始掰的话，面试官和小浩谁有必胜策略？（面试官输了，小浩将赢得面试）</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>作为聪明机智的小浩（没见过这么夸自己的），最后当然是小浩获胜。获胜的方法：<strong>只要小浩一直保持巧克力是正方形就可以了</strong>。不管面试官咋掰，最后都会掰成一个长宽不相等的正方形。直到最后一次将其变成一个1×1的巧克力，此时面试官就输掉了面试。哦不，是小浩赢得了面试。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/47.png" alt></p>
</blockquote>
<p><strong>[超级改编版]</strong> 如果巧克力换成边长为10的等边三角形，长这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/48.png" alt></p>
<p>每次只能<strong>沿着线条掰下一个小等边三角形吃掉</strong>，假若还是由面试官开局，请问，谁必胜？</p>
<blockquote>
<p>等边三角形是小浩赢。</p>
<p>1.面试官先手沿着任意一条线掰开。<br>2.剩下的等腰梯形中，小浩从面试官掰开处将等腰梯形掰成等边三角形和平行四边形，将平行四边形还给面试官。<br>3.面试官在平行四边形的两个角中任意掰出个等边三角形。<br>4.小浩掰另一个角大小跟面试官一致，此时剩下的巧克力有三种可能的形态：</p>
<ul>
<li>平行四边形缺了两个小角：此形状给面试官 他已经没有办法掰出一个等边三角形。面试官输了。</li>
<li>依然是平行四边形：陷入此步循环，直到掰没了：最后的平行四边形可以由两个等边三角形组合而成，小浩后掰，小浩赢了。</li>
</ul>
</blockquote>
<h3 id="10-大鱼和小鱼的问题"><a href="#10-大鱼和小鱼的问题" class="headerlink" title="10.大鱼和小鱼的问题"></a>10.大鱼和小鱼的问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>大鱼小鱼的问题：假设有10条鱼，它们从小到大依次编号为1, 2, …, 10。我们规定，吃鱼必须要严格按顺序执行。也就是说，大鱼只能吃比自己小一级的鱼，不能越级吃更小的鱼；并且只有等到第k条鱼吃了第k-1条鱼后，第k+1条鱼才能吃第k条鱼。</th>
</tr>
</thead>
<tbody>
<tr>
<td>同时：第1条鱼则啥都不能吃，只有被吃的份儿。我们假设，如果有小鱼吃的话，大鱼肯定不会放过；但是，保全性命的优先级显然更高，在吃小鱼之前，大鱼得先保证自己不会被吃掉才行。假设每条鱼都是无限聪明的（并且它们也都知道这一点，并且它们也都知道它们知道这一点……），那么第1条鱼能存活下来吗？</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>我们是有十条鱼，分析起来是比较麻烦的。所以我们从最简单的两条鱼开始分析：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/49.png" alt><br>两条鱼的情况下，第二条鱼就是无敌的存在，他不用担心自己被吃掉！如果是三条鱼：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/50.png" alt><br>3条鱼的情况下，第2条鱼不能吃第1条鱼，否则将化为只有2条鱼的情形，它将会被第3条鱼吃掉。如果是四条鱼，就有意思了：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/51.png" alt><br>此时第2条鱼可以大胆地吃掉第1条鱼，因为根据前面的结论，它知道第3条鱼是不敢吃它的。问题来了，五条鱼会如何：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/52.png" alt><br>5条鱼的情况下，第2条鱼是不敢吃第1条鱼的，因为如果它吃了第一条鱼。问题转化为4条鱼的场景，原3号鱼就可以大胆吃掉原2号鱼，因为它知道4号鱼是不敢吃它的，否则5号鱼就会吃掉4号鱼（绕不绕）。</p>
<p>我们发现一个有趣的结论，只要鱼有奇数个，那么第一条鱼将总是可以活下来。如果鱼是偶数个，那么第二条鱼将总是可以吃掉第一条鱼，将状态转化到奇数条鱼的场景。</p>
<p>所以该题的答案是：不能，在十条鱼的场景下，第一条鱼必死无疑。</p>
</blockquote>
<h2 id="排序系列"><a href="#排序系列" class="headerlink" title="排序系列"></a>排序系列</h2><h3 id="1-按奇偶排序数组"><a href="#1-按奇偶排序数组" class="headerlink" title="1.按奇偶排序数组"></a>1.按奇偶排序数组</h3><blockquote>
<p>插入排序：就是炸金花的时候，你接一个同花顺的过程。（标准定义：在要排序的一组数中，假定前n-1个数已经排好序，现在将第n个数插到前面的有序数列中，使得这n个数也是排好顺序的）</p>
</blockquote>
<p><strong>[第905题]</strong> 给定一个非负整数数组A，返回一个数组，在该数组中， A的所有偶数元素之后跟着所有奇数元素。你可以返回满足此条件的任何数组作为答案。 </p>
<ul>
<li>示例：<br>输入：[3,1,2,4]<br>输出：[2,4,3,1]<br>输出 [4,2,3,1]，[2,4,1,3] 和 [4,2,1,3] 也会被接受。</li>
</ul>
<blockquote>
<p>这道题，按照插入排序的思想，很容易可以想到题解。我们只需要遍历数组，当我们遇到偶数时，将其插入到数组前最近的一个为奇数的位置，<strong>与该位置的奇数元素交换</strong>。为了达成该目的，我们引入一个指针 j，来维持这样一个奇数的位置。</p>
<p>假设我们的数组为：[3,1,2,4]</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/28.jpg" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortArrayByParity</span>(<span class="params">self, A: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A)):</span><br><span class="line">            <span class="keyword">if</span> A[i] % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                A[j], A[i] = A[i], A[j]</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> A</span><br></pre></td></tr></table></figure>
<p>执行耗时:100 ms,击败了61.73% 的Python3用户<br>内存消耗:13.9 MB,击败了50.05% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] sortArrayByParity(<span class="keyword">int</span>[] A) &#123;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; A.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(A[i] % <span class="number">2</span> == <span class="number">0</span>) swap(A, i, j++);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> A;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[] A, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> tmp = A[i];</span><br><span class="line">        A[i] = A[j];</span><br><span class="line">        A[j] = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：39.6 MB, 在所有 Java 提交中击败了5.02% 的用户</p>
<h2 id="位运算系列"><a href="#位运算系列" class="headerlink" title="位运算系列"></a>位运算系列</h2><h3 id="1-使用位运算求和"><a href="#1-使用位运算求和" class="headerlink" title="1.使用位运算求和"></a>1.使用位运算求和</h3><blockquote>
<p>该题很容易出现在各大厂的面试中，属于必须掌握的题型。</p>
</blockquote>
<p><strong>[剑指offer 64]</strong> 求 1 2 … n ，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）。</p>
<ul>
<li>示例 1：<br>输入: n = 3 输出: 6</li>
<li>示例 2：<br>输入: n = 9 输出: 45</li>
<li>限制：<br>1 &lt;= n &lt;= 10000</li>
</ul>
<blockquote>
<p>题目上手，因为不能使用公式直接计算（公式中包含乘除法），所以考虑使用递归进行求解，但是递归中一般又需要使用if来指定返回条件（这里不允许使用if），所以没办法使用普通的递归思路。</p>
<p>首先我们了解一下 &amp;&amp; 的特性，比如有 A&amp;&amp;B<br>如果A为true，返回B的布尔值（继续往下执行）<br>如果A为false，直接返回false（相当于短路）</p>
<p>利用这一特性，我们将递归的返回条件取非然后作为 &amp;&amp; 的第一个条件，递归主体转换为第二个条件语句。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">sumNums</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">		<span class="keyword">return</span> n <span class="keyword">and</span> (n + self.sumNums(n-<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>执行用时：48 ms, 在所有 Python 提交中击败了10.79% 的用户<br>内存消耗：20.1 MB, 在所有 Python 提交中击败了37.95% 的用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sumNums</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> b = n &gt; <span class="number">0</span> &amp;&amp; (n += sumNums(n - <span class="number">1</span>)) &gt; <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了58.91% 的用户<br>内存消耗：35.8 MB, 在所有 Java 提交中击败了28.19% 的用户</p>
<h3 id="2-2的幂"><a href="#2-2的幂" class="headerlink" title="2.2的幂"></a>2.2的幂</h3><p><strong>[第231题]</strong> 给定一个整数，编写一个函数来判断它是否是2的幂次方。</p>
<ul>
<li>示例 1:<br>输入: 1<br>输出: true<br>解释: $2^0 $= 1</li>
<li>示例 2:<br>输入: 16<br>输出: true<br>解释: $2^4$ = 16</li>
<li>示例 3:<br>输入: 218<br>输出: false</li>
</ul>
<blockquote>
<p>先观察一些是2的幂的二进制数：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/29.jpg" alt><br>然后我们再观察下面这样的一组数，对应着上面的数减去1：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/30.jpg" alt><br>我们对两组数求“&amp;”运算：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/31.jpg" alt><br>可以看到，对于N为2的幂的数，都有 N&amp;(N-1)=0 ，所以这就是我们的判断条件。（这个技巧可以记忆下来，在一些别的位运算的题目中也是会用到的）</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isPowerOfTwo</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">return</span> n &gt; <span class="number">0</span> <span class="keyword">and</span> n &amp; (n-<span class="number">1</span>) == <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:52ms,击败了17.68% 的Python3用户<br>内存消耗:13.3 MB,击败了77.73% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPowerOfTwo</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//a % b 若b为2的整数次幂，则该式等价于a与b-1的位与</span></span><br><span class="line">        <span class="keyword">return</span> n &gt; <span class="number">0</span> &amp;&amp; ((n &amp; (n-<span class="number">1</span>)) == <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.6 MB, 在所有 Java 提交中击败了28.30% 的用户</p>
<h3 id="3-返回一个数二进制中1的个数"><a href="#3-返回一个数二进制中1的个数" class="headerlink" title="3.返回一个数二进制中1的个数"></a>3.返回一个数二进制中1的个数</h3><p><strong>[第191题]</strong> 编写一个函数，输入是一个无符号整数，返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为汉明重量）。 </p>
<ul>
<li>示例 1：<br>输入：00000000000000000000000000001011<br>输出：3<br>解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 ‘1’。</li>
<li>示例 2：<br>输入：00000000000000000000000010000000<br>输出：1<br>解释：输入的二进制串 00000000000000000000000010000000 中，共有一位为 ‘1’。</li>
<li>示例 3：<br>输入：11111111111111111111111111111101<br>输出：31<br>解释：输入的二进制串 11111111111111111111111111111101 中，共有31位为 ‘1’。 </li>
</ul>
<p>提示：<br>请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。<br>在 Java 中，编译器使用二进制补码记法来表示有符号整数。因此，在上面的示例3中，输入表示有符号整数-3。 </p>
<p><strong>方法一</strong></p>
<blockquote>
<p>这道题仍然是通过位运算来进行求解的非常典型的题目。掩码是指使用一串二进制代码对目标字段进行位与运算，屏蔽当前的输入位。</p>
<p>我们直接把目标数转化成二进制数，然后遍历每一位看看是不是1，如果是1就记录下来。</p>
<p>我们可以构造一个掩码来进行，其实就是弄个1出来，1的二进制是这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/32.jpg" alt><br>我们只需要让这个掩码每次向左移动一位，然后与目标值求“&amp;”，就可以判断目标值的当前位是不是1。比如目标值为21，21的二进制是这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/33.jpg" alt><br>然后每次移动掩码，来和当前位进行计算：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/34.jpg" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        mask = <span class="number">1</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">            <span class="keyword">if</span> (n &amp; mask) != <span class="number">0</span>:</span><br><span class="line">                result += <span class="number">1</span></span><br><span class="line">            mask &lt;&lt;= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了75.02% 的Python3用户<br>内存消耗:13.4 MB,击败了26.44% 的Python3用户</p>
<p>注意：这里判断 n&amp;mask 的时候，千万不要错写成 (n&amp;mask) == 1，因为这里你对比的是十进制数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="comment">// you need to treat n as an unsigned value</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hammingWeight</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; i++) &#123;</span><br><span class="line">            count += n &amp; <span class="number">1</span>;    </span><br><span class="line">            n &gt;&gt;&gt;= <span class="number">1</span>; <span class="comment">//无符号右移</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.7 MB, 在所有 Java 提交中击败了5.02% 的用户</p>
<p><strong>方法二</strong></p>
<blockquote>
<p>位运算小技巧: 对于任意一个数，将 n 和 n-1 进行 &amp; 运算，我们都可以把 n 中最低位的 1 变成 0</p>
<p>我们拿 11 举个例子：（注意最后一位1变成0的过程）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/35.jpg" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> n != <span class="number">0</span>:</span><br><span class="line">            n = n &amp; (n-<span class="number">1</span>)</span><br><span class="line">            result += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了75.02% 的Python3用户<br>内存消耗:13.6 MB,击败了5.40% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="comment">// you need to treat n as an unsigned value</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hammingWeight</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(n != <span class="number">0</span>) &#123;</span><br><span class="line">            n &amp;= (n-<span class="number">1</span>);    </span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了95.92% 的用户<br>内存消耗：35.1 MB, 在所有 Java 提交中击败了94.71% 的用户</p>
<p><strong>方法三：利用Python内置方法</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hammingWeight</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">bin</span>(n).count(<span class="string">&#x27;1&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了75.02% 的Python3用户<br>内存消耗:13.6 MB,击败了5.40% 的Python3用户</p>
<h3 id="4-只出现一次的数字"><a href="#4-只出现一次的数字" class="headerlink" title="4.只出现一次的数字"></a>4.只出现一次的数字</h3><p><strong>[第136题]</strong> 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。<br>说明：<br>你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？ </p>
<ul>
<li>示例 1:<br>输入: [2,2,1]<br>输出: 1</li>
<li>示例 2:<br>输入: [4,1,2,1,2]<br>输出: 4 </li>
</ul>
<blockquote>
<p>对于任意两个数a和b，我们对其使用 “异或”操作，应该有以下性质：</p>
<p>任意一个数和0异或仍然为自己：a⊕0 = a</p>
<p>任意一个数和自己异或是0：a⊕a=0</p>
<p>异或操作满足交换律和结合律：a⊕b⊕a=(a⊕a)⊕b=0⊕b=b</p>
<p><strong>因为其余元素均出现两次，所以根据异或操作的交换律和结合律对数组进行迭代，最终留下的就是只出现一次的数字</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            res ^= nums[i]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了46.94% 的Python3用户<br>内存消耗:15.1 MB,击败了34.55% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums) res ^= num;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了99.75% 的用户</p>
<h3 id="5-只出现一次的数字Ⅱ"><a href="#5-只出现一次的数字Ⅱ" class="headerlink" title="5.只出现一次的数字Ⅱ"></a>5.只出现一次的数字Ⅱ</h3><p><strong>[第137题]</strong> 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现了三次。找出那个只出现了一次的元素。说明：你的算法应该具有线性时间复杂度。你可以不使用额外空间来实现吗？ </p>
<ul>
<li>示例 1:<br>输入: [2,2,3,2]<br>输出: 3</li>
<li>示例 2:<br>输入: [0,1,0,1,0,1,99]<br>输出: 99 </li>
</ul>
<p><strong>方法一：HashMap求解</strong></p>
<blockquote>
<p>很简单就能想到，说白了就是<strong>统计每个元素出现的次数，最终再返回次数为1的元素</strong>。但是使用了额外空间。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="built_in">map</span> = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> <span class="built_in">map</span>:</span><br><span class="line">                <span class="built_in">map</span>[i] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">map</span>[i] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">map</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">map</span>[i] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> i</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了89.49% 的Python3用户<br>内存消耗:14.8 MB,击败了19.68% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums) map.put(num, map.getOrDefault(num, <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> key: map.keySet())&#123;</span><br><span class="line">            <span class="keyword">if</span>(map.get(key) == <span class="number">1</span>) <span class="keyword">return</span> key;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：7 ms, 在所有 Java 提交中击败了9.09% 的用户<br>内存消耗：38.2 MB, 在所有 Java 提交中击败了55.72% 的用户</p>
<p><strong>方法二：数学方式</strong></p>
<blockquote>
<p>原理：[A,A,A,B,B,B,C,C,C] 和 [A,A,A,B,B,B,C]，差了两个C。即：3×(<em>a</em> <em>b</em> <em>c</em>)−(<em>a</em> <em>a</em> <em>a</em> <em>b</em> <em>b</em> <em>b</em> <em>c</em>)=2<em>c</em></p>
<p>也就是说，如果把<strong>原数组去重、再乘以3得到的值，刚好就是要找的元素的2倍</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>((<span class="built_in">sum</span>(<span class="built_in">set</span>(nums)) * <span class="number">3</span> - <span class="built_in">sum</span>(nums)) / <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了96.69% 的Python3用户<br>内存消耗:14.7 MB,击败了26.89% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Set&lt;Integer&gt; key = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">long</span> sum1 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums) &#123;</span><br><span class="line">            key.add(num);</span><br><span class="line">            sum1 += num;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> sum2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: key) sum2 += num;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>)((<span class="number">3</span> * sum2 - sum1) / <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了37.02% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了85.08% 的用户</p>
<p><strong>方法三：位运算</strong></p>
<blockquote>
<p>对于“每个其余元素，均出现了二次”之所以可以使用“<strong>异或</strong>”进行求解，原因是因为“异或”操作可以让两数相同归0。那对于其余元素出现三次的，是不是只要可以让其三者相同归0，就能达到我们的目的呢？</p>
<p>因为各语言中都没有这样一个现成的方法可以使用，所以我们需要构造一个。（想象一下，位运算也是造出来的对不对？）</p>
<p><strong>异或运算是不是可以理解为，其实就是二进制的加法，然后砍掉进位呢？砍掉进位的过程，是不是又可以理解为对 2 进行取模</strong>，也就是取余。到了这里，问题已经非常非常明确了。那我们要完成一个 a ? a ? a = 0 的运算，是不是其实就是让其二进制的每一位数都相加，最后再对3进行一个取模的过程呢？（一样，如果要定义一个 a ? a ? a ? a = 0 的运算，那就最后对4进行取模就可以了。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># python中int为变长的，所以定义32位的列表</span></span><br><span class="line">        count = [<span class="number">0</span>] * <span class="number">32</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">            <span class="comment"># 每一位都对对应位上的所有数做和</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> nums:</span><br><span class="line">                <span class="comment"># 判断该数是否为负数</span></span><br><span class="line">                <span class="keyword">if</span> j &lt; <span class="number">0</span>:</span><br><span class="line">                    j = j &amp; <span class="number">0xffffffff</span></span><br><span class="line">                <span class="comment"># 记录该位1的个数</span></span><br><span class="line">                <span class="keyword">if</span> (j &gt;&gt; i) &amp; <span class="number">1</span> == <span class="number">1</span>:</span><br><span class="line">                    count[i] += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 最终将抵消后剩余的1放到对应的位数上</span></span><br><span class="line">            <span class="keyword">if</span> count[i] % <span class="number">3</span> == <span class="number">1</span>:</span><br><span class="line">                res |= <span class="number">1</span> &lt;&lt; i</span><br><span class="line">        <span class="comment"># 判断结果正负</span></span><br><span class="line">        <span class="keyword">return</span> res <span class="keyword">if</span> res &lt;= <span class="number">0x7FFFFFFF</span> <span class="keyword">else</span> ~(res ^ <span class="number">0xFFFFFFFF</span>)</span><br></pre></td></tr></table></figure>
<p>执行耗时:124 ms,击败了13.36% 的Python3用户<br>内存消耗:14.7 MB,击败了28.80% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] count = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">32</span>];</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">32</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> num: nums)&#123;</span><br><span class="line">                <span class="keyword">if</span>(((num &gt;&gt;&gt; i) &amp; <span class="number">1</span>) == <span class="number">1</span>) count[i] += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(count[i] % <span class="number">3</span> == <span class="number">1</span>) res += (<span class="number">1</span> &lt;&lt; i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：4 ms, 在所有 Java 提交中击败了37.02% 的用户<br>内存消耗：38.5 MB, 在所有 Java 提交中击败了9.53% 的用户</p>
<p>在上面的代码中，<strong>我们记录每一位数出现的次数</strong>。但是缺点是，我们记录了32位。那如果我们可以同时对所有位进行计数，是不是就可以简化过程。因为我们的目的是把每一位与3取模进行运算，是不是就可以理解为其实是一个<strong>三进制</strong>。所以我们就只有3个状态，00 - 01 - 10，所以我们采用 a 和 b 来记录状态。其中的状态转移过程如下：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/36.jpg" alt></p>
<p>这里 a‘ 和 b’ 的意思代表着 a 和 b 下一次的状态。next 代表着下一个 bit 位对应的值。</p>
<p>写出关系式：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">b = (b ^ next) &amp; ~a;</span><br><span class="line">a = (a ^ next) &amp; ~b; #注意这里的b已经变了，是上式求得的b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">singleNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        a, b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">next</span> <span class="keyword">in</span> nums:</span><br><span class="line">            b = (b ^ <span class="built_in">next</span>) &amp; ~a</span><br><span class="line">            a = (a ^ <span class="built_in">next</span>) &amp; ~b</span><br><span class="line">        <span class="keyword">return</span> b</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了96.69% 的Python3用户<br>内存消耗:14.6 MB,击败了38.94% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">singleNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> next: nums)&#123;</span><br><span class="line">            b = (b ^ next) &amp; ~a;</span><br><span class="line">            a = (a ^ next) &amp; ~b;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.2 MB, 在所有 Java 提交中击败了58.04% 的用户</p>
<h3 id="6-缺失数字"><a href="#6-缺失数字" class="headerlink" title="6.缺失数字"></a>6.缺失数字</h3><p><strong>[第268题]</strong> 给定一个包含[0, n]中n个数的数组nums ，找出[0, n]这个范围内没有出现在数组中的那个数。进阶： 你能否实现线性时间复杂度、仅使用额外常数空间的算法解决此问题? </p>
<ul>
<li>示例 1：<br>输入：nums = [3,0,1]<br>输出：2<br>解释：n = 3，因为有3个数字，所以所有的数字都在范围[0,3]内。2是丢失的数字，因为它没有出现在nums中。 </li>
<li>示例 2：<br>输入：nums = [0,1]<br>输出：2<br>解释：n = 2，因为有2个数字，所以所有的数字都在范围[0,2]内。2是丢失的数字，因为它没有出现在nums中。 </li>
<li>示例 3：<br>输入：nums = [9,6,4,2,3,5,7,0,1]<br>输出：8<br>解释：n = 9，因为有9个数字，所以所有的数字都在范围[0,9]内。8是丢失的数字，因为它没有出现在nums中。 </li>
<li>示例 4：<br>输入：nums = [0]<br>输出：1<br>解释：n = 1，因为有1个数字，所以所有的数字都在范围[0,1]内。1是丢失的数字，因为它没有出现在nums中。</li>
</ul>
<p><strong>方法一：数学方式</strong></p>
<blockquote>
<p>首先求出数组的和，然后再求出前n+1项之和（从0到n），最终求差值，即为缺失的值！</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">missingNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(nums) + <span class="number">1</span>)) - <span class="built_in">sum</span>(nums)</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了98.84% 的Python3用户<br>内存消耗:14.3 MB,击败了81.49% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">missingNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum1 = <span class="number">0</span>, sum2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>; i &lt;= nums.length; i++) sum1 += i;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums) sum2 += num;</span><br><span class="line">        <span class="keyword">return</span> sum1 - sum2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.8 MB, 在所有 Java 提交中击败了75.78% 的用户</p>
<p><strong>方法二：位运算</strong></p>
<blockquote>
<p>利用“<strong>两个相同的数，使用异或可以相消除</strong>”的原理</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">missingNumber</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)):</span><br><span class="line">            result ^= nums[i] ^ i</span><br><span class="line">        <span class="keyword">return</span> result ^ <span class="built_in">len</span>(nums)</span><br></pre></td></tr></table></figure>
<p>执行耗时:60 ms,击败了40.05% 的Python3用户<br>内存消耗:14.6 MB,击败了17.63% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">missingNumber</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) res ^= nums[i] ^ i;</span><br><span class="line">        <span class="keyword">return</span> res ^= nums.length;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了91.43% 的用户</p>
<h2 id="二分法系列"><a href="#二分法系列" class="headerlink" title="二分法系列"></a>二分法系列</h2><h3 id="1-阿珂喜欢吃香蕉"><a href="#1-阿珂喜欢吃香蕉" class="headerlink" title="1.阿珂喜欢吃香蕉"></a>1.阿珂喜欢吃香蕉</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第875题：阿珂喜欢吃香蕉</th>
</tr>
</thead>
<tbody>
<tr>
<td>这里总共有 N 堆香蕉，第 i 堆中有piles[i] 根香蕉。警卫已经离开了，将在 H 小时后回来。 阿珂可以决定她吃香蕉的速度 K （单位：根/小时），每个小时，她将会选择一堆香蕉，从中吃掉 K 根。</td>
</tr>
</tbody>
</table>
</div>
<p>如果这堆香蕉少于 K 根，她将吃掉这堆的所有香蕉，然后这一小时内不会再吃更多的香蕉。</p>
<p>珂珂喜欢慢慢吃，但仍然想在警卫回来前吃掉所有的香蕉。返回她可以在 H 小时内吃掉所有香蕉的最小速度 K（K 为整数）。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: piles = [3,6,7,11], H = 8</span><br><span class="line">输出: 4</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: piles = [30,11,23,4,20], H = 5</span><br><span class="line">输出: 30</span><br></pre></td></tr></table></figure>
<p><strong>示例 3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: piles = [30,11,23,4,20], H = 6</span><br><span class="line">输出: 23</span><br></pre></td></tr></table></figure>
<p><strong>提示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 &lt;= piles.length &lt;= 10^4</span><br><span class="line">piles.length &lt;= H &lt;= 10^9</span><br><span class="line">1 &lt;= piles[i] &lt;= 10^9</span><br></pre></td></tr></table></figure>
<blockquote>
<p>二分查找是计算机科学中最基本、最有用的算法之一。它描述了<strong>在有序集合中搜索特定值的过程</strong>。一般二分查找由以下几个术语构成：</p>
<ul>
<li>目标 Target —— 你要查找的值</li>
<li>索引 Index —— 你要查找的当前位置</li>
<li>左、右指示符 Left，Right —— 我们用来维持查找空间的指标</li>
<li>中间指示符 Mid —— 我们用来应用条件来确定我们应该向左查找还是向右查找的索引</li>
</ul>
<p>在最简单的形式中，二分查找对具有指定左索引和右索引的<strong>连续序列</strong>进行操作。我们也称之为<strong>查找空间</strong>。二分查找维护查找空间的左、右和中间指示符，并比较查找目标；如果条件不满足或值不相等，则清除目标不可能存在的那一半，并在剩下的一半上继续查找，直到成功为止。</p>
<p>总结一下一般实现的几个条件：</p>
<ul>
<li><strong>初始条件：left = 0, right = length-1</strong></li>
<li><strong>终止：left &gt; right</strong></li>
<li><strong>向左查找：right = mid-1</strong></li>
<li><strong>向右查找：left = mid +1</strong></li>
</ul>
<p>绝大部分 <strong>「在递增递减区间中搜索目标值」</strong> 的问题，都可以转化为二分查找问题。并且，二分查找的题目，基本逃不出三种：找特定值，找大于特定值的元素（上界），找小于特定值的元素（下界）。</p>
<p>将上面的思想代入到本题，我们要找 “<strong>阿珂在 H 小时吃掉所有香蕉的最小速度 K</strong>”。那最笨的就是阿珂吃的特别慢，每小时只吃掉 1 根香蕉，然后我们逐渐递增阿珂吃香蕉的速度到 i，刚好满足在 H 小时可以吃掉所有香蕉，此时 i 就是我们要找的最小速度。当然，我们没有这么笨，所以可以想到使用二分的思想来进行优化。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minEatingSpeed</span>(<span class="params">self, piles: <span class="type">List</span>[<span class="built_in">int</span>], H: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 最小速度</span></span><br><span class="line">        low = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 最大的速度，当然等于吃掉最大一堆的香蕉，毕竟一小时只能吃一堆，再大也没有意义</span></span><br><span class="line">        high = <span class="built_in">max</span>(piles)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">canEat</span>(<span class="params">piles, speed, H</span>):</span></span><br><span class="line">            <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> pile <span class="keyword">in</span> piles:</span><br><span class="line">                <span class="comment"># 向上取整</span></span><br><span class="line">                <span class="keyword">if</span> pile % speed &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">sum</span> += pile // speed + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">sum</span> += pile // speed</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">sum</span> &gt; H</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> low &lt; high:</span><br><span class="line">            <span class="comment"># 中间速度</span></span><br><span class="line">            mid = (low + high) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="comment"># 如果超时就往大的方向找，否则往小的方向找</span></span><br><span class="line">            <span class="keyword">if</span> canEat(piles, mid, H):</span><br><span class="line">                low = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                high = mid</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> low</span><br></pre></td></tr></table></figure>
<p>执行耗时:372 ms,击败了59.53% 的Python3用户<br>内存消耗:14.7 MB,击败了9.52% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minEatingSpeed</span><span class="params">(<span class="keyword">int</span>[] piles, <span class="keyword">int</span> h)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> low = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> high = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> pile: piles) high = pile &gt; high? pile: high;</span><br><span class="line">        <span class="keyword">while</span>(low &lt; high)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = low + (high - low) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(canEat(piles, mid, h)) low = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> high = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> low;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canEat</span><span class="params">(<span class="keyword">int</span>[] piles, <span class="keyword">double</span> speed, <span class="keyword">int</span> h)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> pile: piles)&#123;</span><br><span class="line">            sum += Math.ceil(pile / speed);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum &gt; h;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：43 ms, 在所有 Java 提交中击败了10.82% 的用户<br>内存消耗：39.5 MB, 在所有 Java 提交中击败了80.42% 的用户</p>
<h3 id="2-x的平方根"><a href="#2-x的平方根" class="headerlink" title="2.x的平方根"></a>2.x的平方根</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第69题：x的平方根</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算并返回 x 的平方根，其中 x 是非负整数。由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p><strong>整数平方根</strong>一定小于等于 x/2 。即有 0 &lt; 整数平方根 &lt;= x/2。所以我们的问题转化为在 [0,x/2] 中找一个<strong>特定值</strong>，满足二分查找的条件。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mySqrt</span>(<span class="params">self, x: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> x == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        left = <span class="number">1</span></span><br><span class="line">        right = x // <span class="number">2</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="comment"># +1防止陷入死循环</span></span><br><span class="line">            mid = (left + right + <span class="number">1</span>) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> mid ** <span class="number">2</span> &lt;= x:</span><br><span class="line">                left = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> left</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了92.37% 的Python3用户<br>内存消耗:13.6 MB,击败了5.34% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">mySqrt</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> r = x / <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = l + (r - l) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(x / mid &gt; mid) l = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> r = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> x / l &lt; l? l-<span class="number">1</span>: l;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了46.99% 的用户<br>内存消耗：35.3 MB, 在所有 Java 提交中击败了95.82% 的用户</p>
<blockquote>
<p>牛顿迭代法</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">mySqrt</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(x &lt; <span class="number">2</span>) <span class="keyword">return</span> x;</span><br><span class="line">        <span class="keyword">long</span> a = x;</span><br><span class="line">        <span class="keyword">while</span>(x / a &lt; a)&#123;</span><br><span class="line">            a = (a + x / a) / <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>)a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了46.99% 的用户<br>内存消耗：35.6 MB, 在所有 Java 提交中击败了48.99% 的用户</p>
<h3 id="3-第一个错误的版本"><a href="#3-第一个错误的版本" class="headerlink" title="3.第一个错误的版本"></a>3.第一个错误的版本</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第278题：第一个错误的版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>假设你有 n 个版本 [1, 2, …, n]，你想找出导致之后所有版本出错的第一个错误的版本。</td>
</tr>
</tbody>
</table>
</div>
<p>你可以通过调用 bool isBadVersion(version) 接口来判断版本号 version 是否在单元测试中出错。实现一个函数来查找第一个错误的版本。你应该尽量减少对调用 API 的次数。</p>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">给定 n = 5，并且 version = 4 是第一个错误的版本。</span><br><span class="line"></span><br><span class="line">调用 isBadVersion(3) -&gt; false</span><br><span class="line">调用 isBadVersion(5) -&gt; true</span><br><span class="line">调用 isBadVersion(4) -&gt; true</span><br><span class="line"></span><br><span class="line">所以，4 是第一个错误的版本。</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">firstBadVersion</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :type n: int</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        left = <span class="number">1</span></span><br><span class="line">        right = n</span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left + right) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> isBadVersion(mid):</span><br><span class="line">                right = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> left</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了5.21% 的Python3用户<br>内存消耗:13.5 MB,击败了6.31% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> <span class="keyword">extends</span> <span class="title">VersionControl</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">firstBadVersion</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> right = n;</span><br><span class="line">        <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(isBadVersion(mid)) right = mid;</span><br><span class="line">            <span class="keyword">else</span> left = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> left;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：18 ms, 在所有 Java 提交中击败了29.41% 的用户<br>内存消耗：35.1 MB, 在所有 Java 提交中击败了68.44% 的用户</p>
<h3 id="4-旋转排序数组中的最小值I"><a href="#4-旋转排序数组中的最小值I" class="headerlink" title="4.旋转排序数组中的最小值I"></a>4.旋转排序数组中的最小值I</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第153题：旋转排序数组最小值Ⅰ</th>
</tr>
</thead>
<tbody>
<tr>
<td>假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。请找出其中最小的元素。你可以假设数组中不存在重复元素。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [3,4,5,1,2]</span><br><span class="line">输出: 1</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [4,5,6,7,0,1,2]</span><br><span class="line">输出: 0</span><br></pre></td></tr></table></figure>
<blockquote>
<p>无论怎么旋转，我们都可以得到一个结论，首元素 &gt; 尾元素</p>
<p>并且我们已知了首元素值总是大于尾元素，那我们只要找到将其一分为二的那个点（该点左侧的元素都大于首元素，该点右侧的元素都小于首元素），是不是就可以对应找到数组中的最小值。</p>
<p>然后我们通过二分来进行查找，先找到中间节点mid，如果中间元素小于尾元素，我们就把mid向左移动。</p>
<p>如果中间元素大于尾元素，我们就把mid向右移动。</p>
<p>之所以跟尾元素比，是因为测试用例:[11,13,15,17]，算他原地翻转，其结果为11，若跟首元素比，则结果为17导致出错</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMin</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left + right) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] &gt; nums[-<span class="number">1</span>]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right = mid</span><br><span class="line">        <span class="keyword">return</span> nums[left]</span><br></pre></td></tr></table></figure>
<p>执行耗时:28 ms,击败了99.24% 的Python3用户<br>内存消耗:13.7 MB,击败了8.37% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findMin</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>, r = nums.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = l + (r - l) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] &gt; nums[r]) l = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> r = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nums[l];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.8 MB, 在所有 Java 提交中击败了78.33% 的用户</p>
<h3 id="5-旋转排序数组中的最小值II"><a href="#5-旋转排序数组中的最小值II" class="headerlink" title="5.旋转排序数组中的最小值II"></a>5.旋转排序数组中的最小值II</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第154题：旋转排序数组最小值Ⅱ</th>
</tr>
</thead>
<tbody>
<tr>
<td>假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。请找出其中最小的元素。  注意数组中可能存在重复的元素。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,3,5]</span><br><span class="line">输出: 1</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [2,2,2,0,1]</span><br><span class="line">输出: 0</span><br></pre></td></tr></table></figure>
<p><strong>说明：</strong></p>
<ul>
<li>这道题是 <a href="https://www.geekxh.com/1.9.二分法系列/1.9/904.html">旋转排序数组中的最小值(153)</a> 的延伸题目。</li>
<li>允许重复会影响算法的时间复杂度吗？会如何影响，为什么？</li>
</ul>
<blockquote>
<p>相对比昨天题目而言，其实只是多了<strong>nums[mid] 等于 nums[right] 时的额外处理</strong>。</p>
<p>可以看到在 nums[mid] 等于 nums[right] 时的情况下，我们只多了一个 right-1 的操作。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/64.png" alt></p>
<p>因为 mid 和 right 相等时，最小值既可能在左边，又可能在右边，所以此时自然二分思想作废，咱们就砍掉一个右边界。说白了，就是<strong>让子弹再飞一会儿</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMin</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            mid = (left + right) &gt;&gt; <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> nums[mid] &gt; nums[right]:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums[mid] &lt; nums[right]:</span><br><span class="line">                right = mid</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> nums[left]</span><br></pre></td></tr></table></figure>
<p>执行耗时:48 ms,击败了23.32% 的Python3用户<br>内存消耗:13.7 MB,击败了27.84% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findMin</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>, r = nums.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = l + (r - l) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid] &gt; nums[r]) l = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid] &lt; nums[r]) r = mid;</span><br><span class="line">            <span class="keyword">else</span> r--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nums[l];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了27.61% 的用户<br>内存消耗：38.2 MB, 在所有 Java 提交中击败了73.68% 的用户</p>
<h3 id="6-供暖器"><a href="#6-供暖器" class="headerlink" title="6.供暖器"></a>6.供暖器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第475题：供暖器</th>
</tr>
</thead>
<tbody>
<tr>
<td>冬季已经来临。你的任务是设计一个有固定加热半径的供暖器向所有房屋供暖。现在，给出位于一条水平线上的房屋和供暖器的位置，找到可以覆盖所有房屋的最小加热半径。所以，你的输入将会是房屋和供暖器的位置。你将输出供暖器的最小加热半径。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>说明:</strong></p>
<ul>
<li>给出的房屋和供暖器的数目是非负数且不会超过 25000。</li>
<li>给出的房屋和供暖器的位置均是非负数且不会超过10^9。</li>
<li>只要房屋位于供暖器的半径内(包括在边缘上)，它就可以得到供暖。</li>
<li>所有供暖器都遵循你的半径标准，加热的半径也一样。</li>
</ul>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,2,3],[2]</span><br><span class="line">输出: 1</span><br><span class="line">解释: 仅在位置2上有一个供暖器。如果我们将加热半径设为1，那么所有房屋就都能得到供暖。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,2,3,4],[1,4]</span><br><span class="line">输出: 1</span><br><span class="line">解释: 在位置1, 4上有两个供暖器。我们需要将加热半径设为1，这样所有房屋就都能得到供暖。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>我们要对任意一个房屋供暖，要么用前面的暖气，要么用后面的暖气，两者之间取最近的，这就是距离。同时，如果要覆盖到所有的房屋，我们要选择上述距离中最大的一段，这就是最小的加热半径。</p>
<p>第一层：遍历所有的房子，第二层：遍历加热器，找出距离该房子的最小距离。但是我们其实可以通过二分搜索来优化这个过程。</p>
</blockquote>
<p><strong>方法一：暴力法</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findRadius</span>(<span class="params">self, houses: <span class="type">List</span>[<span class="built_in">int</span>], heaters: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        houses.sort()</span><br><span class="line">        heaters.sort()</span><br><span class="line">        <span class="comment"># 防止供暖器只有一个的情况</span></span><br><span class="line">        heaters = [<span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>)] + heaters + [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)]</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> house <span class="keyword">in</span> houses:</span><br><span class="line">            <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(heaters) - <span class="number">1</span> <span class="keyword">and</span> house &gt; heaters[i]:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            res = <span class="built_in">max</span>(res, <span class="built_in">min</span>(heaters[i] - house, house - heaters[i - <span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:140 ms,击败了92.39% 的Python3用户<br>内存消耗:16.1 MB,击败了85.24% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findRadius</span><span class="params">(<span class="keyword">int</span>[] houses, <span class="keyword">int</span>[] heaters)</span> </span>&#123;</span><br><span class="line">        Arrays.sort(houses);</span><br><span class="line">        Arrays.sort(heaters);</span><br><span class="line">        <span class="keyword">int</span>[] nheaters = <span class="keyword">new</span> <span class="keyword">int</span>[heaters.length+<span class="number">2</span>];</span><br><span class="line">        nheaters[<span class="number">0</span>] = Integer.MIN_VALUE;</span><br><span class="line">        nheaters[nheaters.length-<span class="number">1</span>] = Integer.MAX_VALUE;</span><br><span class="line">        System.arraycopy(heaters, <span class="number">0</span>, nheaters, <span class="number">1</span>, heaters.length);</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">double</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">double</span> house: houses)&#123;</span><br><span class="line">            <span class="keyword">while</span>(index &lt; nheaters.length - <span class="number">1</span> &amp;&amp; house &gt; nheaters[index]) index++;</span><br><span class="line">            res = Math.max(res, Math.min(nheaters[index] - house, house - nheaters[index-<span class="number">1</span>]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：9 ms, 在所有 Java 提交中击败了89.71% 的用户<br>内存消耗：41.2 MB, 在所有 Java 提交中击败了92.17% 的用户</p>
<p><strong>方法二：二分法</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findRadius</span>(<span class="params">self, houses: <span class="type">List</span>[<span class="built_in">int</span>], heaters: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        houses.sort()</span><br><span class="line">        <span class="comment"># 找到每个房屋位置所需要的最小半径的最大值</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 防止供暖器只有一个的情况</span></span><br><span class="line">        heaters = [-<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)] + <span class="built_in">sorted</span>(heaters) + [<span class="built_in">float</span>(<span class="string">&quot;inf&quot;</span>)]</span><br><span class="line">        <span class="comment"># 每个屋子都要被覆盖到</span></span><br><span class="line">        <span class="keyword">for</span> house <span class="keyword">in</span> houses:</span><br><span class="line">            <span class="comment"># 每个屋子都要找到1个离他最近的heater，这里用二分法改进</span></span><br><span class="line">            left, right = <span class="number">0</span>, <span class="built_in">len</span>(heaters)-<span class="number">1</span></span><br><span class="line">            <span class="comment"># 找不小于house的第一个heater值</span></span><br><span class="line">            <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            	<span class="comment"># 应该写mid=left+((right-left)&gt;&gt;1)，因为位运算的优先级不如加法运算</span></span><br><span class="line">                mid = left + ((right - left) &gt;&gt; <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> house &gt; heaters[mid]:</span><br><span class="line">                    left = mid + <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    right = mid</span><br><span class="line">            <span class="comment"># house夹在heaters[left-1] heater[left]中间</span></span><br><span class="line">            res = <span class="built_in">max</span>(res, <span class="built_in">min</span>(house - heaters[left - <span class="number">1</span>], heaters[left] - house))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:252 ms,击败了86.09% 的Python3用户<br>内存消耗:15.9 MB,击败了93.07% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findRadius</span><span class="params">(<span class="keyword">int</span>[] houses, <span class="keyword">int</span>[] heaters)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> res = <span class="number">0</span>;</span><br><span class="line">        Arrays.sort(heaters);</span><br><span class="line">        <span class="keyword">int</span>[] nheaters = <span class="keyword">new</span> <span class="keyword">int</span>[heaters.length+<span class="number">2</span>];</span><br><span class="line">        nheaters[<span class="number">0</span>] = Integer.MIN_VALUE;</span><br><span class="line">        nheaters[nheaters.length-<span class="number">1</span>] = Integer.MAX_VALUE;</span><br><span class="line">        System.arraycopy(heaters, <span class="number">0</span>, nheaters, <span class="number">1</span>, heaters.length);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">double</span> house: houses)&#123;</span><br><span class="line">            <span class="keyword">int</span> left = <span class="number">0</span>, right = nheaters.length;</span><br><span class="line">            <span class="keyword">while</span> (left &lt; right)&#123;</span><br><span class="line">                <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">                <span class="keyword">if</span>(house &gt; nheaters[mid]) left = mid + <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span> right = mid;</span><br><span class="line">            &#125;</span><br><span class="line">            res = Math.max(res, Math.min(nheaters[left] - house, house - nheaters[left-<span class="number">1</span>]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：23 ms, 在所有 Java 提交中击败了39.37% 的用户<br>内存消耗：41.3 MB, 在所有 Java 提交中击败了84.79% 的用户</p>
<h2 id="其他补充题目"><a href="#其他补充题目" class="headerlink" title="其他补充题目"></a>其他补充题目</h2><h3 id="1-螺旋矩阵I"><a href="#1-螺旋矩阵I" class="headerlink" title="1.螺旋矩阵I"></a>1.螺旋矩阵I</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第54题：螺旋矩阵</th>
</tr>
</thead>
<tbody>
<tr>
<td>定一个包含 m x n 个元素的矩阵（m 行, n 列），请按照顺时针螺旋顺序，返回矩阵中的所有元素。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">[</span><br><span class="line"> [ 1, 2, 3 ],</span><br><span class="line"> [ 4, 5, 6 ],</span><br><span class="line"> [ 7, 8, 9 ]</span><br><span class="line">]</span><br><span class="line">输出: [1,2,3,6,9,8,7,4,5]</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">[</span><br><span class="line">  [1, 2, 3, 4],</span><br><span class="line">  [5, 6, 7, 8],</span><br><span class="line">  [9,10,11,12]</span><br><span class="line">]</span><br><span class="line">输出: [1,2,3,4,8,12,11,10,9,5,6,7]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>只有我们能找到边界（边界包括：1、数组的边界 2、已经访问过的元素），才可以通过“<strong>右，下，左，上</strong>”的方向来进行移动。同时，每一次<strong>碰壁</strong>，就可以调整到下一个方向。</p>
<p>我们首先对其设置好四个边界:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">up := 0</span><br><span class="line">down := len(matrix) - 1</span><br><span class="line">left := 0</span><br><span class="line">right := len(matrix[0]) - 1</span><br></pre></td></tr></table></figure>
<p>同时，我们定义x和y，来代表行和列。</p>
<p>然后我们从第一个元素开始行军（y=left），完成第一行的遍历，直到碰壁。（y&lt;=right）</p>
<p>下面关键的一步来了，<strong>因为第一行已经走过了，我们将上界下调</strong> <strong>（up++）</strong>，同时转弯向下走。</p>
<p>直到碰到底部时（x&lt;=down），我们将<strong>右界左调（right—）</strong>，转弯向左走。</p>
<p>后面向左和向上，分别完成<strong>下界上调（down—和左界右调（left++）</strong>。</p>
<p>最后，对剩下的矩阵重复整个过程，直到上下、左右的壁与壁碰在一起 <strong>（up &lt;= down &amp;&amp; left &lt;= right，这是避免碰壁的条件）</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spiralOrder</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        result = []</span><br><span class="line">        left, right, up, down = <span class="number">0</span>, <span class="built_in">len</span>(matrix[<span class="number">0</span>]) - <span class="number">1</span>, <span class="number">0</span>, <span class="built_in">len</span>(matrix) - <span class="number">1</span></span><br><span class="line">        x, y = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left &lt;= right <span class="keyword">and</span> up &lt;= down:</span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(left, right+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> left &lt;= right <span class="keyword">and</span> up &lt;= down:</span><br><span class="line">                    result.append(matrix[x][y])</span><br><span class="line">            up += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(up, down+<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> left &lt;= right <span class="keyword">and</span> up &lt;= down:</span><br><span class="line">                    result.append(matrix[x][y])</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(right, left-<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> left &lt;= right <span class="keyword">and</span> up &lt;= down:</span><br><span class="line">                    result.append(matrix[x][y])</span><br><span class="line">            down -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(down, up-<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                <span class="keyword">if</span> left &lt;= right <span class="keyword">and</span> up &lt;= down:</span><br><span class="line">                    result.append(matrix[x][y])</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了60.32% 的Python3用户<br>内存消耗:13.3 MB,击败了73.96% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">spiralOrder</span><span class="params">(<span class="keyword">int</span>[][] matrix)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>, right = matrix[<span class="number">0</span>].length - <span class="number">1</span>, up = <span class="number">0</span>, down = matrix.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(left &lt;= right &amp;&amp; up &lt;= down)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> y = left; y &lt;= right; y++) res.add(matrix[up][y]);</span><br><span class="line">            up++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> x = up; x &lt;= down; x++) res.add(matrix[x][right]);</span><br><span class="line">            right--;</span><br><span class="line">            <span class="keyword">if</span>(up &gt; down) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> y = right; y &gt;= left; y--) res.add(matrix[down][y]);</span><br><span class="line">            down--;</span><br><span class="line">            <span class="keyword">if</span>(left &gt; right) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> x = down; x &gt;= up; x--) res.add(matrix[x][left]);</span><br><span class="line">            left++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.5 MB, 在所有 Java 提交中击败了76.13% 的用户</p>
<h3 id="2-只有两个键的键盘"><a href="#2-只有两个键的键盘" class="headerlink" title="2.只有两个键的键盘"></a>2.只有两个键的键盘</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第650题：只有两个键的键盘</th>
</tr>
</thead>
<tbody>
<tr>
<td>最初在一个记事本上只有一个字符  ‘A’ 。你每次可以对这个记事本进行两种操作：Copy All (复制全部) : 你可以复制这个记事本中的所有字符(部分的复制是不允许的)。Paste (粘贴) : 你可以粘贴你上一次复制的字符。</td>
</tr>
</tbody>
</table>
</div>
<p>给定一个数字 n 。你需要使用<strong>最少的操作次数</strong>，在记事本中打印出恰好 n 个 ‘A’。输出能够打印出 n 个 ‘A’ 的最少操作次数。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 3</span><br><span class="line">输出: 3</span><br><span class="line">解释:</span><br><span class="line">最初, 我们只有一个字符 &#x27;A&#x27;。</span><br><span class="line">第 1 步, 我们使用 Copy All 操作。</span><br><span class="line">第 2 步, 我们使用 Paste 操作来获得 &#x27;AA&#x27;。</span><br><span class="line">第 3 步, 我们使用 Paste 操作来获得 &#x27;AAA&#x27;。</span><br></pre></td></tr></table></figure>
<p><strong>说明:</strong></p>
<p>n 的取值范围是 [1, 1000] 。</p>
<blockquote>
<p>本题的思路，在于<strong>想明白复制和粘贴过程中的规律，找到如何组成N个A的最小操作数。</strong></p>
<p>我们从最简单的开始分析，假如我们给定数字为1，那啥也不用做，因为面板上本来就有一个A。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/65.png" alt></p>
<p>假如我们给定数字为2，那我们需要做C-P，共计2次操作来得到。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/66.png" alt></p>
<p>假如我们给定数字为3，那我们需要做C-P-P，共计3次操作来得到。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/67.png" alt></p>
<p>假如我们给定数字为4，我们发现好像变得不一样了。因为我们有两种方法都可以得到目标。（C-P-C-P）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/68.png" alt></p>
<p>或者（C-P-P-P）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/69.png" alt></p>
<p>但是需要的步骤还是一样。</p>
<p>好了，到这里为止，STOP！通过上面的分析，我们至少可以观察出：<strong>如果 i 为质数，那么 i 是多少，就需要粘贴多少次</strong>。即：素数次数为本身的结论。如 两个A = 2，三个A = 3，五个A = 5。</p>
<p>那对于合数又该如何分析呢？（自然数中除能被1和本身整除外,还能被其他的数整除的数）这里我们直接给出答案：合数的次数为<strong>将其分解质因数的操作次数的和。</strong> 解释一下，这是个啥意思？举个例子：</p>
<p>比如30，可以分解为：3*2*5。什么意思呢？我们演示一遍：首先复制1，进行2次粘贴得到3。然后复制3，进行1次粘贴得到6。然后复制6，进行4次粘贴得到30。总共需要（CPPCPCPPPP）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/70.png" alt></p>
<blockquote>
<p>注意：这里由于每一次都需要进行一次复制，<strong>所以直接就等于分解质因数的操作次数的和</strong>。并且分解的顺序，不会影响到结果。</p>
</blockquote>
<p>综合上面的分析，我们得出分析结果：</p>
<p>1、质数次数为其本身。</p>
<p>2、合数次数为将其分解到<strong>所有不能再分解的质数的操作次数的和</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minSteps</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n+<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">while</span> n % i == <span class="number">0</span>:</span><br><span class="line">                res += i</span><br><span class="line">                n /= i</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了91.24% 的Python3用户<br>内存消耗:13.6 MB,击败了19.97% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minSteps</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= n; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(n % i == <span class="number">0</span>)&#123;</span><br><span class="line">                res += i;</span><br><span class="line">                n /= i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.4 MB, 在所有 Java 提交中击败了43.12% 的用户</p>
<h3 id="3-24点游戏"><a href="#3-24点游戏" class="headerlink" title="3.24点游戏"></a>3.24点游戏</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第679题：24点游戏</th>
</tr>
</thead>
<tbody>
<tr>
<td>你有 4 张写有 1 到 9 数字的牌。你需要判断是否能通  *，/，+，-，(，) 的运算得到 24 。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [4, 1, 8, 7]</span><br><span class="line">输出: True</span><br><span class="line">解释: (8-4) * (7-1) = 24</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1, 2, 1, 2]</span><br><span class="line">输出: False</span><br></pre></td></tr></table></figure>
<p>注意:</p>
<p>​    1、除法<strong>运算符 / 表示实数除法，而不是整数除法</strong>。例如 4 / (1 - 2/3) = 12 。</p>
<p>​    2、每个运算符对两个数进行运算。特别是我们不能用 - 作为一元运算符。例如，[1, 1, 1, 1] 作为输入时，表达式 -1 - 1 - 1 - 1 是不允许的。</p>
<p>​    3、你不能将数字连接在一起。例如，输入为 [1, 2, 1, 2] 时，不能写成 12 + 12 。</p>
<blockquote>
<p>拿到题目，第一反应就可以想到<strong>暴力求解。如果我们要判断给出的4张牌是否可以通过组合得到24，那我们只需找出所有的可组合的方式进行遍历。</strong></p>
<p>4个数字，3个操作符，外加括号，基本目测就能想到组合数不会大到超出边界。所以，我们只要<strong>把他们统统列出来，不就可以进行求解了吗</strong>?</p>
<p>但是这个方法写的正确吗？其实不对！因为在计算机中，实数在计算和存储过程中会有一些微小的误差，<strong>对于一些与零作比较的语句来说，有时会因误差而导致原本是等于零但结果却小于或大于零之类的情况发生</strong>，所以常用一个很小的数 <strong>1e-6</strong> 代替 0，进行判读！</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">judgePoint24</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        op = [<span class="keyword">lambda</span> x, y: x + y, <span class="keyword">lambda</span> x, y: x - y, <span class="keyword">lambda</span> x, y: x * y,</span><br><span class="line">              <span class="keyword">lambda</span> x, y: x / y <span class="keyword">if</span> y != <span class="number">0</span> <span class="keyword">else</span> <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)]</span><br><span class="line">        <span class="comment"># 返回可迭代对象的所有数学全排列方式</span></span><br><span class="line">        <span class="keyword">for</span> a, b, c, d <span class="keyword">in</span> itertools.permutations(nums):</span><br><span class="line">            <span class="comment"># product(list1, list2) 依次取出list1中的每1个元素，与list2中的每1个元素，组成元组，</span></span><br><span class="line">            <span class="comment"># 然后，将所有的元组组成一个列表，返回。</span></span><br><span class="line">            <span class="keyword">for</span> f, g, h <span class="keyword">in</span> itertools.product(op, repeat=<span class="number">3</span>):</span><br><span class="line">                <span class="keyword">if</span> -<span class="number">1e-6</span> &lt; f(g(h(a, b), c), d) - <span class="number">24</span> &lt; <span class="number">1e-6</span> \</span><br><span class="line">                        <span class="keyword">or</span> -<span class="number">1e-6</span> &lt; f(g(a, h(b, c)), d) - <span class="number">24</span> &lt; <span class="number">1e-6</span> \</span><br><span class="line">                        <span class="keyword">or</span> -<span class="number">1e-6</span> &lt; f(g(a, b), h(c, d)) - <span class="number">24</span> &lt; <span class="number">1e-6</span> \</span><br><span class="line">                        <span class="keyword">or</span> -<span class="number">1e-6</span> &lt; f(a, g(h(b, c), d)) - <span class="number">24</span> &lt; <span class="number">1e-6</span> \</span><br><span class="line">                        <span class="keyword">or</span> -<span class="number">1e-6</span> &lt; f(a, g(b, h(c, d))) - <span class="number">24</span> &lt; <span class="number">1e-6</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:68 ms,击败了92.38% 的Python3用户<br>内存消耗:13.3 MB,击败了68.61% 的Python3用户</p>
<blockquote>
<p>可以通过回溯的方法遍历所有不同的可能性。具体做法是，使用一个列表存储目前的全部数字，每次从列表中选出 2 个数字，再选择一种运算操作，用计算得到的结果取代选出的 2 个数字，这样列表中的数字就减少了 1 个。重复上述步骤，直到列表中只剩下 1 个数字，这个数字就是一种可能性的结果，如果结果等于 24，则说明可以通过运算得到 24。如果所有的可能性的结果都不等于 24，则说明无法通过运算得到 24。</p>
<p>实现时，有一些细节需要注意。</p>
<ul>
<li><p>除法运算为实数除法，因此结果为浮点数，列表中存储的数字也都是浮点数。在判断结果是否等于 24 时应考虑精度误差，这道题中，误差小于 10−6 可以认为是相等。</p>
</li>
<li><p>进行除法运算时，除数不能为 0，如果遇到除数为 0 的情况，则这种可能性可以直接排除。由于列表中存储的数字是浮点数，因此判断除数是否为 0 时应考虑精度误差，这道题中，当一个数字的绝对值小于 10−6 时，可以认为该数字等于 0。</p>
</li>
</ul>
<p>还有一个可以优化的点。</p>
<ul>
<li>加法和乘法都满足交换律，因此如果选择的运算操作是加法或乘法，则对于选出的 2 个数字不需要考虑不同的顺序，在遇到第二种顺序时可以不进行运算，直接跳过。</li>
</ul>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="comment">//目标值</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TARGET = <span class="number">24</span>;</span><br><span class="line">    <span class="comment">//误差</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">double</span> EPSILON = <span class="number">1e-6</span>;</span><br><span class="line">    <span class="comment">//四种运算</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> ADD = <span class="number">0</span>, MULTIPLY = <span class="number">1</span>, SUBTRACT = <span class="number">2</span>, DIVIDE = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">judgePoint24</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        List&lt;Double&gt; list = <span class="keyword">new</span> ArrayList&lt;Double&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> num : nums) &#123;</span><br><span class="line">            list.add((<span class="keyword">double</span>) num);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> solve(list);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//回溯</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">solve</span><span class="params">(List&lt;Double&gt; list)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//列表为空，返回false</span></span><br><span class="line">        <span class="keyword">if</span> (list.size() == <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="comment">//组合的结果是否为target</span></span><br><span class="line">        <span class="keyword">if</span> (list.size() == <span class="number">1</span>) <span class="keyword">return</span> Math.abs(list.get(<span class="number">0</span>) - TARGET) &lt; EPSILON;</span><br><span class="line">        <span class="keyword">int</span> size = list.size();</span><br><span class="line">        <span class="comment">//从当前列表中选出两个数</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; size; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i != j) &#123;</span><br><span class="line">                    <span class="comment">//新建列表</span></span><br><span class="line">                    List&lt;Double&gt; list2 = <span class="keyword">new</span> ArrayList&lt;Double&gt;();</span><br><span class="line">                    <span class="comment">//选出的两个数外的数，仍存入列表</span></span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; size; k++) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (k != i &amp;&amp; k != j) list2.add(list.get(k));</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">//选择其中一种运算</span></span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; <span class="number">4</span>; k++) &#123;</span><br><span class="line">                        <span class="comment">//加法和乘法都满足交换律，因此如果选择的运算操作是加法或乘法，则对于选出的数字不需要考虑不同的顺序</span></span><br><span class="line">                        <span class="comment">//在遇到第二种顺序时可以不进行运算，直接跳过</span></span><br><span class="line">                        <span class="keyword">if</span> (k &lt; <span class="number">2</span> &amp;&amp; i &gt; j) &#123;</span><br><span class="line">                            <span class="keyword">continue</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="comment">//将两个数的运算结果存入新数组</span></span><br><span class="line">                        <span class="keyword">if</span> (k == ADD) &#123;</span><br><span class="line">                            list2.add(list.get(i) + list.get(j));</span><br><span class="line">                        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k == MULTIPLY) &#123;</span><br><span class="line">                            list2.add(list.get(i) * list.get(j));</span><br><span class="line">                        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k == SUBTRACT) &#123;</span><br><span class="line">                            list2.add(list.get(i) - list.get(j));</span><br><span class="line">                        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (k == DIVIDE) &#123;</span><br><span class="line">                            <span class="comment">//排除除数为0的情况</span></span><br><span class="line">                            <span class="keyword">if</span> (Math.abs(list.get(j)) &lt; EPSILON) &#123;</span><br><span class="line">                                <span class="keyword">continue</span>;</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                list2.add(list.get(i) / list.get(j));</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="comment">//递归，从新数组中继续选取两个数</span></span><br><span class="line">                        <span class="keyword">if</span> (solve(list2)) <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                        <span class="comment">//回溯</span></span><br><span class="line">                        list2.remove(list2.size() - <span class="number">1</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：5 ms, 在所有 Java 提交中击败了67.43% 的用户<br>内存消耗：38.1 MB, 在所有 Java 提交中击败了62.84% 的用户</p>
<h3 id="4-飞机座位分配概率"><a href="#4-飞机座位分配概率" class="headerlink" title="4.飞机座位分配概率"></a>4.飞机座位分配概率</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第1227题：飞机座位分配概率</th>
</tr>
</thead>
<tbody>
<tr>
<td>有 n 位乘客即将登机，飞机正好有 n 个座位。第一位乘客的票丢了，他随便选了一个座位坐下。</td>
</tr>
</tbody>
</table>
</div>
<p>剩下的乘客将会：</p>
<ul>
<li>如果他们自己的座位还空着，就坐到自己的座位上，</li>
<li>当他们自己的座位被占用时，随机选择其他座位</li>
</ul>
<p>第 n 位乘客坐在自己的座位上的概率是多少？</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：n = 1</span><br><span class="line">输出：1.00000</span><br><span class="line">解释：第一个人只会坐在自己的位置上。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: n = 2</span><br><span class="line">输出: 0.50000</span><br><span class="line">解释：在第一个人选好座位坐下后，第二个人坐在自己的座位上的概率是 0.5。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>一个位置一个人，一屁股蹲下，概率100%，这没啥可说的。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/71.png" alt></p>
<p>两个位置两个人，第一个人已经坐下，要么坐对了，要么坐错了。所以第二个人坐在自己位置上的概率是50%。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/72.png" alt></p>
<p>重点来了，三个位置三个人，第一个一屁股坐下，有三种坐法。<img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/73.jpeg" alt></p>
<p>如果恰好<strong>第一个人坐到了自己的座位</strong>上（1/3），那这种情况下，第二个人也就可以直接坐在自己的座位上，第三个人一样。所以此时第三人坐在自己座位上的可能性是 100%。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/74.png" alt></p>
<p>如果<strong>第一个人占掉了第二个人的位置（1/3）。</strong> 此时第二人上来之后，要么坐在第一人的位置上，要么坐在第三人的位置上。（1/2）所以，在这种情况下，第三人的座位被占的可能性是 1/3*1/2=1/6。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/75.png" alt></p>
<p>那假如第一人直接一屁股坐在第三人的座位上，此时第三人的座位被占的可能性就是第一人选择第三人座位的可能性。（1/3）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/76.png" alt></p>
<p>所以，如果三个座位三个人，第三个人坐到自己位置上的概率就是：1/3 <em> 1/1 + 1/3 </em> 1/2 + 1/3 * 0 = 1/2</p>
<p>而对于 n&gt;3 的情况，我们参照 3 个座位时进行分析：</p>
<ul>
<li>如果第1个乘客选择第1个座位，那么第n个人选择到第n个座位的可能性就是100%。(1/n)</li>
<li>如果第1个乘客选择了第n个座位，那么第n个人选择第n个座位的可能性就是0。(0)</li>
<li><strong>而对于第 1 个乘客选择除了第一个和第 n 个座位之外的座位k (1&lt;k&lt;n)，就会导致有可能出现，前 n-1 位乘客占第 n 位乘客的概率出现。</strong></li>
</ul>
<p>第一二种情况都好说，对于第三种情况。因为此时第k个座位被占用，于第 k 个乘客而言，他又会面临和第一个乘客一样的选择。<strong>相当于乘客1将问题转移到了第k个乘客身上，等同于本次选择无效！</strong>且这个过程会一直持续到没有该选项<strong>。</strong>于是乎，对于第 n 个人，他最后将只有两个选项：1、自己的 2、第一个人。<strong>所以对于n&gt;=3 的情况，等同于 n=2，全部的概率都为 1/2</strong>。</p>
<p>如果还是不能理解的小伙伴，可以这样想。<strong>登机时座位被占的乘客 ，其实相当于和上一位坐错的乘客交换了身份</strong>。直到完成终止条件（坐对位置 或者 坐到最后一个位置），否则该交换将一直进行下去。所以第n位乘客，坐到第n个位置，自然还是 1/2。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nthPersonGetsNthSeat</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">float</span>:</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.5</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了46.71% 的Python3用户<br>内存消耗:13.5 MB,击败了37.32% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">nthPersonGetsNthSeat</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1.0</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0.5</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.3 MB, 在所有 Java 提交中击败了96.75% 的用户</p>
<h3 id="5-水分子的产生"><a href="#5-水分子的产生" class="headerlink" title="5.水分子的产生"></a>5.水分子的产生</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第1117题：水分子的产生</th>
</tr>
</thead>
<tbody>
<tr>
<td>现在有两种线程，氢 oxygen 和氧 hydrogen，你的目标是组织这两种线程来产生水分子。</td>
</tr>
</tbody>
</table>
</div>
<p>存在一个屏障（barrier）使得每个线程必须等候直到一个完整水分子能够被产生出来。</p>
<p>氢和氧线程会被分别给予 releaseHydrogen 和 releaseOxygen 方法来允许它们突破屏障。</p>
<p>这些线程应该三三成组突破屏障并能立即组合产生一个水分子。</p>
<p>你必须保证产生一个水分子所需线程的结合必须发生在下一个水分子产生之前。</p>
<p>换句话说:</p>
<p>如果一个氧线程到达屏障时没有氢线程到达，它必须等候直到两个氢线程到达。</p>
<p>如果一个氢线程到达屏障时没有其它线程到达，它必须等候直到一个氧线程和另一个氢线程到达。</p>
<p>书写满足这些限制条件的氢、氧线程同步代码。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: &quot;HOH&quot;</span><br><span class="line">输出: &quot;HHO&quot;</span><br><span class="line">解释: &quot;HOH&quot; 和 &quot;OHH&quot; 依然都是有效解。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: &quot;OOHHHH&quot;</span><br><span class="line">输出: &quot;HHOHHO&quot;</span><br><span class="line">解释: &quot;HOHHHO&quot;, &quot;OHHHHO&quot;, &quot;HHOHOH&quot;, &quot;HOHHOH&quot;, &quot;OHHHOH&quot;, &quot;HHOOHH&quot;, &quot;HOHOHH&quot; 和 &quot;OHHOHH&quot; 依然都是有效解。</span><br></pre></td></tr></table></figure>
<p>限制条件:</p>
<ul>
<li>输入字符串的总长将会是 3n, 1 ≤ n ≤ 50；</li>
<li>输入字符串中的 “H” 总数将会是 2n；</li>
<li>输入字符串中的 “O” 总数将会是 n。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Semaphore</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">H2O</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.h = Semaphore(<span class="number">2</span>)</span><br><span class="line">        self.o = Semaphore(<span class="number">0</span>)</span><br><span class="line">        self.h_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hydrogen</span>(<span class="params">self, releaseHydrogen: <span class="string">&#x27;Callable[[], None]&#x27;</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.h.acquire(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># releaseHydrogen() outputs &quot;H&quot;. Do not change or remove this line.</span></span><br><span class="line">        releaseHydrogen()</span><br><span class="line">        self.h_num += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> self.h_num == <span class="number">2</span>:</span><br><span class="line">            self.h_num = <span class="number">0</span></span><br><span class="line">            self.o.release(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">oxygen</span>(<span class="params">self, releaseOxygen: <span class="string">&#x27;Callable[[], None]&#x27;</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        self.o.acquire(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># releaseOxygen() outputs &quot;O&quot;. Do not change or remove this line.</span></span><br><span class="line">        releaseOxygen()</span><br><span class="line">        self.h.release(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>执行用时：40 ms, 在所有 Python3 提交中击败了92.16% 的用户<br>内存消耗：15.4 MB, 在所有 Python3 提交中击败了81.37% 的用户</p>
<blockquote>
<p>Semaphore是 synchronized 的加强版，作用是<strong>控制线程的并发数量</strong>。可以通过 acquire 和 release 来进行类似 lock 和 unlock 的操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//请求一个信号量，这时候信号量个数-1，当减少到0的时候，下一次acquire不会再执行，只有当执行一个release()的时候，信号量不为0的时候才可以继续执行acquire</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="comment">//释放一个信号量，这时候信号量个数+1，</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<p>h每获取一次释放一个o许可，o每次获取两个许可（即2次h后执行一次o）</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">H2O</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Semaphore h = <span class="keyword">new</span> Semaphore(<span class="number">2</span>);</span><br><span class="line">    <span class="keyword">private</span> Semaphore o = <span class="keyword">new</span> Semaphore(<span class="number">0</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">H2O</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">hydrogen</span><span class="params">(Runnable releaseHydrogen)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">		h.acquire(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">// releaseHydrogen.run() outputs &quot;H&quot;. Do not change or remove this line.</span></span><br><span class="line">        releaseHydrogen.run();</span><br><span class="line">        o.release(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">oxygen</span><span class="params">(Runnable releaseOxygen)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        o.acquire(<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// releaseOxygen.run() outputs &quot;O&quot;. Do not change or remove this line.</span></span><br><span class="line">		releaseOxygen.run();</span><br><span class="line">        h.release(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：19 ms, 在所有 Java 提交中击败了78.17% 的用户<br>内存消耗：39.9 MB, 在所有 Java 提交中击败了87.10% 的用户</p>
<h3 id="6-救生艇"><a href="#6-救生艇" class="headerlink" title="6.救生艇"></a>6.救生艇</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第881题：救生艇</th>
</tr>
</thead>
<tbody>
<tr>
<td>第 i 个人的体重为 people[i]，每艘船可以承载的最大重量为 limit。每艘船最多可同时载两人，但条件是这些人的重量之和最多为 limit。返回载到每一个人所需的最小船数。(保证每个人都能被船载)。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：people = [1,2], limit = 3</span><br><span class="line">输出：1</span><br><span class="line">解释：1 艘船载 (1, 2)</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：people = [3,2,2,1], limit = 3</span><br><span class="line">输出：3</span><br><span class="line">解释：3 艘船分别载 (1, 2), (2) 和 (3)</span><br></pre></td></tr></table></figure>
<p><strong>示例 3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：people = [3,5,3,4], limit = 5</span><br><span class="line">输出：4</span><br><span class="line">解释：4 艘船分别载 (3), (3), (4), (5)</span><br></pre></td></tr></table></figure>
<p><strong>提示：</strong></p>
<ul>
<li>1 &lt;= people.length &lt;= 50000</li>
<li>1 &lt;= people[i] &lt;= limit &lt;= 30000</li>
</ul>
<blockquote>
<p>这不是一道算法题，这是一个脑筋急转弯。</p>
<p>一个船最多可以装两个人，并且不能把船压垮。同时要求把这些人可以统统装下的最小船数。用脚趾头也可以想到，我们需要<strong>尽最大努力的去维持一个床上得有两个人</strong>。。哦，不，船上。这是什么思想？Bingo，贪心。</p>
<p>思路很简单：</p>
<ol>
<li>我们首先需要让这些人<strong>根据体重进行排序。</strong></li>
<li>同时<strong>维护两个指针，每次让最重的一名上船，同时让最轻的也上船</strong>。（因为最重的要么和最轻的一起上船。要么就无法配对，只能自己占用一艘船的资源）</li>
</ol>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numRescueBoats</span>(<span class="params">self, people: <span class="type">List</span>[<span class="built_in">int</span>], limit: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        people.sort()</span><br><span class="line">        ans = <span class="number">0</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="built_in">len</span>(people) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i &lt;= j:</span><br><span class="line">            <span class="keyword">if</span> people[i] + people[j] &lt;= limit:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">            j -= <span class="number">1</span></span><br><span class="line">            ans += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<p>执行耗时:504 ms,击败了97.01% 的Python3用户<br>内存消耗:20.3 MB,击败了29.93% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numRescueBoats</span><span class="params">(<span class="keyword">int</span>[] people, <span class="keyword">int</span> limit)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        Arrays.sort(people);</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>, r = people.length -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(l &lt;= r)&#123;</span><br><span class="line">            <span class="keyword">if</span>(people[l] + people[r] &lt;= limit) l++;</span><br><span class="line">            r--;</span><br><span class="line">            ans++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：17 ms, 在所有 Java 提交中击败了96.78% 的用户<br>内存消耗：47.2 MB, 在所有 Java 提交中击败了77.37% 的用户</p>
<h3 id="7-25匹马的经典问题"><a href="#7-25匹马的经典问题" class="headerlink" title="7.25匹马的经典问题"></a>7.25匹马的经典问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>25匹马的问题</th>
</tr>
</thead>
<tbody>
<tr>
<td>有一个赛场上共有25匹马，赛场有5个跑道，不使用计时器进行比赛（也就是每次比赛只能得到本次的比赛的顺序）</td>
</tr>
</tbody>
</table>
</div>
<p>试问最少比多少场才能选出最快的三匹马？并给出分析过程！</p>
<blockquote>
<p>分析过程：</p>
<ul>
<li><p>5次：首先我们把25匹马分成5组（A、B、C、D、E），跑上五次，得到每组的第一名。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/77.png" alt></p>
</li>
<li><p>1次：然后我们让这5个第一名跑上一次，得到其中的前三名。<strong>注意：这里就可以得到所有马中跑的最快的第一名A1了。并且，D1和E1所在的组可以直接淘汰。第二名和第三名一定不会在其中产生！</strong></p>
</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/78.png" alt></p>
<ul>
<li><p>1次：因为我们已经跑出了第一名，所以A1不需要再参加比赛，同时，D1和E1所在的组已经淘汰。C1作为第三组的第一名，C组不会有跑的比C1快的。而B2有可能是比C1跑的快的第三名。同理，A2和A3也有可能是比B1和B2跑的快的。所以第7次比赛，我们让<strong>A2，A3，B1，B2，C1</strong>来一起完成。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/79.png" alt></p>
</li>
</ul>
<p>最终，我们<strong>通过7次比赛</strong>，得到25匹马中的前三名。</p>
</blockquote>
<p><strong>升级版本</strong></p>
<p>还是25匹马，如果我们要找到其中跑的最快的<strong>前五名</strong>，最少需要比赛几次呢？（这里我想说一下，我看到<strong>网上有不少地方把这个题讲错了</strong>，所以不会的同学建议还是认真看一看）</p>
<blockquote>
<p>在上面的的分析中，我们已经明确了第一名。<strong>但是第二名和第三名，是可以在A2-A3-B1-B2-C1中产生的</strong>，我们需要分别进行讨论。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/80.png" alt></p>
<ul>
<li>假若二三名分别为：A2，A3</li>
</ul>
<p>对于这种情况，<strong>第四名可能是A4</strong>，此时第五名是A5或者B1。<strong>第四名也可能是B1</strong>，此时第五名是B2或者C1。所以我们只需要让［A4，B1，A5，B2，C1］参加一次比赛，就可以得到前五名。</p>
<ul>
<li>假若二三名分别为：A2，B1</li>
</ul>
<p>对于这种情况，第四名可能是A3、B2、C1。<strong>假设第4名为A3</strong>，第5名可能为A4、B2、C1。<strong>假设第4名为B2</strong>，第5名可能为A3、B3、C1。<strong>假设第4名为C1</strong>，第5名可能为A3、B2、C2、D1。此时我们需要至少两次比赛，才能在［A3，A4，B2，B3，C1，C2，D1］中找到第四名和第五名，所以就需要9次。</p>
<p>其他的可能性还有：</p>
<ul>
<li>假若二三名分别为：B1，A2</li>
<li>假若二三名分别为：B1，B2</li>
<li>假若二三名分别为：B1，C1</li>
</ul>
<p>上面这三种情况分析的方法一致，就不一一说明了，大概的思路就是，我们需要<strong>根据第三名，分析出可能的第四名</strong>。<strong>再根据第四名，分析出对应情况下的第五名</strong>。最终再在这些马匹里，抉择出真正的第四名和第五名。</p>
<p>因为题中问的是<strong>最少比多少场可以跑出前五名</strong>。所以根据分析，假如<strong>第二名和第三名是A2和A3的话，只需要8次就可以跑出前五名</strong>。最少次数是8。（这个题目其实是不严谨的，所以如果有面试官问到这个题，最好是给出所有可能性的推导过程）</p>
</blockquote>
<h3 id="8-灯泡开关"><a href="#8-灯泡开关" class="headerlink" title="8.灯泡开关"></a>8.灯泡开关</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第319题：开关灯泡</th>
</tr>
</thead>
<tbody>
<tr>
<td>初始时有 n 个灯泡关闭。第 1 轮，你打开所有的灯泡。第 2 轮，每两个灯泡关闭一次。第 3  轮，每三个灯泡切换一次开关（如果关闭则开启，如果开启则关闭）。第 i 轮，每 i 个灯泡切换一次开关。对于第 n  轮，你只切换最后一个灯泡的开关。找出 n 轮后有多少个亮着的灯泡。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 3</span><br><span class="line">输出: 1 </span><br><span class="line">解释: </span><br><span class="line">初始时, 灯泡状态 [关闭, 关闭, 关闭].</span><br><span class="line">第一轮后, 灯泡状态 [开启, 开启, 开启].</span><br><span class="line">第二轮后, 灯泡状态 [开启, 关闭, 开启].</span><br><span class="line">第三轮后, 灯泡状态 [开启, 关闭, 关闭]. </span><br><span class="line"></span><br><span class="line">你应该返回 1，因为只有一个灯泡还亮着。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这是一道难度评定为<strong>困难</strong>的题目。但是，其实这并不是一道算法题，而是一个脑筋急转弯。只要我们模拟一下开关灯泡的过程，大家就会瞬间get，一起来分析一下：</p>
<p>我们模拟一下n从1到12的过程。在第一轮，你打开了12个灯泡：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/81.png" alt></p>
<p>因为对于大于n的灯泡你是不care的，所以我们用黑框框表示：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/82.png" alt></p>
<p>然后我们列出n从1-12的过程中所有的灯泡示意图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/83.png" alt></p>
<p>可以得到如下表格：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/84.png" alt></p>
<p>观察一下，这是什么？观察不出来，咱们看看这个：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> n := <span class="number">1</span>; n &lt;= <span class="number">12</span>; n++ &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;n=&quot;</span>, n, <span class="string">&quot;\t灯泡数\t&quot;</span>, math.Sqrt(<span class="keyword">float64</span>(n)))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//print</span></span><br><span class="line">n= <span class="number">1</span>     灯泡数  <span class="number">1</span></span><br><span class="line">n= <span class="number">2</span>     灯泡数  <span class="number">1.4142135623730951</span></span><br><span class="line">n= <span class="number">3</span>     灯泡数  <span class="number">1.7320508075688772</span></span><br><span class="line">n= <span class="number">4</span>     灯泡数  <span class="number">2</span></span><br><span class="line">n= <span class="number">5</span>     灯泡数  <span class="number">2.23606797749979</span></span><br><span class="line">n= <span class="number">6</span>     灯泡数  <span class="number">2.449489742783178</span></span><br><span class="line">n= <span class="number">7</span>     灯泡数  <span class="number">2.6457513110645907</span></span><br><span class="line">n= <span class="number">8</span>     灯泡数  <span class="number">2.8284271247461903</span></span><br><span class="line">n= <span class="number">9</span>     灯泡数  <span class="number">3</span></span><br><span class="line">n= <span class="number">10</span>     灯泡数  <span class="number">3.1622776601683795</span></span><br><span class="line">n= <span class="number">11</span>     灯泡数  <span class="number">3.3166247903554</span></span><br><span class="line">n= <span class="number">12</span>     灯泡数  <span class="number">3.4641016151377544</span></span><br></pre></td></tr></table></figure>
<p>没错，只要我们对n进行开方，就可以得到最终的灯泡数。根据分析，得出代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bulbSwitch</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(sqrt(n))</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了60.08% 的Python3用户<br>内存消耗:13.6 MB,击败了7.43% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">bulbSwitch</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">int</span>) Math.sqrt(n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.1 MB, 在所有 Java 提交中击败了71.93% 的用户</p>
<blockquote>
<p>证明如下：</p>
<p>约数，又称因数。整数a除以整数b(b≠0) 除得的商正好是整数而没有余数，我们就说a能被b整除，或b能整除a。a称为b的倍数，b称为a的约数。</p>
<p>从我们观察可以发现，如果一个灯泡有奇数个约数，那么最后这个灯泡一定会亮着。</p>
<p>什么，你问我奇数是什么？奇数（odd）指不能被2整除的整数 ，数学表达形式为：2k+1， 奇数可以分为正奇数和负奇数。</p>
<p>所以其实我们是求，<strong>从1-n有多少个数的约数有奇数个</strong>。而<strong>有奇数个约数的数一定是完全平方数。</strong> 这是因为，对于数n，如果m是它的约数，则n/m也是它的约数，若m≠n/m，则它的约数是以m、n/m的形式成对出现的。而m＝n/m成立且n/m是正整数时，n是完全平方数，而它有奇数个约数。</p>
<p>我们再次转化问题，<strong>求1-n有多少个数是完全平方数</strong>。</p>
<p>什么，你又不知道什么是完全平方数了？完全平方指用一个整数乘以自己例如1×1，2×2，3×3等，依此类推。若一个数能表示成某个整数的平方的形式，<strong>则称这个数为完全平方数</strong>。</p>
<p>到这里，基本就很明朗了。剩下的，我想不需要再说了吧！</p>
</blockquote>
<h3 id="9-三门问题"><a href="#9-三门问题" class="headerlink" title="9.三门问题"></a>9.三门问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>三门问题</th>
</tr>
</thead>
<tbody>
<tr>
<td>参赛者的面前有三扇关闭着的门，其中一扇的后面是天使，选中后天使会达成你的一个愿望，而另外两扇门后面则是恶魔，选中就会死亡。</td>
</tr>
</tbody>
</table>
</div>
<p>当你选定了一扇门，但未去开启它的时候，上帝会开启剩下两扇门中的一扇，露出其中一只恶魔。（上帝是全能的，必会打开恶魔门）随后上帝会问你要不要更换选择，选另一扇仍然关着的门。</p>
<blockquote>
<p>按照常理，参赛者在做出最开始的决定时，对三扇门后面的事情一无所知，因此他选择正确的概率是1/3，这个应该大家都可以想到。</p>
<p>接下来，主持人排除掉了一个错误答案（有恶魔的门），于是剩下的两扇门必然是一扇是天使，一扇是恶魔，那么此时无论选择哪一扇门，胜率都是1/2，依然合乎直觉。</p>
<p>所以你作为参赛者，你会认为换不换都无必要，获胜概率均为1/2。但是，真的是这样吗？</p>
<p>正确的答案是，<strong>如果你选择了换，碰见天使的概率会高达2/3，而不不换的话，碰见天使的概率只有1/3。</strong> 怎么来的？</p>
<p>我们用一个很通俗的方法，能让你一听就懂。首先刚开始选择的一扇门的概率为1/3，而另外两扇门的总概率为2/3。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/85.png" alt><br>现在上帝打开了其中一扇为恶魔的门，我们知道这个门后面不会再有天使，所以相当于这部分概率被第三个门持有。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/86.png" alt><br>剩下的那扇门的概率（2/3）相当于刚开始选择的门（1/3）的二倍。所以我们得换。</p>
<p>如果还没有听懂。我们可以假设有一百扇门，里边有99只都是恶魔。现在你随机选择一扇门，选择到天使的概率是1/100。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/87.jpeg" alt><br>这时，上帝打开其中的98扇，里边都是恶魔。这时候就相当于99/100的概率都集中在了另一扇门里。自然，我们需要选择换</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/88.jpeg" alt></p>
</blockquote>
<p><strong>代码证明</strong><br>为了验证结果，我用代码跑了一百万次。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123; </span><br><span class="line">    <span class="comment">//换门遇见天使的次数和不换门遇见天使的次数     changeAngelCount, unchangeAngelCount := 0, 0     for i := 0; i &lt; 1000000; i++ &#123; </span></span><br><span class="line">        <span class="comment">//门的总数 </span></span><br><span class="line">        doors := []<span class="keyword">int</span>&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125; </span><br><span class="line">        <span class="comment">//天使门和选中的门         angelDoor, selectedDoor := rand.Intn(3), rand.Intn(3) </span></span><br><span class="line">        <span class="comment">//上帝移除一扇恶魔门</span></span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">0</span>; j &lt; <span class="built_in">len</span>(doors); j++ &#123;</span><br><span class="line">            <span class="keyword">if</span> doors[j] != selectedDoor &amp;&amp; doors[j] != angelDoor &#123;</span><br><span class="line">                doors = <span class="built_in">append</span>(doors[:j], doors[j+<span class="number">1</span>:]...)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//统计        </span></span><br><span class="line">        <span class="keyword">if</span> selectedDoor == angelDoor &#123;</span><br><span class="line">            unchangeAngelCount++</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            changeAngelCount++</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;不换门遇见天使次数:&quot;</span>, unchangeAngelCount, <span class="string">&quot;比例：&quot;</span>, (<span class="keyword">float32</span>(unchangeAngelCount) / <span class="number">1000000</span>))</span><br><span class="line">    fmt.Println(<span class="string">&quot;换门遇见天使次数:&quot;</span>, changeAngelCount, <span class="string">&quot;比例：&quot;</span>, (<span class="keyword">float32</span>(changeAngelCount) / <span class="number">1000000</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>执行结果为：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/89.png" alt></p>
<h3 id="10-猜数字游戏"><a href="#10-猜数字游戏" class="headerlink" title="10.猜数字游戏"></a>10.猜数字游戏</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第299题：猜数字（Bulls and Cows）游戏</th>
</tr>
</thead>
<tbody>
<tr>
<td>你写下一个数字让你的朋友猜。每次他猜测后，你给他一个提示，告诉他有多少位数字和确切位置都猜对了（称为“Bulls”, 公牛），有多少位数字猜对了但是位置不对（称为“Cows”, 奶牛）。你的朋友将会根据提示继续猜，直到猜出秘密数字。</td>
</tr>
</tbody>
</table>
</div>
<p>请写出一个根据秘密数字和朋友的猜测数返回提示的函数，用 A 表示公牛，用 B 表示奶牛。</p>
<p>请注意秘密数字和朋友的猜测数都可能含有重复数字。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: secret = &quot;1807&quot;, guess = &quot;7810&quot;</span><br><span class="line">输出: &quot;1A3B&quot;</span><br><span class="line">解释: 1 公牛和 3 奶牛。公牛是 8，奶牛是 0, 1 和 7。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: secret = &quot;1123&quot;, guess = &quot;0111&quot;</span><br><span class="line">输出: &quot;1A1B&quot;</span><br><span class="line">解释: 朋友猜测数中的第一个 1 是公牛，第二个或第三个 1 可被视为奶牛。</span><br></pre></td></tr></table></figure>
<p><strong>说明:</strong> 你可以假设秘密数字和朋友的猜测数都只包含数字，并且它们的长度永远相等。</p>
<blockquote>
<p>基本拿到题目，我们就能想到可以使用hashmap进行求解，一起来分析一下。</p>
<ul>
<li>因为secret数字和guess数字长度相等，所以我们遍历secret数字。</li>
<li>如果当前索引两个数字相同，就将公牛数加1。</li>
<li><strong>如果不相同，我们将secret和guess当前索引位置处的数字通过map记录下来，统计他们出现的次数。当然，之前我们讲过。有限的map，比如数字 0-10，字母 a-z，都可以通过数组</strong>来进行替换，用以压缩空间。</li>
<li>最后，如果记录的两个map中，<strong>数字出现重叠</strong>（可以通过最小值来判断），则意味着该数字在两边都出现过，就将母牛数加一</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getHint</span>(<span class="params">self, secret: <span class="built_in">str</span>, guess: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        mapS, mapG = &#123;&#125;, &#123;&#125;</span><br><span class="line">        a, b = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(secret)):</span><br><span class="line">            <span class="keyword">if</span> secret[i] == guess[i]:</span><br><span class="line">                a += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> secret[i] <span class="keyword">not</span> <span class="keyword">in</span> mapS:</span><br><span class="line">                    mapS[secret[i]] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mapS[secret[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> guess[i] <span class="keyword">not</span> <span class="keyword">in</span> mapG:</span><br><span class="line">                    mapG[guess[i]] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mapG[guess[i]] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> mapS.keys():</span><br><span class="line">            <span class="keyword">if</span> key <span class="keyword">in</span> mapG:</span><br><span class="line">                b += <span class="built_in">min</span>(mapS[key], mapG[key])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(a)+<span class="string">&#x27;A&#x27;</span>+<span class="built_in">str</span>(b)+<span class="string">&#x27;B&#x27;</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了88.82% 的Python3用户<br>内存消耗:13.5 MB,击败了16.77% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getHint</span><span class="params">(String secret, String guess)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] mapS = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">        <span class="keyword">int</span>[] mapG = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">        <span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; secret.length(); i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(secret.charAt(i) == guess.charAt(i)) a++;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                mapS[secret.charAt(i) - <span class="string">&#x27;0&#x27;</span>]++;</span><br><span class="line">                mapG[guess.charAt(i) - <span class="string">&#x27;0&#x27;</span>]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">            b += Math.min(mapS[i], mapG[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> a + <span class="string">&quot;A&quot;</span> + b + <span class="string">&quot;B&quot;</span>; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：8 ms, 在所有 Java 提交中击败了34.92% 的用户<br>内存消耗：38.5 MB, 在所有 Java 提交中击败了41.70% 的用户</p>
<h3 id="11-LRU缓存机制"><a href="#11-LRU缓存机制" class="headerlink" title="11.LRU缓存机制"></a>11.LRU缓存机制</h3><blockquote>
<p>LRU 是 Least Recently Used 的缩写，译为最近最少使用。它的理论基础为“<strong>最近使用的数据会在未来一段时期内仍然被使用，已经很久没有使用的数据大概率在未来很长一段时间仍然不会被使用</strong>”由于该思想非常契合业务场景 ，并且可以解决很多实际开发中的问题，所以我们经常通过 LRU 的思想来作缓存，一般也将其称为<strong>LRU缓存机制</strong>。</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>第146题：LRU缓存机制</th>
</tr>
</thead>
<tbody>
<tr>
<td>运用你所掌握的数据结构，设计和实现一个  LRU (最近最少使用) 缓存机制。它应该支持以下操作：获取数据 get 和 写入数据 put 。</td>
</tr>
</tbody>
</table>
</div>
<p>获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回  -1 。</p>
<p>写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。</p>
<p>进阶:你是否可以在 O(1) 时间复杂度内完成这两种操作？</p>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LRUCache cache = new LRUCache( 2 /* 缓存容量 */ );</span><br><span class="line">cache.put(1, 1);</span><br><span class="line">cache.put(2, 2);</span><br><span class="line">cache.get(1);       // 返回  1</span><br><span class="line">cache.put(3, 3);    // 该操作会使得密钥 2 作废</span><br><span class="line">cache.get(2);       // 返回 -1 (未找到)</span><br><span class="line">cache.put(4, 4);    // 该操作会使得密钥 1 作废</span><br><span class="line">cache.get(1);       // 返回 -1 (未找到)</span><br><span class="line">cache.get(3);       // 返回  3</span><br><span class="line">cache.get(4);       // 返回  4</span><br></pre></td></tr></table></figure>
<p><strong>方法一</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, capacity: <span class="built_in">int</span></span>):</span></span><br><span class="line">        self.capacity = capacity</span><br><span class="line">        self.cache = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">self, key: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 搜索不到返回-1</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        <span class="comment"># 取出缓存中的key并赋值,使最近被使用的排在最后面</span></span><br><span class="line">        self.cache[key] = self.cache.pop(key)</span><br><span class="line">        <span class="keyword">return</span> self.cache[key]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">put</span>(<span class="params">self, key: <span class="built_in">int</span>, value: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># 如存在就先删除key</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.cache:</span><br><span class="line">            self.cache.pop(key)</span><br><span class="line">        <span class="comment"># 先放「密钥/数据值」，之后再判断是否达到上限</span></span><br><span class="line">        self.cache[key] = value</span><br><span class="line">        <span class="comment">#  若超出容量则取最前面的删除，即最近最少使用</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.cache) &gt; self.capacity:</span><br><span class="line">            x = <span class="built_in">list</span>(self.cache)[<span class="number">0</span>]</span><br><span class="line">            self.cache.pop(x)</span><br></pre></td></tr></table></figure>
<p>执行耗时:232 ms,击败了54.22% 的Python3用户<br>内存消耗:21.8 MB,击败了65.84% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> LinkedHashMap&lt;Integer, Integer&gt; map = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!map.containsKey(key)) <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> value = map.remove(key);</span><br><span class="line">        map.put(key, value);</span><br><span class="line">        <span class="keyword">return</span> map.get(key);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(map.containsKey(key)) map.remove(key);</span><br><span class="line">        map.put(key, value);</span><br><span class="line">        <span class="keyword">if</span>(map.size() &gt; capacity) map.remove(map.keySet().iterator().next());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：21 ms, 在所有 Java 提交中击败了45.53% 的用户<br>内存消耗：46.7 MB, 在所有 Java 提交中击败了29.06% 的用户</p>
<p><strong>方法二：优化</strong></p>
<blockquote>
<p>py的原生<code>dict</code>自带链表，已经实现了<code>collections.OrderedDict</code>的绝大部分功能，继承就好。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>(<span class="params"><span class="built_in">dict</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, capacity: <span class="built_in">int</span></span>):</span></span><br><span class="line">        self.c = capacity</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span>(<span class="params">self, key: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self:</span><br><span class="line">            self[key] = self.pop(key)</span><br><span class="line">            <span class="keyword">return</span> self[key]</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">put</span>(<span class="params">self, key: <span class="built_in">int</span>, value: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        key <span class="keyword">in</span> self <span class="keyword">and</span> self.pop(key)</span><br><span class="line">        self[key] = value</span><br><span class="line">        <span class="built_in">len</span>(self) &gt; self.c <span class="keyword">and</span> self.pop(<span class="built_in">next</span>(<span class="built_in">iter</span>(self)))</span><br></pre></td></tr></table></figure>
<p>执行耗时:164 ms,击败了99.39% 的Python3用户<br>内存消耗:21.8 MB,击败了67.73% 的Python3用户</p>
<blockquote>
<p>Java的<code>LinkedHashMap</code>已实现<strong>removeEldestEntry()方法</strong>用于检查是否删除最旧的条目，只需重写即可</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">Integer</span>, <span class="title">Integer</span>&gt;</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 加载因子，一般是 0.75f</span></span><br><span class="line">        <span class="comment">// true: 是访问的顺序，也就是谁最先访问，就排在第一位  </span></span><br><span class="line">        <span class="comment">// false:存放顺序，就是你put 元素的时候的顺序  </span></span><br><span class="line">        <span class="keyword">super</span>(capacity, <span class="number">0.75F</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.getOrDefault(key, -<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.put(key, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Map.Entry&lt;Integer, Integer&gt; eldest)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> size() &gt; capacity; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：20 ms, 在所有 Java 提交中击败了56.47% 的用户<br>内存消耗：46.6 MB, 在所有 Java 提交中击败了46.56% 的用户</p>
<h3 id="12-最小的k个数"><a href="#12-最小的k个数" class="headerlink" title="12.最小的k个数"></a>12.最小的k个数</h3><div class="table-container">
<table>
<thead>
<tr>
<th>剑指offer第40题：最小的k个数</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：arr = [3,2,1], k = 2</span><br><span class="line">输出：[1,2] 或者 [2,1]</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：arr = [0,1,2,1], k = 1</span><br><span class="line">输出：[0]</span><br></pre></td></tr></table></figure>
<p><strong>限制：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0 &lt;= k &lt;= arr.length &lt;= 10000</span><br><span class="line">0 &lt;= arr[i] &lt;= 10000</span><br></pre></td></tr></table></figure>
<blockquote>
<p>堆的特性是<strong>父节点的值总是比其两个子节点的值大或小</strong>。如果父节点比它的两个子节点的值都要大，我们叫做<strong>大顶堆</strong>。如果父节点比它的两个子节点的值都要小，我们叫做<strong>小顶堆</strong>。</p>
<p>我们对堆中的结点按层进行编号，将这种逻辑结构映射到数组中就是下面这个样子。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/90.png" alt><br>大顶堆，满足以下公式: arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2]</p>
<p>小顶堆也一样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/91.png" alt><br>小顶堆，满足以下公式:     arr[i] &lt;= arr[2i+1] &amp;&amp; arr[i] &lt;= arr[2i+2]</p>
<p>上面我们学习了大顶堆，现在考虑如何用大根堆进行求解。</p>
<p>首先，我们创建一个大小为k的大顶堆。假如数组为[4,5,1,6,2,7,3,8]，k=4。大概是下面这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/92.png" alt><br>我想肯定这里有不知道如何建堆的同学。记住：<strong>对于一个没有维护过的堆（完全二叉树），我们可以从其最后一个节点的父节点开始进行调整</strong>。这个不需要死记硬背，其实就是一个层层调节的过程。</p>
<p>从最后一个节点的父节点调整</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/93.png" alt><br>继续向上调整<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/94.png" alt><br>继续向上调整<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/95.png" alt><br>然后我们从下标 k 继续开始依次遍历数组的剩余元素。如果元素小于堆顶元素，那么取出堆顶元素，将当前元素入堆。在上面的示例中 ，因为2小于堆顶元素6，所以将2入堆。我们发现现在的完全二叉树不满足大顶堆，所以对其进行调整。<br>调整前<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/96.png" alt><br>调整后<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/97.png" alt><br>继续重复上述步骤，依次将7,3,8入堆。这里因为7和8都大于堆顶元素5，所以只有3会入堆。<br>调整前<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/98.png" alt><br>调整后<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/99.png" alt><br>最后得到的堆，就是我们想要的结果。由于堆的大小是 K，所以这里空间复杂度是O(K)，时间复杂度是O(NlogK)。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getLeastNumbers</span>(<span class="params">self, arr: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">        <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        <span class="comment"># 最小的k个数 最大堆</span></span><br><span class="line">        <span class="comment"># 最大堆 顶点最大</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">maxHeapfy</span>(<span class="params">maxHeap, i, n</span>):</span></span><br><span class="line">            <span class="comment"># 左右子节点</span></span><br><span class="line">            left = <span class="number">2</span> * i + <span class="number">1</span></span><br><span class="line">            right = <span class="number">2</span> * i + <span class="number">2</span></span><br><span class="line">            <span class="comment"># 假定当前节点最大</span></span><br><span class="line">            maxPoint = i</span><br><span class="line">            <span class="comment"># 和当前节点的左右节点比较，如果节点中有更大的数，那么交换，并继续对交换后的节点进行维护</span></span><br><span class="line">            <span class="keyword">if</span> left &lt; n <span class="keyword">and</span> maxHeap[left] &gt; maxHeap[maxPoint]:</span><br><span class="line">                maxPoint = left</span><br><span class="line">            <span class="keyword">if</span> right &lt; n <span class="keyword">and</span> maxHeap[right] &gt; maxHeap[maxPoint]:</span><br><span class="line">                maxPoint = right</span><br><span class="line">            <span class="comment"># 如果最大的数不是节点i的话，那么交换后，调整节点i的子树。</span></span><br><span class="line">            <span class="keyword">if</span> maxPoint != i:</span><br><span class="line">                maxHeap[i], maxHeap[maxPoint] = maxHeap[maxPoint], maxHeap[i]</span><br><span class="line">                maxHeapfy(maxHeap, maxPoint, n)</span><br><span class="line">        <span class="comment"># 初始化 取前k个树，组成最大堆</span></span><br><span class="line">        maxHeap = arr[:k]</span><br><span class="line">        <span class="comment"># 对于一个还没维护过的堆，从他的最后一个节点的父节点开始进行调整。</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k // <span class="number">2</span> - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            maxHeapfy(maxHeap, i, k)</span><br><span class="line">        <span class="comment"># 继续调整后面节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, <span class="built_in">len</span>(arr)):</span><br><span class="line">            <span class="comment"># 如果元素小于堆顶元素，那么取出堆顶元素，将当前元素入堆</span></span><br><span class="line">            <span class="keyword">if</span> arr[i] &lt; maxHeap[<span class="number">0</span>]:</span><br><span class="line">                maxHeap[<span class="number">0</span>] = arr[i]</span><br><span class="line">                maxHeapfy(maxHeap, <span class="number">0</span>, k)</span><br><span class="line">        <span class="comment"># 最后得到的堆，就是我们想要的结果</span></span><br><span class="line">        <span class="keyword">return</span> maxHeap</span><br></pre></td></tr></table></figure>
<p>执行耗时:136 ms,击败了26.01% 的Python3用户<br>内存消耗:14.5 MB,击败了57.67% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] getLeastNumbers(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[k];</span><br><span class="line">        Arrays.sort(arr);</span><br><span class="line">        System.arraycopy(arr, <span class="number">0</span>, res, <span class="number">0</span>, k);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：7 ms, 在所有 Java 提交中击败了72.61% 的用户<br>内存消耗：39.8 MB, 在所有 Java 提交中击败了58.60% 的用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] getLeastNumbers(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="number">0</span> || arr.length == <span class="number">0</span>) <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">0</span>];</span><br><span class="line">        <span class="comment">// 默认是小根堆，实现大根堆需要重写一下比较器。</span></span><br><span class="line">        Queue&lt;Integer&gt; pq = <span class="keyword">new</span> PriorityQueue&lt;&gt;((v1, v2) -&gt; v2 - v1);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> num: arr) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pq.size() &lt; k) &#123;</span><br><span class="line">                pq.offer(num);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (num &lt; pq.peek()) &#123;</span><br><span class="line">                pq.poll();</span><br><span class="line">                pq.offer(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 返回堆中的元素</span></span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[k];</span><br><span class="line">        <span class="keyword">int</span> idx = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: pq) &#123;</span><br><span class="line">            res[idx++] = num;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：14 ms, 在所有 Java 提交中击败了41.61% 的用户<br>内存消耗：39.8 MB, 在所有 Java 提交中击败了57.97% 的用户</p>
<h3 id="13-不同路径"><a href="#13-不同路径" class="headerlink" title="13.不同路径"></a>13.不同路径</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第62题：不同路径</th>
</tr>
</thead>
<tbody>
<tr>
<td>一个机器人位于一个 m x n 网格的左上角，起始点在下图中标记为“Start”。机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角，在下图中标记为“Finish”。        问：总共有多少条不同的路径？</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/100.png" alt></p>
<p>例如，上图是一个7 x 3 的网格。有多少可能的路径？</p>
<p><strong>说明：</strong>m 和 n 的值均不超过 100。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: m = 3, n = 2</span><br><span class="line">输出: 3</span><br><span class="line"></span><br><span class="line">解释:</span><br><span class="line">从左上角开始，总共有 3 条路径可以到达右下角。</span><br><span class="line">\1. 向右 -&gt; 向右 -&gt; 向下</span><br><span class="line">\2. 向右 -&gt; 向下 -&gt; 向右</span><br><span class="line">\3. 向下 -&gt; 向右 -&gt; 向右</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: m = 7, n = 3</span><br><span class="line">输出: 28</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这道题属于相当标准的动态规划，虽然还有一些公式法等其他解法，但是如果面试官问到，基本就是想考察你的动态规划。</p>
<p>因为有横纵坐标，明显属于二维DP。我们定义<strong>DP[i][j]表示到达i行j列的最多路径</strong>。同时，因为第0行和第0列都只有一条路径，所以需要初始化为1。</p>
<p>状态转移方程一目了然，dp[i][j] = dp[i-1][j]  +dp[i][j-1]</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePaths</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 初始化为1，因为第0行和第0列为1</span></span><br><span class="line">        dp = [[ <span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                dp[i][j] = dp[i-<span class="number">1</span>][j] + dp[i][j-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了41.96% 的Python3用户<br>内存消耗:13.7 MB,击败了5.03% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[m][n];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;m; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;n; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span> || j==<span class="number">0</span>) dp[i][j] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span> dp[i][j] = dp[i-<span class="number">1</span>][j] + dp[i][j-<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.6 MB, 在所有 Java 提交中击败了5.30% 的用户</p>
<p><strong>优化</strong></p>
<blockquote>
<p>上面的答案，如果在面试时给出，可以给到7分，后面3分怎么拿，我们真的需要用一个二维数组来存储吗？一起看下！</p>
<p>我们使用<strong>二维数组</strong>记录状态。但是这里观察一下，每一个格子可能的路径，<strong>都是由左边的格子和上面的格子的总路径计算而来， 对于之前更早的数据，其实已经用不到了</strong>。如计算第三行时，已经用不到第一行的数据了。</p>
<p>那我们只要能定义一个状态，同时可以表示左边的格子和上面的格子，是不是就可以解决问题？所以我们定义状态dp[j]，用来表示<strong>当前行到达第j列的最多路径</strong>。这个“当前行”三个字很重要，比如我们要计算dp[3]，因为还没有计算出，所以这时dp[3]保存的其实是4（上一行的数据），而dp[2]由于已经计算出了，所以保存的是6（当前行的数据）。理解了这个，就理解如何压缩状态。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/101.png" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePaths</span>(<span class="params">self, m: <span class="built_in">int</span>, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        dp = [<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n):</span><br><span class="line">                dp[j] = dp[j] + dp[j-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了67.50% 的Python3用户<br>内存消耗:13.6 MB,击败了8.16% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePaths</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;m; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;n; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span> || j==<span class="number">0</span>) dp[j] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span> dp[j] = dp[j-<span class="number">1</span>] + dp[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="14-不同路径-障碍物"><a href="#14-不同路径-障碍物" class="headerlink" title="14.不同路径-障碍物"></a>14.不同路径-障碍物</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第63题：不同路径 - 障碍物</th>
</tr>
</thead>
<tbody>
<tr>
<td>一个机器人位于一个 m x n  网格的左上角，起始点在下图中标记为“Start”。机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角，在下图中标记为“Finish”。现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？      问总共有多少条不同的路径？</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/102.png" alt></p>
<p>网格中的障碍物和空位置分别用 1 和 0 来表示。</p>
<p><strong>说明：</strong> m 和 n 的值均不超过 100。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">[</span><br><span class="line">  [0,0,0],</span><br><span class="line">  [0,1,0],</span><br><span class="line">  [0,0,0]</span><br><span class="line">]</span><br><span class="line">输出: 2</span><br><span class="line"></span><br><span class="line">解释:</span><br><span class="line">3x3 网格的正中间有一个障碍物。</span><br><span class="line">从左上角到右下角一共有 2 条不同的路径：</span><br><span class="line">\1. 向右 -&gt; 向右 -&gt; 向下 -&gt; 向下</span><br><span class="line">\2. 向下 -&gt; 向下 -&gt; 向右 -&gt; 向右</span><br></pre></td></tr></table></figure>
<blockquote>
<p>首先我们还是定义状态，<strong>用DP[i][j]表示到达i行j列的最多路径</strong>。同时，因为第0行和第0列都只有一条路径，所以需要初始化为1。但有一点不一样的就是：<strong>如果在0行0列中遇到障碍物，后面的就都是0，意为此路不通</strong>。</p>
<p>完成了初始化，下面就是状态转移方程。和没有障碍物的相比没什么特别的，仍然是dp[i][j] = dp[i-1][j]+dp[i][j-1]。唯一需要处理的是：<strong>如果恰好[i][j]位置上有障碍物，则dp[i][j]为0</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePathsWithObstacles</span>(<span class="params">self, obstacleGrid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> obstacleGrid[<span class="number">0</span>][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        dp = [[<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(obstacleGrid[<span class="number">0</span>]))] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(obstacleGrid))]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(obstacleGrid[<span class="number">0</span>])):</span><br><span class="line">            dp[<span class="number">0</span>][j] = <span class="number">0</span> <span class="keyword">if</span> obstacleGrid[<span class="number">0</span>][j] == <span class="number">1</span> <span class="keyword">else</span> dp[<span class="number">0</span>][j-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(obstacleGrid)):</span><br><span class="line">            dp[i][<span class="number">0</span>] = <span class="number">0</span> <span class="keyword">if</span> obstacleGrid[i][<span class="number">0</span>] == <span class="number">1</span> <span class="keyword">else</span> dp[i-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(obstacleGrid)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(obstacleGrid[<span class="number">0</span>])):</span><br><span class="line">                dp[i][j] = <span class="number">0</span> <span class="keyword">if</span> obstacleGrid[i][j] == <span class="number">1</span> <span class="keyword">else</span> dp[i-<span class="number">1</span>][j]+dp[i][j-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>][-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了73.20% 的Python3用户<br>内存消耗:13.7 MB,击败了5.03% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="keyword">int</span>[][] obstacleGrid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = obstacleGrid.length;</span><br><span class="line">        <span class="keyword">int</span> n = obstacleGrid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[m][n];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> row = <span class="number">0</span>; row &lt; m; row++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> col = <span class="number">0</span>; col &lt; n; col++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(row == <span class="number">0</span> &amp;&amp; col == <span class="number">0</span>) dp[row][col] = obstacleGrid[row][col] == <span class="number">1</span>? <span class="number">0</span>: <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(row == <span class="number">0</span>) dp[row][col] = obstacleGrid[row][col] == <span class="number">1</span>? <span class="number">0</span>: dp[row][col-<span class="number">1</span>];</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(col == <span class="number">0</span>) dp[row][col] = obstacleGrid[row][col] == <span class="number">1</span>? <span class="number">0</span>: dp[row-<span class="number">1</span>][col];</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    dp[row][col] = obstacleGrid[row][col] == <span class="number">1</span>? <span class="number">0</span>: dp[row-<span class="number">1</span>][col]+dp[row][col-<span class="number">1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[m-<span class="number">1</span>][n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.7 MB, 在所有 Java 提交中击败了60.14% 的用户</p>
<p><strong>优化</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniquePathsWithObstacles</span>(<span class="params">self, obstacleGrid: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        m, n = <span class="built_in">len</span>(obstacleGrid), <span class="built_in">len</span>(obstacleGrid[<span class="number">0</span>]),</span><br><span class="line">        dp = [<span class="number">1</span>] + [<span class="number">0</span>] * (n-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> obstacleGrid[i][j]:</span><br><span class="line">                    dp[j] = <span class="number">0</span></span><br><span class="line">                <span class="keyword">elif</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                    dp[j] = dp[j] + dp[j - <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> dp[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了89.96% 的Python3用户<br>内存消耗:13.4 MB,击败了54.45% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">uniquePathsWithObstacles</span><span class="params">(<span class="keyword">int</span>[][] obstacleGrid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = obstacleGrid.length;</span><br><span class="line">        <span class="keyword">int</span> n = obstacleGrid[<span class="number">0</span>].length;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> row = <span class="number">0</span>; row &lt; m; row++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> col = <span class="number">0</span>; col &lt; n; col++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(obstacleGrid[row][col] == <span class="number">1</span>) dp[col] = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(col &gt; <span class="number">0</span>) dp[col] = dp[col-<span class="number">1</span>] + dp[col];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n-<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.8 MB, 在所有 Java 提交中击败了52.90% 的用户</p>
<h3 id="15-盛最多水的容器"><a href="#15-盛最多水的容器" class="headerlink" title="15.盛最多水的容器"></a>15.盛最多水的容器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第11题：盛最多水的容器</th>
</tr>
</thead>
<tbody>
<tr>
<td>给你 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。</td>
</tr>
</tbody>
</table>
</div>
<p>说明：你不能倾斜容器，且 n 的值至少为 2。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/103.jpg" alt></p>
<p>图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。</p>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：[1,8,6,2,5,4,8,3,7] </span><br><span class="line">输出：49</span><br></pre></td></tr></table></figure>
<blockquote>
<p>观察可得，垂直的两条线段将会与坐标轴构成一个矩形区域，较短线段的长度将会作为矩形区域的宽度，两线间距将会作为矩形区域的长度，我们求解容纳水的最大值，实为找到该矩形最大化的区域面积。</p>
<p>首先，本题自然可以暴力求解，只要<strong>找到每对可能出现的线段组合，然后找出这些情况下的最大面积</strong>。这种解法直接略过，大家有兴趣可以下去自己尝试。这道题比较经典是是使用双指针进行求解，已经会的朋友不妨复习复习。</p>
<p>我们初始化两个指针，分别指向两边，构成我们的第一个矩形区域。</p>
<p>根据木桶原理，水的高度取决于短的一侧。我们总是<strong>选择将短的一侧向长的一侧移动</strong>。并且在每一次的移动中，我们记录下来当前面积大小。</p>
<p>一直到两个棒子撞在一起。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxArea</span>(<span class="params">self, height: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="built_in">len</span>(height) - <span class="number">1</span></span><br><span class="line">        maxArea = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">if</span> height[left] &lt; height[right]:</span><br><span class="line">                maxArea = <span class="built_in">max</span>(maxArea, height[left] * (right - left))</span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                maxArea = <span class="built_in">max</span>(maxArea, height[right] * (right - left))</span><br><span class="line">                right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> maxArea</span><br></pre></td></tr></table></figure>
<p>执行耗时:64 ms,击败了90.74% 的Python3用户<br>内存消耗:14.9 MB,击败了38.00% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxArea</span><span class="params">(<span class="keyword">int</span>[] height)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>, right = height.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> maxArea = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">            <span class="keyword">if</span>(height[left] &lt; height[right])&#123;</span><br><span class="line">                maxArea = Math.max(maxArea, height[left]*(right - left));</span><br><span class="line">                left++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                maxArea = Math.max(maxArea, height[right]*(right - left));</span><br><span class="line">                right--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxArea;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了94.88% 的用户<br>内存消耗：51.7 MB, 在所有 Java 提交中击败了53.67% 的用户</p>
<h3 id="16-扑克牌中的顺子容器"><a href="#16-扑克牌中的顺子容器" class="headerlink" title="16.扑克牌中的顺子容器"></a>16.扑克牌中的顺子容器</h3><div class="table-container">
<table>
<thead>
<tr>
<th>剑指offer第61题：扑克牌中的顺子</th>
</tr>
</thead>
<tbody>
<tr>
<td>从扑克牌中随机抽5张牌，判断是不是一个顺子，即这5张牌是不是连续的。2～10为数字本身，A为1，J为11，Q为12，K为13，而大、小王为 0 ，可以看成任意数字。A 不能视为 14。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,2,3,4,5]</span><br><span class="line">输出: True</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [0,0,1,2,5]</span><br><span class="line">输出: True</span><br></pre></td></tr></table></figure>
<p><strong>限制：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">数组长度为 5 </span><br><span class="line">数组的数取值为 [0, 13] </span><br></pre></td></tr></table></figure>
<blockquote>
<p>数组长度限制了是5，非常省事，意味着我们不需要一些额外的处理。拿到牌，第一个想法排序！<strong>因为是5连，无论接没接到大小王，最小值和最大值之间，一定小于5</strong>。</p>
<p>排序后，我们通过累积每两张牌之间的差值，来计算最小值和最大值中间的总差值。</p>
<p>拿到了王，就相当于拿到了通行证，直接跳过。因为是排序的牌，如果接到对子，也就意味着不是五连，直接返回false。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isStraight</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        sub = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> nums[i] == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> nums[i] == nums[i+<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">            sub += nums[i+<span class="number">1</span>] - nums[i]</span><br><span class="line">        <span class="keyword">return</span> sub &lt; <span class="number">5</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了40.35% 的Python3用户<br>内存消耗:13.5 MB,击败了16.56% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isStraight</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        <span class="keyword">int</span> sub = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length - <span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] == nums[i+<span class="number">1</span>]) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            sub += (nums[i+<span class="number">1</span>] - nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sub &lt; <span class="number">5</span>; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了91.62% 的用户<br>内存消耗：35.7 MB, 在所有 Java 提交中击败了86.90% 的用户</p>
<h3 id="17-整数拆分"><a href="#17-整数拆分" class="headerlink" title="17.整数拆分"></a>17.整数拆分</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第343题：整数拆分</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个正整数 <em>n</em>，将其拆分为<strong>至少</strong>两个正整数的和，并使这些整数的乘积最大化。返回你可以获得的最大乘积。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 2</span><br><span class="line">输出: 1</span><br><span class="line">解释: 2 = 1 + 1, 1 × 1 = 1。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 10</span><br><span class="line">输出: 36</span><br><span class="line">解释: 10 = 3 + 3 + 4, 3 × 3 × 4 = 36。</span><br></pre></td></tr></table></figure>
<p><strong>说明: </strong>你可以假设 n 不小于 2 且不大于 58。</p>
<blockquote>
<p>要对一个整数进行拆分，并且要使这些拆分完后的因子的乘积最大。我们可以先尝试拆分几个数值，测试一下。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/104.png" alt></p>
<p>通过观察，首先肯定可以明确，<strong>2 和 3 是没办法进行拆分的最小因子</strong>。同时，我们好像能看出来：</p>
<ul>
<li>只要把 n 尽可能的拆分成包含3的组合，就可以得到最大值。</li>
<li>如果没办法拆成 3 的组合，就退一步拆成 2 的组合。</li>
<li>对于 3 和 2 ，没办法再进行拆分。</li>
</ul>
<p>根据分析，我们尝试使用<strong>贪心</strong>进行求解。因为一个数（假设为n）除以另一个数，总是包括整数部分（x）和余数部分（y）。那刚才也得到了，<strong>最优因子是3</strong>，所以我们需要让 n/3，这样的话，余数可能是 1,2 两种可能性。</p>
<ul>
<li>如果余数是 1 ，刚才我们也分析过，对于 1 的拆分是没有意义的，所以我们退一步，将最后一次的 3 和 1 的拆分，用 2 和 2 代替。</li>
<li>如果余数是 2 ，那不消多说，直接乘以最后的 2 即可。</li>
</ul>
</blockquote>
<p><strong>方法一</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">integerBreak</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">if</span> n &lt;= <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> n - <span class="number">1</span></span><br><span class="line">        <span class="comment"># 恰好整除，直接为3^x</span></span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">3</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span> ** (n // <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 余数为1，退一步 3^(x-1)*2*2</span></span><br><span class="line">        <span class="keyword">elif</span> n % <span class="number">3</span> == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span> ** (n // <span class="number">3</span> - <span class="number">1</span>) * <span class="number">4</span></span><br><span class="line">        <span class="comment"># 余数为2，直接乘以2</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">3</span> ** (n // <span class="number">3</span>) * <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了96.37% 的Python3用户<br>内存消耗:13.5 MB,击败了31.43% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">integerBreak</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">3</span>) <span class="keyword">return</span> n-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(n % <span class="number">3</span> == <span class="number">0</span>) <span class="keyword">return</span> (<span class="keyword">int</span>)Math.pow(<span class="number">3</span>, n/<span class="number">3</span>);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(n % <span class="number">3</span> == <span class="number">1</span>) <span class="keyword">return</span> (<span class="keyword">int</span>)Math.pow(<span class="number">3</span>, n/<span class="number">3</span>-<span class="number">1</span>)*<span class="number">4</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> (<span class="keyword">int</span>)Math.pow(<span class="number">3</span>, n/<span class="number">3</span>)*<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.3 MB, 在所有 Java 提交中击败了31.03% 的用户</p>
<p><strong>方法二：动态规划</strong></p>
<blockquote>
<p>dp[i]代表 i 拆分之后得到的乘积的最大的元素，比如dp[4]就保存将4拆分后得到的最大的乘积。状态转移方程式为 dp[i]=max(dp[i], (i-j)*max(dp[j],j))</p>
<p>整体思路就是这样，将一个大的问题，分解成一个一个的小问题，然后完成一个<strong>自底向上</strong>的过程。举一个例子，比如计算 10 ，可以拆分 6 和 4 ，因为 6 的最大值 3x3，以及 4 的最大值 2x2 都已经得到，所以就替换成 9 和 4 ，也就是 10=3x3x4。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">integerBreak</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        dp = [<span class="number">0</span>] * (n + <span class="number">1</span>)</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">                dp[i] = <span class="built_in">max</span>(dp[i], <span class="built_in">max</span>(dp[j], j) * (i - j))</span><br><span class="line">        <span class="keyword">return</span> dp[n]</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了57.61% 的Python3用户<br>内存消耗:13.5 MB,击败了31.43% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">integerBreak</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= n; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++)&#123;</span><br><span class="line">                dp[i] = Math.max(dp[i], Math.max(dp[j], j)*(i - j));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了12.89% 的用户<br>内存消耗：35.1 MB, 在所有 Java 提交中击败了80.09% 的用户</p>
<h3 id="18-移动石子直到连续"><a href="#18-移动石子直到连续" class="headerlink" title="18.移动石子直到连续"></a>18.移动石子直到连续</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第1033题：移动石子直到连续</th>
</tr>
</thead>
<tbody>
<tr>
<td>三枚石子放置在数轴上，位置分别为 a，b，c。每一回合，我们假设这三枚石子当前分别位于位置 x, y, z 且 x &lt; y &lt; z。从位置 x 或者是位置 z  拿起一枚石子，并将该石子移动到某一整数位置 k 处，其中 x &lt; k &lt; z 且 k !=  y。当你无法进行任何移动时，即，这些石子的位置连续时，游戏结束。要使游戏结束，你可以执行的最小和最大移动次数分别是多少？以长度为 2  的数组形式返回答案：answer = [minimum_moves, maximum_moves]</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：a = 1, b = 2, c = 5</span><br><span class="line">输出：[1, 2]</span><br><span class="line">解释：将石子从 5 移动到 4 再移动到 3，或者我们可以直接将石子移动到 3。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：a = 4, b = 3, c = 2</span><br><span class="line">输出：[0, 0]</span><br><span class="line">解释：我们无法进行任何移动。</span><br></pre></td></tr></table></figure>
<p><strong>提示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 &lt;= a &lt;= 100</span><br><span class="line">1 &lt;= b &lt;= 100</span><br><span class="line">1 &lt;= c &lt;= 100</span><br><span class="line">a != b, b != c, c != a</span><br></pre></td></tr></table></figure>
<blockquote>
<p>读懂了题意，开始进行分析。首先可以明确，每一次我们其实<strong>是从边上来挑选石子，然后往中间进行移动</strong>。所以，我们首先得找到min（左），max（右）以及mid（中）三个值。我们设，min和mid中的距离为x，max和min中的距离为y。大概就是下面这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/105.png" alt></p>
<p>然后只需要计算x和y的和，就是我们要找的最大值。而最小值，就很容易了，只有0,1,2三种可能性。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">numMovesStones</span>(<span class="params">self, a: <span class="built_in">int</span>, b: <span class="built_in">int</span>, c: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span></span><br><span class="line">    	<span class="comment"># 将石子从小到大排序</span></span><br><span class="line">        arr = <span class="built_in">sorted</span>([a, b, c])</span><br><span class="line">        x = arr[<span class="number">1</span>] - arr[<span class="number">0</span>] - <span class="number">1</span></span><br><span class="line">        y = arr[<span class="number">2</span>] - arr[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line">        <span class="built_in">max</span> = x + y</span><br><span class="line">        <span class="built_in">min</span> = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> x != <span class="number">0</span> <span class="keyword">or</span> y != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> x &gt; <span class="number">1</span> <span class="keyword">and</span> y &gt; <span class="number">1</span>:</span><br><span class="line">                <span class="built_in">min</span> = <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">min</span> = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="built_in">min</span>, <span class="built_in">max</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:28 ms,击败了99.36% 的Python3用户<br>内存消耗:13.5 MB,击败了33.33% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] numMovesStones(<span class="keyword">int</span> a, <span class="keyword">int</span> b, <span class="keyword">int</span> c) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;a, b ,c&#125;;</span><br><span class="line">        Arrays.sort(arr);</span><br><span class="line">        <span class="keyword">int</span> x = arr[<span class="number">1</span>] - arr[<span class="number">0</span>] -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> y = arr[<span class="number">2</span>] - arr[<span class="number">1</span>] -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> max_move = x + y;</span><br><span class="line">        <span class="keyword">int</span> min_move = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(x != <span class="number">0</span> || y != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(x &gt; <span class="number">1</span> &amp;&amp; y &gt; <span class="number">1</span>) min_move = <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">else</span> min_move = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;min_move, max_move&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了49.13% 的用户<br>内存消耗：36.1 MB, 在所有 Java 提交中击败了93.93% 的用户</p>
<h3 id="19-Nim游戏"><a href="#19-Nim游戏" class="headerlink" title="19.Nim游戏"></a>19.Nim游戏</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第292题：Nim 游戏</th>
</tr>
</thead>
<tbody>
<tr>
<td>你和你的朋友，两个人一起玩 Nim 游戏：桌子上有一堆石头，每次你们轮流拿掉 1 - 3 块石头。拿掉最后一块石头的人就是获胜者。你作为先手。 你们是聪明人，每一步都是最优解。编写一个函数，来判断你是否可以在给定石头数量的情况下赢得游戏。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 4</span><br><span class="line">输出: false </span><br><span class="line">解释: 如果堆中有 4 块石头，那么你永远不会赢得比赛；</span><br><span class="line">     因为无论你拿走 1 块、2 块 还是 3 块石头，最后一块石头总是会被你的朋友拿走。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>首先如果石头数小于4个，那么因为你是先手，一把拿走，肯定会赢。</p>
<p>而如果石头是4个，那不管你是拿了1,2,3个，最后一个都可以被你的对手拿走，所以怎么样都赢不了。</p>
<p>再继续分析到8个石头：对于5,6,7而言，你只需要对应的拿走1,2,3，然后留下4个，则对方必输。但是如果你要面对的是8，不管先拿（1,2,3）个，另一个人都可以通过 8-(1,2,3) ，使得你面对4个石头，则你必输无疑。通过观察，我们发现，好像是<strong>只要N是4的倍数，我们就必输无疑</strong>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">canWinNim</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">return</span> n % <span class="number">4</span> != <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了55.90% 的Python3用户<br>内存消耗:13.5 MB,击败了11.08% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canWinNim</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> n % <span class="number">4</span> != <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：35.4 MB, 在所有 Java 提交中击败了16.27% 的用户</p>
<h3 id="20-寻找两个正序数组的中位数"><a href="#20-寻找两个正序数组的中位数" class="headerlink" title="20.寻找两个正序数组的中位数"></a>20.寻找两个正序数组的中位数</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第4题：寻找两个正序数组的中位数</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定两个大小为 m 和 n 的有序数组 nums1 和 nums2。请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。你可以假设 nums1 和 nums2 不会同时为空。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nums1 = [1, 3]</span><br><span class="line">nums2 = [2]</span><br><span class="line">则中位数是 2.0</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nums1 = [1, 2]</span><br><span class="line">nums2 = [3, 4]</span><br><span class="line">则中位数是 (2 + 3)/2 = 2.5</span><br></pre></td></tr></table></figure>
<p><strong>示例 3：</strong><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [0,0], nums2 = [0,0]</span><br><span class="line">输出：0.00000</span><br></pre></td></tr></table></figure></p>
<p><strong>示例 4：</strong><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [], nums2 = [1]</span><br><span class="line">输出：1.00000</span><br></pre></td></tr></table></figure></p>
<p><strong>示例 5：</strong><br><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [2], nums2 = []</span><br><span class="line">输出：2.00000</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><strong>一般如果题目要求时间复杂度在O(log(n))，大部分都是可以使用二分的思想来进行求解</strong>。</p>
<p>如果只有一个有序数组，我们需要找中位数，那肯定需要判断元素是奇数个还是偶数个，如果是奇数个那最中间的就是中位数，如果是偶数个的话，那就是最中间两个数的和除以2。</p>
<p>那如果是两个数组，也是一样的，我们先求出两个数组长度之和。如果为奇数，就找中间的那个数，也就是 <strong>(长度之和 + 1)/2</strong> 。如果为偶数，那就找 <strong>长度之和/2</strong>。比如下面的 (9 + 5)/2 = 7，那我们最终就是<strong>找到排列第7位的值</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/106.jpg" alt></p>
<p>现在的问题是，我们如何用二分的思想来找到中间排列第7位的数。这里有一种不太好想到的方式，<strong>是用删的方式</strong>，因为<strong>如果我们可以把多余的数排除掉，最终剩下的那个数，是不是就是我们要找的数？</strong> 对于上面的数组，我们可以先删掉 7/2=3 个数。那这里，可以选择删上面的，也可以选择删下面的。那这里因为 i&lt;j，所以我们选择删除上面的3个数。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/107.jpg" alt></p>
<p>（删除前）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/108.png" alt></p>
<p>（删除后）</p>
<p>由于我们已经排除掉了 3 个数字，现在对于两个数组，我们需要找到7-3=4的数字，来进行下一步运算。我们可以继续删掉4/2=2个数。我们比较i和j的值，删除小的一边。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/109.png" alt></p>
<p>（删除前）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/110.jpg" alt></p>
<p>（删除后）</p>
<p>继续上面的步骤，我们删除 2/2=1 个数。<strong>同理，比较7和6的大小，删除小的一边</strong>。删完后是下面这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/111.png" alt></p>
<p>（7和6，删除6）</p>
<p>不要忘记我们的目的，我们是为了找第7小的数。此时，<strong>两个数组的第一个元素，哪个小，就是我们要找的那个数</strong>。因为7&lt;8，所以7就是我们要找的第7小的数。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/112.jpg" alt></p>
<p>这里有一点比较特殊的，如果在删除过程中，我们<strong>要删除的K/2个数，大于其中一边的数组长度</strong>，那我们就将小的一侧数组元素都删除。比如下面这个，此时7/2=3，但是下面的数组只有2个元素，我们就将它全部删除。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/113.jpg" alt></p>
<p>删完之后，此时因为只删除了2个元素，所以k变成了5。那我们只需要返回其中一边的第5个元素就ok。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/114.jpg" alt></p>
<p>整个上面的过程，完成了本题的算法架构！</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">float</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">findK</span>(<span class="params">nums1, i, nums2, j, k</span>):</span></span><br><span class="line">            <span class="comment"># 特殊情况：要删除的个数大于其中一边的数组长度</span></span><br><span class="line">            <span class="keyword">if</span> i &gt;= len1:</span><br><span class="line">                <span class="keyword">return</span> nums2[j + k - <span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 特殊情况：要删除的个数大于其中一边的数组长度</span></span><br><span class="line">            <span class="keyword">if</span> j &gt;= len2:</span><br><span class="line">                <span class="keyword">return</span> nums1[i + k - <span class="number">1</span>]</span><br><span class="line">            <span class="comment"># 正常情况</span></span><br><span class="line">            <span class="keyword">if</span> k == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">min</span>(nums1[i], nums2[j])</span><br><span class="line">            <span class="comment"># 计算出每次要比较的两个数的值，来决定&quot;删除&quot;哪边的元素</span></span><br><span class="line">            mid1 = nums1[i + k // <span class="number">2</span> - <span class="number">1</span>] <span class="keyword">if</span> (i + k // <span class="number">2</span> - <span class="number">1</span>) &lt; len1 <span class="keyword">else</span> inf</span><br><span class="line">            mid2 = nums2[j + k // <span class="number">2</span> - <span class="number">1</span>] <span class="keyword">if</span> (j + k // <span class="number">2</span> - <span class="number">1</span>) &lt; len2 <span class="keyword">else</span> inf</span><br><span class="line">            <span class="comment">#　通过递归的方式，来模拟删除掉前K//2个元素</span></span><br><span class="line">            <span class="keyword">if</span> mid1 &lt; mid2:</span><br><span class="line">                <span class="keyword">return</span> findK(nums1, i + k // <span class="number">2</span>, nums2, j, k - k // <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">return</span> findK(nums1, i, nums2, j + k // <span class="number">2</span>, k - k // <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        len1 = <span class="built_in">len</span>(nums1)</span><br><span class="line">        len2 = <span class="built_in">len</span>(nums2)</span><br><span class="line">        total = len1 + len2</span><br><span class="line">        <span class="comment"># 比如总数为偶数14，就要找第7个和第8个</span></span><br><span class="line">        <span class="comment"># 比如总数为奇数5，就要找第3个</span></span><br><span class="line">        left = (total + <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">        right = (total + <span class="number">2</span>) // <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> (findK(nums1, <span class="number">0</span>, nums2, <span class="number">0</span>, left) + findK(nums1, <span class="number">0</span>, nums2, <span class="number">0</span>, right)) / <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了77.16% 的Python3用户<br>内存消耗:13.8 MB,击败了5.17% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> length1 = nums1.length, length2 = nums2.length;</span><br><span class="line">        <span class="keyword">int</span> totalLength = length1 + length2;</span><br><span class="line">        <span class="keyword">int</span> left = (totalLength + <span class="number">1</span>) / <span class="number">2</span>, right = (totalLength + <span class="number">2</span>) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">double</span> median = (getKthElement(nums1, nums2, left) + getKthElement(nums1, nums2, right)) / <span class="number">2.0</span>;</span><br><span class="line">        <span class="keyword">return</span> median;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getKthElement</span><span class="params">(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">         <span class="comment">/* 主要思路：要找到第 k (k&gt;1) 小的元素，那么就取 pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较</span></span><br><span class="line"><span class="comment">         * 这里的 &quot;/&quot; 表示整除</span></span><br><span class="line"><span class="comment">         * nums1 中小于等于 pivot1 的元素有 nums1[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="comment">         * nums2 中小于等于 pivot2 的元素有 nums2[0 .. k/2-2] 共计 k/2-1 个</span></span><br><span class="line"><span class="comment">         * 取 pivot = min(pivot1, pivot2)，两个数组中小于等于 pivot 的元素共计不会超过 (k/2-1) + (k/2-1) &lt;= k-2 个</span></span><br><span class="line"><span class="comment">         * 这样 pivot 本身最大也只能是第 k-1 小的元素</span></span><br><span class="line"><span class="comment">         * 如果 pivot = pivot1，那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums1 数组</span></span><br><span class="line"><span class="comment">         * 如果 pivot = pivot2，那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 &quot;删除&quot;，剩下的作为新的 nums2 数组</span></span><br><span class="line"><span class="comment">         * 由于我们 &quot;删除&quot; 了一些元素（这些元素都比第 k 小的元素要小），因此需要修改 k 的值，减去删除的数的个数</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> length1 = nums1.length, length2 = nums2.length;</span><br><span class="line">        <span class="keyword">int</span> index1 = <span class="number">0</span>, index2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> kthElement = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 边界情况</span></span><br><span class="line">            <span class="keyword">if</span> (index1 == length1) &#123;</span><br><span class="line">                <span class="keyword">return</span> nums2[index2 + k - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (index2 == length2) &#123;</span><br><span class="line">                <span class="keyword">return</span> nums1[index1 + k - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (k == <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> Math.min(nums1[index1], nums2[index2]);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 正常情况</span></span><br><span class="line">            <span class="keyword">int</span> half = k / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">int</span> newIndex1 = Math.min(index1 + half, length1) - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> newIndex2 = Math.min(index2 + half, length2) - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> pivot1 = nums1[newIndex1], pivot2 = nums2[newIndex2];</span><br><span class="line">            <span class="keyword">if</span> (pivot1 &lt;= pivot2) &#123;</span><br><span class="line">                k -= (newIndex1 - index1 + <span class="number">1</span>);</span><br><span class="line">                index1 = newIndex1 + <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                k -= (newIndex2 - index2 + <span class="number">1</span>);</span><br><span class="line">                index2 = newIndex2 + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：3 ms, 在所有 Java 提交中击败了82.06% 的用户<br>内存消耗：39.2 MB, 在所有 Java 提交中击败了99.34% 的用户</p>
<h3 id="21-第k个最大元素"><a href="#21-第k个最大元素" class="headerlink" title="21.第k个最大元素"></a>21.第k个最大元素</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第215题：第K个最大元素</th>
</tr>
</thead>
<tbody>
<tr>
<td>在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [3,2,1,5,6,4] 和 k = 2</span><br><span class="line">输出: 5</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [3,2,3,1,2,4,5,5,6] 和 k = 4</span><br><span class="line">输出: 4</span><br></pre></td></tr></table></figure>
<p><strong>说明:</strong></p>
<p>你可以假设 k 总是有效的，且 1 ≤ k ≤ 数组的长度。</p>
<blockquote>
<p>这种题目，从个人来讲，我一般是比较偏好使用堆来做的。毕竟大小顶堆，刚好有着与本类题型契合的特性。我们对其构造一个小顶堆（每个结点的值均不大于其左右孩子结点的值，堆顶元素为整个堆的最小值），整个过程是这样：</p>
<p>构造一个小顶堆，依次将元素放入堆中，并保证堆中元素为k。</p>
<p>如果当前元素小于堆顶元素，那基本就不用看了（因为我们要找的是 排序后的第 k 个最大的元素）</p>
<p>自然，如果我们遇到比堆顶元素大的元素，就把它放入到堆中。</p>
<p>重复上面的步骤。</p>
</blockquote>
<p><strong>方法一：小顶堆</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="comment"># 最大的k个数 最小堆</span></span><br><span class="line">        <span class="comment"># 最小堆 顶点最小</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">minHeapfy</span>(<span class="params">minHeap, i, k</span>):</span></span><br><span class="line">            <span class="comment"># 左右子节点</span></span><br><span class="line">            left = <span class="number">2</span> * i + <span class="number">1</span></span><br><span class="line">            right = <span class="number">2</span> * i + <span class="number">2</span></span><br><span class="line">            <span class="comment"># 假定当前节点最小</span></span><br><span class="line">            minPoint = i</span><br><span class="line">            <span class="comment"># 和当前节点的左右节点比较，如果节点中有更小的数，那么交换，并继续对交换后的节点进行维护</span></span><br><span class="line">            <span class="keyword">if</span> left &lt; k <span class="keyword">and</span> minHeap[left] &lt; minHeap[minPoint]:</span><br><span class="line">                minPoint = left</span><br><span class="line">            <span class="keyword">if</span> right &lt; k <span class="keyword">and</span> minHeap[right] &lt; minHeap[minPoint]:</span><br><span class="line">                minPoint = right</span><br><span class="line">            <span class="comment"># 如果最小的数不是节点i的话，那么交换后，调整节点i的子树。</span></span><br><span class="line">            <span class="keyword">if</span> minPoint != i:</span><br><span class="line">                minHeap[i], minHeap[minPoint] = minHeap[minPoint], minHeap[i]</span><br><span class="line">                minHeapfy(minHeap, minPoint, k)</span><br><span class="line">        <span class="comment"># 初始化 取前k个树，组成最小堆</span></span><br><span class="line">        minHeap = nums[:k]</span><br><span class="line">        <span class="comment"># 对于一个还没维护过的堆，从他的最后一个节点的父节点开始进行调整。</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k // <span class="number">2</span> - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            minHeapfy(minHeap, i, k)</span><br><span class="line">        <span class="comment"># 继续调整后面节点</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k, <span class="built_in">len</span>(nums)):</span><br><span class="line">            <span class="comment"># 如果元素大于堆顶元素，那么取出堆顶元素，将当前元素入堆</span></span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; minHeap[<span class="number">0</span>]:</span><br><span class="line">                minHeap[<span class="number">0</span>] = nums[i]</span><br><span class="line">                minHeapfy(minHeap, <span class="number">0</span>, k)</span><br><span class="line">        <span class="comment"># 最后得到的堆顶，就是我们想要的结果</span></span><br><span class="line">        <span class="keyword">return</span> minHeap[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>执行耗时:64 ms,击败了44.82% 的Python3用户<br>内存消耗:15.3 MB,击败了14.45% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findKthLargest</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] minHeap = Arrays.copyOf(nums, k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = k / <span class="number">2</span> - <span class="number">1</span>; i &gt; -<span class="number">1</span>; i--) minHeap(minHeap, i, k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = k; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; minHeap[<span class="number">0</span>])&#123;</span><br><span class="line">                minHeap[<span class="number">0</span>] = nums[i];</span><br><span class="line">                minHeap(minHeap, <span class="number">0</span>, k);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> minHeap[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">minHeap</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> i, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">2</span> * i + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">2</span> * i + <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> minPoint = i;</span><br><span class="line">        <span class="keyword">if</span>(left &lt; k &amp;&amp; nums[left] &lt; nums[minPoint]) minPoint = left;</span><br><span class="line">        <span class="keyword">if</span>(right &lt; k &amp;&amp; nums[right] &lt; nums[minPoint]) minPoint = right;</span><br><span class="line">        <span class="keyword">if</span>(minPoint != i)&#123;</span><br><span class="line">            <span class="keyword">int</span> tmp = nums[i];</span><br><span class="line">            nums[i] = nums[minPoint];</span><br><span class="line">            nums[minPoint] = tmp;</span><br><span class="line">            minHeap(nums, minPoint, k);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了99.35% 的用户<br>内存消耗：38.8 MB, 在所有 Java 提交中击败了51.50% 的用户</p>
<p><strong>方法二：调用内置函数</strong></p>
<blockquote>
<p>python可以使用heapq.nlargest 或 heapq.nsmallest，来找出某个集合中找出最大或最小的N个元素。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> heapq.nlargest(k, nums)[-<span class="number">1</span>]  <span class="comment"># [6,5]</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了91.38% 的Python3用户<br>内存消耗:15.3 MB,击败了14.45% 的Python3用户</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>第347题：前 K 个高频元素</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个非空的整数数组，返回其中出现频率前 k 高的元素。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,1,1,2,2,3] 和 k = 2</span><br><span class="line">输出: [1, 2]</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1] 和 k = 1</span><br><span class="line">输出: [1]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这题也是同样的道理，只是需要先统计各元素出现的次数，然后按照次数的大小为基准加入小顶堆，这里提供Java内置小顶堆函数的用法。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] topKFrequent(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: nums) map.put(num, map.getOrDefault(num, <span class="number">0</span>) + <span class="number">1</span>);</span><br><span class="line">        Queue&lt;Integer&gt; minHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;((v1, v2) -&gt; map.get(v1) - map.get(v2));    </span><br><span class="line">        map.forEach((num, cnt) -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (minHeap.size() &lt; k) &#123;</span><br><span class="line">                minHeap.offer(num);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (map.get(minHeap.peek()) &lt; cnt) &#123;</span><br><span class="line">                minHeap.poll();</span><br><span class="line">                minHeap.offer(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[k];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; k; i++) res[i] = minHeap.poll();</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：18 ms, 在所有 Java 提交中击败了26.53% 的用户<br>内存消耗：41 MB, 在所有 Java 提交中击败了70.04% 的用户</p>
<h3 id="22-镜面反射"><a href="#22-镜面反射" class="headerlink" title="22.镜面反射"></a>22.镜面反射</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第858题：镜面反射</th>
</tr>
</thead>
<tbody>
<tr>
<td>有一个特殊的正方形房间，每面墙上都有一面镜子。除西南角以外，每个角落都放有一个接受器，编号为 0，1，以及 2。正方形房间的墙壁长度为 p，一束激光从西南角射出，首先会与东墙相遇，入射点到接收器 0 的距离为 q  。返回光线最先遇到的接收器的编号（保证光线最终会遇到一个接收器）。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入： p = 2, q = 1</span><br><span class="line">输出： 2</span><br><span class="line">解释： 这条光线在第一次被反射回左边的墙时就遇到了接收器 2 </span><br></pre></td></tr></table></figure>
<p>上面的题目绕得很，大概就是这么个意思：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/115.png" alt></p>
<blockquote>
<p>我们知道光是由西南角发出的，也就是左下角。发出之后可能会出现多种情况（注意，下图略过了部分光线反射的情况）。看起来是十分复杂，无迹可寻。</p>
<p>但是如果我们把光线的运动轨迹拆开来看，就可以观测到，<strong>光线每经过一次折反，都会在纵向距离上移动 q</strong>（首次与东墙相距的距离）。同时，<strong>一旦其向上行走的距离为 p 的整数倍，就一定会碰到某个接收点</strong>（<strong>注意：这里我们不需要考虑北面墙是否存在，根据光的反射定律可得</strong>）可以参考一下下面这张图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/116.png" alt></p>
<p>问题变得简单了，<strong>光线最终向上走的距离，其实就是 p 和 q 的最小公倍数</strong>。我们设最小公倍数为 L，会发现如果 L 是 p 的<strong>奇数倍</strong>，光线则到达<strong>北墙</strong>（可以参考上面的图）当 L 是 p 的 <strong>偶数倍</strong>，光线将会射到<strong>南墙</strong>。</p>
<p>问题来了，如果光线是射向南墙，因为只有一个接收器了，必定只能遇到接收器 0。但是如果射到了北墙，如何区分是 1 和 2。这回到了一个初中数学题，我们可以通过<strong>光线与东西墙的接触次数，来判断最终的落点是 1 还是 2。</strong></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">mirrorReflection</span>(<span class="params">self, p: <span class="built_in">int</span>, q: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        m, n = p, q</span><br><span class="line">        <span class="comment"># 最大公约数</span></span><br><span class="line">        <span class="comment"># 假设x和y的最大公约数是m,最小公倍数是n,则xy=mn</span></span><br><span class="line">        <span class="keyword">while</span> n &gt; <span class="number">0</span>:</span><br><span class="line">            r = m % n</span><br><span class="line">            m = n</span><br><span class="line">            n = r</span><br><span class="line">        <span class="comment"># 假设x和y的最大公约数是m,最小公倍数是n,则xy=mn</span></span><br><span class="line">        <span class="comment"># 所以最小公倍数为pq/m</span></span><br><span class="line">        <span class="comment"># 若q/m为偶数则最小公倍数为p的偶数倍，射向南墙</span></span><br><span class="line">        <span class="keyword">if</span> (q / m) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 否则为奇数倍，判断与东西墙的接触次数</span></span><br><span class="line">        <span class="comment"># 若p/m为偶数则最小公倍数为q的偶数倍，落点为2</span></span><br><span class="line">        <span class="keyword">elif</span> (p / m) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">        <span class="comment"># 否则落点为1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了83.16% 的Python3用户<br>内存消耗:14.9 MB,击败了5.43% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">mirrorReflection</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = p, n = q;</span><br><span class="line">        <span class="keyword">while</span>(n &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> r = m % n;</span><br><span class="line">            m = n;</span><br><span class="line">            n = r;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (q / m % <span class="number">2</span> == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(p / m % <span class="number">2</span> == <span class="number">0</span>)  <span class="keyword">return</span> <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：34.9 MB, 在所有 Java 提交中击败了92.59% 的用户</p>
<h3 id="23-整数转罗马数字"><a href="#23-整数转罗马数字" class="headerlink" title="23.整数转罗马数字"></a>23.整数转罗马数字</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第12题：整数转罗马数字</th>
</tr>
</thead>
<tbody>
<tr>
<td>罗马数字包含以下七种字符：I， V， X，L，C，D 和 M。</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">字符          数值</span><br><span class="line">I             1</span><br><span class="line">V             5</span><br><span class="line">X             10</span><br><span class="line">L             50</span><br><span class="line">C             100</span><br><span class="line">D             500</span><br><span class="line">M             1000</span><br></pre></td></tr></table></figure>
<p>例如， 罗马数字 2 写做 II ，即为两个并列的 1。12 写做 XII ，即为 X + II 。27 写做  XXVII， 即为 XX + V + II 。</p>
<p>通常情况下，罗马数字中小的数字在大的数字的右边。但也存在特例，例如 4 不写做 IIII，而是 IV。数字 1 在数字 5 的左边，所表示的数等于大数 5 减小数 1 得到的数值 4 。同样地，数字 9 表示为 IX。这个特殊的规则只适用于以下六种情况：</p>
<p>I 可以放在 V (5) 和 X (10) 的左边，来表示 4 和 9。</p>
<p>X 可以放在 L (50) 和 C (100) 的左边，来表示 40 和 90。</p>
<p>C 可以放在 D (500) 和 M (1000) 的左边，来表示 400 和 900。</p>
<p>给定一个整数，将其转为罗马数字。输入确保在 1 到 3999 的范围内。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 3</span><br><span class="line">输出: &quot;III&quot;</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 4</span><br><span class="line">输出: &quot;IV&quot;</span><br></pre></td></tr></table></figure>
<p><strong>示例 3:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 9</span><br><span class="line">输出: &quot;IX&quot;</span><br></pre></td></tr></table></figure>
<p><strong>示例 4:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 58</span><br><span class="line">输出: &quot;LVIII&quot;</span><br><span class="line">解释: L = 50, V = 5, III = 3.</span><br></pre></td></tr></table></figure>
<p><strong>示例 5:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 1994</span><br><span class="line">输出: &quot;MCMXCIV&quot;</span><br><span class="line">解释: M = 1000, CM = 900, XC = 90, IV = 4.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>我们把题目中所有的字符列出来，一些特殊的规则也得列出来。假设我们要找的数为2834，大概的流程如下（其实是一种类似贪心的思想）：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/117.png" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intToRoman</span>(<span class="params">self, num: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span></span><br><span class="line">        nums = [<span class="number">1000</span>, <span class="number">900</span>, <span class="number">500</span>, <span class="number">400</span>, <span class="number">100</span>, <span class="number">90</span>, <span class="number">50</span>, <span class="number">40</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line">        romas = [<span class="string">&quot;M&quot;</span>, <span class="string">&quot;CM&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="string">&quot;CD&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;XC&quot;</span>, <span class="string">&quot;L&quot;</span>, <span class="string">&quot;XL&quot;</span>, <span class="string">&quot;X&quot;</span>, <span class="string">&quot;IX&quot;</span>, <span class="string">&quot;V&quot;</span>, <span class="string">&quot;IV&quot;</span>, <span class="string">&quot;I&quot;</span>]</span><br><span class="line">        result = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> num &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> num &gt;= nums[index]:</span><br><span class="line">                result += romas[index]</span><br><span class="line">                num -= nums[index]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了88.55% 的Python3用户<br>内存消耗:14.8 MB,击败了5.03% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>[] values = &#123;<span class="number">1000</span>, <span class="number">900</span>, <span class="number">500</span>, <span class="number">400</span>, <span class="number">100</span>, <span class="number">90</span>, <span class="number">50</span>, <span class="number">40</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">1</span>&#125;;</span><br><span class="line">    String[] symbols = &#123;<span class="string">&quot;M&quot;</span>, <span class="string">&quot;CM&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="string">&quot;CD&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;XC&quot;</span>, <span class="string">&quot;L&quot;</span>, <span class="string">&quot;XL&quot;</span>, <span class="string">&quot;X&quot;</span>, <span class="string">&quot;IX&quot;</span>, <span class="string">&quot;V&quot;</span>, <span class="string">&quot;IV&quot;</span>, <span class="string">&quot;I&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">intToRoman</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        StringBuffer roman = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; values.length; ++i) &#123;</span><br><span class="line">            <span class="keyword">int</span> value = values[i];</span><br><span class="line">            String symbol = symbols[i];</span><br><span class="line">            <span class="keyword">while</span> (num &gt;= value) &#123;</span><br><span class="line">                num -= value;</span><br><span class="line">                roman.append(symbol);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (num == <span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> roman.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：6 ms, 在所有 Java 提交中击败了47.30% 的用户<br>内存消耗：37.8 MB, 在所有 Java 提交中击败了72.05% 的用户</p>
<h3 id="24-荷兰国旗问题"><a href="#24-荷兰国旗问题" class="headerlink" title="24.荷兰国旗问题"></a>24.荷兰国旗问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第75题：荷兰国旗问题：现在有若干个红、白、蓝三种颜色的球随机排列成一条直线。现在我们的任务是把这些球按照红、白、蓝排序。</th>
</tr>
</thead>
<tbody>
<tr>
<td>这个问题之所以叫荷兰国旗，是因为我们可以将红白蓝三色小球想象成条状物，有序排列后正好组成荷兰国旗。</td>
</tr>
</tbody>
</table>
</div>
<p>大概就是这么个意思：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/118.png" alt></p>
<blockquote>
<p>改成这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/119.png" alt><br>那总共就三个颜色，我们要区分开来，是不是最少需要两条分隔线？A线的左侧为0，右侧为1。B线的左侧为1，右侧为2。</p>
<p>剩下的是不是只需要把 A线 和 B线 间的数据维护成满足 AB 线的规则就可以了？那要维护 AB 线间的数据，是不是至少你得遍历下 AB 线间的数据？我们从 C 位置处开始。</p>
<ul>
<li>1）若遍历到的位置为0，则说明它一定位于A的左侧。于是就和A处的元素交换，同时向右移动A和C。</li>
<li>2）若遍历到的位置为1，则说明它一定位于AB之间，满足规则，不需要动弹。只需向右移动C。</li>
<li>3）若遍历到的位置为2，则说明它一定位于B的右侧。于是就和B处的元素交换，交换后只把B向左移动，C仍然指向原位置。（因为交换后的C可能是属于A之前的，所以C仍然指向原位置）</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sortColors</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify nums in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        a = c = <span class="number">0</span></span><br><span class="line">        b = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> c &lt;= b:</span><br><span class="line">            <span class="keyword">if</span> nums[c] == <span class="number">0</span>:</span><br><span class="line">                nums[a], nums[c] = nums[c], nums[a]</span><br><span class="line">                a += <span class="number">1</span></span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> nums[c] == <span class="number">2</span>:</span><br><span class="line">                nums[c], nums[b] = nums[b], nums[c]</span><br><span class="line">                b -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                c += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了86.24% 的Python3用户<br>内存消耗:14.9 MB,击败了5.10% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sortColors</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> l = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> r = nums.length;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(cur &lt; r)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[cur] &lt; <span class="number">1</span>) swap(nums, ++l, cur++);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[cur] &gt; <span class="number">1</span>) swap(nums, --r, cur);</span><br><span class="line">            <span class="keyword">else</span> cur++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> temp = arr[i];</span><br><span class="line">        arr[i] = arr[j];</span><br><span class="line">        arr[j] = temp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.8 MB, 在所有 Java 提交中击败了84.85% 的用户</p>
<h3 id="25-六九问题"><a href="#25-六九问题" class="headerlink" title="25.六九问题"></a>25.六九问题</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第1323题：6 和 9 组成的最大数字</th>
</tr>
</thead>
<tbody>
<tr>
<td>给你一个仅由数字 6 和 9 组成的正整数 <code>num</code>。</td>
</tr>
</tbody>
</table>
</div>
<p>大概就是这么个意思：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/120.png" alt></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：num = 9669</span><br><span class="line">输出：9969</span><br><span class="line"></span><br><span class="line">解释：</span><br><span class="line">改变第一位数字可以得到 6669 。</span><br><span class="line">改变第二位数字可以得到 9969 。</span><br><span class="line">改变第三位数字可以得到 9699 。</span><br><span class="line">改变第四位数字可以得到 9666 。</span><br><span class="line">其中最大的数字是 9969 。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>我们只要找到 num 中最高位的 6，将其翻转成 9，就可以找到答案。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maximum69Number</span> (<span class="params">self, num: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">str</span>(num).replace(<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;9&#x27;</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>执行耗时:60 ms,击败了5.65% 的Python3用户<br>内存消耗:14.7 MB,击败了5.20% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maximum69Number</span> <span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        String res = Integer.toString(num);</span><br><span class="line">        <span class="keyword">return</span> Integer.parseInt(res.replaceFirst(<span class="string">&quot;6&quot;</span>, <span class="string">&quot;9&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：5 ms, 在所有 Java 提交中击败了37.53% 的用户<br>内存消耗：35.3 MB, 在所有 Java 提交中击败了64.39% 的用户</p>
<h3 id="26-有效的数独"><a href="#26-有效的数独" class="headerlink" title="26.有效的数独"></a>26.有效的数独</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第36题：有效的数独</th>
</tr>
</thead>
<tbody>
<tr>
<td>判断一个 9x9 的数独是否有效。只需要根据以下规则，验证已经填入的数字是否有效即可。</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>数字 1-9 在每一行只能出现一次。</li>
<li>数字 1-9 在每一列只能出现一次。</li>
<li>数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。</li>
</ul>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：</span><br><span class="line">[</span><br><span class="line"></span><br><span class="line">  [&quot;5&quot;,&quot;3&quot;,&quot;.&quot;,&quot;.&quot;,&quot;7&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;6&quot;,&quot;.&quot;,&quot;.&quot;,&quot;1&quot;,&quot;9&quot;,&quot;5&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;.&quot;,&quot;9&quot;,&quot;8&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;6&quot;,&quot;.&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;8&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;6&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;3&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;4&quot;,&quot;.&quot;,&quot;.&quot;,&quot;8&quot;,&quot;.&quot;,&quot;3&quot;,&quot;.&quot;,&quot;.&quot;,&quot;1&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;7&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;2&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;6&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;.&quot;,&quot;6&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;2&quot;,&quot;8&quot;,&quot;.&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;4&quot;,&quot;1&quot;,&quot;9&quot;,&quot;.&quot;,&quot;.&quot;,&quot;5&quot;],</span><br><span class="line"></span><br><span class="line">  [&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;.&quot;,&quot;8&quot;,&quot;.&quot;,&quot;.&quot;,&quot;7&quot;,&quot;9&quot;]</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">输出: true</span><br><span class="line"></span><br><span class="line">解释:</span><br><span class="line"></span><br><span class="line">数独部分空格内已填入了数字，空白格用 &#x27;.&#x27; 表示。</span><br></pre></td></tr></table></figure>
<p><strong>说明:</strong></p>
<p><strong>一个有效的数独（部分已被填充）不一定是可解的。</strong></p>
<p>只需要根据以上规则，验证已经填入的数字是否有效即可。</p>
<p>给定数独序列只包含数字 1-9 和字符 ‘.’ 。</p>
<p>给定数独永远是 9x9 形式的。</p>
<p>画出来就是下面这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/121.png" alt></p>
<blockquote>
<p>我们要做的就是<strong>用程序来完成这个验证的过程</strong>，如何验证？那其实就两步：</p>
<ul>
<li>第一步：遍历数独中的每一个元素</li>
<li>第二步：验证该元素是否满足上述条件</li>
</ul>
<p>遍历这个没什么好说的，<strong>从左到右，从上到下进行遍历即可</strong>。就一个两层循环。因为题目本身就是常数级的规模，所以时间复杂度就是 O(1)。</p>
<p>问题来了：如何验证元素在 行 / 列 / 子数独中没有重复项？</p>
<p>其实很简单，我们建立三个数组分别记录每行，每列，每个子数独（子数独就是上面各种颜色的小框框）中出现的数字。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//JAVA</span></span><br><span class="line"><span class="keyword">int</span>[][] rows = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br><span class="line"><span class="keyword">int</span>[][] col = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br><span class="line"><span class="keyword">int</span>[][] sbox = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br></pre></td></tr></table></figure>
<p>当然，刚开始的时候他们都是空的。然后<strong>每遍历到一个元素，我们就看看这个元素在里边存不存在，不存在就放进去，存在那说明数独不合法。</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/122.png" alt></p>
<p>比如这个数独。第6行5列为2，那我们就对 rows 和 col 进行设置：（1表示元素存在)<br>    rows[当前行-1][当前元素值-1] = rows[6-1][2-1] = 1<br>    col[当前列-1][当前元素值-1] = col[5-1][2-1] = 1</p>
<p>现在的题是，对于 sbox 该如何设置呢？我们用下面的公式来计算得到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">boxIndex = (row / 3) * 3 + columns / 3</span><br></pre></td></tr></table></figure>
<p>其实很容易理解：我们把上面的第6行5列代入到这个公式里，(5 / 3) * 3 + 4 / 3 = 3 + 1 = 4。这个 4 也就代表最终落到 4 的这个小区域中。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/123.png" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isValidSudoku</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">str</span>]]</span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        rows = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)]</span><br><span class="line">        cols = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)]</span><br><span class="line">        sbox = [[<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                <span class="keyword">if</span> board[i][j] != <span class="string">&#x27;.&#x27;</span>:</span><br><span class="line">                    num = <span class="built_in">int</span>(board[i][j]) - <span class="number">1</span></span><br><span class="line">                    boxIndex = (i // <span class="number">3</span>) * <span class="number">3</span> + j // <span class="number">3</span></span><br><span class="line">                    <span class="keyword">if</span> rows[i][num] == <span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    rows[i][num] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> cols[j][num] == <span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    cols[j][num] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> sbox[boxIndex][num] == <span class="number">1</span>:</span><br><span class="line">                        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                    sbox[boxIndex][num] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:56 ms,击败了46.19% 的Python3用户<br>内存消耗:14.9 MB,击败了5.10% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isValidSudoku</span><span class="params">(<span class="keyword">char</span>[][] board)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] rows = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br><span class="line">        <span class="keyword">int</span>[][] col = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br><span class="line">        <span class="keyword">int</span>[][] sbox = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">9</span>][<span class="number">9</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">9</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">9</span>; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(board[i][j] != <span class="string">&#x27;.&#x27;</span>)&#123;</span><br><span class="line">                    <span class="keyword">int</span> num = board[i][j] - <span class="string">&#x27;0&#x27;</span> - <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">int</span> boxIndex = i / <span class="number">3</span> * <span class="number">3</span> + j / <span class="number">3</span>;</span><br><span class="line">                    <span class="keyword">if</span>(rows[i][num] == <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                    rows[i][num] = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">if</span>(col[j][num] == <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                    col[j][num] = <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">if</span>(sbox[boxIndex][num] == <span class="number">1</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                    sbox[boxIndex][num] = <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：2 ms, 在所有 Java 提交中击败了94.35% 的用户<br>内存消耗：38.5 MB, 在所有 Java 提交中击败了55.46% 的用户</p>
<h3 id="27-费米估算"><a href="#27-费米估算" class="headerlink" title="27.费米估算"></a>27.费米估算</h3><div class="table-container">
<table>
<thead>
<tr>
<th>问题：北京有多少加油站？</th>
</tr>
</thead>
<tbody>
<tr>
<td>对的，你没看错，这就是原题。。。</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>截止到2019年，北京共有1063个加油站</p>
<p>这道题目主要考察人的估算能力。而估算界，有一个估算大牛叫做费米。</p>
<p>费米估算，其实说白了就是将<strong>正确答案，转化为一系列估算变量的乘法</strong>。首先要把变量选的准确，其次要把变量估的准确。回到本题，我们要分析的问题是：北京有多少加油站？</p>
<p>那我们至少得有多少辆车吧？但是并不是所有的车，每天都会上路。所以准确的说我们需要知道每天上路的车有多少。</p>
<p>但是是所有上路的车都需要加油吗？当然不是，所以我们还得改改：每天上路需要加油的车有多少？</p>
<p>知道了每天上路需要加油的车辆数，我们得知道每个加油站可以满足多少辆车吧？</p>
<p>那加油站用什么满足车？自然是油咯。</p>
<p>问题来了，那我们如何知道每天上路需要加油的车辆数？是不是我们可以转化为 北京车辆总数 / 加油频次。</p>
<p>这个加油频次，相信大家就很容易估算出来了。跑滴滴的一天一次油，正常开的话一周一次，开的少一点的话差不多半个月一次。</p>
<p>① 每天上路需要加油的车辆数   ② 每个加油站的容量</p>
<p>所以我们只要回答出上面两个参数，再给出计算公式。就可以很完美的解答本题了！</p>
</blockquote>
<h3 id="28-分发饼干"><a href="#28-分发饼干" class="headerlink" title="28.分发饼干"></a>28.分发饼干</h3><div class="table-container">
<table>
<thead>
<tr>
<th>题目455：分发饼干</th>
</tr>
</thead>
<tbody>
<tr>
<td>假设你是一位很棒（多棒？？？）的家长，想要给你的孩子们一些小饼干（不能给大饼干吗？？？）但是，每个孩子最多只能给一块饼干（有毒吧。。。）</td>
</tr>
</tbody>
</table>
</div>
<p>对每个孩子 i ，都有一个胃口值 gi ，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j ，都有一个尺寸 sj 。如果 sj &gt;= gi  ，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。</p>
<p>注意：你可以假设胃口值为正（特么不正难道往外吐吗？？？）。一个小朋友最多只能拥有一块饼干。</p>
<p><strong>示例 :</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: [1,2,3], [1,1] </span><br><span class="line">输出: 1 </span><br><span class="line"></span><br><span class="line">解释: </span><br><span class="line">你有三个孩子和两块小饼干，3个孩子的胃口值分别是：1,2,3。</span><br><span class="line">虽然你有两块小饼干，由于他们的尺寸都是1，你只能让胃口值是1的孩子满足。</span><br><span class="line">所以你应该输出1。 </span><br></pre></td></tr></table></figure>
<blockquote>
<p>其实策略就很简单了：<strong>我们只需要在满足孩子胃口的前提下，尽可能分配小的饼干给到他</strong>。</p>
<p>具体怎么做呢，我们把饼干和小朋友都按照<strong>从大到小</strong>排列。</p>
<ul>
<li>如果最大的饼干可以满足肚子最大的孩子，那就给他吃，同时比较下一个。</li>
<li>如果最大的饼干不能满足肚子最大的孩子，<strong>那就让他饿着</strong>，然后看看能不能满足第二个孩子。（有点黑暗系，<strong>放弃小朋友</strong>）</li>
</ul>
<p>但是这里有个问题。凭什么就要先满足肚子最大的孩子。按道理讲，肚子越大应该越扛饿才对吧。所以我们换种思路，从<strong>肚子最小的孩子</strong>开始。</p>
<ul>
<li>如果最小的饼干可以满足肚子最小的孩子，那就给他吃，同时比较下一个。</li>
<li>如果最小的饼干不能满足肚子最小的孩子，<strong>那就扔掉饼干</strong>，看看下一个饼干能不能给他吃。（<strong>放弃的是饼干</strong>）</li>
</ul>
<p>那这两种其实都算是贪心：</p>
<ul>
<li>一种是胃口太大轮到下一个孩子</li>
<li>一种是饼干太小轮到下一个饼干</li>
</ul>
<p>因为要同时控制饼干和小孩，所以我们采用双指针。这里给出先满足小肚子孩子的代码：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findContentChildren</span>(<span class="params">self, g: <span class="type">List</span>[<span class="built_in">int</span>], s: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        g.sort()</span><br><span class="line">        s.sort()</span><br><span class="line">        gi, si = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> gi &lt; <span class="built_in">len</span>(g) <span class="keyword">and</span> si &lt; <span class="built_in">len</span>(s):</span><br><span class="line">            <span class="keyword">if</span> g[gi] &lt;= s[si]:</span><br><span class="line">                gi+=<span class="number">1</span></span><br><span class="line">            si+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> gi</span><br></pre></td></tr></table></figure>
<p>执行耗时:60 ms,击败了92.10% 的Python3用户<br>内存消耗:16.1 MB,击败了5.14% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findContentChildren</span><span class="params">(<span class="keyword">int</span>[] g, <span class="keyword">int</span>[] s)</span> </span>&#123;</span><br><span class="line">        Arrays.sort(g);</span><br><span class="line">        Arrays.sort(s);</span><br><span class="line">        <span class="keyword">int</span> ch = <span class="number">0</span>, bis = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(ch &lt; g.length &amp;&amp; bis &lt; s.length)&#123;</span><br><span class="line">            <span class="keyword">if</span>(g[ch] &lt;= s[bis]) ch++;</span><br><span class="line">            bis++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ch;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：9 ms, 在所有 Java 提交中击败了21.24% 的用户<br>内存消耗：39.2 MB, 在所有 Java 提交中击败了50.44% 的用户</p>
<h3 id="29-生命游戏"><a href="#29-生命游戏" class="headerlink" title="29.生命游戏"></a>29.生命游戏</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第289题：生命游戏</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个包含 m × n 个格子的面板，每一个格子都可以看成是一个细胞。每个细胞都具有一个初始状态：1 即为活细胞（live），或 0 即为死细胞（dead）。</td>
</tr>
</tbody>
</table>
</div>
<p>每个细胞与其八个相邻位置（水平，垂直，对角线）的细胞都遵循以下四条生存定律：</p>
<ul>
<li>如果活细胞周围八个位置的活细胞数少于两个，则该位置活细胞死亡；</li>
<li>如果活细胞周围八个位置有两个或三个活细胞，则该位置活细胞仍然存活；</li>
<li>如果活细胞周围八个位置有超过三个活细胞，则该位置活细胞死亡；</li>
<li>如果死细胞周围正好有三个活细胞，则该位置死细胞复活；</li>
</ul>
<p>根据当前状态，写一个函数来计算面板上所有细胞的下一个（一次更新后的）状态。下一个状态是通过将上述规则同时应用于当前状态下的每个细胞所形成的，其中细胞的出生和死亡是同时发生的。</p>
<p>题目有点复杂，举例说明：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/124.png" alt></p>
<p>注意：<strong>面板上所有格子需要同时被更新</strong>：你不能先更新某些格子，然后使用它们的更新后的值再更新其他格子。</p>
<blockquote>
<p>最自然的想法是：一个个的更新细胞状态。</p>
<p><strong>已更新细胞的状态会影响到周围其他还未更新细胞状态的计算</strong>。这明显不是我们想要的！</p>
<p>那我们最简单的思路：是不是只要我们能一直获取原始数组的数据，不就可以保证更新一直正确了吗！至于在哪里，其实不管是copy一个数组，还是说用hashmap存一下数值其实都ok。</p>
</blockquote>
<p><strong>方法一</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gameOfLife</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># 每个细胞统周围八个相邻位置的偏移量</span></span><br><span class="line">        neighbors = [<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 创建复制数组 copyBoard</span></span><br><span class="line">        <span class="comment"># 注意直接用切片的方式或者list()方式是浅复制，被坑了好久。。。</span></span><br><span class="line">        copyBoard = [[<span class="number">0</span>] * <span class="built_in">len</span>(board[<span class="number">0</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board))]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                copyBoard[i][j] = board[i][j]</span><br><span class="line">        <span class="comment"># 遍历面板每一个格子里的细胞</span></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                <span class="comment"># 对于每一个细胞统计其八个相邻位置里的活细胞数量</span></span><br><span class="line">                liveNeighbors = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">                        <span class="keyword">if</span> neighbors[i] != <span class="number">0</span> <span class="keyword">or</span> neighbors[j] != <span class="number">0</span>:</span><br><span class="line">                            r = row + neighbors[i]</span><br><span class="line">                            c = col + neighbors[j]</span><br><span class="line">                            <span class="comment"># 查看相邻的细胞是否是活细胞</span></span><br><span class="line">                            <span class="keyword">if</span> r &lt; <span class="built_in">len</span>(board) <span class="keyword">and</span> r &gt;= <span class="number">0</span> <span class="keyword">and</span> c &lt; <span class="built_in">len</span>(board[<span class="number">0</span>]) <span class="keyword">and</span> c &gt;= <span class="number">0</span> <span class="keyword">and</span> copyBoard[r][c] == <span class="number">1</span>:</span><br><span class="line">                                liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 规则 1 或规则 3</span></span><br><span class="line">                <span class="keyword">if</span> copyBoard[row][col] == <span class="number">1</span> <span class="keyword">and</span> (liveNeighbors &lt; <span class="number">2</span> <span class="keyword">or</span> liveNeighbors &gt; <span class="number">3</span>):</span><br><span class="line">                    board[row][col] = <span class="number">0</span></span><br><span class="line">                <span class="comment"># 规则 4</span></span><br><span class="line">                <span class="keyword">if</span> copyBoard[row][col] == <span class="number">0</span> <span class="keyword">and</span> liveNeighbors == <span class="number">3</span>:</span><br><span class="line">                    board[row][col] = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了71.15% 的Python3用户<br>内存消耗:14.8 MB,击败了7.69% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] neighbors = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">0</span>, <span class="number">1</span>, -<span class="number">1</span>&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">gameOfLife</span><span class="params">(<span class="keyword">int</span>[][] board)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] copyBoard = <span class="keyword">new</span> <span class="keyword">int</span>[board.length][board[<span class="number">0</span>].length];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; board.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; board[<span class="number">0</span>].length; j++)&#123;</span><br><span class="line">                copyBoard[i][j] = board[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> row = <span class="number">0</span>; row &lt; board.length; row++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> col = <span class="number">0</span>; col &lt; board[<span class="number">0</span>].length; col++)&#123;</span><br><span class="line">                <span class="keyword">int</span> liveNeighbors = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++)&#123;</span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">3</span>; j++)&#123;</span><br><span class="line">                        <span class="keyword">if</span>(neighbors[i] != <span class="number">0</span> || neighbors[j] != <span class="number">0</span>)&#123;</span><br><span class="line">                            <span class="keyword">int</span> r = row + neighbors[i];</span><br><span class="line">                            <span class="keyword">int</span> c = col + neighbors[j];</span><br><span class="line">                            <span class="keyword">if</span>(r &lt; board.length &amp;&amp; r &gt;= <span class="number">0</span> &amp;&amp; c &lt; board[<span class="number">0</span>].length &amp;&amp; c &gt;= <span class="number">0</span> &amp;&amp; copyBoard[r][c] == <span class="number">1</span>)&#123;</span><br><span class="line">                                liveNeighbors++;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(copyBoard[row][col] == <span class="number">1</span> &amp;&amp; (liveNeighbors &lt; <span class="number">2</span> || liveNeighbors &gt; <span class="number">3</span>)) board[row][col] = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">if</span>(copyBoard[row][col] == <span class="number">0</span> &amp;&amp; liveNeighbors == <span class="number">3</span>) board[row][col] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.8 MB, 在所有 Java 提交中击败了53.60% 的用户</p>
<p><strong>方法二</strong></p>
<blockquote>
<p><strong>你不就想既可以保存原数组的状态，还可以更新新的状态吗？这些统统都可以在原有数组上搞</strong>。具体怎么搞呢？</p>
<ul>
<li>原来的 0 和 1 不就是代表死和生吗？但是你要更新新的状态，无非就是从生-&gt;死，从死-&gt;生。那我们加个状态 2，代表 生-&gt;死，加个状态 3 表示从 死&gt;生。</li>
<li>对于一个节点来说，如果它周边的点是 1 或者 2，就说明该点上一轮是活的。</li>
<li>整体策略是完成 原始状态-&gt;过渡状态-&gt;真实状态 的过程。</li>
<li>过渡状态 到 真实状态，代码就是把 0 和 2 变回 0，1 和 3 变回1的过程。用模只是代码技巧。</li>
<li>策略实现的第一步是先找到当前节点周围的存活节点数。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gameOfLife</span>(<span class="params">self, board: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment">#  原始状态 -&gt; 过渡状态</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                liveNeighbors = <span class="number">0</span></span><br><span class="line">                <span class="comment"># 判断上边</span></span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i - <span class="number">1</span>][j] == <span class="number">1</span> <span class="keyword">or</span> board[i - <span class="number">1</span>][j] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断左边</span></span><br><span class="line">                <span class="keyword">if</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i][j - <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i][j - <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断下边</span></span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(board) - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i + <span class="number">1</span>][j] == <span class="number">1</span> <span class="keyword">or</span> board[i + <span class="number">1</span>][j] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断右边</span></span><br><span class="line">                <span class="keyword">if</span> j &lt; <span class="built_in">len</span>(board[<span class="number">0</span>]) - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i][j + <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i][j + <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断左上角</span></span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i - <span class="number">1</span>][j - <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i - <span class="number">1</span>][j - <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断右下角</span></span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(board) - <span class="number">1</span> <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(board[<span class="number">0</span>]) - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i + <span class="number">1</span>][j + <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i + <span class="number">1</span>][j + <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断右上角</span></span><br><span class="line">                <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(board[<span class="number">0</span>]) - <span class="number">1</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i - <span class="number">1</span>][j + <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i - <span class="number">1</span>][j + <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 判断左下角</span></span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(board) - <span class="number">1</span> <span class="keyword">and</span> j &gt; <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">if</span> board[i + <span class="number">1</span>][j - <span class="number">1</span>] == <span class="number">1</span> <span class="keyword">or</span> board[i + <span class="number">1</span>][j - <span class="number">1</span>] == <span class="number">2</span>:</span><br><span class="line">                        liveNeighbors += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 根据周边存活数量更新当前点，结果是 0 和 1 的情况不用更新</span></span><br><span class="line">                <span class="keyword">if</span> board[i][j] == <span class="number">0</span> <span class="keyword">and</span> liveNeighbors == <span class="number">3</span>:</span><br><span class="line">                    board[i][j] = <span class="number">3</span></span><br><span class="line">                <span class="keyword">elif</span> board[i][j] == <span class="number">1</span> <span class="keyword">and</span> (liveNeighbors &lt; <span class="number">2</span> <span class="keyword">or</span> liveNeighbors &gt; <span class="number">3</span>):</span><br><span class="line">                    board[i][j] = <span class="number">2</span></span><br><span class="line">        <span class="comment"># 过渡状态 -&gt; 真实状态</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(board[<span class="number">0</span>])):</span><br><span class="line">                board[i][j] = board[i][j] % <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:52 ms,击败了15.25% 的Python3用户<br>内存消耗:14.7 MB,击败了7.69% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">gameOfLife</span><span class="params">(<span class="keyword">int</span>[][] board)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; board.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; board[<span class="number">0</span>].length; j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> liveNeighbors = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; (board[i-<span class="number">1</span>][j] == <span class="number">1</span> || board[i-<span class="number">1</span>][j] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(j &gt; <span class="number">0</span> &amp;&amp; (board[i][j-<span class="number">1</span>] == <span class="number">1</span> || board[i][j-<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(i &lt; board.length-<span class="number">1</span> &amp;&amp; (board[i+<span class="number">1</span>][j] == <span class="number">1</span> || board[i+<span class="number">1</span>][j] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(j &lt; board[<span class="number">0</span>].length-<span class="number">1</span> &amp;&amp; (board[i][j+<span class="number">1</span>] == <span class="number">1</span> || board[i][j+<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; j &gt; <span class="number">0</span> &amp;&amp; (board[i-<span class="number">1</span>][j-<span class="number">1</span>] == <span class="number">1</span> || board[i-<span class="number">1</span>][j-<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(i &lt; board.length-<span class="number">1</span> &amp;&amp; j &lt; board[<span class="number">0</span>].length-<span class="number">1</span> &amp;&amp; (board[i+<span class="number">1</span>][j+<span class="number">1</span>] == <span class="number">1</span> || board[i+<span class="number">1</span>][j+<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(i &gt; <span class="number">0</span> &amp;&amp; j &lt; board[<span class="number">0</span>].length-<span class="number">1</span> &amp;&amp; (board[i-<span class="number">1</span>][j+<span class="number">1</span>] == <span class="number">1</span> || board[i-<span class="number">1</span>][j+<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(i &lt; board.length-<span class="number">1</span> &amp;&amp; j &gt; <span class="number">0</span> &amp;&amp; (board[i+<span class="number">1</span>][j-<span class="number">1</span>] == <span class="number">1</span> || board[i+<span class="number">1</span>][j-<span class="number">1</span>] == <span class="number">2</span>)) liveNeighbors++;</span><br><span class="line">                <span class="keyword">if</span>(board[i][j] == <span class="number">0</span> &amp;&amp; liveNeighbors == <span class="number">3</span>) board[i][j] = <span class="number">3</span>;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(board[i][j] == <span class="number">1</span> &amp;&amp; (liveNeighbors &lt; <span class="number">2</span> || liveNeighbors &gt; <span class="number">3</span>)) board[i][j] = <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; board.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; board[<span class="number">0</span>].length; j++) board[i][j] %= <span class="number">2</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.5 MB, 在所有 Java 提交中击败了93.77% 的用户</p>
<h3 id="30-搜索二维矩阵"><a href="#30-搜索二维矩阵" class="headerlink" title="30.搜索二维矩阵"></a>30.搜索二维矩阵</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第74题：搜索二维矩阵</th>
</tr>
</thead>
<tbody>
<tr>
<td>编写一个高效的算法来判断 m x n 矩阵中，是否存在一个目标值。</td>
</tr>
</tbody>
</table>
</div>
<p>该矩阵具有如下特性：</p>
<ul>
<li>每行中的整数从左到右按升序排列。</li>
<li>每行的第一个整数大于前一行的最后一个整数。</li>
</ul>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">matrix = [</span><br><span class="line">  [1,   3,  5,  7],</span><br><span class="line">  [10, 11, 16, 20],</span><br><span class="line">  [23, 30, 34, 50]</span><br><span class="line">]</span><br><span class="line">target = 3</span><br><span class="line"></span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入:</span><br><span class="line">matrix = [</span><br><span class="line">  [1,   3,  5,  7],</span><br><span class="line">  [10, 11, 16, 20],</span><br><span class="line">  [23, 30, 34, 50]</span><br><span class="line">]</span><br><span class="line">target = 13</span><br><span class="line"></span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<blockquote>
<p>第一个条件意味着可以通过二分搜索确定哪行；</p>
<p>第二个条件意味着可以在行里进行二分搜索确定哪个元素；</p>
</blockquote>
<p><strong>方法一</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchMatrix</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(matrix) == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(matrix[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> target &lt; matrix[<span class="number">0</span>][<span class="number">0</span>] <span class="keyword">or</span> target &gt; matrix[-<span class="number">1</span>][-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 二分法找到target所在的行</span></span><br><span class="line">        top, bottom = <span class="number">0</span>, <span class="built_in">len</span>(matrix) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> top &lt; bottom:</span><br><span class="line">            mid = top + (bottom - top) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> matrix[mid][-<span class="number">1</span>] &lt; target:</span><br><span class="line">                top = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                bottom = mid</span><br><span class="line">        <span class="comment"># 在行里进行二分搜索确定哪个元素</span></span><br><span class="line">        l, r = <span class="number">0</span>, <span class="built_in">len</span>(matrix[top]) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> l &lt;= r:</span><br><span class="line">            mid = (l + r) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> matrix[top][mid] == target:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> matrix[top][mid] &lt; target:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                r = mid - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了87.44% 的Python3用户<br>内存消耗:15 MB,击败了5.38% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">searchMatrix</span><span class="params">(<span class="keyword">int</span>[][] matrix, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> row = matrix.length;</span><br><span class="line">        <span class="keyword">int</span> col = matrix[<span class="number">0</span>].length;</span><br><span class="line">        <span class="keyword">if</span>(row == <span class="number">0</span> || col == <span class="number">0</span> || target &lt; matrix[<span class="number">0</span>][<span class="number">0</span>] || target &gt; matrix[row-<span class="number">1</span>][col-<span class="number">1</span>]) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">int</span> top = <span class="number">0</span>, bottom = row;</span><br><span class="line">        <span class="keyword">while</span>(top &lt; bottom)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (bottom + top) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(matrix[mid][col-<span class="number">1</span>] &lt; target) top = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> bottom = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>, right = col;</span><br><span class="line">        <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (right + left) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(matrix[top][mid] &lt; target) left = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> right = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> matrix[top][left] == target;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.6 MB, 在所有 Java 提交中击败了94.20% 的用户</p>
<p><strong>方法二</strong></p>
<blockquote>
<p>根据题目特性直接将数组拉平，当作一个一维数组的二分查找</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">searchMatrix</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]], target: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(matrix) == <span class="number">0</span> <span class="keyword">or</span> <span class="built_in">len</span>(matrix[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> target &lt; matrix[<span class="number">0</span>][<span class="number">0</span>] <span class="keyword">or</span> target &gt; matrix[-<span class="number">1</span>][-<span class="number">1</span>]:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        m = <span class="built_in">len</span>(matrix)</span><br><span class="line">        n = <span class="built_in">len</span>(matrix[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># 根据题目特性直接将数组拉平，当作一个一维数组的二分查找</span></span><br><span class="line">        l = <span class="number">0</span></span><br><span class="line">        r = m * n</span><br><span class="line">        <span class="keyword">while</span> l &lt; r:</span><br><span class="line">            mid = (l + r) // <span class="number">2</span></span><br><span class="line">            i = mid // n</span><br><span class="line">            j = mid % n</span><br><span class="line">            <span class="keyword">if</span> target == matrix[i][j]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> target &gt; matrix[i][j]:</span><br><span class="line">                l = mid + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                r = mid</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了96.26% 的Python3用户<br>内存消耗:15.1 MB,击败了5.38% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">searchMatrix</span><span class="params">(<span class="keyword">int</span>[][] matrix, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> row = matrix.length;</span><br><span class="line">        <span class="keyword">int</span> col = matrix[<span class="number">0</span>].length;</span><br><span class="line">        <span class="keyword">if</span>(row == <span class="number">0</span> || col == <span class="number">0</span> || target &lt; matrix[<span class="number">0</span>][<span class="number">0</span>] || target &gt; matrix[row-<span class="number">1</span>][col-<span class="number">1</span>]) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">int</span> l = <span class="number">0</span>, r = row * col;</span><br><span class="line">        <span class="keyword">while</span>(l &lt; r)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (l + r) &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(matrix[mid / col][mid % col] &lt; target) l = mid + <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> r = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> matrix[l / col][l % col] == target;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：37.5 MB, 在所有 Java 提交中击败了95.90% 的用户</p>
<h3 id="31-子集"><a href="#31-子集" class="headerlink" title="31.子集"></a>31.子集</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第78题：子集</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一组<strong>不含重复元素</strong>的整数数组 nums，返回该数组所有可能的子集（幂集）。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>说明：</strong> 解集不能包含重复的子集</p>
<p><strong>示例:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: nums = [1,2,3] </span><br><span class="line"></span><br><span class="line">输出: [ [3], [1], [2], [1,2,3], [1,3], [2,3], [1,2], [] ] </span><br></pre></td></tr></table></figure>
<blockquote>
<p>首先我们可以证明一下 N 个元素的子集个数有 2^N 个</p>
<p>可以类比为 N 个不同的小球，一次拿出若干个小球（可以不拿），对于每一个球都可以选择拿或者不拿，共有 N 个球，总共判断 N 次，产生了 2^N 个子集。</p>
<p><strong>我们其实可以用二进制来模拟每个元素是否选中的状态。</strong> 又因为我们已知了对于 N 个元素共有 2^N 个子集，所以我们直接遍历 2^N 个元素。</p>
<p>但是我们并不知道具体的子集元素。那如何找到对应的子集元素呢？<strong>对于 2^N 个 N 位的二进制数，我们可以通过从后往前的第 j 个二进制位的 0 和 1 来表示是否放入子集集合。</strong></p>
</blockquote>
<p><strong>方法一：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        k = <span class="built_in">len</span>(nums)</span><br><span class="line">        res = [[]]</span><br><span class="line">        <span class="comment"># 子集总数共有 2^N 个</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">1</span> &lt;&lt; k):</span><br><span class="line">            <span class="comment"># 找到对应的子集元素</span></span><br><span class="line">            temp = []</span><br><span class="line">            <span class="comment"># 对于 2^N 个 N 位的二进制数，我们可以通过从后往前的第 j 个二进制位的 0 和 1 来表示是否放入子集集合。</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                <span class="keyword">if</span> i &gt;&gt; j &amp; <span class="number">1</span>:</span><br><span class="line">                    temp.append(nums[j])</span><br><span class="line">            res.append(temp)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:40 ms,击败了66.14% 的Python3用户<br>内存消耗:14.9 MB,击败了5.37% 的Python3用户</p>
<p>为帮助大家理解，假设 nums 为 [1,2,3]，res 的存储过程为：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/125.png" alt></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; subsets(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        <span class="keyword">int</span> k = nums.length;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; (<span class="number">1</span> &lt;&lt; k); i++)&#123;</span><br><span class="line">            List&lt;Integer&gt; tmp = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; k; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(((i &gt;&gt; j) &amp; <span class="number">1</span>) != <span class="number">0</span>) tmp.add(nums[j]);</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(tmp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了87.14% 的用户<br>内存消耗：38.6 MB, 在所有 Java 提交中击败了75.78% 的用户</p>
<p><strong>方法二：</strong></p>
<blockquote>
<p>直接遍历，遇到一个数就把所有子集加上该数组成新的子集</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        res = [[]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> subres <span class="keyword">in</span> res[:]: res.append(subres + [nums[i]])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了40.73% 的Python3用户<br>内存消耗:14.9 MB,击败了5.37% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; subsets(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        res.add(<span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> all = res.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; all; j++)&#123;</span><br><span class="line">                List&lt;Integer&gt; tmp = <span class="keyword">new</span> ArrayList&lt;&gt;(res.get(j));</span><br><span class="line">                tmp.add(nums[i]);</span><br><span class="line">                res.add(tmp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了87.14% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了63.70% 的用户</p>
<p><strong>方法三：</strong></p>
<blockquote>
<p>集合中所有元素的选/不选，其实构成了一个满二叉树。左子树选，右子树不选。自然，那从根节点到所有叶子节点的路径，就构成了所有的子集。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/126.png" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        res = []</span><br><span class="line">        n = <span class="built_in">len</span>(nums)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">i, tmp</span>):</span></span><br><span class="line">            res.append(tmp)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, n):</span><br><span class="line">                dfs(j + <span class="number">1</span>, tmp + [nums[j]])</span><br><span class="line">        dfs(<span class="number">0</span>, [])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了40.73% 的Python3用户<br>内存消耗:14.9 MB,击败了5.37% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; subsets(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        dfs(<span class="number">0</span>, nums, <span class="keyword">new</span> ArrayList&lt;&gt;());</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">int</span>[] nums, List&lt;Integer&gt; tmp)</span></span>&#123;</span><br><span class="line">        res.add(tmp);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = index; i &lt; nums.length; i++)&#123;</span><br><span class="line">            List&lt;Integer&gt; new_tmp = <span class="keyword">new</span> ArrayList&lt;&gt;(tmp);</span><br><span class="line">            new_tmp.add(nums[i]);</span><br><span class="line">            dfs(i + <span class="number">1</span>, nums, new_tmp);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：1 ms, 在所有 Java 提交中击败了87.14% 的用户<br>内存消耗：38.6 MB, 在所有 Java 提交中击败了73.80% 的用户</p>
<h3 id="32-量出4升水"><a href="#32-量出4升水" class="headerlink" title="32.量出4升水"></a>32.量出4升水</h3><div class="table-container">
<table>
<thead>
<tr>
<th>题目：量出4升水</th>
</tr>
</thead>
<tbody>
<tr>
<td>怎么用3升和5升的桶量出4升的水？</td>
</tr>
</tbody>
</table>
</div>
<p>题目没什么补充的，直接分析，一个3升和5升的水桶：</p>
<p>首先用三升水桶装满水，倒入五升水桶：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/127.png" alt></p>
<p>再次倒满三升水桶，填满后继续倒入五升水桶，直到五升水桶倒满。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/128.png" alt></p>
<p>清空五升水桶，将三升水桶的一升水倒入：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/129.png" alt></p>
<p>再次填满三升水桶，倒入五升水桶中：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/130.png" alt></p>
<h3 id="33-最大的钻石"><a href="#33-最大的钻石" class="headerlink" title="33.最大的钻石"></a>33.最大的钻石</h3><div class="table-container">
<table>
<thead>
<tr>
<th>题目：最大的钻石</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 楼到 n 楼的每层电梯门口都放着一颗钻石，钻石大小不一。你乘坐电梯从 1 楼到 n 楼，每层楼电梯门都会打开一次，只能拿一次钻石，问怎样才能拿到「最大」的一颗？</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>面试时如果被问到这种题目，其实大多数面试官心中并没有一个标准答案。（不排除有面试官深究的）事实是作为面试者，我们只要流畅的给出答案，大概率都是可以顺利过关。</p>
<p>回到题目。其实题中包含一个隐藏条件：<strong>随机放置</strong>。所有的分析都是基于随机放置给出的。<strong>换句话说，如果放置钻石是人为干预大小，那么本题的所以分析则全部不成立</strong>。</p>
<p>其实这个问题的原型叫做秘书问题，该类问题全部属于<strong>最佳停止问题</strong>。</p>
<p>这类问题都有着统一的解法：</p>
<p><strong>我们要选择先放弃前 37%（就是1/e）的钻石，此后选择比前 37% 都大的第一颗钻石。</strong></p>
<p>其实该法则还有很多运用，比如一些常见的推文《谈恋爱拒绝掉前面37%的人》，其实就是一样的原因。</p>
<p>改题目还有一些变种，比如：</p>
<p>一个活动，n个女生手里拿着长短不一的玫瑰花，无序的排成一排，一个男生从头走到尾，试图拿更长的玫瑰花，一旦拿了一朵就不能再拿其他的，错过了就不能回头，问最好的策略?</p>
<p>现在要聘请 1 名秘书，共有 n 个应聘者，每面试 1 人后，就知道了应聘者的好坏程度，且必须立刻决定是否聘用，不可重复面试。策略是拒绝前 k  个应聘者，而从第 k+1 个应聘者开始，一旦有比前 k 个都好的，就立刻聘用。如何决定 k 的值，使得聘用到最佳应聘者的概率最大？等等。</p>
<p>这里再给出一个严谨的推导过程：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/131.png" alt></p>
</blockquote>
<h3 id="34-思维定势"><a href="#34-思维定势" class="headerlink" title="34.思维定势"></a>34.思维定势</h3><blockquote>
<p>下面这道题也是一道常见的智力题，但是这道题绝对不会出现在面试中了。拿出来分享给大家的原因，是期望不要被思维定势局限。</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/132.png" alt></p>
<p>这道题中有六个停车位，每个车位上都有一个数字，然而有一个车位上的数字被汽车挡住了，要求学生们在20秒内答出这个被挡住的车位上的数字。这是中国香港小学一道给6岁儿童设计的“停车场智力题”。</p>
<blockquote>
<p>答案：L8，即87</p>
</blockquote>
<h3 id="35-图的基础知识"><a href="#35-图的基础知识" class="headerlink" title="35.图的基础知识"></a>35.图的基础知识</h3><blockquote>
<p>图（Graph）是表示物件与物件之间的关系的数学对象，是图论的基本研究对象。</p>
</blockquote>
<p>图是一个比树形关系复杂一点点，比线性关系复杂两点点的东东。</p>
<ul>
<li>线性关系是一对一：一个前驱一个后继。</li>
<li>树形结构是一对多：一个父多个子</li>
<li>图形结构是多对多：任意两个顶点（图中的节点叫做顶点）都有可能相关，是一种多对多的关系。</li>
</ul>
<p>图我们一般表示为 G = (V，E)</p>
<ul>
<li>V：代表点</li>
<li>E：代表边</li>
</ul>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/133.png" alt></p>
<p>啥意思嘞，比如就上面那个绿油油的图，就可以表示为:</p>
<ul>
<li>V={1,2,3,4,5,6}</li>
<li>E={(1,2),(1,5),(2,3),(2,5),(3,4),(4,5),(4,6)}</li>
</ul>
<p>图里最基本的单元是顶点（vertex），相当于树中的节点。顶点之间的关联关系，被称为边（edge）。而边可以分配一个数值（正负都ok），这个数值就叫做权重。</p>
<p><strong>无向图和有向图</strong></p>
<p>有方向的图就是有向图，无方向的图就是无向图。</p>
<p><strong>完全图</strong></p>
<p>所有的顶点互相连接在一起，那就是完全图。</p>
<p>在无向图中，若每对顶点之间都有一条边相连，则称该图为完全图。大概就是这样：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/134.png" alt></p>
<p>而在有向图中，若每对顶点之间都有二条有向边相互连接，也算是完全图。</p>
<p><strong>循环图和DAG</strong></p>
<p>循环图中的循环二字，指的是<strong>起点和终点是同一节点时</strong>产生的路径。所以，<strong>循环图和有向图或无向图并没有什么关系，因为都有可能产生循环</strong>。有向图，那就遵循边的方向。无向图，那只要成环就行。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/135.png" alt></p>
<p>这三个：</p>
<ul>
<li>第一个就是无向循环图</li>
<li>第二个就是有向非循环图</li>
<li>第三个就是有向循环图</li>
</ul>
<p>第二个更多的是被称为有向无环图DAG（Directed Acyclic Graph）。下面这个也是 ：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/136.png" alt></p>
<p>那上面这个像不像一棵树。。。。。所以计算机结构中的树（大多都是有向的），其实就是一个DAG。</p>
<p><strong>加权图</strong></p>
<blockquote>
<p> 用数学语言讲，设G为图，对图的每一条边e来说，都对应于一个实数W(e)（可以通俗的理解为边的“长度”，只是在数学定义中图的权可以为负数），我们把W(e)称为e的“权”。把这样的图G称为“加权图”。</p>
</blockquote>
<p>但是这里如果细分的话，又分为<strong>顶点加权图和边加权图。</strong> 说白了，就是有人发现如果只给边加上权值（就是长度）并不够用，有时候也需要给顶点加上权值。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/137.jpg" alt></p>
<p><strong>连通图</strong></p>
<blockquote>
<p>在图论中，连通图基于连通的概念。在一个无向图 G 中，若从顶点i到顶点j有路径相连（当然从j到i也一定有路径），则称i和j是连通的。</p>
</blockquote>
<p>连通的图，就是连通图：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/138.png" alt></p>
<p>如果不通了，就是非连通图：（这是一个图）</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/139.png" alt></p>
<p>那没有连通在一起的这两坨（或者说移动的这两坨），我们叫作<strong>岛</strong>。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/140.png" alt></p>
<p>所以，如果我们的图里包含岛，那就是非连通图。</p>
<p><strong>稠密图和稀疏图</strong></p>
<p>如何定义稠密和稀疏？<strong>梵蒂冈也有人觉得他们的圣彼得大教堂拥挤</strong>，所以稠密稀疏本身就是一个主观定义。</p>
<p>我们可以简单的认为，稀疏图的边数远远少于完全图，反之，稠密图的边数接近于或等于完全图。</p>
<h3 id="36-旋转图像"><a href="#36-旋转图像" class="headerlink" title="36.旋转图像"></a>36.旋转图像</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第48题：旋转图像</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个 n × n 的二维矩阵表示一个图像。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>说明：</strong></p>
<p>你必须在原地旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。</p>
<p><strong>示例 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">给定 matrix = </span><br><span class="line">[</span><br><span class="line">  [1,2,3],</span><br><span class="line">  [4,5,6],</span><br><span class="line">  [7,8,9]</span><br><span class="line">],</span><br><span class="line"></span><br><span class="line">原地旋转输入矩阵，使其变为:</span><br><span class="line">[</span><br><span class="line">  [7,4,1],</span><br><span class="line">  [8,5,2],</span><br><span class="line">  [9,6,3]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><strong>示例 2:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">给定 matrix =</span><br><span class="line">[</span><br><span class="line">  [ 5, 1, 9,11],</span><br><span class="line">  [ 2, 4, 8,10],</span><br><span class="line">  [13, 3, 6, 7],</span><br><span class="line">  [15,14,12,16]</span><br><span class="line">], </span><br><span class="line"></span><br><span class="line">原地旋转输入矩阵，使其变为:</span><br><span class="line">[</span><br><span class="line">  [15,13, 2, 5],</span><br><span class="line">  [14, 3, 4, 1],</span><br><span class="line">  [12, 6, 8, 9],</span><br><span class="line">  [16, 7,10,11]</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><strong>方法一</strong></p>
<blockquote>
<p>一般容易想到的是，一层层的从外到内旋转每一圈（至于为什么不从内到外，如果你觉得方便，也ok），也就是俗称的找框框。</p>
<p>对每个框框，其实都有 4 个顶点：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/141.png" alt><br>交换完毕之后，再继续交换移动后的四个顶点：<br><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/142.png" alt><br>那代码实现其实就很简单了：</p>
<ul>
<li>我们通过 x 和 y 就可以定义这个框框的边界</li>
<li>找到框框后，我们再通过框框边界来定义出4个顶点</li>
<li>然后完成交换</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotate</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        x, y = <span class="number">0</span>, <span class="built_in">len</span>(matrix[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">        <span class="comment"># 从最外圈开始到最内圈</span></span><br><span class="line">        <span class="keyword">while</span> x &lt; y:</span><br><span class="line">            s = x</span><br><span class="line">            e = y</span><br><span class="line">            <span class="comment"># 每一圈每轮换4个顶点</span></span><br><span class="line">            <span class="keyword">while</span> s &lt; y:</span><br><span class="line">                matrix[x][s], matrix[e][x], matrix[y][e], matrix[s][y] \</span><br><span class="line">                    = matrix[e][x], matrix[y][e], matrix[s][y], matrix[x][s]</span><br><span class="line">                s += <span class="number">1</span></span><br><span class="line">                e -= <span class="number">1</span></span><br><span class="line">            x += <span class="number">1</span></span><br><span class="line">            y -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> matrix</span><br></pre></td></tr></table></figure>
<p>执行耗时:36 ms,击败了81.13% 的Python3用户<br>内存消耗:14.8 MB,击败了38.77% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rotate</span><span class="params">(<span class="keyword">int</span>[][] matrix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> x = <span class="number">0</span>, y = matrix[<span class="number">0</span>].length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(x &lt; y)&#123;</span><br><span class="line">            <span class="keyword">int</span> s = x, e = y;</span><br><span class="line">            <span class="keyword">while</span>(s &lt; y)&#123;</span><br><span class="line">                swap(matrix, x, s, e, x);</span><br><span class="line">                swap(matrix, e, x, y, e);</span><br><span class="line">                swap(matrix, y, e, s, y);</span><br><span class="line">                s++;</span><br><span class="line">                e--;</span><br><span class="line">            &#125;</span><br><span class="line">            x++;</span><br><span class="line">            y--;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>[][] matrix, <span class="keyword">int</span> x1, <span class="keyword">int</span> y1, <span class="keyword">int</span> x2, <span class="keyword">int</span> y2)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> tmp = matrix[x1][y1];</span><br><span class="line">        matrix[x1][y1] = matrix[x2][y2];</span><br><span class="line">        matrix[x2][y2] = tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了26.87% 的用户</p>
<p><strong>方法二</strong></p>
<blockquote>
<p>我们观察这个矩阵，向右旋转90°，是不是可以理解为<strong>先上下翻转，再沿对角线翻转</strong>：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/143.png" alt></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rotate</span>(<span class="params">self, matrix: <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="comment"># 上下翻转</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(matrix)//<span class="number">2</span>):</span><br><span class="line">            matrix[i], matrix[<span class="built_in">len</span>(matrix)-i-<span class="number">1</span>] = matrix[<span class="built_in">len</span>(matrix)-i-<span class="number">1</span>], matrix[i]</span><br><span class="line">        <span class="comment"># 对角线翻转</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(matrix)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, <span class="built_in">len</span>(matrix)):</span><br><span class="line">                matrix[i][j], matrix[j][i] = matrix[j][i], matrix[i][j]</span><br><span class="line">        <span class="keyword">return</span> matrix</span><br></pre></td></tr></table></figure>
<p>执行耗时:32 ms,击败了93.70% 的Python3用户<br>内存消耗:14.8 MB,击败了34.93% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rotate</span><span class="params">(<span class="keyword">int</span>[][] matrix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; matrix.length / <span class="number">2</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span>[] tmp = matrix[i];</span><br><span class="line">            matrix[i] = matrix[matrix.length - i - <span class="number">1</span>];</span><br><span class="line">            matrix[matrix.length - i - <span class="number">1</span>] = tmp;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; matrix.length; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; matrix.length; j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> tmp = matrix[i][j];</span><br><span class="line">                matrix[i][j] = matrix[j][i];</span><br><span class="line">                matrix[j][i] = tmp;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：38.7 MB, 在所有 Java 提交中击败了22.51% 的用户</p>
<h3 id="37-螺旋矩阵II"><a href="#37-螺旋矩阵II" class="headerlink" title="37.螺旋矩阵II"></a>37.螺旋矩阵II</h3><div class="table-container">
<table>
<thead>
<tr>
<th>第59题：螺旋矩阵Ⅱ</th>
</tr>
</thead>
<tbody>
<tr>
<td>给定一个正整数 n，生成一个包含 1 到 $n^2$ 所有元素，且元素按顺时针顺序螺旋排列的正方形矩阵。</td>
</tr>
</tbody>
</table>
</div>
<p><strong>示例：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: 3</span><br><span class="line">输出: [ [ 1, 2, 3 ], [ 8, 9, 4 ], [ 7, 6, 5 ] ]</span><br></pre></td></tr></table></figure>
<p>题目理解较为容易，给定 n = 3，那就生成一个 3^2 = 9 的矩阵。大家看下面的图可能更加直观一些：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/144.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateMatrix</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span></span><br><span class="line">        res = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        x, y = <span class="number">0</span>, n - <span class="number">1</span></span><br><span class="line">        count = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 从外圈到里圈</span></span><br><span class="line">        <span class="keyword">while</span> x &lt;= y:</span><br><span class="line">            <span class="comment"># 向右取</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(x, y + <span class="number">1</span>):</span><br><span class="line">                res[x][j] = count</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 向下取</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x + <span class="number">1</span>, y + <span class="number">1</span>):</span><br><span class="line">                res[i][y] = count</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 向左取</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(y - <span class="number">1</span>, x - <span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">                res[y][j] = count</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 向上取</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(y - <span class="number">1</span>, x, -<span class="number">1</span>):</span><br><span class="line">                res[i][x] = count</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            x += <span class="number">1</span></span><br><span class="line">            y -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>执行耗时:44 ms,击败了33.33% 的Python3用户<br>内存消耗:14.7 MB,击败了22.80% 的Python3用户</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[][] generateMatrix(<span class="keyword">int</span> n) &#123;</span><br><span class="line">        <span class="keyword">int</span>[][] res = <span class="keyword">new</span> <span class="keyword">int</span>[n][n];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>, x = <span class="number">0</span>, y = n - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(x &lt;= y)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = x; j &lt;= y; j++) res[x][j] = count++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = x + <span class="number">1</span>; i &lt;= y; i++) res[i][y] = count++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = y - <span class="number">1</span>; j &gt;= x; j--) res[y][j] = count++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = y - <span class="number">1</span>; i &gt; x; i--) res[i][x] = count++;</span><br><span class="line">            x++;</span><br><span class="line">            y--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行用时：0 ms, 在所有 Java 提交中击败了100.00% 的用户<br>内存消耗：36.6 MB, 在所有 Java 提交中击败了32.38% 的用户</p>
<h2 id="排序系列-1"><a href="#排序系列-1" class="headerlink" title="排序系列"></a>排序系列</h2><h3 id="1-排序专栏"><a href="#1-排序专栏" class="headerlink" title="1.排序专栏"></a>1.排序专栏</h3><p>所谓排序，就是使一串记录，按照其中的某个或某些关键字的大小，递增或递减的排列起来的操作。排序算法，就是如何使得记录按照要求排列的方法。是《数据结构与算法》中最基本的算法之一。</p>
<blockquote>
<p>我们常说的十大排序算法为：冒泡、选择、插入、希尔、归并、快速、堆、计数、桶、基数</p>
</blockquote>
<p><strong>基本分类</strong><br>我们常根据是否可以在线性时间内比较对其分类：</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/145.png" alt></p>
<p><strong>时间复杂度</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/146.png" alt></p>
<p><strong>如何记忆时间复杂度呢？</strong></p>
<ol>
<li>平方阶 (O(n2)) 插入、选择、冒泡</li>
<li>线性对数阶 (O(nlog2n)) 快速、归并、堆</li>
<li>特殊的希尔 O(n^(1.3—2))</li>
<li>牛皮的线性 基数、桶、箱、计数</li>
</ol>
<p><strong>啥是稳定：</strong></p>
<p>稳定：如果 a 原本在 b 前面，而 a=b，排序之后 a 仍然在 b 的前面。<br>不稳定：如果 a 原本在 b 的前面，而 a=b，排序之后 a 可能会出现在 b 的后面。</p>
<p><strong>哪些稳定：</strong></p>
<p>稳定：冒泡、插入、归并和基数。 不稳定：选择、快速、希尔、堆。</p>
<h3 id="2-冒泡排序"><a href="#2-冒泡排序" class="headerlink" title="2.冒泡排序"></a>2.冒泡排序</h3><p>冒泡排序（Bubble  Sort）也是一种简单直观的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。</p>
<p>作为最简单的排序算法之一，冒泡排序给我的感觉就像 Abandon 在单词书里出现的感觉一样，每次都在第一页第一位，所以最熟悉。冒泡排序还有一种优化算法，就是立一个  flag，当在一趟序列遍历中元素没有发生交换，则证明该序列已经有序。但这种改进对于提升性能来说并没有什么太大作用。</p>
<blockquote>
<p>算法步骤</p>
<ol>
<li>比较相邻的元素。如果第一个比第二个大，就交换他们两个。</li>
<li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。</li>
<li>针对所有的元素重复以上的步骤，除了最后一个。</li>
<li>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。<br>最慢和最快</li>
</ol>
</blockquote>
<p>正序时最快，反序时最慢</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubbleSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr) - <span class="number">1</span>):</span><br><span class="line">    	flag = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr) - <span class="number">1</span> - i):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &gt; arr[j + <span class="number">1</span>]:</span><br><span class="line">                arr[j], arr[j+<span class="number">1</span>] = arr[j+<span class="number">1</span>], arr[j]</span><br><span class="line">                flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> flag: <span class="keyword">break</span> </span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BubbleSort</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">bubbleSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;arr.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">boolean</span> flag = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt; arr.length-i-<span class="number">1</span>; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(arr[j] &gt; arr[j+<span class="number">1</span>])&#123;</span><br><span class="line">                    <span class="keyword">int</span> tmp = arr[j];</span><br><span class="line">                    arr[j] = arr[j+<span class="number">1</span>];</span><br><span class="line">                    arr[j+<span class="number">1</span>] = tmp;</span><br><span class="line">                    flag = <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (flag) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">9</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">2</span>&#125;;</span><br><span class="line">        bubbleSort(arr);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-基数排序"><a href="#3-基数排序" class="headerlink" title="3.基数排序"></a>3.基数排序</h3><p>基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。</p>
<blockquote>
<p>基数排序 vs 计数排序 vs 桶排序</p>
</blockquote>
<p>基数排序有两种方法：</p>
<p>这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异案例看大家发的：</p>
<ul>
<li>基数排序：根据键值的每位数字来分配桶；</li>
<li>计数排序：每个桶只存储单一键值；</li>
<li>桶排序：每个桶存储一定范围的数值；</li>
</ul>
<blockquote>
<p> LSD 基数排序动图演示</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/147.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">radix</span>(<span class="params">arr</span>):</span></span><br><span class="line">    digit = <span class="number">0</span></span><br><span class="line">    max_digit = <span class="number">1</span></span><br><span class="line">    max_value = <span class="built_in">max</span>(arr)</span><br><span class="line">    <span class="comment"># 找出列表中最大的位数</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">10</span>**max_digit &lt; max_value:</span><br><span class="line">        max_digit = max_digit + <span class="number">1</span> </span><br><span class="line">    <span class="keyword">while</span> digit &lt; max_digit:</span><br><span class="line">        <span class="comment"># 创建桶</span></span><br><span class="line">        temp = [[] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">            <span class="comment"># 求出每一个元素的个、十、百位直到最高位的值</span></span><br><span class="line">            t = <span class="built_in">int</span>((i/<span class="number">10</span>**digit)%<span class="number">10</span>)</span><br><span class="line">            <span class="comment"># 添加进相应的桶中</span></span><br><span class="line">            temp[t].append(i)</span><br><span class="line">        <span class="comment"># 将桶中的数据依次取出</span></span><br><span class="line">        coll = []</span><br><span class="line">        <span class="keyword">for</span> bucket <span class="keyword">in</span> temp:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> bucket:</span><br><span class="line">                coll.append(i)</span><br><span class="line">        <span class="comment"># 作为下次装桶的数据        </span></span><br><span class="line">        arr = coll</span><br><span class="line">        <span class="comment"># 直到遍历完所有位</span></span><br><span class="line">        digit = digit + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//java</span></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RadixSort</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取最高位数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getMaxDigit</span><span class="params">(<span class="keyword">int</span>[] arr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> maxValue = getMaxValue(arr);</span><br><span class="line">        <span class="keyword">return</span> getNumLenght(maxValue);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getMaxValue</span><span class="params">(<span class="keyword">int</span>[] arr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> maxValue = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> value : arr) &#123;</span><br><span class="line">            <span class="keyword">if</span> (maxValue &lt; value) &#123;</span><br><span class="line">                maxValue = value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getNumLenght</span><span class="params">(<span class="keyword">long</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (num == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> lenght = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> temp = num; temp != <span class="number">0</span>; temp /= <span class="number">10</span>) &#123;</span><br><span class="line">            lenght++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> lenght;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span>[] radixSort(<span class="keyword">int</span>[] arr) &#123;</span><br><span class="line">        <span class="keyword">int</span> mod = <span class="number">10</span>;</span><br><span class="line">        <span class="keyword">int</span> dev = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> maxDigit = getMaxDigit(arr);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; maxDigit; i++, dev *= <span class="number">10</span>) &#123;</span><br><span class="line">            <span class="comment">// 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10)</span></span><br><span class="line">            List&lt;Integer&gt;[] counter = <span class="keyword">new</span> List[mod * <span class="number">2</span>];</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; arr.length; j++) &#123;</span><br><span class="line">                <span class="comment">// 求每位的余数，并加10，使得负数映射到0-9，正数映射到10-19</span></span><br><span class="line">                <span class="keyword">int</span> bucket = (arr[j] / dev % mod) + mod;</span><br><span class="line">                <span class="keyword">if</span>(counter[bucket] == <span class="keyword">null</span>) counter[bucket] = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">                counter[bucket].add(arr[j]);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//将桶中的数按顺序取出，进行下一位的排序</span></span><br><span class="line">            <span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (List&lt;Integer&gt; bucket : counter) &#123;</span><br><span class="line">                <span class="keyword">if</span>(bucket != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> value : bucket) &#123;</span><br><span class="line">                        arr[pos++] = value;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;-<span class="number">5</span>, -<span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>, -<span class="number">9</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(radixSort(arr)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="4-选择排序"><a href="#4-选择排序" class="headerlink" title="4.选择排序"></a>4.选择排序</h3><p>选择排序是一种简单直观的排序算法，无论什么数据进去都是 O(n²) 的时间复杂度。所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。</p>
<blockquote>
<p>算法步骤</p>
</blockquote>
<ol>
<li>首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置</li>
<li>再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。</li>
<li>重复第二步，直到所有元素均排序完毕。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selectionSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr) - <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 记录最小数的索引</span></span><br><span class="line">        minIndex = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(arr)):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &lt; arr[minIndex]:</span><br><span class="line">                minIndex = j</span><br><span class="line">        <span class="comment"># i 不是最小数时，将 i 和最小数进行交换</span></span><br><span class="line">        <span class="keyword">if</span> i != minIndex:</span><br><span class="line">            arr[i], arr[minIndex] = arr[minIndex], arr[i]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SelectionSort</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">selectSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;arr.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> minPos = i;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>; j&lt;arr.length; j++)&#123;</span><br><span class="line">                minPos = arr[j] &lt; arr[minPos]? j: minPos;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> tmp = arr[i];</span><br><span class="line">            arr[i] = arr[minPos];</span><br><span class="line">            arr[minPos] = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        selectSort(arr);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="5-插入排序"><a href="#5-插入排序" class="headerlink" title="5.插入排序"></a>5.插入排序</h3><p>插入排序的代码实现虽然没有冒泡排序和选择排序那么简单粗暴，但它的原理应该是最容易理解的了，因为只要打过扑克牌的人都应该能够秒懂。插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p>
<p>插入排序和冒泡排序一样，也有一种优化算法，叫做拆半插入。</p>
<blockquote>
<p>算法步骤</p>
</blockquote>
<ol>
<li>将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。</li>
<li>从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertionSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">        preIndex = i-<span class="number">1</span></span><br><span class="line">        current = arr[i]</span><br><span class="line">        <span class="keyword">while</span> preIndex &gt;= <span class="number">0</span> <span class="keyword">and</span> arr[preIndex] &gt; current:</span><br><span class="line">            arr[preIndex+<span class="number">1</span>] = arr[preIndex]</span><br><span class="line">            preIndex-=<span class="number">1</span></span><br><span class="line">        arr[preIndex+<span class="number">1</span>] = current</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InsertionSort</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertionSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt; arr.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> tmp =  arr[i];</span><br><span class="line">            <span class="keyword">int</span> j = i;</span><br><span class="line">            <span class="keyword">while</span>(j &gt; <span class="number">0</span> &amp;&amp; tmp &lt; arr[j-<span class="number">1</span>])&#123;</span><br><span class="line">                arr[j] = arr[j-<span class="number">1</span>];</span><br><span class="line">                j--;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(j != i) arr[j] = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        insertionSort(arr);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="6-希尔排序"><a href="#6-希尔排序" class="headerlink" title="6.希尔排序"></a>6.希尔排序</h3><p>希尔排序(Shell  Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。  希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。</p>
<p><strong>希尔排序过程</strong><br>希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。<br>   例如，假设有这样一组数[ 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10  ]，如果我们以步长为5开始进行排序，我们可以通过将这列表放在有5列的表中来更好地描述算法，这样他们就应该看起来是这样(竖着的元素是步长组成)：</p>
   <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">13 14 94 33 82</span><br><span class="line">25 59 94 65 23</span><br><span class="line">45 27 73 25 39</span><br><span class="line">10</span><br></pre></td></tr></table></figure>
<p>   然后我们对每列进行排序：</p>
   <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10 14 73 25 23</span><br><span class="line">13 27 94 33 39</span><br><span class="line">25 59 94 65 82</span><br><span class="line">45</span><br></pre></td></tr></table></figure>
<p>   将上述四行数字，依序接在一起时我们得到：[ 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 ]。这时10已经移至正确位置了，然后再以3为步长进行排序：</p>
   <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10 14 73</span><br><span class="line">25 23 13</span><br><span class="line">27 94 33</span><br><span class="line">39 25 59</span><br><span class="line">94 65 82</span><br><span class="line">45</span><br></pre></td></tr></table></figure>
<p>   排序之后变为：<br>   <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">10 14 13</span><br><span class="line">25 23 33</span><br><span class="line">27 25 59</span><br><span class="line">39 65 73</span><br><span class="line">45 94 82</span><br><span class="line">94</span><br></pre></td></tr></table></figure><br>   最后以1步长进行排序（此时就是简单的插入排序了）</p>
<p>   <strong>希尔排序的分析</strong></p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/148.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shellSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="comment"># 初始步长</span></span><br><span class="line">    gap=<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span>(gap &lt; <span class="built_in">len</span>(arr)/<span class="number">3</span>):</span><br><span class="line">        gap = gap*<span class="number">3</span>+<span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 按步长进行划分</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(gap, n):</span><br><span class="line">            j = i</span><br><span class="line">            <span class="comment"># 对每列进行插入排序</span></span><br><span class="line">            <span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> arr[j - gap] &gt; arr[j]:</span><br><span class="line">                arr[j - gap], arr[j] = arr[j], arr[j - gap]</span><br><span class="line">                j -= gap</span><br><span class="line">        <span class="comment"># 得到新的步长</span></span><br><span class="line">        gap = gap // <span class="number">3</span></span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShellSort</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">shellSort</span><span class="params">(<span class="keyword">int</span>[] arr)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> gap = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (gap &lt; arr.length/<span class="number">3</span>) &#123;</span><br><span class="line">            gap = gap * <span class="number">3</span> + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(gap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=gap; i &lt; arr.length; i++)&#123;</span><br><span class="line">                <span class="keyword">int</span> tmp = arr[i];</span><br><span class="line">                <span class="keyword">int</span> j = i - gap;</span><br><span class="line">                <span class="keyword">while</span>(j &gt;= <span class="number">0</span> &amp;&amp; arr[j] &gt; tmp)&#123;</span><br><span class="line">                    arr[j+gap] = arr[j];</span><br><span class="line">                    j -= gap;</span><br><span class="line">                &#125;</span><br><span class="line">                arr[j+gap] = tmp;</span><br><span class="line">            &#125;</span><br><span class="line">            gap /= <span class="number">3</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        shellSort(arr);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="7-归并排序"><a href="#7-归并排序" class="headerlink" title="7.归并排序"></a>7.归并排序</h3><p>归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。</p>
<p>作为一种典型的分而治之思想的算法应用，归并排序的实现由两种方法：</p>
<ul>
<li>自上而下的递归（所有递归的方法都可以用迭代重写，所以就有了第 2 种方法）；</li>
<li>自下而上的迭代；</li>
</ul>
<p>在《数据结构与算法 JavaScript 描述》中，作者给出了自下而上的迭代方法。但是对于递归法，作者却认为：</p>
<blockquote>
<p>However, it is not possible to do so in JavaScript, as the recursion goes too deep for the language to handle.</p>
<p>然而，在 JavaScript 中这种方式不太可行，因为这个算法的递归深度对它来讲太深了。</p>
</blockquote>
<p>和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(nlogn) 的时间复杂度。代价是需要额外的内存空间。</p>
<blockquote>
<p>算法步骤</p>
</blockquote>
<ol>
<li>申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；</li>
<li>设定两个指针，最初位置分别为两个已经排序序列的起始位置；</li>
<li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；</li>
<li>重复步骤 3 直到某一指针达到序列尾；</li>
<li>将另一序列剩下的所有元素直接复制到合并序列尾。</li>
</ol>
<blockquote>
<p>动图演示</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/149.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mergeSort</span>(<span class="params">alist</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(alist) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> alist</span><br><span class="line">    <span class="comment"># 二分分解</span></span><br><span class="line">    num = <span class="built_in">len</span>(alist)//<span class="number">2</span></span><br><span class="line">    left = mergeSort(alist[:num])</span><br><span class="line">    right = mergeSort(alist[num:])</span><br><span class="line">    <span class="comment"># 合并</span></span><br><span class="line">    <span class="keyword">return</span> merge(left,right)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span>(<span class="params">left, right</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;合并操作，将两个有序数组left[]和right[]合并成一个大的有序数组&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment">#left与right的下标指针</span></span><br><span class="line">    l, r = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">while</span> l&lt;<span class="built_in">len</span>(left) <span class="keyword">and</span> r&lt;<span class="built_in">len</span>(right):</span><br><span class="line">        <span class="keyword">if</span> left[l] &lt;= right[r]:</span><br><span class="line">            result.append(left[l])</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(right[r])</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">    result += left[l:]</span><br><span class="line">    result += right[r:]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MergeSort</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] mergeSort(<span class="keyword">int</span>[] arr)&#123;</span><br><span class="line">        <span class="keyword">if</span> (arr.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> arr;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> middle = arr.length / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] left = mergeSort(Arrays.copyOfRange(arr, <span class="number">0</span>, middle));</span><br><span class="line">        <span class="keyword">int</span>[] right = mergeSort(Arrays.copyOfRange(arr, middle, arr.length));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> merge(left, right);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] merge(<span class="keyword">int</span>[] left, <span class="keyword">int</span>[] right) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[left.length + right.length];</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>, l = <span class="number">0</span>, r = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (l &lt; left.length &amp;&amp; r &lt; right.length) &#123;</span><br><span class="line">            <span class="keyword">if</span> (left[l] &lt;= right[r]) result[i++] = left[l++];</span><br><span class="line">            <span class="keyword">else</span> result[i++] = right[r++];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (l &lt; left.length) result[i++] = left[l++];</span><br><span class="line">        <span class="keyword">while</span> (r &lt; right.length) result[i++] = right[r++];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(mergeSort(arr)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="8-快速排序"><a href="#8-快速排序" class="headerlink" title="8.快速排序"></a>8.快速排序</h3><p>快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n2)  次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner  loop）可以在大部分的架构上很有效率地被实现出来。</p>
<p>快速排序使用分治法（Divide and conquer）策略来把一个串行（list）分为两个子串行（sub-lists）。</p>
<p>快速排序又是一种分而治之思想在排序算法上的典型应用。本质上来看，快速排序应该算是在冒泡排序基础上的递归分治法。</p>
<p>快速排序的名字起的是简单粗暴，因为一听到这个名字你就知道它存在的意义，就是快，而且效率高！它是处理大数据最快的排序算法之一了。虽然 Worst Case 的时间复杂度达到了 O(n²)，但是人家就是优秀，在大多数情况下都比平均时间复杂度为 O(nlogn)  的排序算法表现要更好：</p>
<blockquote>
<p>快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于  O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。</p>
<p>算法步骤</p>
</blockquote>
<ol>
<li>从数列中挑出一个元素，称为 “基准”（pivot）;</li>
<li>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；</li>
<li>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；</li>
</ol>
<p>递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会退出，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。</p>
<blockquote>
<p>动图演示</p>
</blockquote>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/150.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span>(<span class="params">alist, start, end</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;快速排序&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 递归的退出条件</span></span><br><span class="line">    <span class="keyword">if</span> start &gt;= end:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="comment"># 设定起始元素为要寻找位置的基准元素</span></span><br><span class="line">    mid = alist[start]</span><br><span class="line">    <span class="comment"># low为序列左边的由左向右移动的游标</span></span><br><span class="line">    low = start</span><br><span class="line">    <span class="comment"># high为序列右边的由右向左移动的游标</span></span><br><span class="line">    high = end</span><br><span class="line">    <span class="keyword">while</span> low &lt; high:</span><br><span class="line">        <span class="comment"># 如果low与high未重合，high指向的元素不比基准元素小，则high向左移动</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high <span class="keyword">and</span> alist[high] &gt;= mid:</span><br><span class="line">            high -= <span class="number">1</span></span><br><span class="line">        <span class="comment"># 将high指向的元素放到low的位置上</span></span><br><span class="line">        alist[low] = alist[high]</span><br><span class="line">        <span class="comment"># 如果low与high未重合，low指向的元素比基准元素小，则low向右移动</span></span><br><span class="line">        <span class="keyword">while</span> low &lt; high <span class="keyword">and</span> alist[low] &lt; mid:</span><br><span class="line">            low += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 将low指向的元素放到high的位置上</span></span><br><span class="line">        alist[high] = alist[low]</span><br><span class="line">    <span class="comment"># 退出循环后，low与high重合，此时所指位置为基准元素的正确位置</span></span><br><span class="line">    <span class="comment"># 将基准元素放到该位置</span></span><br><span class="line">    alist[low] = mid</span><br><span class="line">    <span class="comment"># 对基准元素左边的子序列进行快速排序</span></span><br><span class="line">    quick_sort(alist, start, low-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 对基准元素右边的子序列进行快速排序</span></span><br><span class="line">    quick_sort(alist, low+<span class="number">1</span>, end)</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">quickSort</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(start &gt;= end) <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">//设定基准</span></span><br><span class="line">        <span class="keyword">int</span> pivot = arr[start];</span><br><span class="line">        <span class="keyword">int</span> low = start;</span><br><span class="line">        <span class="keyword">int</span> high = end;</span><br><span class="line">        <span class="keyword">while</span>(low &lt; high)&#123;</span><br><span class="line">            <span class="keyword">while</span>(low &lt; high &amp;&amp; arr[high] &gt;= pivot) high--;</span><br><span class="line">            arr[low] = arr[high];</span><br><span class="line">            <span class="keyword">while</span>(low &lt; high &amp;&amp; arr[low] &lt;= pivot) low++;</span><br><span class="line">            arr[high] = arr[low];</span><br><span class="line">        &#125;</span><br><span class="line">        arr[low] = pivot;</span><br><span class="line">        quickSort(arr, start, low - <span class="number">1</span>);</span><br><span class="line">        quickSort(arr, low + <span class="number">1</span>, end);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">8</span>, <span class="number">7</span>, <span class="number">2</span> ,<span class="number">1</span>, <span class="number">9</span>&#125;;</span><br><span class="line">        <span class="keyword">new</span> QuickSort().quickSort(arr, <span class="number">0</span>, arr.length-<span class="number">1</span>);</span><br><span class="line">        System.out.println(Arrays.toString(arr));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//sout: [1, 2, 7, 8, 9]</span></span><br></pre></td></tr></table></figure>
<h3 id="9-堆排序"><a href="#9-堆排序" class="headerlink" title="9.堆排序"></a>9.堆排序</h3><p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法：</p>
<ol>
<li>大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；</li>
<li>小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；</li>
</ol>
<p>堆排序的平均时间复杂度为 Ο(nlogn)。</p>
<blockquote>
<p>算法步骤</p>
</blockquote>
<ol>
<li>将待排序序列构建成一个堆 H[0……n-1]，根据（升序降序需求）选择大顶堆或小顶堆；</li>
<li>把堆首（最大值）和堆尾互换；</li>
<li>把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置；</li>
<li>重复步骤 2，直到堆的尺寸为 1。</li>
</ol>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/151.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="comment">#大顶堆</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapify</span>(<span class="params">arr, i, length</span>):</span></span><br><span class="line">    left = <span class="number">2</span> * i + <span class="number">1</span></span><br><span class="line">    right = <span class="number">2</span> * i + <span class="number">2</span></span><br><span class="line">    maxIndex = i</span><br><span class="line">    <span class="keyword">if</span> left &lt; length <span class="keyword">and</span> arr[left] &gt; arr[maxIndex]:</span><br><span class="line">        maxIndex = left</span><br><span class="line">    <span class="keyword">if</span> right &lt; length <span class="keyword">and</span> arr[right] &gt; arr[maxIndex]:</span><br><span class="line">        maxIndex = right</span><br><span class="line">    <span class="keyword">if</span> maxIndex != i:</span><br><span class="line">        arr[i], arr[maxIndex] = arr[maxIndex], arr[i]</span><br><span class="line">        heapify(arr, maxIndex, length)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heapSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    n = <span class="built_in">len</span>(arr)</span><br><span class="line">    <span class="comment"># 初始化大顶堆</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr) // <span class="number">2</span> - <span class="number">1</span> , -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        heapify(arr, i, n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr) - <span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 根节点为最大</span></span><br><span class="line">        arr[<span class="number">0</span>], arr[i] =  arr[i], arr[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 换出根节点后 再对剩下的排序 最后形成升序</span></span><br><span class="line">        n -= <span class="number">1</span></span><br><span class="line">        heapify(arr, <span class="number">0</span>, n)</span><br><span class="line">    <span class="keyword">return</span> arr</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.PriorityQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.Queue;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HeapSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] heapSort(<span class="keyword">int</span>[] arr)&#123;</span><br><span class="line">        Queue&lt;Integer&gt; heap = <span class="keyword">new</span> PriorityQueue&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num: arr) heap.offer(num);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; arr.length; i++) arr[i] = heap.poll();</span><br><span class="line">        <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(heapSort(arr)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="10-计数排序"><a href="#10-计数排序" class="headerlink" title="10.计数排序"></a>10.计数排序</h3><p>计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。</p>
<blockquote>
<p>算法步骤</p>
</blockquote>
<ol>
<li>找出原数组中元素值最大的，记为max。</li>
<li>创建一个新数组count，其长度是max加1，其元素默认值都为0。</li>
<li>遍历原数组中的元素，以原数组中的元素作为count数组的索引，以原数组中的元素出现次数作为count数组的元素值。</li>
<li>创建结果数组result，起始索引index。</li>
<li>遍历count数组，找出其中元素值大于0的元素，将其对应的索引作为元素值填充到result数组中去，每处理一次，count中的该元素值减1，直到该元素值不大于0，依次处理count中剩下的元素。</li>
<li>返回结果数组result。</li>
</ol>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/152.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countingSort</span>(<span class="params">arr</span>):</span></span><br><span class="line">    maxLen = <span class="built_in">max</span>(arr) + <span class="number">1</span></span><br><span class="line">    count = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(maxLen)]</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arr:</span><br><span class="line">        count[i] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(maxLen):</span><br><span class="line">        <span class="keyword">while</span> count[i] &gt; <span class="number">0</span>:</span><br><span class="line">            result.append(i)</span><br><span class="line">            count[i] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountSort</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] countSort(<span class="keyword">int</span>[] arr)&#123;</span><br><span class="line">        <span class="keyword">if</span>(arr.length &lt; <span class="number">2</span>) <span class="keyword">return</span> arr;</span><br><span class="line">        <span class="keyword">int</span> maxValue = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : arr) maxValue=i &gt; maxValue?i: maxValue;</span><br><span class="line">        <span class="keyword">int</span>[] count = <span class="keyword">new</span> <span class="keyword">int</span>[maxValue+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : arr) count[i]++;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>, j=<span class="number">0</span>; i&lt;=maxValue; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(count[i]-- &gt; <span class="number">0</span>) res[j++]=i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(countSort(arr)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里有个问题：上述写法并不是稳定排序，因此这里做改进，稳定的计数排序如下：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CountSort</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] countSort(<span class="keyword">int</span>[] arr)&#123;</span><br><span class="line">        <span class="keyword">if</span>(arr.length &lt; <span class="number">2</span>) <span class="keyword">return</span> arr;</span><br><span class="line">        <span class="keyword">int</span> maxValue = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : arr) maxValue = i &gt; maxValue?i: maxValue;</span><br><span class="line">        <span class="keyword">int</span>[] count = <span class="keyword">new</span> <span class="keyword">int</span>[maxValue+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i : arr) count[i]++;</span><br><span class="line">        <span class="comment">//做累加，使桶中记录的为每个数的最后一个索引</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=maxValue; i++) count[i] = count[i] + count[i-<span class="number">1</span>];</span><br><span class="line">        <span class="comment">//逆序遍历，直接往相应索引填数，使得算法稳定</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=arr.length-<span class="number">1</span>; i&gt;=<span class="number">0</span>; i--)&#123;</span><br><span class="line">            res[--count[arr[i]]] = arr[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(countSort(arr)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="11-桶排序"><a href="#11-桶排序" class="headerlink" title="11.桶排序"></a>11.桶排序</h3><p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点：</p>
<ol>
<li>在额外空间充足的情况下，尽量增大桶的数量</li>
<li>使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中</li>
</ol>
<p>同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。</p>
<blockquote>
<p>什么时候最快</p>
</blockquote>
<p>当输入的数据可以均匀的分配到每一个桶中。 </p>
<blockquote>
<p>什么时候最慢</p>
</blockquote>
<p>当输入的数据被分配到了同一个桶中。</p>
<p><img src="https://yuanblog-1300912400.cos.ap-shanghai.myqcloud.com/img/leetcode_python/153.gif" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bucket_sort</span>(<span class="params">array, bucketSize=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="comment"># bucketSize设置每个桶的容量</span></span><br><span class="line">    maxValue = <span class="built_in">max</span>(array)</span><br><span class="line">    minValue = <span class="built_in">min</span>(array)</span><br><span class="line">    <span class="comment"># 1.创建空桶</span></span><br><span class="line">    bucketCount = (maxValue - minValue) // bucketSize + <span class="number">1</span></span><br><span class="line">    buckets = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(bucketCount)]</span><br><span class="line">    <span class="comment"># 2.利用映射函数将数据分配到各个桶中</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> array:</span><br><span class="line">        index = (<span class="built_in">int</span>)(data - minValue) // bucketSize</span><br><span class="line">        buckets[index].append(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.桶内排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bucketCount):</span><br><span class="line">        buckets[i].sort()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.产生新的排序后的列表</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bucketCount):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(buckets[i])):</span><br><span class="line">            array[index] = buckets[i][j]</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> array</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Java</span></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BucketSort</span> </span>&#123;</span><br><span class="line">    <span class="comment">//bucketSize用于设置每个桶的容量</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] bucketSort(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> bucketSize)&#123;</span><br><span class="line">        <span class="keyword">if</span> (arr.length == <span class="number">0</span>) <span class="keyword">return</span> arr;</span><br><span class="line">        <span class="comment">//得到数组中的最大，最小值</span></span><br><span class="line">        <span class="keyword">int</span> minValue = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> maxValue = arr[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> value : arr) &#123;</span><br><span class="line">            <span class="keyword">if</span> (value &lt; minValue) &#123;</span><br><span class="line">                minValue = value;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (value &gt; maxValue) &#123;</span><br><span class="line">                maxValue = value;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//多少个桶</span></span><br><span class="line">        <span class="keyword">int</span> bucketCount = (maxValue - minValue) / bucketSize + <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//创建空桶</span></span><br><span class="line">        List&lt;Integer&gt;[] buckets = <span class="keyword">new</span> List[bucketCount];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> value : arr) &#123;</span><br><span class="line">            <span class="comment">//映射函数，存放到相应桶中</span></span><br><span class="line">            <span class="keyword">int</span> index = (value - minValue) / bucketSize;</span><br><span class="line">            <span class="keyword">if</span>(buckets[index] == <span class="keyword">null</span>) buckets[index] = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">            buckets[index].add(value);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//对每个桶排序</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;Integer&gt; bucket : buckets) &#123;</span><br><span class="line">            <span class="comment">//桶不为空</span></span><br><span class="line">            <span class="keyword">if</span>(bucket != <span class="keyword">null</span>) Collections.sort(bucket);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//产生排序后的新列表</span></span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[arr.length];</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (List&lt;Integer&gt; bucket : buckets)&#123;</span><br><span class="line">            <span class="comment">//桶不为空</span></span><br><span class="line">            <span class="keyword">if</span>(bucket != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (Integer integer : bucket) &#123;</span><br><span class="line">                    res[index] = integer;</span><br><span class="line">                    index++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">8</span>, <span class="number">7</span>, <span class="number">2</span> ,<span class="number">1</span>, <span class="number">9</span>&#125;;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> BucketSort().bucketSort(arr, <span class="number">3</span>);</span><br><span class="line">        System.out.println(Arrays.toString(res));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
</search>
