<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://Qiyuan-Z.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="article">
<meta property="og:title" content="SSD代码解析">
<meta property="og:url" content="https://qiyuan-z.github.io/2020/04/23/SSD%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/index.html">
<meta property="og:site_name" content="Yuan">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/640.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/641.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/642.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/643.png">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/644.webp">
<meta property="article:published_time" content="2020-04-23T01:53:33.255Z">
<meta property="article:modified_time" content="2020-04-24T02:26:34.191Z">
<meta property="article:author" content="Qiyuan-Z">
<meta property="article:tag" content="目标检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/640.webp">

<link rel="canonical" href="https://qiyuan-z.github.io/2020/04/23/SSD%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style>
  <title>SSD代码解析 | Yuan</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yuan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">记录学习中的点点滴滴</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://qiyuan-z.github.io/2020/04/23/SSD%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/wallhaven-915.png">
      <meta itemprop="name" content="Qiyuan-Z">
      <meta itemprop="description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yuan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SSD代码解析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-04-23 09:53:33" itemprop="dateCreated datePublished" datetime="2020-04-23T09:53:33+08:00">2020-04-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-24 10:26:34" itemprop="dateModified" datetime="2020-04-24T10:26:34+08:00">2020-04-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>30k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>28 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a id="more"></a>前言</h2><p>本篇文章是在SSD算法原理解析的基础上做的代码解析，今天要解析的SSD源码来自于github一个非常火的Pytorch实现，已经有3K+星，地址为：<a href="https://github.com/amdegroot/ssd.pytorch/" target="_blank" rel="noopener">https://github.com/amdegroot/ssd.pytorch/</a></p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>为了比较好的对应SSD的结构来看代码，我们首先放出SSD的网络结构，如下图所示：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/640.webp" alt></p>
<p>可以看到原始的SSD网络是以VGG-16作Backbone（骨干网络）的。为了更加清晰看到相比于VGG16，SSD的网络使用了哪些变化，带有特征图维度信息的更清晰的骨干网络和VGG16的对比图如下：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/641.webp" alt></p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><p>OK，现在我们就要开始从源码剖析SSD了 。主要弄清楚三个方面，网络结构的搭建，Anchor还有损失函数，就算是理解这个源码了。</p>
<h3 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h3><p>从上面的图中我们可以清晰的看到在以VGG16做骨干网络时，在conv5后丢弃了VGG16中的全连接层改为了1024 x 3 x 3和1024 x 1 x 1 的卷积层。其中<code>conv4-1</code>卷积层前面的<code>maxpooling</code>层的<code>ceil_model=True</code>，使得输出特征图长宽为38 x 38。还有<code>conv5-3</code>后面的一层<code>maxpooling</code>层参数为$(\text {kernelsize}=3, \text {stride}=1, \text {padding}=1)$，不进行下采样。然后在<code>fc7</code>后面接上多尺度提取的另外4个卷积层就构成了完整的SSD网络。这里VGG16修改后的代码如下，来自ssd.py：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def vgg(cfg, i, batch_norm&#x3D;False):</span><br><span class="line">    layers &#x3D; []</span><br><span class="line">    in_channels &#x3D; i</span><br><span class="line">    for v in cfg:</span><br><span class="line">        if v &#x3D;&#x3D; &#39;M&#39;:</span><br><span class="line">            layers +&#x3D; [nn.MaxPool2d(kernel_size&#x3D;2, stride&#x3D;2)]</span><br><span class="line">        elif v &#x3D;&#x3D; &#39;C&#39;:</span><br><span class="line">            layers +&#x3D; [nn.MaxPool2d(kernel_size&#x3D;2, stride&#x3D;2, ceil_mode&#x3D;True)]</span><br><span class="line">        else:</span><br><span class="line">            conv2d &#x3D; nn.Conv2d(in_channels, v, kernel_size&#x3D;3, padding&#x3D;1)</span><br><span class="line">            if batch_norm:</span><br><span class="line">                layers +&#x3D; [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace&#x3D;True)]</span><br><span class="line">            else:</span><br><span class="line">                layers +&#x3D; [conv2d, nn.ReLU(inplace&#x3D;True)]</span><br><span class="line">            in_channels &#x3D; v</span><br><span class="line">    pool5 &#x3D; nn.MaxPool2d(kernel_size&#x3D;3, stride&#x3D;1, padding&#x3D;1)</span><br><span class="line">    conv6 &#x3D; nn.Conv2d(512, 1024, kernel_size&#x3D;3, padding&#x3D;6, dilation&#x3D;6)</span><br><span class="line">    conv7 &#x3D; nn.Conv2d(1024, 1024, kernel_size&#x3D;1)</span><br><span class="line">    layers +&#x3D; [pool5, conv6,</span><br><span class="line">               nn.ReLU(inplace&#x3D;True), conv7, nn.ReLU(inplace&#x3D;True)]</span><br><span class="line">    return layers</span><br></pre></td></tr></table></figure>
<p>可以看到和我们上面的那张图是完全一致的。代码里面最后获得的<code>conv7</code>就是我们上面图里面的<code>fc7</code>，特征维度是：$[\text { None }, 1024,19,19]$。现在可以开始搭建SSD网络后面的多尺度提取网络了。也就是网络结构图中的Extra Feature Layers。我们从开篇的结构图中截取一下这一部分，方便我们对照代码。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/642.webp" alt></p>
<p>实现的代码如下（同样来自ssd.py）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def add_extras(cfg, i, batch_norm&#x3D;False):</span><br><span class="line">    # Extra layers added to VGG for feature scaling</span><br><span class="line">    layers &#x3D; []</span><br><span class="line">    in_channels &#x3D; i</span><br><span class="line">    flag &#x3D; False #flag 用来控制 kernel_size&#x3D; 1 or 3</span><br><span class="line">    for k, v in enumerate(cfg):</span><br><span class="line">        if in_channels !&#x3D; &#39;S&#39;:</span><br><span class="line">            if v &#x3D;&#x3D; &#39;S&#39;:</span><br><span class="line">                layers +&#x3D; [nn.Conv2d(in_channels, cfg[k + 1],</span><br><span class="line">                           kernel_size&#x3D;(1, 3)[flag], stride&#x3D;2, padding&#x3D;1)]</span><br><span class="line">            else:</span><br><span class="line">                layers +&#x3D; [nn.Conv2d(in_channels, v, kernel_size&#x3D;(1, 3)[flag])]</span><br><span class="line">            flag &#x3D; not flag</span><br><span class="line">        in_channels &#x3D; v</span><br><span class="line">return layers</span><br></pre></td></tr></table></figure>
<p>可以看到网络结构中除了魔改后的VGG16和Extra  Layers还有6个横着的线，这代表的是对6个尺度的特征图进行卷积获得预测框的回归(loc)和类别(cls)信息，注意SSD将背景也看成类别了，所以对于VOC数据集类别数就是20+1=21。这部分的代码为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">def multibox(vgg, extra_layers, cfg, num_classes):</span><br><span class="line">    loc_layers &#x3D; []#多尺度分支的回归网络</span><br><span class="line">    conf_layers &#x3D; []#多尺度分支的分类网络</span><br><span class="line">    # 第一部分，vgg 网络的 Conv2d-4_3(21层)， Conv2d-7_1(-2层)</span><br><span class="line">    vgg_source &#x3D; [21, -2]</span><br><span class="line">    for k, v in enumerate(vgg_source):</span><br><span class="line">        # 回归 box*4(坐标)</span><br><span class="line">        loc_layers +&#x3D; [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">                                 cfg[k] * 4, kernel_size&#x3D;3, padding&#x3D;1)]</span><br><span class="line">        # 置信度 box*(num_classes)</span><br><span class="line">        conf_layers +&#x3D; [nn.Conv2d(vgg[v].out_channels,</span><br><span class="line">                        cfg[k] * num_classes, kernel_size&#x3D;3, padding&#x3D;1)]</span><br><span class="line">    # 第二部分，cfg从第三个开始作为box的个数，而且用于多尺度提取的网络分别为1,3,5,7层</span><br><span class="line">    for k, v in enumerate(extra_layers[1::2], 2):</span><br><span class="line">        loc_layers +&#x3D; [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">                                 * 4, kernel_size&#x3D;3, padding&#x3D;1)]</span><br><span class="line">        conf_layers +&#x3D; [nn.Conv2d(v.out_channels, cfg[k]</span><br><span class="line">                                  * num_classes, kernel_size&#x3D;3, padding&#x3D;1)]</span><br><span class="line">    return vgg, extra_layers, (loc_layers, conf_layers)</span><br><span class="line"># 用下面的测试代码测试一下</span><br><span class="line">if __name__  &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    vgg, extra_layers, (l, c) &#x3D; multibox(vgg(base[&#39;300&#39;], 3),</span><br><span class="line">                                         add_extras(extras[&#39;300&#39;], 1024),</span><br><span class="line">                                         [4, 6, 6, 6, 4, 4], 21)</span><br><span class="line">    print(nn.Sequential(*l))</span><br><span class="line">    print(&#39;---------------------------&#39;)</span><br><span class="line">    print(nn.Sequential(*c))</span><br></pre></td></tr></table></figure>
<p>在jupter notebook输出信息为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#39;&#39;&#39;</span><br><span class="line">loc layers:</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(512, 16, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (1): Conv2d(1024, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (2): Conv2d(512, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (3): Conv2d(256, 24, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (4): Conv2d(256, 16, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (5): Conv2d(256, 16, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">)</span><br><span class="line">---------------------------</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">conf layers:</span><br><span class="line">&#39;&#39;&#39;</span><br><span class="line">Sequential(</span><br><span class="line">  (0): Conv2d(512, 84, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (1): Conv2d(1024, 126, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (2): Conv2d(512, 126, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (3): Conv2d(256, 126, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (4): Conv2d(256, 84, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">  (5): Conv2d(256, 84, kernel_size&#x3D;(3, 3), stride&#x3D;(1, 1), padding&#x3D;(1, 1))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="Anchor生成-Prior-Box层"><a href="#Anchor生成-Prior-Box层" class="headerlink" title="Anchor生成(Prior_Box层)"></a>Anchor生成(Prior_Box层)</h3><p>这个在前面SSD的原理篇中讲过了，这里不妨再回忆一下，SSD从魔改后的VGG16的<code>conv4_3</code>开始一共使用了6个不同大小的特征图，大小分别为<code>(38,28),(19,19),(10,10),(5,5),(3,3),(1,1)</code>，但每个特征图上设置的先验框(Anchor)的数量不同。先验框的设置包含尺度和长宽比两个方面。对于先验框的设置，公式如下： $s_{k}=s_{\min }+\frac{s_{m a x}-s_{\min }}{m-1}(k-1), k \in[1, m]$，其中$m$指的是特征图个数，这里为5，因为第一层<code>conv4_3</code>的Anchor是单独设置的，$s_{k}$代表先验框大小相对于原图的比例。最后，$s_{min}$和$s_{max}$表示比例的最小值和最大值，论文中分别取0.2和0.9。对于第一个特征图，它的先验框尺度比例设置为$s_{min}/2=0.1$，则他的尺度为300 x 0.1 = 30，后面的特征图带入公式计算，计算时$\frac{s_{m a x}-s_{\min }}{m-1}$保留两位小数为0.17，比如300 x (0.17 x 0 + 0.2) = 60，300 x  (0.17 x 1 + 0.2) = 111，所以剩下的5个特征图的min_size尺度$s_{k}$为60，111，162，213，264。综合起来，6个特征图的min_size尺度$s_{k}$为30，60，111，162，213，264。有了Anchor的尺度，接下来设置Anchor的长宽，论文中长宽设置一般为$a_{r}=1,2,3, \frac{1}{2}, \frac{1}{3}$，根据面积和长宽比可以得到先验框的宽度和高度：$w_{k}^{a}=s_{k} \sqrt{a_{r}}, h_{k}^{a}=s_{k} / \sqrt{a_{r}}$ 。这里有一些值得注意的点，如下：</p>
<ul>
<li><p>上面的$s_{k}$是相对于原图的大小。</p>
</li>
<li><p>默认情况下，每个特征图除了上面5个比例的Anchor，还会设置一个尺度为$s_{k}^{\prime}=\sqrt{s_{k} s_{k+1}}$且$a_{r}=1$的先验框，这样每个特征图都设置了两个长宽比为1但大小不同的正方形先验框。最后一个特征图需要参考一个虚拟$s_{k+1}=300\times(0.17\times5 + 0.2) = 315$所以综合起来，6个特征图的max_size尺度$s_{k}$为60，111，162，213，264，315。</p>
</li>
<li><p>在实现<code>conv4_3</code>,<code>conv10_2</code>,<code>conv11_2</code>层时仅使用4个先验框，不使用长宽比为$3, \frac{1}{3}$的Anchor。</p>
</li>
<li><p>每个单元的先验框中心点分布在每个单元的中心，即：$\left[\frac{i+0.5}{\left|f_{k}\right|}, \frac{j+0.5}{\left|f_{k}\right|}\right], i, j \in\left[0,\left|f_{k}\right|\right]$ ，其中$f_{k}$是特征图的大小。</p>
</li>
</ul>
<p>从Anchor的值来看，越前面的特征图Anchor的尺寸越小，也就是说对小目标的效果越好。先验框的总数为<code>num_priors = 38x38x4+19x19x6+10x10x6+5x5x6+3x3x4+1x1x4=8732</code>。</p>
<p>生成先验框的代码如下（来自layers/functions/prior_box.py）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">class PriorBox(object):</span><br><span class="line">    &quot;&quot;&quot;Compute priorbox coordinates in center-offset form for each source</span><br><span class="line">    feature map.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, cfg):</span><br><span class="line">        super(PriorBox, self).__init__()</span><br><span class="line">        self.image_size &#x3D; cfg[&#39;min_dim&#39;]</span><br><span class="line">        # number of priors for feature map location (either 4 or 6)</span><br><span class="line">        self.num_priors &#x3D; len(cfg[&#39;aspect_ratios&#39;])</span><br><span class="line">        self.variance &#x3D; cfg[&#39;variance&#39;] or [0.1]</span><br><span class="line">        self.feature_maps &#x3D; cfg[&#39;feature_maps&#39;]</span><br><span class="line">        self.min_sizes &#x3D; cfg[&#39;min_sizes&#39;]</span><br><span class="line">        self.max_sizes &#x3D; cfg[&#39;max_sizes&#39;]</span><br><span class="line">        self.steps &#x3D; cfg[&#39;steps&#39;]</span><br><span class="line">        self.aspect_ratios &#x3D; cfg[&#39;aspect_ratios&#39;]</span><br><span class="line">        self.clip &#x3D; cfg[&#39;clip&#39;]</span><br><span class="line">        self.version &#x3D; cfg[&#39;name&#39;]</span><br><span class="line">        for v in self.variance:</span><br><span class="line">            if v &lt;&#x3D; 0:</span><br><span class="line">                raise ValueError(&#39;Variances must be greater than 0&#39;)</span><br><span class="line"></span><br><span class="line">    def forward(self):</span><br><span class="line">        mean &#x3D; []</span><br><span class="line">        # 遍历多尺度的 特征图: [38, 19, 10, 5, 3, 1]</span><br><span class="line">        for k, f in enumerate(self.feature_maps):</span><br><span class="line">            # 遍历每个像素</span><br><span class="line">            for i, j in product(range(f), repeat&#x3D;2):</span><br><span class="line">                # k-th 层的feature map 大小</span><br><span class="line">                f_k &#x3D; self.image_size &#x2F; self.steps[k]</span><br><span class="line">                # # 每个框的中心坐标</span><br><span class="line">                cx &#x3D; (j + 0.5) &#x2F; f_k</span><br><span class="line">                cy &#x3D; (i + 0.5) &#x2F; f_k</span><br><span class="line"></span><br><span class="line">                # aspect_ratio: 1 当 ratio&#x3D;&#x3D;1的时候，会产生两个 box</span><br><span class="line">                # r&#x3D;&#x3D;1, size &#x3D; s_k， 正方形</span><br><span class="line">                s_k &#x3D; self.min_sizes[k]&#x2F;self.image_size</span><br><span class="line">                mean +&#x3D; [cx, cy, s_k, s_k]</span><br><span class="line"></span><br><span class="line">                # r&#x3D;&#x3D;1, size &#x3D; sqrt(s_k * s_(k+1)), 正方形</span><br><span class="line">                # rel size: sqrt(s_k * s_(k+1))</span><br><span class="line">                s_k_prime &#x3D; sqrt(s_k * (self.max_sizes[k]&#x2F;self.image_size))</span><br><span class="line">                mean +&#x3D; [cx, cy, s_k_prime, s_k_prime]</span><br><span class="line"></span><br><span class="line">                # 当 ratio !&#x3D; 1 的时候，产生的box为矩形</span><br><span class="line">                for ar in self.aspect_ratios[k]:</span><br><span class="line">                    mean +&#x3D; [cx, cy, s_k*sqrt(ar), s_k&#x2F;sqrt(ar)]</span><br><span class="line">                    mean +&#x3D; [cx, cy, s_k&#x2F;sqrt(ar), s_k*sqrt(ar)]</span><br><span class="line">        # 转化为 torch的Tensor</span><br><span class="line">        output &#x3D; torch.Tensor(mean).view(-1, 4)</span><br><span class="line">        #归一化，把输出设置在 [0,1]</span><br><span class="line">        if self.clip:</span><br><span class="line">            output.clamp_(max&#x3D;1, min&#x3D;0)</span><br><span class="line">return output</span><br></pre></td></tr></table></figure>
<h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><p>结合了前面介绍的魔改后的VGG16，还有Extra Layers，还有生成Anchor的Priobox策略，我们可以写出SSD的整体结构如下（代码在ssd.py）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">class SSD(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;Single Shot Multibox Architecture</span><br><span class="line">    The network is composed of a base VGG network followed by the</span><br><span class="line">    added multibox conv layers.  Each multibox layer branches into</span><br><span class="line">        1) conv2d for class conf scores</span><br><span class="line">        2) conv2d for localization predictions</span><br><span class="line">        3) associated priorbox layer to produce default bounding</span><br><span class="line">           boxes specific to the layer&#39;s feature map size.</span><br><span class="line">    See: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1512.02325.pdf for more details.</span><br><span class="line">    Args:</span><br><span class="line">        phase: (string) Can be &quot;test&quot; or &quot;train&quot;</span><br><span class="line">        size: input image size</span><br><span class="line">        base: VGG16 layers for input, size of either 300 or 500</span><br><span class="line">        extras: extra layers that feed to multibox loc and conf layers</span><br><span class="line">        head: &quot;multibox head&quot; consists of loc and conf conv layers</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, phase, size, base, extras, head, num_classes):</span><br><span class="line">        super(SSD, self).__init__()</span><br><span class="line">        self.phase &#x3D; phase</span><br><span class="line">        self.num_classes &#x3D; num_classes</span><br><span class="line">        # 配置config</span><br><span class="line">        self.cfg &#x3D; (coco, voc)[num_classes &#x3D;&#x3D; 21]</span><br><span class="line">        # 初始化先验框</span><br><span class="line">        self.priorbox &#x3D; PriorBox(self.cfg)</span><br><span class="line">        self.priors &#x3D; Variable(self.priorbox.forward(), volatile&#x3D;True)</span><br><span class="line">        self.size &#x3D; size</span><br><span class="line"></span><br><span class="line">        # SSD network</span><br><span class="line">        # backbone网络</span><br><span class="line">        self.vgg &#x3D; nn.ModuleList(base)</span><br><span class="line">        # Layer learns to scale the l2 normalized features from conv4_3</span><br><span class="line">        # conv4_3后面的网络，L2 正则化</span><br><span class="line">        self.L2Norm &#x3D; L2Norm(512, 20)</span><br><span class="line">        self.extras &#x3D; nn.ModuleList(extras)</span><br><span class="line">        # 回归和分类网络</span><br><span class="line">        self.loc &#x3D; nn.ModuleList(head[0])</span><br><span class="line">        self.conf &#x3D; nn.ModuleList(head[1])</span><br><span class="line"></span><br><span class="line">        if phase &#x3D;&#x3D; &#39;test&#39;:</span><br><span class="line">            self.softmax &#x3D; nn.Softmax(dim&#x3D;-1)</span><br><span class="line">            self.detect &#x3D; Detect(num_classes, 0, 200, 0.01, 0.45)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        &quot;&quot;&quot;Applies network layers and ops on input image(s) x.</span><br><span class="line">        Args:</span><br><span class="line">            x: input image or batch of images. Shape: [batch,3,300,300].</span><br><span class="line">        Return:</span><br><span class="line">            Depending on phase:</span><br><span class="line">            test:</span><br><span class="line">                Variable(tensor) of output class label predictions,</span><br><span class="line">                confidence score, and corresponding location predictions for</span><br><span class="line">                each object detected. Shape: [batch,topk,7]</span><br><span class="line">            train:</span><br><span class="line">                list of concat outputs from:</span><br><span class="line">                    1: confidence layers, Shape: [batch*num_priors,num_classes]</span><br><span class="line">                    2: localization layers, Shape: [batch,num_priors*4]</span><br><span class="line">                    3: priorbox layers, Shape: [2,num_priors*4]</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        sources &#x3D; list()</span><br><span class="line">        loc &#x3D; list()</span><br><span class="line">        conf &#x3D; list()</span><br><span class="line"></span><br><span class="line">        # apply vgg up to conv4_3 relu</span><br><span class="line">        # vgg网络到conv4_3</span><br><span class="line">        for k in range(23):</span><br><span class="line">            x &#x3D; self.vgg[k](x)</span><br><span class="line">        # l2 正则化</span><br><span class="line">        s &#x3D; self.L2Norm(x)</span><br><span class="line">        sources.append(s)</span><br><span class="line"></span><br><span class="line">        # apply vgg up to fc7</span><br><span class="line">        # conv4_3 到 fc</span><br><span class="line">        for k in range(23, len(self.vgg)):</span><br><span class="line">            x &#x3D; self.vgg[k](x)</span><br><span class="line">        sources.append(x)</span><br><span class="line"></span><br><span class="line">        # apply extra layers and cache source layer outputs</span><br><span class="line">        # extras 网络</span><br><span class="line">        for k, v in enumerate(self.extras):</span><br><span class="line">            x &#x3D; F.relu(v(x), inplace&#x3D;True)</span><br><span class="line">            if k % 2 &#x3D;&#x3D; 1:</span><br><span class="line">                # 把需要进行多尺度的网络输出存入 sources</span><br><span class="line">                sources.append(x)</span><br><span class="line"></span><br><span class="line">        # apply multibox head to source layers</span><br><span class="line">        # 多尺度回归和分类网络</span><br><span class="line">        for (x, l, c) in zip(sources, self.loc, self.conf):</span><br><span class="line">            loc.append(l(x).permute(0, 2, 3, 1).contiguous())</span><br><span class="line">            conf.append(c(x).permute(0, 2, 3, 1).contiguous())</span><br><span class="line"></span><br><span class="line">        loc &#x3D; torch.cat([o.view(o.size(0), -1) for o in loc], 1)</span><br><span class="line">        conf &#x3D; torch.cat([o.view(o.size(0), -1) for o in conf], 1)</span><br><span class="line">        if self.phase &#x3D;&#x3D; &quot;test&quot;:</span><br><span class="line">            output &#x3D; self.detect(</span><br><span class="line">                loc.view(loc.size(0), -1, 4),                   # loc preds</span><br><span class="line">                self.softmax(conf.view(conf.size(0), -1,</span><br><span class="line">                             self.num_classes)),                # conf preds</span><br><span class="line">                self.priors.type(type(x.data))                  # default boxes</span><br><span class="line">            )</span><br><span class="line">        else:</span><br><span class="line">            output &#x3D; (</span><br><span class="line">                # loc的输出，size:(batch, 8732, 4)</span><br><span class="line">                loc.view(loc.size(0), -1, 4),</span><br><span class="line">                # conf的输出，size:(batch, 8732, 21)</span><br><span class="line">                conf.view(conf.size(0), -1, self.num_classes),</span><br><span class="line">                # 生成所有的候选框 size([8732, 4])</span><br><span class="line">                self.priors</span><br><span class="line">            )</span><br><span class="line">        return output</span><br><span class="line">    # 加载模型参数</span><br><span class="line">    def load_weights(self, base_file):</span><br><span class="line">        other, ext &#x3D; os.path.splitext(base_file)</span><br><span class="line">        if ext &#x3D;&#x3D; &#39;.pkl&#39; or &#39;.pth&#39;:</span><br><span class="line">            print(&#39;Loading weights into state dict...&#39;)</span><br><span class="line">            self.load_state_dict(torch.load(base_file,</span><br><span class="line">                                 map_location&#x3D;lambda storage, loc: storage))</span><br><span class="line">            print(&#39;Finished!&#39;)</span><br><span class="line">        else:</span><br><span class="line">			print(&#39;Sorry only .pth and .pkl files supported.&#39;)</span><br></pre></td></tr></table></figure>
<p>然后为了增加可读性，重新封装了一下，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">base &#x3D; &#123;</span><br><span class="line">    &#39;300&#39;: [64, 64, &#39;M&#39;, 128, 128, &#39;M&#39;, 256, 256, 256, &#39;C&#39;, 512, 512, 512, &#39;M&#39;,</span><br><span class="line">            512, 512, 512],</span><br><span class="line">    &#39;512&#39;: [],</span><br><span class="line">&#125;</span><br><span class="line">extras &#x3D; &#123;</span><br><span class="line">    &#39;300&#39;: [256, &#39;S&#39;, 512, 128, &#39;S&#39;, 256, 128, 256, 128, 256],</span><br><span class="line">    &#39;512&#39;: [],</span><br><span class="line">&#125;</span><br><span class="line">mbox &#x3D; &#123;</span><br><span class="line">    &#39;300&#39;: [4, 6, 6, 6, 4, 4],  # number of boxes per feature map location</span><br><span class="line">    &#39;512&#39;: [],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def build_ssd(phase, size&#x3D;300, num_classes&#x3D;21):</span><br><span class="line">    if phase !&#x3D; &quot;test&quot; and phase !&#x3D; &quot;train&quot;:</span><br><span class="line">        print(&quot;ERROR: Phase: &quot; + phase + &quot; not recognized&quot;)</span><br><span class="line">        return</span><br><span class="line">    if size !&#x3D; 300:</span><br><span class="line">        print(&quot;ERROR: You specified size &quot; + repr(size) + &quot;. However, &quot; +</span><br><span class="line">              &quot;currently only SSD300 (size&#x3D;300) is supported!&quot;)</span><br><span class="line">        return</span><br><span class="line">    # 调用multibox，生成vgg,extras,head</span><br><span class="line">    base_, extras_, head_ &#x3D; multibox(vgg(base[str(size)], 3),</span><br><span class="line">                                     add_extras(extras[str(size)], 1024),</span><br><span class="line">                                     mbox[str(size)], num_classes)</span><br><span class="line">	return SSD(phase, size, base_, extras_, head_, num_classes)</span><br></pre></td></tr></table></figure>
<h3 id="Loss解析"><a href="#Loss解析" class="headerlink" title="Loss解析"></a>Loss解析</h3><p>SSD的损失函数包含两个部分，一个是定位损失$L_{l o c}$，一个是分类损失$L_{conf}$，整个损失函数表达如下：$L(x, c, l, g)=\frac{1}{N}\left(L_{c o n f}(x, c)+\alpha L_{l o c}(x, l, g)\right)$ 其中，$N$是先验框的正样本数量，$c$是类别置信度预测值，$l$是先验框对应的边界框预测值，$g$是ground truth的位置参数，$x$代表网络的预测值。对于位置损失，采用Smooth L1 Loss，位置信息都是<code>encode</code>之后的数值，后面会讲这个encode的过程。而对于分类损失，首先需要使用<code>hard negtive mining</code>将正负样本按照<code>1:3</code> 的比例把负样本抽样出来，抽样的方法是：针对所有batch的confidence，按照置信度误差进行降序排列，取出前<code>top_k</code>个负样本。损失函数可以用下图表示：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/643.png" alt></p>
<h4 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h4><ul>
<li>Reshape所有batch中的conf，即代码中的<code>batch_conf = conf_data.view(-1, self.num_classes)</code>，方便后续排序。</li>
<li>置信度误差越大，实际上就是预测背景的置信度越小。</li>
<li>把所有conf进行<code>logsoftmax</code>处理(均为负值)，预测的置信度越小，则<code>logsoftmax</code>越小，取绝对值，则<code>|logsoftmax|</code>越大，降序排列<code>-logsoftmax</code>，取前<code>top_k</code>的负样本。其中，log_sum_exp函数的代码如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def log_sum_exp(x):</span><br><span class="line">    x_max &#x3D; x.detach().max()</span><br><span class="line">    return torch.log(torch.sum(torch.exp(x-x_max), 1, keepdim&#x3D;True))+x_max</span><br></pre></td></tr></table></figure>
<p>分类损失<code>conf_logP</code>函数如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf_logP &#x3D; log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1, 1))</span><br></pre></td></tr></table></figure>
<p>这样计算的原因主要是为了增强<code>logsoftmax</code>损失的数值稳定性。放一张手推图：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ssd%20code/644.webp" alt></p>
<p>损失函数完整代码实现，来自<code>layers/modules/multibox_loss.py</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line">class MultiBoxLoss(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;SSD Weighted Loss Function</span><br><span class="line">    Compute Targets:</span><br><span class="line">        1) Produce Confidence Target Indices by matching  ground truth boxes</span><br><span class="line">           with (default) &#39;priorboxes&#39; that have jaccard index &gt; threshold parameter</span><br><span class="line">           (default threshold: 0.5).</span><br><span class="line">        2) Produce localization target by &#39;encoding&#39; variance into offsets of ground</span><br><span class="line">           truth boxes and their matched  &#39;priorboxes&#39;.</span><br><span class="line">        3) Hard negative mining to filter the excessive number of negative examples</span><br><span class="line">           that comes with using a large number of default bounding boxes.</span><br><span class="line">           (default negative:positive ratio 3:1)</span><br><span class="line">    Objective Loss:</span><br><span class="line">        L(x,c,l,g) &#x3D; (Lconf(x, c) + αLloc(x,l,g)) &#x2F; N</span><br><span class="line">        Where, Lconf is the CrossEntropy Loss and Lloc is the SmoothL1 Loss</span><br><span class="line">        weighted by α which is set to 1 by cross val.</span><br><span class="line">        Args:</span><br><span class="line">            c: class confidences,</span><br><span class="line">            l: predicted boxes,</span><br><span class="line">            g: ground truth boxes</span><br><span class="line">            N: number of matched default boxes</span><br><span class="line">        See: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1512.02325.pdf for more details.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    def __init__(self, num_classes, overlap_thresh, prior_for_matching,</span><br><span class="line">                 bkg_label, neg_mining, neg_pos, neg_overlap, encode_target,</span><br><span class="line">                 use_gpu&#x3D;True):</span><br><span class="line">        super(MultiBoxLoss, self).__init__()</span><br><span class="line">        self.use_gpu &#x3D; use_gpu</span><br><span class="line">        self.num_classes &#x3D; num_classes</span><br><span class="line">        self.threshold &#x3D; overlap_thresh</span><br><span class="line">        self.background_label &#x3D; bkg_label</span><br><span class="line">        self.encode_target &#x3D; encode_target</span><br><span class="line">        self.use_prior_for_matching &#x3D; prior_for_matching</span><br><span class="line">        self.do_neg_mining &#x3D; neg_mining</span><br><span class="line">        self.negpos_ratio &#x3D; neg_pos</span><br><span class="line">        self.neg_overlap &#x3D; neg_overlap</span><br><span class="line">        self.variance &#x3D; cfg[&#39;variance&#39;]</span><br><span class="line"></span><br><span class="line">    def forward(self, predictions, targets):</span><br><span class="line">        &quot;&quot;&quot;Multibox Loss</span><br><span class="line">        Args:</span><br><span class="line">            predictions (tuple): A tuple containing loc preds, conf preds,</span><br><span class="line">            and prior boxes from SSD net.</span><br><span class="line">                conf shape: torch.size(batch_size,num_priors,num_classes)</span><br><span class="line">                loc shape: torch.size(batch_size,num_priors,4)</span><br><span class="line">                priors shape: torch.size(num_priors,4)</span><br><span class="line">            targets (tensor): Ground truth boxes and labels for a batch,</span><br><span class="line">                shape: [batch_size,num_objs,5] (last idx is the label).</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        loc_data, conf_data, priors &#x3D; predictions</span><br><span class="line">        num &#x3D; loc_data.size(0)# batch_size</span><br><span class="line">        priors &#x3D; priors[:loc_data.size(1), :]</span><br><span class="line">        num_priors &#x3D; (priors.size(0)) # 先验框个数</span><br><span class="line">        num_classes &#x3D; self.num_classes #类别数</span><br><span class="line"></span><br><span class="line">        # match priors (default boxes) and ground truth boxes</span><br><span class="line">        # 获取匹配每个prior box的 ground truth</span><br><span class="line">        # 创建 loc_t 和 conf_t 保存真实box的位置和类别</span><br><span class="line">        loc_t &#x3D; torch.Tensor(num, num_priors, 4)</span><br><span class="line">        conf_t &#x3D; torch.LongTensor(num, num_priors)</span><br><span class="line">        for idx in range(num):</span><br><span class="line">            truths &#x3D; targets[idx][:, :-1].data #ground truth box信息</span><br><span class="line">            labels &#x3D; targets[idx][:, -1].data # ground truth conf信息</span><br><span class="line">            defaults &#x3D; priors.data # priors的 box 信息</span><br><span class="line">            # 匹配 ground truth</span><br><span class="line">            match(self.threshold, truths, defaults, self.variance, labels,</span><br><span class="line">                  loc_t, conf_t, idx)</span><br><span class="line">        if self.use_gpu:</span><br><span class="line">            loc_t &#x3D; loc_t.cuda()</span><br><span class="line">            conf_t &#x3D; conf_t.cuda()</span><br><span class="line">        # wrap targets</span><br><span class="line">        loc_t &#x3D; Variable(loc_t, requires_grad&#x3D;False)</span><br><span class="line">        conf_t &#x3D; Variable(conf_t, requires_grad&#x3D;False)</span><br><span class="line">        # 匹配中所有的正样本mask,shape[b,M]</span><br><span class="line">        pos &#x3D; conf_t &gt; 0</span><br><span class="line">        num_pos &#x3D; pos.sum(dim&#x3D;1, keepdim&#x3D;True)</span><br><span class="line">        # Localization Loss,使用 Smooth L1</span><br><span class="line">        # shape[b,M]--&gt;shape[b,M,4]</span><br><span class="line">        pos_idx &#x3D; pos.unsqueeze(pos.dim()).expand_as(loc_data)</span><br><span class="line">        loc_p &#x3D; loc_data[pos_idx].view(-1, 4) #预测的正样本box信息</span><br><span class="line">        loc_t &#x3D; loc_t[pos_idx].view(-1, 4) #真实的正样本box信息</span><br><span class="line">        loss_l &#x3D; F.smooth_l1_loss(loc_p, loc_t, size_average&#x3D;False) #Smooth L1 损失</span><br><span class="line">		</span><br><span class="line">		&#39;&#39;&#39;</span><br><span class="line">        Target；</span><br><span class="line">            下面进行hard negative mining</span><br><span class="line">        过程:</span><br><span class="line">            1、 针对所有batch的conf，按照置信度误差(预测背景的置信度越小，误差越大)进行降序排列;</span><br><span class="line">            2、 负样本的label全是背景，那么利用log softmax 计算出logP,</span><br><span class="line">               logP越大，则背景概率越低,误差越大;</span><br><span class="line">            3、 选取误差较大的top_k作为负样本，保证正负样本比例接近1:3;</span><br><span class="line">        &#39;&#39;&#39;</span><br><span class="line">        # Compute max conf across batch for hard negative mining</span><br><span class="line">        # shape[b*M,num_classes]</span><br><span class="line">        batch_conf &#x3D; conf_data.view(-1, self.num_classes)</span><br><span class="line">        # 使用logsoftmax，计算置信度,shape[b*M, 1]</span><br><span class="line">        loss_c &#x3D; log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1, 1))</span><br><span class="line"></span><br><span class="line">        # Hard Negative Mining</span><br><span class="line">        loss_c[pos] &#x3D; 0  # 把正样本排除，剩下的就全是负样本，可以进行抽样</span><br><span class="line">        loss_c &#x3D; loss_c.view(num, -1)# shape[b, M]</span><br><span class="line">        # 难预测的损失大</span><br><span class="line">        # 两次sort排序，能够得到每个元素在降序排列中的位置idx_rank</span><br><span class="line">        # 即得到原Tensor的元素按dim指定维度，排第几，索引变成了排名</span><br><span class="line">        # 比如[4, 9, 7, 8, 5]</span><br><span class="line">        # 第一次sort排序结果为[9,8,7,5,4] 对应索引为[1,3,2,4,0]</span><br><span class="line">        # 第二次sort排序结果为[0,1,2,3,4] 对应索引为[4,0,2,1,3]</span><br><span class="line">        # 即第一排的元素9，它是第一排（也就是按dim&#x3D;1看）里面最大的，所以它的排名是0，原Tensor第一排的元素4，它是第一排里面最小的，所以它的排名是4</span><br><span class="line">        _, loss_idx &#x3D; loss_c.sort(1, descending&#x3D;True) </span><br><span class="line">        _, idx_rank &#x3D; loss_idx.sort(1) </span><br><span class="line">        # 抽取负样本</span><br><span class="line">        # 每个batch中正样本的数目，shape[b,1]</span><br><span class="line">        num_pos &#x3D; pos.long().sum(1, keepdim&#x3D;True)</span><br><span class="line">        num_neg &#x3D; torch.clamp(self.negpos_ratio*num_pos, max&#x3D;pos.size(1)-1)</span><br><span class="line">        # 小于num_neg为True，限制负样本的数量，shape[b, M]</span><br><span class="line">        # 排名靠前的留下</span><br><span class="line">        neg &#x3D; idx_rank &lt; num_neg.expand_as(idx_rank)</span><br><span class="line"></span><br><span class="line">        # Confidence Loss Including Positive and Negative Examples</span><br><span class="line">        # shape[b,M] --&gt; shape[b,M,num_classes]</span><br><span class="line">        pos_idx &#x3D; pos.unsqueeze(2).expand_as(conf_data)</span><br><span class="line">        neg_idx &#x3D; neg.unsqueeze(2).expand_as(conf_data)</span><br><span class="line">        # 提取出所有筛选好的正负样本(预测的和真实的)</span><br><span class="line">        conf_p &#x3D; conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)</span><br><span class="line">        targets_weighted &#x3D; conf_t[(pos+neg).gt(0)]</span><br><span class="line">        # 计算conf交叉熵</span><br><span class="line">        loss_c &#x3D; F.cross_entropy(conf_p, targets_weighted, size_average&#x3D;False)</span><br><span class="line"></span><br><span class="line">        # Sum of losses: L(x,c,l,g) &#x3D; (Lconf(x, c) + αLloc(x,l,g)) &#x2F; N</span><br><span class="line">		# 正样本个数</span><br><span class="line">        N &#x3D; num_pos.data.sum()</span><br><span class="line">        loss_l &#x2F;&#x3D; N</span><br><span class="line">        loss_c &#x2F;&#x3D; N</span><br><span class="line">		return loss_l, loss_c</span><br></pre></td></tr></table></figure>
<h4 id="先验框匹配策略"><a href="#先验框匹配策略" class="headerlink" title="先验框匹配策略"></a>先验框匹配策略</h4><p>上面的代码中还有一个地方没讲到，就是match函数。这是SSD算法的先验框匹配函数。在训练时首先需要确定训练图片中的ground truth是由哪一个先验框来匹配，与之匹配的先验框所对应的边界框将负责预测它。SSD的先验框和ground  truth匹配原则主要有2点。第一点是对于图片中的每个ground  truth，找到和它IOU最大的先验框，该先验框与其匹配，这样可以保证每个ground  truth一定与某个prior匹配。第二点是对于剩余的未匹配的先验框，若某个ground  truth和它的IOU大于某个阈值(一般设为0.5)，那么该prior和这个ground  truth匹配，剩下没有匹配上的先验框都是负样本（如果多个ground  truth和某一个先验框的IOU均大于阈值，那么prior只与IOU最大的那个进行匹配）。代码实现如下，来自<code>layers/box_utils.py</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx):</span><br><span class="line">    &quot;&quot;&quot;把和每个prior box 有最大的IOU的ground truth box进行匹配，</span><br><span class="line">    同时，编码包围框，返回匹配的索引，对应的置信度和位置</span><br><span class="line">    Args:</span><br><span class="line">        threshold: IOU阈值，小于阈值设为背景</span><br><span class="line">        truths: ground truth boxes, shape[N,4]</span><br><span class="line">        priors: 先验框， shape[M,4]</span><br><span class="line">        variances: prior的方差, list(float)</span><br><span class="line">        labels: 图片的所有类别，shape[num_obj]</span><br><span class="line">        loc_t: 用于填充encoded loc 目标张量</span><br><span class="line">        conf_t: 用于填充encoded conf 目标张量</span><br><span class="line">        idx: 现在的batch index</span><br><span class="line">        The matched indices corresponding to 1)location and 2)confidence preds.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # jaccard index</span><br><span class="line">    # 计算IOU</span><br><span class="line">    overlaps &#x3D; jaccard(</span><br><span class="line">        truths,</span><br><span class="line">        point_form(priors)</span><br><span class="line">    )</span><br><span class="line">    # (Bipartite Matching)</span><br><span class="line">    # [1,num_objects] 和每个ground truth box 交集最大的 prior box</span><br><span class="line">    best_prior_overlap, best_prior_idx &#x3D; overlaps.max(1, keepdim&#x3D;True)</span><br><span class="line">    # [1,num_priors] 和每个prior box 交集最大的 ground truth box</span><br><span class="line">    best_truth_overlap, best_truth_idx &#x3D; overlaps.max(0, keepdim&#x3D;True)</span><br><span class="line">    best_truth_idx.squeeze_(0) #M</span><br><span class="line">    best_truth_overlap.squeeze_(0) #M</span><br><span class="line">    best_prior_idx.squeeze_(1) #N</span><br><span class="line">    best_prior_overlap.squeeze_(1) #N</span><br><span class="line">    # 保证每个ground truth box 与某一个prior box 匹配，固定值为 2 &gt; threshold</span><br><span class="line">    best_truth_overlap.index_fill_(0, best_prior_idx, 2)  # ensure best prior</span><br><span class="line">    # TODO refactor: index  best_prior_idx with long tensor</span><br><span class="line">    # ensure every gt matches with its prior of max overlap</span><br><span class="line">    # 保证每一个ground truth 匹配它的都是具有最大IOU的prior</span><br><span class="line">    # 根据 best_prior_dix 锁定 best_truth_idx里面的最大IOU prior</span><br><span class="line">    for j in range(best_prior_idx.size(0)):</span><br><span class="line">        best_truth_idx[best_prior_idx[j]] &#x3D; j</span><br><span class="line">    matches &#x3D; truths[best_truth_idx]          # 提取出所有匹配的ground truth box, Shape: [M,4]</span><br><span class="line">    conf &#x3D; labels[best_truth_idx] + 1         # 提取出所有GT框的类别， Shape:[M]</span><br><span class="line">    # 把 iou &lt; threshold 的框类别设置为 bg,即为0</span><br><span class="line">    conf[best_truth_overlap &lt; threshold] &#x3D; 0  # label as background</span><br><span class="line">    # 编码包围框</span><br><span class="line">    loc &#x3D; encode(matches, priors, variances)</span><br><span class="line">    # 保存匹配好的loc和conf到loc_t和conf_t中</span><br><span class="line">    loc_t[idx] &#x3D; loc    # [num_priors,4] encoded offsets to learn</span><br><span class="line">    conf_t[idx] &#x3D; conf  # [num_priors] top class label for each prior</span><br></pre></td></tr></table></figure>
<h3 id="位置坐标转换"><a href="#位置坐标转换" class="headerlink" title="位置坐标转换"></a>位置坐标转换</h3><p>我们看到上面出现了一个point_form函数，这是什么意思呢？这是因为目标框有2种表示方式：</p>
<ul>
<li>$\left(x_{\min }, y_{\min }, x_{\max }, y_{\max }\right)$</li>
<li>$(x, y, w, h)$这部分的代码在<code>layers/box_utils.py</code>下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def point_form(boxes):</span><br><span class="line">    &quot;&quot;&quot; Convert prior_boxes to (xmin, ymin, xmax, ymax)</span><br><span class="line">   把 prior_box (cx, cy, w, h)转化为(xmin, ymin, xmax, ymax)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return torch.cat((boxes[:, :2] - boxes[:, 2:]&#x2F;2,     # xmin, ymin</span><br><span class="line">                     boxes[:, :2] + boxes[:, 2:]&#x2F;2), 1)  # xmax, ymax</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def center_size(boxes):</span><br><span class="line">    &quot;&quot;&quot; Convert prior_boxes to (cx, cy, w, h)</span><br><span class="line">    把 prior_box (xmin, ymin, xmax, ymax) 转化为 (cx, cy, w, h)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    return torch.cat((boxes[:, 2:] + boxes[:, :2])&#x2F;2,  # cx, cy</span><br><span class="line">                            boxes[:, 2:] - boxes[:, :2], 1) # w, h</span><br></pre></td></tr></table></figure>
<h3 id="IOU计算"><a href="#IOU计算" class="headerlink" title="IOU计算"></a>IOU计算</h3><p>这部分比较简单，对于两个Box来讲，首先计算两个box左上角点坐标的最大值和右下角坐标的最小值，然后计算交集面积，最后把交集面积除以对应的并集面积。代码仍在<code>layers/box_utils.py</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">def intersect(box_a, box_b):</span><br><span class="line">    &quot;&quot;&quot; We resize both tensors to [A,B,2] without new malloc:</span><br><span class="line">    [A,2] -&gt; [A,1,2] -&gt; [A,B,2]</span><br><span class="line">    [B,2] -&gt; [1,B,2] -&gt; [A,B,2]</span><br><span class="line">    Then we compute the area of intersect between box_a and box_b.</span><br><span class="line">    Args:</span><br><span class="line">      box_a: (tensor) bounding boxes, Shape: [A,4].</span><br><span class="line">      box_b: (tensor) bounding boxes, Shape: [B,4].</span><br><span class="line">    Return:</span><br><span class="line">      (tensor) intersection area, Shape: [A,B].</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    A &#x3D; box_a.size(0)</span><br><span class="line">    B &#x3D; box_b.size(0)</span><br><span class="line">     # 右下角，选出最小值</span><br><span class="line">    max_xy &#x3D; torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),</span><br><span class="line">                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))</span><br><span class="line">    # 左上角，选出最大值</span><br><span class="line">    min_xy &#x3D; torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),</span><br><span class="line">                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))</span><br><span class="line">    # 负数用0截断，为0代表交集为0</span><br><span class="line">    inter &#x3D; torch.clamp((max_xy - min_xy), min&#x3D;0)</span><br><span class="line">    return inter[:, :, 0] * inter[:, :, 1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def jaccard(box_a, box_b):</span><br><span class="line">    &quot;&quot;&quot;Compute the jaccard overlap of two sets of boxes.  The jaccard overlap</span><br><span class="line">    is simply the intersection over union of two boxes.  Here we operate on</span><br><span class="line">    ground truth boxes and default boxes.</span><br><span class="line">    E.g.:</span><br><span class="line">        A ∩ B &#x2F; A ∪ B &#x3D; A ∩ B &#x2F; (area(A) + area(B) - A ∩ B)</span><br><span class="line">    Args:</span><br><span class="line">        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]</span><br><span class="line">        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]</span><br><span class="line">    Return:</span><br><span class="line">        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    inter &#x3D; intersect(box_a, box_b)# A∩B</span><br><span class="line">     # box_a和box_b的面积</span><br><span class="line">    area_a &#x3D; ((box_a[:, 2]-box_a[:, 0]) *</span><br><span class="line">              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]#(N,)</span><br><span class="line">    area_b &#x3D; ((box_b[:, 2]-box_b[:, 0]) *</span><br><span class="line">              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]#(M,)</span><br><span class="line">    union &#x3D; area_a + area_b - inter</span><br><span class="line">    return inter &#x2F; union  # [A,B]</span><br></pre></td></tr></table></figure>
<h3 id="L2标准化"><a href="#L2标准化" class="headerlink" title="L2标准化"></a>L2标准化</h3><p>VGG16的<code>conv4_3</code>特征图的大小为38 x 38，网络层靠前，方差比较大，需要加一个L2标准化，以保证和后面的检测层差异不是很大。L2标准化的公式如下：$\hat{x}=\frac{x}{|x|^{2}}$ ，其中$x=\left(x_{1} \ldots x_{d}\right)|x|_{2}=\left(\sum_{i=1}^{d}\left|x_{i}\right|^{2}\right)^{1 / 2}$。同时，这里还要注意的是如果简单的对一个layer的输入进行L2标准化就会改变该层的规模，并且会减慢学习速度，因此这里引入了一个缩放系数$\gamma_{i}$ ，对于每一个通道l2标准化后的结果为：$y_{i}=\gamma_{i} \hat{x}_{i}$ ，通常的值设10或者20，效果比较好。代码来自layers/modules/l2norm.py。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class L2Norm(nn.Module):</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    conv4_3特征图大小38x38，网络层靠前，norm较大，需要加一个L2 Normalization,以保证和后面的检测层差异不是很大，具体可以参考：ParseNet。这个前面的推文里面有讲。</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    def __init__(self, n_channels, scale):</span><br><span class="line">        super(L2Norm, self).__init__()</span><br><span class="line">        self.n_channels &#x3D; n_channels</span><br><span class="line">        self.gamma &#x3D; scale or None</span><br><span class="line">        self.eps &#x3D; 1e-10</span><br><span class="line">        # 将一个不可训练的类型Tensor转换成可以训练的类型 parameter</span><br><span class="line">        self.weight &#x3D; nn.Parameter(torch.Tensor(self.n_channels))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    # 初始化参数</span><br><span class="line">    def reset_parameters(self):</span><br><span class="line">        nn.init.constant_(self.weight, self.gamma)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        # 计算x的2范数</span><br><span class="line">        norm &#x3D; x.pow(2).sum(dim&#x3D;1, keepdim&#x3D;True).sqrt()+self.eps # shape[b,1,38,38]</span><br><span class="line">        x &#x3D; torch.div(x,norm)   # shape[b,512,38,38]</span><br><span class="line"></span><br><span class="line">        # 扩展self.weight的维度为shape[1,512,1,1]，然后参考公式计算</span><br><span class="line">        out &#x3D; self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x) * x</span><br><span class="line">        return out</span><br></pre></td></tr></table></figure>
<h3 id="位置信息编解码"><a href="#位置信息编解码" class="headerlink" title="位置信息编解码"></a>位置信息编解码</h3><p>上面提到了计算坐标损失的时候，坐标是<code>encoding</code>之后的，这是怎么回事呢？根据论文的描述，预测框和ground truth边界框存在一个转换关系，先定义一些变量：</p>
<ul>
<li><p>先验框位置：$d=\left(d^{c x}, d^{c y}, d^{w}, d^{h}\right)$</p>
</li>
<li><p>ground truth框位置：$g=\left(g^{c x}, g^{c y}, g^{w}, g^{h}\right)$</p>
</li>
<li><p>variance是先验框的坐标方差。然后<strong>编码</strong>的过程可以表示为：$g_{j}^{\hat{c} x}=\left(g_{j}^{c x}-d_{i}^{c x}\right) / d_{i}^{w} /$varicance[0]，$g_{j}^{\hat{c} y}=\left(g_{j}^{c y}-d_{i}^{c y}\right) / d_{i}^{h} /$varicance[1]，$g_{j}^{\hat{w}}=\log \left(\frac{g_{j}^{w}}{d_{i}^{w}}\right) /$variance[2]，$g_{j}^{\hat{h}}=\log \left(\frac{g_{j}^{h}}{d_{i}^{h}}\right) /$variance[3]</p>
</li>
</ul>
<p><strong>解码</strong>的过程可以表示为：$g_{\text {predict}}^{c x}=d^{w} <em>\left(\text {variance}[0] </em> l^{c x}\right)+d^{c x}$，$g_{\text {predict}}^{c y}=d^{h} <em>\left(\text {variance}[1] </em> l^{c y}\right)+d^{c y}$，$g_{\text {predict}}^{w}=d^{w} \exp \left(\text {vairance}[2] <em> l^{w}\right)$，$g_{\text {predict}}^{h}=d^{h} \exp \left(\text {vairance}[3] </em> l^{h}\right)$</p>
<p>这部分对应的代码在<code>layers/box_utils.py</code>里面：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">def encode(matched, priors, variances):</span><br><span class="line">    &quot;&quot;&quot;Encode the variances from the priorbox layers into the ground truth boxes</span><br><span class="line">    we have matched (based on jaccard overlap) with the prior boxes.</span><br><span class="line">    Args:</span><br><span class="line">        matched: (tensor) Coords of ground truth for each prior in point-form</span><br><span class="line">            Shape: [num_priors, 4].</span><br><span class="line">        priors: (tensor) Prior boxes in center-offset form</span><br><span class="line">            Shape: [num_priors,4].</span><br><span class="line">        variances: (list[float]) Variances of priorboxes</span><br><span class="line">    Return:</span><br><span class="line">        encoded boxes (tensor), Shape: [num_priors, 4]</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    # dist b&#x2F;t match center and prior&#39;s center</span><br><span class="line">    g_cxcy &#x3D; (matched[:, :2] + matched[:, 2:])&#x2F;2 - priors[:, :2]</span><br><span class="line">    # encode variance</span><br><span class="line">    g_cxcy &#x2F;&#x3D; (variances[0] * priors[:, 2:])</span><br><span class="line">    # match wh &#x2F; prior wh</span><br><span class="line">    g_wh &#x3D; (matched[:, 2:] - matched[:, :2]) &#x2F; priors[:, 2:]</span><br><span class="line">    g_wh &#x3D; torch.log(g_wh) &#x2F; variances[1]</span><br><span class="line">    # return target for smooth_l1_loss</span><br><span class="line">    return torch.cat([g_cxcy, g_wh], 1)  # [num_priors,4]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Adapted from https:&#x2F;&#x2F;github.com&#x2F;Hakuyume&#x2F;chainer-ssd</span><br><span class="line">def decode(loc, priors, variances):</span><br><span class="line">    &quot;&quot;&quot;Decode locations from predictions using priors to undo</span><br><span class="line">    the encoding we did for offset regression at train time.</span><br><span class="line">    Args:</span><br><span class="line">        loc (tensor): location predictions for loc layers,</span><br><span class="line">            Shape: [num_priors,4]</span><br><span class="line">        priors (tensor): Prior boxes in center-offset form.</span><br><span class="line">            Shape: [num_priors,4].</span><br><span class="line">        variances: (list[float]) Variances of priorboxes</span><br><span class="line">    Return:</span><br><span class="line">        decoded bounding box predictions</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    boxes &#x3D; torch.cat((</span><br><span class="line">        priors[:, :2] + loc[:, :2] * variances[0] * priors[:, 2:],</span><br><span class="line">        priors[:, 2:] * torch.exp(loc[:, 2:] * variances[1])), 1)</span><br><span class="line">    boxes[:, :2] -&#x3D; boxes[:, 2:] &#x2F; 2</span><br><span class="line">    boxes[:, 2:] +&#x3D; boxes[:, :2]</span><br><span class="line">return boxes</span><br></pre></td></tr></table></figure>
<h3 id="后处理NMS"><a href="#后处理NMS" class="headerlink" title="后处理NMS"></a>后处理NMS</h3><p>这里不再赘述了。这里IOU阈值取了0.5。这部分的代码也在<code>layers/box_utils.py</code>里面。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">def nms(boxes, scores, overlap&#x3D;0.5, top_k&#x3D;200):</span><br><span class="line">    &quot;&quot;&quot;Apply non-maximum suppression at test time to avoid detecting too many</span><br><span class="line">    overlapping bounding boxes for a given object.</span><br><span class="line">    Args:</span><br><span class="line">        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].</span><br><span class="line">        scores: (tensor) The class predscores for the img, Shape:[num_priors].</span><br><span class="line">        overlap: (float) The overlap thresh for suppressing unnecessary boxes.</span><br><span class="line">        top_k: (int) The Maximum number of box preds to consider.</span><br><span class="line">    Return:</span><br><span class="line">        The indices of the kept boxes with respect to num_priors.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    keep &#x3D; scores.new(scores.size(0)).zero_().long()</span><br><span class="line">    if boxes.numel() &#x3D;&#x3D; 0:</span><br><span class="line">        return keep</span><br><span class="line">    x1 &#x3D; boxes[:, 0]</span><br><span class="line">    y1 &#x3D; boxes[:, 1]</span><br><span class="line">    x2 &#x3D; boxes[:, 2]</span><br><span class="line">    y2 &#x3D; boxes[:, 3]</span><br><span class="line">    area &#x3D; torch.mul(x2 - x1, y2 - y1)</span><br><span class="line">    v, idx &#x3D; scores.sort(0)  # sort in ascending order</span><br><span class="line">    # I &#x3D; I[v &gt;&#x3D; 0.01]</span><br><span class="line">    idx &#x3D; idx[-top_k:]  # indices of the top-k largest vals</span><br><span class="line">    xx1 &#x3D; boxes.new()</span><br><span class="line">    yy1 &#x3D; boxes.new()</span><br><span class="line">    xx2 &#x3D; boxes.new()</span><br><span class="line">    yy2 &#x3D; boxes.new()</span><br><span class="line">    w &#x3D; boxes.new()</span><br><span class="line">    h &#x3D; boxes.new()</span><br><span class="line"></span><br><span class="line">    # keep &#x3D; torch.Tensor()</span><br><span class="line">    count &#x3D; 0</span><br><span class="line">    while idx.numel() &gt; 0:</span><br><span class="line">        i &#x3D; idx[-1]  # index of current largest val</span><br><span class="line">        # keep.append(i)</span><br><span class="line">        keep[count] &#x3D; i</span><br><span class="line">        count +&#x3D; 1</span><br><span class="line">        if idx.size(0) &#x3D;&#x3D; 1:</span><br><span class="line">            break</span><br><span class="line">        idx &#x3D; idx[:-1]  # remove kept element from view</span><br><span class="line">        # load bboxes of next highest vals</span><br><span class="line">        torch.index_select(x1, 0, idx, out&#x3D;xx1)</span><br><span class="line">        torch.index_select(y1, 0, idx, out&#x3D;yy1)</span><br><span class="line">        torch.index_select(x2, 0, idx, out&#x3D;xx2)</span><br><span class="line">        torch.index_select(y2, 0, idx, out&#x3D;yy2)</span><br><span class="line">        # store element-wise max with next highest score</span><br><span class="line">        xx1 &#x3D; torch.clamp(xx1, min&#x3D;x1[i])</span><br><span class="line">        yy1 &#x3D; torch.clamp(yy1, min&#x3D;y1[i])</span><br><span class="line">        xx2 &#x3D; torch.clamp(xx2, max&#x3D;x2[i])</span><br><span class="line">        yy2 &#x3D; torch.clamp(yy2, max&#x3D;y2[i])</span><br><span class="line">        w.resize_as_(xx2)</span><br><span class="line">        h.resize_as_(yy2)</span><br><span class="line">        w &#x3D; xx2 - xx1</span><br><span class="line">        h &#x3D; yy2 - yy1</span><br><span class="line">        # check sizes of xx1 and xx2.. after each iteration</span><br><span class="line">        w &#x3D; torch.clamp(w, min&#x3D;0.0)</span><br><span class="line">        h &#x3D; torch.clamp(h, min&#x3D;0.0)</span><br><span class="line">        inter &#x3D; w*h</span><br><span class="line">        # IoU &#x3D; i &#x2F; (area(a) + area(b) - i)</span><br><span class="line">        rem_areas &#x3D; torch.index_select(area, 0, idx)  # load remaining areas)</span><br><span class="line">        union &#x3D; (rem_areas - inter) + area[i]</span><br><span class="line">        IoU &#x3D; inter&#x2F;union  # store result in iou</span><br><span class="line">        # keep only elements with an IoU &lt;&#x3D; overlap</span><br><span class="line">        idx &#x3D; idx[IoU.le(overlap)]</span><br><span class="line">    return keep, count</span><br></pre></td></tr></table></figure>
<h3 id="检测函数"><a href="#检测函数" class="headerlink" title="检测函数"></a>检测函数</h3><p>模型在测试的时候，需要把loc和conf输入到detect函数进行nms，然后给出结果。这部分的代码在<code>layers/functions/detection.py</code>里面，如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">class Detect(Function):</span><br><span class="line">    &quot;&quot;&quot;At test time, Detect is the final layer of SSD.  Decode location preds,</span><br><span class="line">    apply non-maximum suppression to location predictions based on conf</span><br><span class="line">    scores and threshold to a top_k number of output predictions for both</span><br><span class="line">    confidence score and locations.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    def __init__(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh):</span><br><span class="line">        self.num_classes &#x3D; num_classes</span><br><span class="line">        self.background_label &#x3D; bkg_label</span><br><span class="line">        self.top_k &#x3D; top_k</span><br><span class="line">        # Parameters used in nms.</span><br><span class="line">        self.nms_thresh &#x3D; nms_thresh</span><br><span class="line">        if nms_thresh &lt;&#x3D; 0:</span><br><span class="line">            raise ValueError(&#39;nms_threshold must be non negative.&#39;)</span><br><span class="line">        self.conf_thresh &#x3D; conf_thresh</span><br><span class="line">        self.variance &#x3D; cfg[&#39;variance&#39;]</span><br><span class="line"></span><br><span class="line">    def forward(self, loc_data, conf_data, prior_data):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Args:</span><br><span class="line">            loc_data: 预测出的loc张量，shape[b,M,4], eg:[b, 8732, 4]</span><br><span class="line">            conf_data:预测出的置信度，shape[b,M,num_classes], eg:[b, 8732, 21]</span><br><span class="line">            prior_data:先验框，shape[M,4], eg:[8732, 4]</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        num &#x3D; loc_data.size(0)  # batch size</span><br><span class="line">        num_priors &#x3D; prior_data.size(0)</span><br><span class="line">        output &#x3D; torch.zeros(num, self.num_classes, self.top_k, 5)# 初始化输出</span><br><span class="line">        conf_preds &#x3D; conf_data.view(num, num_priors,</span><br><span class="line">                                    self.num_classes).transpose(2, 1)</span><br><span class="line"></span><br><span class="line">        # 解码loc的信息，变为正常的bboxes</span><br><span class="line">        for i in range(num):</span><br><span class="line">            # 解码loc</span><br><span class="line">            decoded_boxes &#x3D; decode(loc_data[i], prior_data, self.variance)</span><br><span class="line">            # 拷贝每个batch内的conf，用于nms</span><br><span class="line">            conf_scores &#x3D; conf_preds[i].clone()</span><br><span class="line">            # 遍历每一个类别</span><br><span class="line">            for cl in range(1, self.num_classes):</span><br><span class="line">                # 筛选掉 conf &lt; conf_thresh 的conf</span><br><span class="line">                c_mask &#x3D; conf_scores[cl].gt(self.conf_thresh)</span><br><span class="line">                scores &#x3D; conf_scores[cl][c_mask]</span><br><span class="line">                # 如果都被筛掉了，则跳入下一类</span><br><span class="line">                if scores.size(0) &#x3D;&#x3D; 0:</span><br><span class="line">                    continue</span><br><span class="line">                # 筛选掉 conf &lt; conf_thresh 的框</span><br><span class="line">                l_mask &#x3D; c_mask.unsqueeze(1).expand_as(decoded_boxes)</span><br><span class="line">                boxes &#x3D; decoded_boxes[l_mask].view(-1, 4)</span><br><span class="line">                # idx of highest scoring and non-overlapping boxes per class</span><br><span class="line">                # nms</span><br><span class="line">                ids, count &#x3D; nms(boxes, scores, self.nms_thresh, self.top_k)</span><br><span class="line">                # nms 后得到的输出拼接</span><br><span class="line">                output[i, cl, :count] &#x3D; \</span><br><span class="line">                    torch.cat((scores[ids[:count]].unsqueeze(1),</span><br><span class="line">                               boxes[ids[:count]]), 1)</span><br><span class="line">        flt &#x3D; output.contiguous().view(num, -1, 5)</span><br><span class="line">        _, idx &#x3D; flt[:, :, 0].sort(1, descending&#x3D;True)</span><br><span class="line">        _, rank &#x3D; idx.sort(1)</span><br><span class="line">        flt[(rank &lt; self.top_k).unsqueeze(-1).expand_as(flt)].fill_(0)</span><br><span class="line">	return output</span><br></pre></td></tr></table></figure>

    </div>

    
    
    <div class="post-widgets">
      <div id="needsharebutton-postbottom">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    </div>
	<div>

	  

		<div>

    

        <div >-------------本文结束感谢您的阅读-------------</div>

    

</div>

	  

	</div>
      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"><i class="fa fa-tag"></i> 目标检测</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/04/20/Feature-Pyramid-Network/" rel="prev" title="Feature Pyramid Network">
      <i class="fa fa-chevron-left"></i> Feature Pyramid Network
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/30/%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%AE%9E%E6%97%B6%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9CThunderNet/" rel="next" title="两阶段实时检测网络ThunderNet">
      两阶段实时检测网络ThunderNet <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>



<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络结构"><span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#源码解析"><span class="nav-text">源码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#网络搭建"><span class="nav-text">网络搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Anchor生成-Prior-Box层"><span class="nav-text">Anchor生成(Prior_Box层)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络结构-1"><span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss解析"><span class="nav-text">Loss解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#实现步骤"><span class="nav-text">实现步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#先验框匹配策略"><span class="nav-text">先验框匹配策略</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#位置坐标转换"><span class="nav-text">位置坐标转换</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IOU计算"><span class="nav-text">IOU计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L2标准化"><span class="nav-text">L2标准化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#位置信息编解码"><span class="nav-text">位置信息编解码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后处理NMS"><span class="nav-text">后处理NMS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检测函数"><span class="nav-text">检测函数</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->
	  
     
	  
      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qiyuan-Z"
      src="/images/wallhaven-915.png">
  <p class="site-author-name" itemprop="name">Qiyuan-Z</p>
  <div class="site-description" itemprop="description">偉大な魂は目的を持ち、そうでないものは願望を持つ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">98</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Qiyuan-Z" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Qiyuan-Z" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:601872068@qq.com" title="E-Mail → mailto:601872068@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://project-inkstone.github.io/project-inkstone/?tdsourcetag=s_pctim_aiomsg" title="https:&#x2F;&#x2F;project-inkstone.github.io&#x2F;project-inkstone&#x2F;?tdsourcetag&#x3D;s_pctim_aiomsg" rel="noopener" target="_blank">project-inkstone</a>
        </li>
    </ul>
  </div>

      </div>
	  
      <div id="music163player">
		   <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=29784463&auto=1&height=66"></iframe>
		   </iframe>
	  </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qiyuan-Z</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">557k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:26</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span> 
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("12/01/2019 13:14:21");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
	<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
	<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
	<script type="text/javascript">
    		var gitalk = new Gitalk({
		        clientID: '2d10cfb27783db577e70',
		        clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
		        id: md5(location.pathname),
		        repo: 'gitalk',
		        owner: 'Qiyuan-Z',
		        admin: 'Qiyuan-Z',
			distractionFreeMode: '',

		    });
	    gitalk.render('gitalk-container');
	</script>



  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "bottomCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
  </script>
	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
	<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
	<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
	<script type="text/javascript">
    		var gitalk = new Gitalk({
		        clientID: '2d10cfb27783db577e70',
		        clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
		        id: md5(location.pathname),
		        repo: 'gitalk',
		        owner: 'Qiyuan-Z',
		        admin: 'Qiyuan-Z',
			distractionFreeMode: '',

		    });
	    gitalk.render('gitalk-container');
	</script>


  <script type="text/javascript" src="/js/src/clicklove.js"></script>
</body>
</html>

