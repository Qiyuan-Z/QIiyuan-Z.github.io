<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CNN结构无痛涨点技巧：ACNet | Yuan</title><meta name="keywords" content="目标检测"><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="article">
<meta property="og:title" content="CNN结构无痛涨点技巧：ACNet">
<meta property="og:url" content="https://qiyuan-z.github.io/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/index.html">
<meta property="og:site_name" content="Yuan">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qiyuan-z.github.io/img/1097380.jpg">
<meta property="article:published_time" content="2020-04-17T02:54:37.109Z">
<meta property="article:modified_time" content="2020-04-17T05:17:34.979Z">
<meta property="article:author" content="Qiyuan-Z">
<meta property="article:tag" content="目标检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qiyuan-z.github.io/img/1097380.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/2020/04/17/CNN%E7%BB%93%E6%9E%84%E6%97%A0%E7%97%9B%E6%B6%A8%E7%82%B9%E6%8A%80%E5%B7%A7%EF%BC%9AACNet/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"ZQZI62NB22","apiKey":"f208969d7174c4878fcfe069d1a5a6dd","indexName":"blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: Qiyuan-Z","link":"链接: ","source":"来源: Yuan","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-right"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-04-17 13:17:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">114</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">CNN结构无痛涨点技巧：ACNet</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-04-17T02:54:37.109Z" title="发表于 2020-04-17 10:54:37">2020-04-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-04-17T05:17:34.979Z" title="更新于 2020-04-17 13:17:34">2020-04-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>7分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="前言"><a href="#前言" class="headerlink" title=" 前言"></a><span id="more"></span> 前言</h2><p>CNN的结构创新在这两年已经变得相对很少了，同时要做出有影响力并且Solid的工作也变得越来越难，最近CNN结构方面的创新主要包含两个方面：</p>
<ul>
<li>网络结构搜索，以Google Brain的EfficientNet为代表作。</li>
<li>获取更好的特征表达，主要是将特征复用，特征细化做得更加极致，以HRNet，Res2Net等为代表作。</li>
</ul>
<p>本文要介绍的是ICCV 2019的一个新CNN架构ACNet（全称为Asymmetric Convolution  Net），因此这篇文章的目的是讲清楚ACNet的原理并总结它的核心思想，另外借助作者开源的Pytorch代码端来加深理解。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>ACNet的切入点为获取更好的特征表达，但和其它方法最大的区别在于它没有带来额外的超参数，而且在推理阶段没有增加计算量，这是十分具有吸引力的。</p>
<p>在正式介绍ACNet之前，首先来明确一下关于卷积计算的一个等式，这个等式表达的意思就是<strong>「对于输入特征图$I$，先进行$K^{(1)}$和$I$卷积，$K^{(2)}$和$I$卷积后再对结果进行相加，与先进行$K^{(1)}$和$K^{(2)}$的逐点相加后再和$I$进行卷积得到的结果是一致的」</strong>。这也是ACNet在推理阶段不增加任何计算量的理论基础。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/640.png" alt></p>
<h2 id="ACNet原理"><a href="#ACNet原理" class="headerlink" title="ACNet原理"></a>ACNet原理</h2><p>下面的Figure1展示了ACNet的思想：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/641.png" alt></p>
<p>宏观上来看<strong>「ACNet分为训练和推理阶段，训练阶段重点在于强化特征提取，实现效果提升。而测试阶段重点在于卷积核融合，不增加任何计算量」</strong>。</p>
<ul>
<li><p><strong>「训练阶段」</strong>：因为3 x 3卷积是大多数网络的基础组件，因此ACNet的实验都是针对3 x 3卷积进行的。训练阶段就是将现有网络中的每一个3 x 3卷积换成3 x 1卷积+1 x 3卷积+3 x 3卷积共三个卷积层，最终将这三个卷积层的计算结果进行融合获得卷积层的输出。因为这个过程中引入的1 x 3卷积和3 x 1卷积是非对称的，所以将其命名为Asymmetric Convolution。</p>
</li>
<li><p><strong>「推理阶段」</strong>：如上图右半部分所示，这部分主要是对三个卷积核进行融合。这部分在实现过程中就是使用融合后的卷积核参数来初始化现有的网络，因此在推理阶段，网络结构和原始网络是完全一样的了，只不过网络参数采用了特征提取能力更强的参数即融合后的卷积核参数，因此在推理阶段不会增加计算量。</p>
</li>
</ul>
<p>总结一下就是ACNet在训练阶段强化了原始网络的特征提取能力，在推理阶段融合卷积核达到不增加计算量的目的。虽然训练时间增加了一些时间，但却换来了在推理阶段速度无痛的精度提升，怎么看都是一笔非常划算的交易。下面的Table3展示了在一些经典网络上应用ACNet的结果，对于AlexNet精度提升了比较多，而对ResNet和DenseNet精度则提升不到一个百分点，不过考虑到这个提升是白赚的也还是非常值得肯定的。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/642.png" alt></p>
<h2 id="为什么ACNet能涨点？"><a href="#为什么ACNet能涨点？" class="headerlink" title="为什么ACNet能涨点？"></a>为什么ACNet能涨点？</h2><p>为什么ACNet这个看起来十分简单的操作能为各种网络带来涨点？论文中提到，ACNet有一个特点是<strong>「它提升了模型对图像翻转和旋转的鲁棒性」</strong>，例如训练好后的1 x 3卷积和在图像翻转后仍然能提取正确的特征（如Figure4左图所示，2个红色矩形框就是图像翻转前后的特征提取操作，在输入图像的相同位置处提取出来的特征还是一样的）。那么假设训练阶段只用3 x 3卷积核，当图像上下翻转之后，如Figure4右图所示，提取出来的特征显然是不一样的。</p>
<p>因此，引入1 x 3这样的水平卷积核可以提升模型对图像上下翻转的鲁棒性，竖直方向的卷积核同理。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/643.png" alt></p>
<p>下面的Table4则继续从实验角度解释了这种鲁棒性：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/644.png" alt></p>
<h2 id="推理阶段的卷积核融合"><a href="#推理阶段的卷积核融合" class="headerlink" title="推理阶段的卷积核融合"></a>推理阶段的卷积核融合</h2><p>推理阶段的融合操作如Figure3所示，在论文中提到具体的融合操作是和BN层一起的，然后融合操作时发生在BN之后的。但是其实也可以把融合操作放在BN层之前，也就是三个卷积层计算完之后就开始融合。论文对这两种融合方式进行了实验，在上面的Table4中BN in branch这一列有√的话表示融合是在BN之后，可以看到这种方式使得效果确实会更好一些。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ACNet/645.png" alt></p>
<h2 id="Pytorch代码实现"><a href="#Pytorch代码实现" class="headerlink" title="Pytorch代码实现"></a>Pytorch代码实现</h2><p>我们来看一下作者的ACNet基础结构Pytorch实现，即将原始的3 x 3卷积变成：3 x 3 + 3 x 1 + 1 x 3：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># 去掉因为3x3卷积的padding多出来的行或者列</span><br><span class="line">class CropLayer(nn.Module):</span><br><span class="line"></span><br><span class="line">    #   E.g., (-1, 0) means this layer should crop the first and last rows of the feature map. And (0, -1) crops the first and last columns</span><br><span class="line">    def __init__(self, crop_set):</span><br><span class="line">        super(CropLayer, self).__init__()</span><br><span class="line">        self.rows_to_crop = - crop_set[0]</span><br><span class="line">        self.cols_to_crop = - crop_set[1]</span><br><span class="line">        assert self.rows_to_crop &gt;= 0</span><br><span class="line">        assert self.cols_to_crop &gt;= 0</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        return input[:, :, self.rows_to_crop:-self.rows_to_crop, self.cols_to_crop:-self.cols_to_crop]</span><br><span class="line"></span><br><span class="line"># 论文提出的3x3+1x3+3x1</span><br><span class="line">class ACBlock(nn.Module):</span><br><span class="line"></span><br><span class="line">    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, padding_mode=&#x27;zeros&#x27;, deploy=False):</span><br><span class="line">        super(ACBlock, self).__init__()</span><br><span class="line">        self.deploy = deploy</span><br><span class="line">        if deploy:</span><br><span class="line">            self.fused_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(kernel_size,kernel_size), stride=stride,</span><br><span class="line">                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)</span><br><span class="line">        else:</span><br><span class="line">            self.square_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,</span><br><span class="line">                                         kernel_size=(kernel_size, kernel_size), stride=stride,</span><br><span class="line">                                         padding=padding, dilation=dilation, groups=groups, bias=False,</span><br><span class="line">                                         padding_mode=padding_mode)</span><br><span class="line">            self.square_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line"></span><br><span class="line">            center_offset_from_origin_border = padding - kernel_size // 2</span><br><span class="line">            ver_pad_or_crop = (center_offset_from_origin_border + 1, center_offset_from_origin_border)</span><br><span class="line">            hor_pad_or_crop = (center_offset_from_origin_border, center_offset_from_origin_border + 1)</span><br><span class="line">            if center_offset_from_origin_border &gt;= 0:</span><br><span class="line">                self.ver_conv_crop_layer = nn.Identity()</span><br><span class="line">                ver_conv_padding = ver_pad_or_crop</span><br><span class="line">                self.hor_conv_crop_layer = nn.Identity()</span><br><span class="line">                hor_conv_padding = hor_pad_or_crop</span><br><span class="line">            else:</span><br><span class="line">                self.ver_conv_crop_layer = CropLayer(crop_set=ver_pad_or_crop)</span><br><span class="line">                ver_conv_padding = (0, 0)</span><br><span class="line">                self.hor_conv_crop_layer = CropLayer(crop_set=hor_pad_or_crop)</span><br><span class="line">                hor_conv_padding = (0, 0)</span><br><span class="line">            self.ver_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 1),</span><br><span class="line">                                      stride=stride,</span><br><span class="line">                                      padding=ver_conv_padding, dilation=dilation, groups=groups, bias=False,</span><br><span class="line">                                      padding_mode=padding_mode)</span><br><span class="line"></span><br><span class="line">            self.hor_conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(1, 3),</span><br><span class="line">                                      stride=stride,</span><br><span class="line">                                      padding=hor_conv_padding, dilation=dilation, groups=groups, bias=False,</span><br><span class="line">                                      padding_mode=padding_mode)</span><br><span class="line">            self.ver_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line">            self.hor_bn = nn.BatchNorm2d(num_features=out_channels)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # forward函数</span><br><span class="line">    def forward(self, input):</span><br><span class="line">        if self.deploy:</span><br><span class="line">            return self.fused_conv(input)</span><br><span class="line">        else:</span><br><span class="line">            square_outputs = self.square_conv(input)</span><br><span class="line">            square_outputs = self.square_bn(square_outputs)</span><br><span class="line">            # print(square_outputs.size())</span><br><span class="line">            # return square_outputs</span><br><span class="line">            vertical_outputs = self.ver_conv_crop_layer(input)</span><br><span class="line">            vertical_outputs = self.ver_conv(vertical_outputs)</span><br><span class="line">            vertical_outputs = self.ver_bn(vertical_outputs)</span><br><span class="line">            # print(vertical_outputs.size())</span><br><span class="line">            horizontal_outputs = self.hor_conv_crop_layer(input)</span><br><span class="line">            horizontal_outputs = self.hor_conv(horizontal_outputs)</span><br><span class="line">            horizontal_outputs = self.hor_bn(horizontal_outputs)</span><br><span class="line">            # print(horizontal_outputs.size())</span><br><span class="line">            return square_outputs + vertical_outputs + horizontal_outputs</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然后在推理阶段进行卷积核融合的代码实现地址为：<code>https://github.com/DingXiaoH/ACNet/blob/master/acnet/acnet_fusion.py</code>，对照Figure3就比较好理解了，介于篇幅这里就不贴这段代码了。</p>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>从实验结果中可以看到，在推理阶段即使融合操作放在BN层之前，相比原始网络仍有一定提升（AlexNet的56.18% vs 55.92%，ResNet-18的70.82% vs 70.36%），作者没有讲解这部分的原理，某位大佬提出的观点，如下：</p>
<blockquote>
<p>这部分的原因个人理解是来自梯度差异化，原来只有一个3 x 3卷积层，梯度可以看出一份，而添加了1 x 3和3 x 1卷积层后，部分位置的梯度变为2份和3份，也是更加细化了。而且理论上可以融合无数个卷积层不断逼近现有网络的效果极限，融合方式不限于相加（训练和推理阶段一致即可），融合的卷积层也不限于1 x 3或3 x 1尺寸。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文简要讲述了ACNet这个无痛的调参方法，这种方法创新点是非常棒的，我们不一定需要重型BackBone去提取特征，也不一定需要复杂的结构复用特征，像ACNet这样的优雅并且有效的作品确实让人眼前一亮。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></div><div class="post_share"><div class="social-share" data-image="/img/1097380.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/04/18/ICCV-2019-TridentNet%EF%BC%88%E4%B8%89%E5%8F%89%E6%88%9F%E7%BD%91%E7%BB%9C%EF%BC%8C%E5%88%B7%E6%96%B0COCO%E7%BA%AA%E5%BD%95%EF%BC%8C%E5%B7%B2%E5%BC%80%E6%BA%90%EF%BC%89/"><img class="prev-cover" src="/img/1097380.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">ICCV 2019 TridentNet（三叉戟网络，刷新COCO纪录，已开源）</div></div></a></div><div class="next-post pull-right"><a href="/2020/04/17/AlexeyAB-DarkNet-Dropout%E5%B1%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/"><img class="next-cover" src="/img/1097380.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">AlexeyAB DarkNet Dropout层代码详解</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-09</div><div class="title">Perceptual Generative Adversarial Networks for Small Object Detection</div></div></a></div><div><a href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-–-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-08</div><div class="title">An Analysis of Scale Invariance in Object Detection – SNIP</div></div></a></div><div><a href="/2020/05/08/回归损失函数：L1-loss,-L2-loss以及Smooth-L1-Loss的对比/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-08</div><div class="title">回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比</div></div></a></div><div><a href="/2020/04/30/两阶段实时检测网络ThunderNet/" title="两阶段实时检测网络ThunderNet"><img class="cover" src="/img/34125236_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-30</div><div class="title">两阶段实时检测网络ThunderNet</div></div></a></div><div><a href="/2020/04/23/SSD代码解析/" title="SSD代码解析"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-23</div><div class="title">SSD代码解析</div></div></a></div><div><a href="/2020/04/20/自适应空间特征融合-(ASFF)/" title="自适应空间特征融合 (ASFF)"><img class="cover" src="/img/34125236_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-20</div><div class="title">自适应空间特征融合 (ASFF)</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text"> 前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ACNet%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">ACNet原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88ACNet%E8%83%BD%E6%B6%A8%E7%82%B9%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">为什么ACNet能涨点？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E9%98%B6%E6%AE%B5%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%A0%B8%E8%9E%8D%E5%90%88"><span class="toc-number">5.</span> <span class="toc-text">推理阶段的卷积核融合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.</span> <span class="toc-text">Pytorch代码实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83"><span class="toc-number">7.</span> <span class="toc-text">思考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">8.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Qiyuan-Z</div><div class="footer_custom_text">昨日までの私は、もうどこにもいない</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '2d10cfb27783db577e70',
      clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
      repo: 'gitalk',
      owner: 'Qiyuan-Z',
      admin: ['Qiyuan-Z'],
      id: 'b3e646b94604b612e08689160179de24',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>