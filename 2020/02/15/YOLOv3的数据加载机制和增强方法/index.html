<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>YOLOv3的数据加载机制和增强方法 | Yuan</title><meta name="keywords" content="目标检测,YOLOv3"><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="article">
<meta property="og:title" content="YOLOv3的数据加载机制和增强方法">
<meta property="og:url" content="https://qiyuan-z.github.io/2020/02/15/YOLOv3%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%92%8C%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/index.html">
<meta property="og:site_name" content="Yuan">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qiyuan-z.github.io/img/1097380.jpg">
<meta property="article:published_time" content="2020-02-15T04:34:41.575Z">
<meta property="article:modified_time" content="2020-02-15T04:55:51.050Z">
<meta property="article:author" content="Qiyuan-Z">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="YOLOv3">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qiyuan-z.github.io/img/1097380.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/2020/02/15/YOLOv3%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%92%8C%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"ZQZI62NB22","apiKey":"f208969d7174c4878fcfe069d1a5a6dd","indexName":"blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: Qiyuan-Z","link":"链接: ","source":"来源: Yuan","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-right"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-02-15 12:55:51'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">114</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">YOLOv3的数据加载机制和增强方法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-02-15T04:34:41.575Z" title="发表于 2020-02-15 12:34:41">2020-02-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-02-15T04:55:51.050Z" title="更新于 2020-02-15 12:55:51">2020-02-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="1-标注格式"><a href="#1-标注格式" class="headerlink" title=" 1. 标注格式"></a><span id="more"></span> 1. 标注格式</h2><p><code>voc_label.py</code>，其作用是将xml文件转成txt文件格式，具体文件如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># class id, x, y, w, h</span><br><span class="line">0 0.8604166666666666 0.5403899721448469 0.058333333333333334 0.055710306406685235</span><br></pre></td></tr></table></figure>
<p>其中的x,y 的意义是归一化以后的框的中心坐标，w,h是归一化后的框的宽和高。</p>
<p>具体的归一化方式为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def convert(size, box):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    size是图片的长和宽</span><br><span class="line">    box是xmin,xmax,ymin,ymax坐标值</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    dw = 1. / (size[0])</span><br><span class="line">    dh = 1. / (size[1])</span><br><span class="line">    # 得到长和宽的缩放比</span><br><span class="line">    x = (box[0] + box[1])/2.0  </span><br><span class="line">    y = (box[2] + box[3])/2.0  </span><br><span class="line">    w = box[1] - box[0]</span><br><span class="line">    h = box[3] - box[2]</span><br><span class="line">    # 分别计算中心点坐标，框的宽和高</span><br><span class="line">    x = x * dw</span><br><span class="line">    w = w * dw</span><br><span class="line">    y = y * dh</span><br><span class="line">    h = h * dh</span><br><span class="line">    # 按照图片长和宽进行归一化</span><br><span class="line">    return (x,y,w,h)</span><br></pre></td></tr></table></figure>
<p>可以看出，归一化都是相对于图片的宽和高进行归一化的。</p>
<h2 id="2-调用"><a href="#2-调用" class="headerlink" title="2. 调用"></a>2. 调用</h2><p>下边是train.py文件中的有关数据的调用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># Dataset</span><br><span class="line">dataset = LoadImagesAndLabels(train_path, img_size, batch_size,</span><br><span class="line">                              augment=True,</span><br><span class="line">                              hyp=hyp,  # augmentation hyperparameters</span><br><span class="line">                              rect=opt.rect,  # rectangular training</span><br><span class="line">                              cache_labels=True,</span><br><span class="line">                              cache_images=opt.cache_images)</span><br><span class="line"></span><br><span class="line">batch_size = min(batch_size, len(dataset))</span><br><span class="line"></span><br><span class="line"># 使用多少个线程加载数据集</span><br><span class="line">nw = min([os.cpu_count(), batch_size if batch_size &gt; 1 else 0, 1])</span><br><span class="line"></span><br><span class="line">dataloader = DataLoader(dataset,</span><br><span class="line">                        batch_size=batch_size,</span><br><span class="line">                        num_workers=nw,</span><br><span class="line">                        shuffle=not opt.rect,</span><br><span class="line">                        # Shuffle=True</span><br><span class="line">                        # unless rectangular training is used</span><br><span class="line">                        pin_memory=True,</span><br><span class="line">                        collate_fn=dataset.collate_fn)</span><br></pre></td></tr></table></figure>
<p>在pytorch中，数据集加载主要是重构datasets类，然后再使用dataloader中加载dataset，就构建好了数据部分。</p>
<p>下面是一个简单的使用模板：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line"># 根据自己的数据集格式进行重构</span><br><span class="line">class MyDataset(Dataset):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        #下载数据、初始化数据，都可以在这里完成</span><br><span class="line">        xy = np.loadtxt(&#x27;label.txt&#x27;, delimiter=&#x27;,&#x27;, dtype=np.float32)</span><br><span class="line">        # 使用numpy读取数据</span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, 0:-1])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-1]])</span><br><span class="line">        self.len = xy.shape[0]</span><br><span class="line">    </span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        # dataloader中使用该方法，通过index进行访问</span><br><span class="line">        return self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        # 查询数据集中数量，可以通过len(mydataset)得到</span><br><span class="line">        return self.len</span><br><span class="line"></span><br><span class="line"># 实例化这个类，然后我们就得到了Dataset类型的数据，记下来就将这个类传给DataLoader，就可以了。</span><br><span class="line">myDataset = MyDataset()</span><br><span class="line"></span><br><span class="line"># 构建dataloader</span><br><span class="line">train_loader = DataLoader(dataset=myDataset,</span><br><span class="line">                          batch_size=32,</span><br><span class="line">                          shuffle=True)</span><br><span class="line"></span><br><span class="line">for epoch in range(2):</span><br><span class="line">    for i, data in enumerate(train_loader):</span><br><span class="line">        # 将数据从 train_loader 中读出来,一次读取的样本数是32个</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        # 将这些数据转换成Variable类型</span><br><span class="line">        inputs, labels = Variable(inputs), Variable(labels)</span><br><span class="line">		# 模型训练...</span><br></pre></td></tr></table></figure>
<p>通过以上模板就能大致了解pytorch中的数据加载机制，下面开始介绍YOLOv3中的数据加载。</p>
<h2 id="3-YOLOv3中的数据加载"><a href="#3-YOLOv3中的数据加载" class="headerlink" title="3. YOLOv3中的数据加载"></a>3. YOLOv3中的数据加载</h2><p>下面解析的是LoadImagesAndLabels类中的几个主要的函数：</p>
<h3 id="3-1-init函数"><a href="#3-1-init函数" class="headerlink" title="3.1 init函数"></a>3.1 init函数</h3><p>init函数中包含了大部分需要处理的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br></pre></td><td class="code"><pre><span class="line">class LoadImagesAndLabels(Dataset):  # for training/testing</span><br><span class="line">    def __init__(self,</span><br><span class="line">                 path,</span><br><span class="line">                 img_size=416,</span><br><span class="line">                 batch_size=16,</span><br><span class="line">                 augment=False,</span><br><span class="line">                 hyp=None,</span><br><span class="line">                 rect=False,</span><br><span class="line">                 image_weights=False,</span><br><span class="line">                 cache_labels=False,</span><br><span class="line">                 cache_images=False):</span><br><span class="line">        path = str(Path(path))  # os-agnostic</span><br><span class="line">        assert os.path.isfile(path), &#x27;File not found %s. See %s&#x27; % (path,</span><br><span class="line">                                                                    help_url)</span><br><span class="line">        with open(path, &#x27;r&#x27;) as f:</span><br><span class="line">            self.img_files = [</span><br><span class="line">                x.replace(&#x27;/&#x27;, os.sep)</span><br><span class="line">                for x in f.read().splitlines()  # os-agnostic</span><br><span class="line">                if os.path.splitext(x)[-1].lower() in img_formats</span><br><span class="line">            ]</span><br><span class="line">        # img_files是一个list，保存的是图片的路径</span><br><span class="line"></span><br><span class="line">        n = len(self.img_files)</span><br><span class="line">        assert n &gt; 0, &#x27;No images found in %s. See %s&#x27; % (path, help_url)</span><br><span class="line">        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index</span><br><span class="line">        # 如果n=10, batch=2, bi=[0,0,1,1,2,2,3,3,4,4]</span><br><span class="line">        nb = bi[-1] + 1  # 最多有多少个batch</span><br><span class="line"></span><br><span class="line">        self.n = n</span><br><span class="line">        self.batch = bi  # 图片的batch索引，代表第几个batch的图片</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.augment = augment</span><br><span class="line">        self.hyp = hyp</span><br><span class="line">        self.image_weights = image_weights # 是否选择根据权重进行采样</span><br><span class="line">        self.rect = False if image_weights else rect</span><br><span class="line">        # 如果选择根据权重进行采样，将无法使用矩形训练：</span><br><span class="line">        # 具体内容见下文</span><br><span class="line"></span><br><span class="line">        # 标签文件是通过images替换为labels, .jpg替换为.txt得到的。</span><br><span class="line">        self.label_files = [</span><br><span class="line">            x.replace(&#x27;images&#x27;,</span><br><span class="line">                      &#x27;labels&#x27;).replace(os.path.splitext(x)[-1], &#x27;.txt&#x27;)</span><br><span class="line">            for x in self.img_files</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        # 矩形训练具体内容见下文解析</span><br><span class="line">        if self.rect:</span><br><span class="line">            # 获取图片的长和宽 (wh)</span><br><span class="line">            sp = path.replace(&#x27;.txt&#x27;, &#x27;.shapes&#x27;)</span><br><span class="line">            # 字符串替换</span><br><span class="line">            # shapefile path</span><br><span class="line">            try:</span><br><span class="line">                with open(sp, &#x27;r&#x27;) as f:  # 读取shape文件</span><br><span class="line">                    s = [x.split() for x in f.read().splitlines()]</span><br><span class="line">                    assert len(s) == n, &#x27;Shapefile out of sync&#x27;</span><br><span class="line">            except:</span><br><span class="line">                s = [</span><br><span class="line">                    exif_size(Image.open(f))</span><br><span class="line">                    for f in tqdm(self.img_files, desc=&#x27;Reading image shapes&#x27;)</span><br><span class="line">                ]</span><br><span class="line">                np.savetxt(sp, s, fmt=&#x27;%g&#x27;)  # overwrites existing (if any)</span><br><span class="line"></span><br><span class="line">            # 根据长宽比进行排序</span><br><span class="line">            s = np.array(s, dtype=np.float64)</span><br><span class="line">            ar = s[:, 1] / s[:, 0]  # aspect ratio</span><br><span class="line">            i = ar.argsort()</span><br><span class="line"></span><br><span class="line">            # 根据顺序重排顺序</span><br><span class="line">            self.img_files = [self.img_files[i] for i in i]</span><br><span class="line">            self.label_files = [self.label_files[i] for i in i]</span><br><span class="line">            self.shapes = s[i]  # wh</span><br><span class="line">            ar = ar[i]</span><br><span class="line"></span><br><span class="line">            # 设置训练的图片形状</span><br><span class="line">            shapes = [[1, 1]] * nb</span><br><span class="line">            for i in range(nb):</span><br><span class="line">                ari = ar[bi == i]</span><br><span class="line">                mini, maxi = ari.min(), ari.max()</span><br><span class="line">                if maxi &lt; 1:</span><br><span class="line">                    shapes[i] = [maxi, 1]</span><br><span class="line">                elif mini &gt; 1:</span><br><span class="line">                    shapes[i] = [1, 1 / mini]</span><br><span class="line"></span><br><span class="line">            self.batch_shapes = np.ceil(</span><br><span class="line">                np.array(shapes) * img_size / 32.).astype(np.int) * 32</span><br><span class="line"></span><br><span class="line">        # 预载标签</span><br><span class="line">        # weighted CE 训练时需要这个步骤</span><br><span class="line">        # 否则无法按照权重进行采样</span><br><span class="line">        self.imgs = [None] * n</span><br><span class="line">        self.labels = [None] * n</span><br><span class="line">        if cache_labels or image_weights:  # cache labels for faster training</span><br><span class="line">            self.labels = [np.zeros((0, 5))] * n</span><br><span class="line">            extract_bounding_boxes = False</span><br><span class="line">            create_datasubset = False</span><br><span class="line">            pbar = tqdm(self.label_files, desc=&#x27;Caching labels&#x27;)</span><br><span class="line">            nm, nf, ne, ns, nd = 0, 0, 0, 0, 0  # number missing, found, empty, datasubset, duplicate</span><br><span class="line">            for i, file in enumerate(pbar):</span><br><span class="line">                try:</span><br><span class="line">                    # 读取每个文件内容</span><br><span class="line">                    with open(file, &#x27;r&#x27;) as f:</span><br><span class="line">                        l = np.array(</span><br><span class="line">                            [x.split() for x in f.read().splitlines()],</span><br><span class="line">                            dtype=np.float32)</span><br><span class="line">                except:</span><br><span class="line">                    nm += 1  # print(&#x27;missing labels for image %s&#x27; % self.img_files[i])  # file missing</span><br><span class="line">                    continue</span><br><span class="line"></span><br><span class="line">                if l.shape[0]:</span><br><span class="line">                    # 判断文件内容是否符合要求</span><br><span class="line">                    # 所有的值需要&gt;0, &lt;1, 一共5列</span><br><span class="line">                    assert l.shape[1] == 5, &#x27;&gt; 5 label columns: %s&#x27; % file</span><br><span class="line">                    assert (l &gt;= 0).all(), &#x27;negative labels: %s&#x27; % file</span><br><span class="line">                    assert (l[:, 1:] &lt;= 1).all(</span><br><span class="line">                    ), &#x27;non-normalized or out of bounds coordinate labels: %s&#x27; % file</span><br><span class="line">                    if np.unique(</span><br><span class="line">                            l, axis=0).shape[0] &lt; l.shape[0]:  # duplicate rows</span><br><span class="line">                        nd += 1  # print(&#x27;WARNING: duplicate rows in %s&#x27; % self.label_files[i])  # duplicate rows</span><br><span class="line"></span><br><span class="line">                    self.labels[i] = l</span><br><span class="line">                    nf += 1  # file found</span><br><span class="line"></span><br><span class="line">                    # 创建一个小型的数据集进行试验</span><br><span class="line">                    if create_datasubset and ns &lt; 1E4:</span><br><span class="line">                        if ns == 0:</span><br><span class="line">                            create_folder(path=&#x27;./datasubset&#x27;)</span><br><span class="line">                            os.makedirs(&#x27;./datasubset/images&#x27;)</span><br><span class="line">                        exclude_classes = 43</span><br><span class="line">                        if exclude_classes not in l[:, 0]:</span><br><span class="line">                            ns += 1</span><br><span class="line">                            # shutil.copy(src=self.img_files[i], dst=&#x27;./datasubset/images/&#x27;)  # copy image</span><br><span class="line">                            with open(&#x27;./datasubset/images.txt&#x27;, &#x27;a&#x27;) as f:</span><br><span class="line">                                f.write(self.img_files[i] + &#x27;\n&#x27;)</span><br><span class="line"></span><br><span class="line">                    # 为两阶段分类器提取目标检测的检测框</span><br><span class="line">                    # 默认开关是关掉的，不是很理解</span><br><span class="line">                    if extract_bounding_boxes:</span><br><span class="line">                        p = Path(self.img_files[i])</span><br><span class="line">                        img = cv2.imread(str(p))</span><br><span class="line">                        h, w = img.shape[:2]</span><br><span class="line">                        for j, x in enumerate(l):</span><br><span class="line">                            f = &#x27;%s%sclassifier%s%g_%g_%s&#x27; % (p.parent.parent,</span><br><span class="line">                                                              os.sep, os.sep,</span><br><span class="line">                                                              x[0], j, p.name)</span><br><span class="line">                            if not os.path.exists(Path(f).parent):</span><br><span class="line">                                os.makedirs(Path(f).parent)</span><br><span class="line">                                # make new output folder</span><br><span class="line"></span><br><span class="line">                            b = x[1:] * np.array([w, h, w, h])  # box</span><br><span class="line">                            b[2:] = b[2:].max()  # rectangle to square</span><br><span class="line">                            b[2:] = b[2:] * 1.3 + 30  # pad</span><br><span class="line"></span><br><span class="line">                            b = xywh2xyxy(b.reshape(-1,4)).ravel().astype(np.int)</span><br><span class="line"></span><br><span class="line">                            b[[0,2]] = np.clip(b[[0, 2]], 0,w)  # clip boxes outside of image</span><br><span class="line">                            b[[1, 3]] = np.clip(b[[1, 3]], 0, h)</span><br><span class="line">                            assert cv2.imwrite(f, img[b[1]:b[3], b[0]:b[2]]), &#x27;Failure extracting classifier boxes&#x27;</span><br><span class="line">                else:</span><br><span class="line">                    ne += 1</span><br><span class="line"></span><br><span class="line">                pbar.desc = &#x27;Caching labels (%g found, %g missing, %g empty, %g duplicate, for %g images)&#x27; </span><br><span class="line">                % (nf, nm, ne, nd, n) # 统计发现，丢失，空，重复标签的数量。</span><br><span class="line">            assert nf &gt; 0, &#x27;No labels found. See %s&#x27; % help_url</span><br><span class="line"></span><br><span class="line">        # 将图片加载到内存中，可以加速训练</span><br><span class="line">        # 警告：如果在数据比较多的情况下可能会超出RAM</span><br><span class="line">        if cache_images:  # if training</span><br><span class="line">            gb = 0  # 计算缓存到内存中的图片占用的空间GB为单位</span><br><span class="line">            pbar = tqdm(range(len(self.img_files)), desc=&#x27;Caching images&#x27;)</span><br><span class="line">            self.img_hw0, self.img_hw = [None] * n, [None] * n</span><br><span class="line">            for i in pbar:  # max 10k images</span><br><span class="line">                self.imgs[i], self.img_hw0[i], self.img_hw[i] = load_image(</span><br><span class="line">                    self, i)  # img, hw_original, hw_resized</span><br><span class="line">                gb += self.imgs[i].nbytes</span><br><span class="line">                pbar.desc = &#x27;Caching images (%.1fGB)&#x27; % (gb / 1E9)</span><br><span class="line"></span><br><span class="line">        # 删除损坏的文件</span><br><span class="line">        # 根据需要进行手动开关</span><br><span class="line">        detect_corrupted_images = False</span><br><span class="line">        if detect_corrupted_images:</span><br><span class="line">            from skimage import io  # conda install -c conda-forge scikit-image</span><br><span class="line">            for file in tqdm(self.img_files,</span><br><span class="line">                             desc=&#x27;Detecting corrupted images&#x27;):</span><br><span class="line">                try:</span><br><span class="line">                    _ = io.imread(file)</span><br><span class="line">                except:</span><br><span class="line">                    print(&#x27;Corrupted image detected: %s&#x27; % file)</span><br></pre></td></tr></table></figure>
<p><strong>Rectangular inference（矩形推理）</strong></p>
<ol>
<li>矩形推理是在detect.py，也就是测试过程中的实现，可以减少推理时间。YOLOv3中是下采样32倍，长宽也必须是32的倍数，所以在进入模型前，数据需要处理到416×416大小，这个过程称为仿射变换，如果用opencv实现可以用以下代码：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 来自 https://zhuanlan.zhihu.com/p/93822508</span><br><span class="line">def cv2_letterbox_image(image, expected_size):</span><br><span class="line">    ih, iw = image.shape[0:2]</span><br><span class="line">    ew, eh = expected_size</span><br><span class="line">    scale = min(eh / ih, ew / iw)</span><br><span class="line">    nh = int(ih * scale)</span><br><span class="line">    nw = int(iw * scale)</span><br><span class="line">    image = cv2.resize(image, (nw, nh), interpolation=cv2.INTER_CUBIC)</span><br><span class="line">    top = (eh - nh) // 2</span><br><span class="line">    bottom = eh - nh - top</span><br><span class="line">    left = (ew - nw) // 2</span><br><span class="line">    right = ew - nw - left</span><br><span class="line">    new_img = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT)</span><br><span class="line">    return new_img</span><br></pre></td></tr></table></figure>
<p>比如下图是一个h&gt;w，一个是w&gt;h的图片经过仿射变换后resize到416×416的示例：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/pyyolov3/643.webp" alt></p>
<p>以上就是正方形推理，但是可以看出以上通过补充得到的结果会存在很多冗余信息，而Rectangular Training思路就是想要去掉这些冗余的部分。</p>
<p>具体过程为：求得较长边缩放到416的比例，然后对图片w:h按这个比例缩放，使得较长边达到416,再对较短边进行尽量少的填充使得较短边满足32的倍数。</p>
<p>示例如下：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/pyyolov3/644.webp" alt></p>
<p><strong>Rectangular Training（矩形训练）</strong></p>
<p>很自然的，训练的过程也可以用到这个想法，减少冗余。不过训练的时候情况比较复杂，由于在训练过程中是一个batch的图片，而每个batch图片是有可能长宽比不同的，这就是与测试最大的区别。具体是实现是取这个batch中最大的场合宽，然后将整个batch中填充到max width和max  height,这样操作对小一些的图片来说也是比较浪费。这里的yolov3的实现主要就是优化了一下如何将比例相近的图片放在一个batch，这样显然填充的就更少一些了。作者在issue中提到，在coco数据集中使用这个策略进行训练，能够快1/3。</p>
<p>而如果选择开启矩形训练，必须要关闭dataloader中的shuffle参数，防止对数据的顺序进行调整。同时如果选择image_weights, 根据图片进行采样，也无法与矩阵训练同时使用。</p>
<h3 id="3-2-getitem函数"><a href="#3-2-getitem函数" class="headerlink" title="3.2 getitem函数"></a>3.2 getitem函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">def __getitem__(self, index):</span><br><span class="line">    # 新的下角标</span><br><span class="line">    if self.image_weights:</span><br><span class="line">        index = self.indices[index]</span><br><span class="line"></span><br><span class="line">    img_path = self.img_files[index]</span><br><span class="line">    label_path = self.label_files[index]</span><br><span class="line"></span><br><span class="line">    hyp = self.hyp</span><br><span class="line">    mosaic = True and self.augment</span><br><span class="line">    # 如果开启组合变化、数据增强</span><br><span class="line">    # 加载四张图片，作为一个拼图，具体看下文解析。</span><br><span class="line">    if mosaic:</span><br><span class="line">        # 加载拼图内容</span><br><span class="line">        img, labels = load_mosaic(self, index)</span><br><span class="line">        shapes = None</span><br><span class="line"></span><br><span class="line">    else:</span><br><span class="line">        # 加载图片</span><br><span class="line">        img, (h0, w0), (h, w) = load_image(self, index)</span><br><span class="line"></span><br><span class="line">        # 仿射变换</span><br><span class="line">        shape = self.batch_shapes[self.batch[</span><br><span class="line">            index]] if self.rect else self.img_size</span><br><span class="line">        img, ratio, pad = letterbox(img,</span><br><span class="line">                                    shape,</span><br><span class="line">                                    auto=False,</span><br><span class="line">                                    scaleup=self.augment)</span><br><span class="line">        shapes = (h0, w0), (</span><br><span class="line">            (h / h0, w / w0), pad)</span><br><span class="line"></span><br><span class="line">        # 加载标注文件</span><br><span class="line">        labels = []</span><br><span class="line">        if os.path.isfile(label_path):</span><br><span class="line">            x = self.labels[index]</span><br><span class="line">            if x is None:  # 如果标签没有加载，读取label_path内容</span><br><span class="line">                with open(label_path, &#x27;r&#x27;) as f:</span><br><span class="line">                    x = np.array(</span><br><span class="line">                        [x.split() for x in f.read().splitlines()],</span><br><span class="line">                        dtype=np.float32)</span><br><span class="line"></span><br><span class="line">            if x.size &gt; 0:</span><br><span class="line">                # 将归一化后的xywh转化为左上角、右下角的表达形式</span><br><span class="line">                labels = x.copy()</span><br><span class="line">                labels[:, 1] = ratio[0] * w * (</span><br><span class="line">                    x[:, 1] - x[:, 3] / 2) + pad[0]  # pad width</span><br><span class="line">                labels[:, 2] = ratio[1] * h * (</span><br><span class="line">                    x[:, 2] - x[:, 4] / 2) + pad[1]  # pad height</span><br><span class="line">                labels[:, 3] = ratio[0] * w * (x[:, 1] +</span><br><span class="line">                                               x[:, 3] / 2) + pad[0]</span><br><span class="line">                labels[:, 4] = ratio[1] * h * (x[:, 2] +</span><br><span class="line">                                               x[:, 4] / 2) + pad[1]</span><br><span class="line"></span><br><span class="line">    if self.augment:</span><br><span class="line">        # 图片空间的数据增强</span><br><span class="line">        if not mosaic:</span><br><span class="line">            # 如果没有使用组合的方法，那么对图片进行随机放射</span><br><span class="line">            img, labels = random_affine(img,</span><br><span class="line">                                        labels,</span><br><span class="line">                                        degrees=hyp[&#x27;degrees&#x27;],</span><br><span class="line">                                        translate=hyp[&#x27;translate&#x27;],</span><br><span class="line">                                        scale=hyp[&#x27;scale&#x27;],</span><br><span class="line">                                        shear=hyp[&#x27;shear&#x27;])</span><br><span class="line"></span><br><span class="line">        # 增强hsv空间</span><br><span class="line">        augment_hsv(img,</span><br><span class="line">                    hgain=hyp[&#x27;hsv_h&#x27;],</span><br><span class="line">                    sgain=hyp[&#x27;hsv_s&#x27;],</span><br><span class="line">                    vgain=hyp[&#x27;hsv_v&#x27;])</span><br><span class="line"></span><br><span class="line">    nL = len(labels)  # 标注文件个数</span><br><span class="line"></span><br><span class="line">    if nL:</span><br><span class="line">        # 将 xyxy 格式转化为 xywh 格式</span><br><span class="line">        labels[:, 1:5] = xyxy2xywh(labels[:, 1:5])</span><br><span class="line"></span><br><span class="line">        # 归一化到0-1之间</span><br><span class="line">        labels[:, [2, 4]] /= img.shape[0]  # height</span><br><span class="line">        labels[:, [1, 3]] /= img.shape[1]  # width</span><br><span class="line"></span><br><span class="line">    if self.augment:</span><br><span class="line">        # 随机左右翻转</span><br><span class="line">        lr_flip = True</span><br><span class="line">        if lr_flip and random.random() &lt; 0.5:</span><br><span class="line">            img = np.fliplr(img)</span><br><span class="line">            if nL:</span><br><span class="line">                labels[:, 1] = 1 - labels[:, 1]</span><br><span class="line"></span><br><span class="line">        # 随机上下翻转</span><br><span class="line">        ud_flip = False</span><br><span class="line">        if ud_flip and random.random() &lt; 0.5:</span><br><span class="line">            img = np.flipud(img)</span><br><span class="line">            if nL:</span><br><span class="line">                labels[:, 2] = 1 - labels[:, 2]</span><br><span class="line"></span><br><span class="line">    labels_out = torch.zeros((nL, 6))</span><br><span class="line">    if nL:</span><br><span class="line">        labels_out[:, 1:] = torch.from_numpy(labels)</span><br><span class="line"></span><br><span class="line">    # 图像维度转换</span><br><span class="line">    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416</span><br><span class="line">    img = np.ascontiguousarray(img)</span><br><span class="line"></span><br><span class="line">    return torch.from_numpy(img), labels_out, img_path, shapes</span><br></pre></td></tr></table></figure>
<p>下图是开启了组合和旋转以后的增强效果</p>
<p>这里理解组合就是将四张图片，以不同的比例，合成为一张图片。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/pyyolov3/645.webp" alt></p>
<h3 id="3-3-collate-fn函数"><a href="#3-3-collate-fn函数" class="headerlink" title="3.3 collate_fn函数"></a>3.3 collate_fn函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@staticmethod</span><br><span class="line">def collate_fn(batch):</span><br><span class="line">    img, label, path, shapes = zip(*batch)  # transposed</span><br><span class="line">    for i, l in enumerate(label):</span><br><span class="line">        l[:, 0] = i  # add target image index for build_targets()</span><br><span class="line">    return torch.stack(img, 0), torch.cat(label, 0), path, shapes</span><br></pre></td></tr></table></figure>
<p>还有最后一点内容，是关于pytorch的数据读取机制，在pytorch的dataloader中是会对通过getitem方法得到的结果（batch）进行包装，而这个包装可能与我们想要的有所不同。默认的方法可以看以下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">def default_collate(batch):</span><br><span class="line">    r&quot;&quot;&quot;Puts each data field into a tensor with outer dimension batch size&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    elem_type = type(batch[0])</span><br><span class="line">    if isinstance(batch[0], torch.Tensor):</span><br><span class="line">        out = None</span><br><span class="line">        if _use_shared_memory:</span><br><span class="line">            # If we&#x27;re in a background process, concatenate directly into a</span><br><span class="line">            # shared memory tensor to avoid an extra copy</span><br><span class="line">            numel = sum([x.numel() for x in batch])</span><br><span class="line">            storage = batch[0].storage()._new_shared(numel)</span><br><span class="line">            out = batch[0].new(storage)</span><br><span class="line">        return torch.stack(batch, 0, out=out)</span><br><span class="line">    elif elem_type.__module__ == &#x27;numpy&#x27; and elem_type.__name__ != &#x27;str_&#x27; \</span><br><span class="line">            and elem_type.__name__ != &#x27;string_&#x27;:</span><br><span class="line">        elem = batch[0]</span><br><span class="line">        if elem_type.__name__ == &#x27;ndarray&#x27;:</span><br><span class="line">            # array of string classes and object</span><br><span class="line">            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:</span><br><span class="line">                raise TypeError(error_msg_fmt.format(elem.dtype))</span><br><span class="line"></span><br><span class="line">            return default_collate([torch.from_numpy(b) for b in batch])</span><br><span class="line">        if elem.shape == ():  # scalars</span><br><span class="line">            py_type = float if elem.dtype.name.startswith(&#x27;float&#x27;) else int</span><br><span class="line">            return numpy_type_map[elem.dtype.name](list(map(py_type, batch)))</span><br><span class="line">    elif isinstance(batch[0], float):</span><br><span class="line">        return torch.tensor(batch, dtype=torch.float64)</span><br><span class="line">    elif isinstance(batch[0], int_classes):</span><br><span class="line">        return torch.tensor(batch)</span><br><span class="line">    elif isinstance(batch[0], string_classes):</span><br><span class="line">        return batch</span><br><span class="line">    elif isinstance(batch[0], container_abcs.Mapping):</span><br><span class="line">        return &#123;key: default_collate([d[key] for d in batch]) for key in batch[0]&#125;</span><br><span class="line">    elif isinstance(batch[0], tuple) and hasattr(batch[0], &#x27;_fields&#x27;):  # namedtuple</span><br><span class="line">        return type(batch[0])(*(default_collate(samples) for samples in zip(*batch)))</span><br><span class="line">    elif isinstance(batch[0], container_abcs.Sequence):</span><br><span class="line">        transposed = zip(*batch)</span><br><span class="line">        return [default_collate(samples) for samples in transposed]</span><br><span class="line"></span><br><span class="line">    raise TypeError((error_msg_fmt.format(type(batch[0]))))</span><br></pre></td></tr></table></figure>
<p>会根据你的数据类型进行相应的处理，但是这往往不是我们需要的，所以需要修改<code>collate_fn</code>,具体内容请看代码，比较简单，就不多赘述。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a><a class="post-meta__tags" href="/tags/YOLOv3/">YOLOv3</a></div><div class="post_share"><div class="social-share" data-image="/img/1097380.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/02/15/YOLOv3%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E8%BF%9B%E5%8C%96/"><img class="prev-cover" src="/img/34125236_p0.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">YOLOv3中的参数进化</div></div></a></div><div class="next-post pull-right"><a href="/2020/02/15/Pytorch%E7%89%88YOLOv3%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%A0%81%E9%85%8D%E7%BD%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E6%9E%84%E5%BB%BA/"><img class="next-cover" src="/img/40356157_p0.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Pytorch版YOLOv3中的代码配置和数据集构建</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/04/17/AlexeyAB-DarkNet-Dropout层代码详解/" title="AlexeyAB DarkNet Dropout层代码详解"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-17</div><div class="title">AlexeyAB DarkNet Dropout层代码详解</div></div></a></div><div><a href="/2020/03/01/AlexeyAB-DarkNet-BN层代码详解(batchnorm_layer.c)/" title="AlexeyAB DarkNet BN层代码详解(batchnorm_layer.c)"><img class="cover" src="/img/34125236_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-01</div><div class="title">AlexeyAB DarkNet BN层代码详解(batchnorm_layer.c)</div></div></a></div><div><a href="/2020/02/29/AlexeyAB-DarkNet池化层代码详解(maxpool_layer.c)/" title="AlexeyAB DarkNet池化层代码详解(maxpool_layer.c)"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-29</div><div class="title">AlexeyAB DarkNet池化层代码详解(maxpool_layer.c)</div></div></a></div><div><a href="/2020/02/28/YOLOV3损失函数代码详解(yolo_layer.c)/" title="YOLOV3损失函数代码详解(yolo_layer.c)"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-28</div><div class="title">YOLOV3损失函数代码详解(yolo_layer.c)</div></div></a></div><div><a href="/2020/02/27/YOLOV2损失函数代码详解(region_layer.c)/" title="YOLOV2损失函数代码详解(region_layer.c)"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-27</div><div class="title">YOLOV2损失函数代码详解(region_layer.c)</div></div></a></div><div><a href="/2020/02/26/YOLOV1损失函数代码详解(detection_layer.c)/" title="YOLOV1损失函数代码详解(detection_layer.c)"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-02-26</div><div class="title">YOLOV1损失函数代码详解(detection_layer.c)</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A0%87%E6%B3%A8%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.</span> <span class="toc-text"> 1. 标注格式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E8%B0%83%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">2. 调用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-YOLOv3%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="toc-number">3.</span> <span class="toc-text">3. YOLOv3中的数据加载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-init%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 init函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-getitem%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 getitem函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-collate-fn%E5%87%BD%E6%95%B0"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 collate_fn函数</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Qiyuan-Z</div><div class="footer_custom_text">昨日までの私は、もうどこにもいない</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '2d10cfb27783db577e70',
      clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
      repo: 'gitalk',
      owner: 'Qiyuan-Z',
      admin: ['Qiyuan-Z'],
      id: '0108ec8c9d1671136988422ddd0d5f69',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>