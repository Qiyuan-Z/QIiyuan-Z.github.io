<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://Qiyuan-Z.github.io').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta property="og:type" content="article">
<meta property="og:title" content="AlexeyAB版Darknet使用教程">
<meta property="og:url" content="https://qiyuan-z.github.io/2020/02/20/AlexeyAB%E7%89%88Darknet%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/index.html">
<meta property="og:site_name" content="Yuan">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/640.jpg">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/641.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/642.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/643.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/644.jpg">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/645.webp">
<meta property="og:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/646.webp">
<meta property="article:published_time" content="2020-02-20T01:30:53.277Z">
<meta property="article:modified_time" content="2020-02-20T02:48:15.651Z">
<meta property="article:author" content="Qiyuan-Z">
<meta property="article:tag" content="目标检测">
<meta property="article:tag" content="YOLOv3">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/640.jpg">

<link rel="canonical" href="https://qiyuan-z.github.io/2020/02/20/AlexeyAB%E7%89%88Darknet%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style>
  <title>AlexeyAB版Darknet使用教程 | Yuan</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yuan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">记录学习中的点点滴滴</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://qiyuan-z.github.io/2020/02/20/AlexeyAB%E7%89%88Darknet%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Qiyuan-Z">
      <meta itemprop="description" content="偉大な魂は目的を持ち、そうでないものは願望を持つ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yuan">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AlexeyAB版Darknet使用教程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-02-20 09:30:53 / 修改时间：10:48:15" itemprop="dateCreated datePublished" datetime="2020-02-20T09:30:53+08:00">2020-02-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>23k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>21 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="前言"><a href="#前言" class="headerlink" title=" 前言"></a><a id="more"></a> 前言</h2><p>自从Joseph Redmon提出了yolov3后，其darknet仓库已经获得了16k的star，足以说明darknet的流行。该作者最新一次更新也是一年前了，没有继续维护。不过自来自俄国的大神AlexeyAB在不断地更新darknet, 不仅添加了darknet在window下的适配，而且实现了多种SOTA目标检测算法。AlexeyAB也在库中提供了一份详细的建议，从编译、配置、涉及网络到测量指标等，一应俱全。通过阅读和理解AlexeyAB的建议，可以为我们带来很多启发。本文是来自翻译AlexeyAB的darknet中的README。</p>
<p>下图是CSPNet中统计的目前的State of the Art的目标检测模型。其中csresnext50-panet-spp-optimal模型是CSPNet中提出来的，结合AlexeyAB版本的Darknet就可以实现。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/640.jpg" alt></p>
<h2 id="1-依赖"><a href="#1-依赖" class="headerlink" title="1. 依赖"></a>1. 依赖</h2><h3 id="1-1-环境要求"><a href="#1-1-环境要求" class="headerlink" title="1.1 环境要求"></a>1.1 环境要求</h3><ul>
<li>window系统或者linux系统。</li>
<li>CMake版本高于3.8。</li>
<li>CUDA 10.0，cuDNN&gt;=7.0。</li>
<li>OpenCV版本高于2.4。</li>
<li>Linux下需要GCC 或者Clang, Window下需要Visual Studio 15、17或19版。</li>
</ul>
<h3 id="1-2-数据集获取"><a href="#1-2-数据集获取" class="headerlink" title="1.2 数据集获取"></a>1.2 数据集获取</h3><ol>
<li>MS COCO数据集: 使用<code>./scripits/get_coco_dataset.sh</code>来获取数据集。</li>
<li>OpenImages数据集: 使用<code>./scripits/get_openimages_dataset.py</code>获取数据集,并按照规定的格式重排训练集。</li>
<li>Pascal VOC数据集: 使用<code>./scripits/voc_label.py</code>对数据集标注进行处理。</li>
<li>ILSVRC2012数据集(ImageNet Classification): 使用<code>./scripits/get_imagenet_train.sh</code>获取数据集，运行<code>./scripits/imagenet_label.sh</code>用于验证集。</li>
<li>German/Belgium/Russian/LISA/MASTIF 交通标志数据集。</li>
<li>其他数据集，请访问<code>https://github.com/AlexeyAB/darknet/tree/master/scripts#datasets</code></li>
</ol>
<p>结果示意：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/641.webp" alt></p>
<p>其他测试结果可以访问:<code>https://www.youtube.com/user/pjreddie/videos</code></p>
<h2 id="2-相比原作者Darknet的改进"><a href="#2-相比原作者Darknet的改进" class="headerlink" title="2. 相比原作者Darknet的改进"></a>2. 相比原作者Darknet的改进</h2><ul>
<li>添加了对windows下运行darknet的支持。</li>
<li>添加了SOTA模型： CSPNet, PRN, EfficientNet。</li>
<li>在官方Darknet的基础上添加了新的层：[conv_lstm], [scale_channels] SE/ASFF/BiFPN, [local_avgpool], [sam],  [Gaussian_yolo], [reorg3d] (修复 [reorg]), 修复 [batchnorm]。</li>
<li>可以使用<code>[conv_lstm]</code>层或者<code>[crnn]</code>层来实现针对视频的目标检测。</li>
<li>添加了多种数据增强策略: <code>[net] mixup=1 cutmix=1 mosaic=1 blur=1</code>。</li>
<li>添加了多种激活函数: SWISH, MISH, NORM_CHAN, NORM\CHAN_SOFTMAX。</li>
<li>增加了使用CPU-RAM提高GPU处理训练的能力，以增加<code>mini_batch_size</code>和准确性。</li>
<li>提升了二值网络，让其在CPU和GPU上的训练和测试速度变为原来的2-4倍。</li>
<li>通过将Convolutional层和Batch-Norm层合并成一个层，提升了约7%速度。</li>
<li>如果在Makefile中使用CUDNN_HALF参数，可以让网络在TeslaV100，GeForce RTX等型号的GPU上的检测速度提升两倍。</li>
<li>针对视频的检测进行了优化，对高清视频检测速度可以提升1.2倍，对4k的视频检测速度可以提升2倍。</li>
<li>数据增强部分使用Opencv SSE/AVX指令优化了原来朴素实现的数据增强，数据增强速度提升为原来的3.5倍。</li>
<li>在CPU上使用AVX指令来提高了检测速度，yolov3提高了约85%。</li>
<li>在网络多尺度训练（<code>random=1</code>）的时候优化了内存分配。</li>
<li>优化了检测时的GPU初始化策略，在bacth=1的时候执行初始化而不是当batch=1的时候重新初始化。</li>
<li>添加了计算mAP,F1,IoU, Precision-Recall等指标的方法，只需要运行<code>darknet detector map</code>命令即可。</li>
<li>支持在训练的过程中画loss曲线和准确率曲线，只需要添加<code>-map</code>标志即可。</li>
<li>提供了<code>-json_port</code>,<code>-mjpeg_port</code>选项，支持作为json和mjpeg 服务器来在线获取的结果。可以使用你的编写的软件或者web浏览器与<strong>json和mjpeg服务器</strong>连接。</li>
<li>添加了Anchor的计算功能，可以根据数据集来聚类得到合适的Anchor。</li>
<li>添加了一些目标检测和目标跟踪的示例：<code>https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp</code></li>
<li>在使用错误的cfg文件或者数据集的时候，添加了运行时的建议和警告。</li>
<li>其它一些代码修复。</li>
</ul>
<h2 id="3-命令行使用"><a href="#3-命令行使用" class="headerlink" title="3. 命令行使用"></a>3. 命令行使用</h2><p>Linux中使用./darknet，window下使用darknet.exe.</p>
<p>Linux中命令格式类似<code>./darknet detector test ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights</code></p>
<p>Linux中的可执行文件在根目录下，Window下则在<code>\build\darknet\x64</code>文件夹中。以是不同情况下应该使用的命令：</p>
<ul>
<li>Yolo v3 COCO - <strong>图片测试</strong>: <code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -thresh 0.25</code></li>
<li><strong>输出坐标</strong> of objects: <code>darknet.exe detector test cfg/coco.data yolov3.cfg yolov3.weights -ext_output dog.jpg</code></li>
<li>Yolo v3 COCO - <strong>视频测试</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -ext_output test.mp4</code></li>
<li><strong>网络摄像头</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights -c 0</code></li>
<li><strong>网络视频摄像头</strong> - Smart WebCam: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg</code></li>
<li>Yolo v3 - <strong>保存视频结果为res.avi</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3.cfg yolov3.weights test.mp4 -out_filename res.avi</code></li>
<li>Yolo v3 <strong>Tiny版本</strong> COCO - video: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights test.mp4</code></li>
<li><strong>JSON and MJPEG 服务器</strong> ：创建JSON和MJPEG服务器，允许软件或Web浏览器进行与服务器之间进行多个连接 。假设两者需要的端口为<code>ip-address:8070</code> 和 <code>8090</code>: <code>./darknet detector demo ./cfg/coco.data ./cfg/yolov3.cfg ./yolov3.weights  test50.mp4 -json_port 8070 -mjpeg_port 8090 -ext_output</code></li>
<li>Yolo v3 <strong>Tiny</strong> <strong>on GPU</strong>: <code>darknet.exe detector demo cfg/coco.data cfg/yolov3-tiny.cfg yolov3-tiny.weights -i 1 test.mp4</code></li>
<li>另一个可进行图片测试的命令 Yolo v3 COCO - <strong>图片测试</strong>: <code>darknet.exe detect cfg/yolov3.cfg yolov3.weights -i 0 -thresh 0.25</code></li>
<li>在 <strong>Amazon EC2</strong>上训练, 如果想要看mAP和Loss曲线，运行以下命令: <code>http://ec2-35-160-228-91.us-west-2.compute.amazonaws.com:8090</code>  (<strong>Darknet 必须使用OpenCV进行编译才能使用该功能</strong>): <code>./darknet detector train cfg/coco.data yolov3.cfg darknet53.conv.74 -dont_show -mjpeg_port 8090 -map</code></li>
<li>186 MB Yolo9000 - <strong>图片分类</strong>: <code>darknet.exe detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights</code></li>
<li><strong>处理一系列图片，并保存结果为json文件</strong>：<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -ext_output  -dont_show -out result.json &lt; data/train.txt</code></li>
<li><strong>处理一系列图片，并保存结果为txt文件</strong>:<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -dont_show -ext_output &lt; data/train.txt &gt; result.txt</code></li>
<li><strong>伪标注：</strong> 处理一个list的图片 <code>data/new_train.txt</code> ，可以让结果保存为Yolo训练所需的格式，标注文件为 <code>.txt</code> 。通过这种方法可以迅速增加训练数据量。具体命令为:<code>darknet.exe detector test cfg/coco.data cfg/yolov3.cfg yolov3.weights -thresh 0.25  -dont_show -save_labels &lt; data/new_train.txt</code></li>
<li><strong>如何计算anchor</strong>(通过聚类得到): <code>darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416</code></li>
<li><strong>计算mAP@IoU=50</strong>: <code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights</code></li>
<li><strong>计算mAP@IoU=75</strong>: <code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights -iou_thresh 0.75</code></li>
</ul>
<p><strong>利用Video-Camera和Mjepg-Stream在Android智能设备中运行YOLOv3</strong></p>
<ol>
<li><p>下载 mjpeg-stream APP: IP Webcam / Smart WebCam:</p>
</li>
<li><ul>
<li>Smart WebCam - 从此处下载: <code>https://play.google.com/store/apps/details?id=com.acontech.android.SmartWebCam2</code></li>
<li>IP Webcam下载地址: <code>https://play.google.com/store/apps/details?id=com.pas.webcam</code></li>
</ul>
</li>
<li><p>将你的手机与电脑通过WIFI或者USB相连。</p>
</li>
<li><p>开启手机中的Smart WebCam APP。</p>
</li>
<li><p>将以下IP地址替换,在Smart WebCam APP中显示，并运行以下命令：</p>
</li>
</ol>
<p>Yolo v3 COCO-model: <code>darknet.exe detector demo data/coco.data yolov3.cfg yolov3.weights http://192.168.0.80:8080/video?dummy=param.mjpg -i 0</code></p>
<h2 id="4-Linux下如何编译Darknet"><a href="#4-Linux下如何编译Darknet" class="headerlink" title="4. Linux下如何编译Darknet"></a>4. Linux下如何编译Darknet</h2><h3 id="4-1-使用CMake编译Darknet"><a href="#4-1-使用CMake编译Darknet" class="headerlink" title="4.1 使用CMake编译Darknet"></a>4.1 使用CMake编译Darknet</h3><p>CMakeList.txt是一个尝试发现所有安装过的、可选的依赖项(比如CUDA，cuDNN, ZED)的配置文件，然后使用这些依赖项进行编译。它将创建一个共享库文件，这样就可以使用Darknet进行代码开发。</p>
<p>在克隆了项目库以后按照以下命令进行执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir build-release</span><br><span class="line">cd build-release</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<h3 id="4-2-使用make编译Darknet"><a href="#4-2-使用make编译Darknet" class="headerlink" title="4.2 使用make编译Darknet"></a>4.2 使用make编译Darknet</h3><p>在克隆了项目库以后，直接运行<code>make</code>命令，需要注意的是Makefile中有一些可选参数：</p>
<ul>
<li>GPU=1代表编译完成后将可以使用CUDA来进行GPU加速(CUDA应该在<code>/usr/local/cuda</code>中)。</li>
<li>CUDNN=1代表通过cuDNN v5-v7进行编译，这样将可以加速使用GPU训练过程(cuDNN应该在<code>/usr/local/cudnn</code>中)。</li>
<li>CUDNN_HALF=1代表在编译的过程中是否添加Tensor Cores, 编译完成后将可以将目标检测速度提升为原来的3倍，训练网络的速度提高为原来的2倍。</li>
<li>OPENCV=1代表编译的过程中加入OpenCV, 目前支持的OpenCV的版本有4.x/3.x/2.4.x， 编译结束后将允许Darknet对网络摄像头的视频流或者视频文件进行目标检测。</li>
<li>DEBUG=1 代表是否开启YOLO的debug模式。</li>
<li>OPENMP=1代表编译过程将引入openmp,编译结束后将代表可以使用多核CPU对yolo进行加速。</li>
<li>LIBSO=1 代表编译库darknet.so。</li>
<li>ZED_CAMERA=1 构建具有ZED-3D相机支持的库(应安装ZED SDK)，然后运行。</li>
</ul>
<h2 id="5-如何在Window下编译Darknet"><a href="#5-如何在Window下编译Darknet" class="headerlink" title="5. 如何在Window下编译Darknet"></a>5. 如何在Window下编译Darknet</h2><h3 id="5-1-使用CMake-GUI进行编译"><a href="#5-1-使用CMake-GUI进行编译" class="headerlink" title="5.1 使用CMake-GUI进行编译"></a>5.1 使用CMake-GUI进行编译</h3><p>建议使用以下方法来完成Window下Darknet的编译，需要环境有：Visual Studio 15/17/19, CUDA&gt;10.0, cuDNN&gt;7.0, OpenCV&gt;2.4</p>
<p>使用CMake-GUI编译流程：</p>
<ol>
<li>Configure.</li>
<li>Optional platform for generator (Set: x64) .</li>
<li>Finish.</li>
<li>Generate.</li>
<li>Open Project.</li>
<li>Set: x64 &amp; Release.</li>
<li>Build.</li>
<li>Build solution.</li>
</ol>
<h3 id="5-2-使用vcpkg进行编译"><a href="#5-2-使用vcpkg进行编译" class="headerlink" title="5.2 使用vcpkg进行编译"></a>5.2 使用vcpkg进行编译</h3><p>如果你已经满足Visual Studio 15/17/19 、CUDA&gt;10.0、 cuDNN&gt;7.0、OpenCV&gt;2.4的条件, 那么推荐使用通过CMake-GUI的方式进行编译。</p>
<p>否则按照以下步骤进行编译:</p>
<ul>
<li>安装或更新Visual Studio到17+,确保已经对其进行全面修补。</li>
<li>安装CUDA和cuDNN。</li>
<li>安装Git和CMake, 并将它们加入环境变量中。</li>
<li>安装vcpkg然后尝试安装一个测试库来确认安装是正确的，比如：<code>vcpkg install opengl</code>。</li>
<li>定义一个环境变量<code>VCPKG_ROOT</code>, 指向vcpkg的安装路径。</li>
<li>定义另一个环境变量<code>VCPKG_DEFAULT_TRIPLET</code>将其指向x64-windows。</li>
<li>打开Powershell然后运行以下命令：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS \&gt;                  cd $env:VCPKG_ROOT</span><br><span class="line">PS Code\vcpkg&gt;         .\vcpkg install pthreads opencv[ffmpeg] </span><br><span class="line">#replace with opencv[cuda,ffmpeg] in case you want to use cuda-accelerated openCV</span><br></pre></td></tr></table></figure>
<ul>
<li>打开Powershell, 切换到darknet文件夹，然后运行<code>.\build.ps1</code>进行编译。如果要使用Visual Studio，将在Build后找到CMake为您创建的两个自定义解决方案，一个在<code>build_win_debug</code>中，另一个在<code>build_win_release</code>中，其中包含适用于系统的所有配置标志。</li>
</ul>
<h3 id="5-3-使用legacy-way进行编译"><a href="#5-3-使用legacy-way进行编译" class="headerlink" title="5.3 使用legacy way进行编译"></a>5.3 使用legacy way进行编译</h3><ul>
<li><p>如果你有CUDA10.0、cuDNN 7.4 和OpenCV 3.x , 那么打开<code>build\darknet\darknet.sln</code>, 设置x64和Release 然后运行Build， 进行darknet的编译，将cuDNN加入环境变量中。</p>
<ul>
<li>在<code>C:\opencv_3.0\opencv\build\x64\vc14\bin</code>找到<code>opencv_world320.dll</code>和<code>opencv_ffmpeg320_64.dll</code>, 然后将其复制到<code>darknet.exe</code>同级目录中。</li>
<li>在<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0</code>中检查是否含有bin和include文件夹。如果没有这两个文件夹，那就将他们从CUDA安装的地方复制到这个地方。</li>
<li>安装cuDNN 7.4.1 来匹配CUDA 10.0, 将cuDNN添加到环境变量<code>CUDNN</code>。将<code>cudnn64_7.dll</code>复制到<code>\build\darknet\x64</code>中。</li>
</ul>
</li>
<li><p>如果你是用的是其他版本的CUDA（不是CUDA 10.0）, 那么使用Notepad打开<code>build\darknet\darknet.vxcproj</code>, 将其中的CUDA 10.0替换为你的CUDA的版本。然后打开<code>\darknet.sln</code>, 然后右击工程，点击属性properties, 选择CUDA C/C++, 然后选择Device , 然后移除<code>compute_75,sm_75</code>。之后从第一步从头开始执行。</p>
</li>
<li><p>如果你没有GPU但是有OpenCV3.0， 那么打开<code>build\darknet\darknet_no_gpu.sln</code>, 设置x64和Release， 然后运行build -&gt; build darknet_no_gpu。</p>
</li>
<li><p>如果你只安装了OpenCV 2.4.14，那你应该修改<code>\darknet.sln</code>中的路径。</p>
</li>
<li><ul>
<li>(右键点击工程) -&gt; properties -&gt; C/C++ -&gt; General -&gt; Additional Include Directories: <code>C:\opencv_2.4.13\opencv\build\include</code></li>
<li>(右键点击工程)-&gt; properties -&gt; Linker -&gt; General -&gt; Additional Library Directories: <code>C:\opencv_2.4.13\opencv\build\x64\vc14\lib</code></li>
</ul>
</li>
<li><p>如果你的GPU有Tensor Cores(Nvidia Titan V/ Tesla V100/ DGX-2等型号)， 可以提升目标检测模型测试速度为原来的3倍，训练速度变为原来的2倍。<code>\darknet.sln</code> -&gt; (右键点击工程) -&gt; properties -&gt; C/C++ -&gt; Preprocessor -&gt; Preprocessor Definitions, and add here: <code>CUDNN_HALF;</code></p>
<p><strong>注意</strong>：CUDA 必须在Visual Studio安装后再安装。</p>
</li>
</ul>
<h2 id="6-如何训练"><a href="#6-如何训练" class="headerlink" title="6. 如何训练"></a>6. 如何训练</h2><h3 id="6-1-Pascal-VOC-dataset"><a href="#6-1-Pascal-VOC-dataset" class="headerlink" title="6.1 Pascal VOC dataset"></a>6.1 Pascal VOC dataset</h3><ol>
<li><p>下载预训练模型 (154 MB): <code>http://pjreddie.com/media/files/darknet53.conv.74</code> 将其放在 <code>build\darknet\x64</code>文件夹中。</p>
</li>
<li><p>下载pascal voc数据集并解压到 <code>build\darknet\x64\data\voc</code> 放在 <code>build\darknet\x64\data\voc\VOCdevkit\</code>文件夹中:</p>
<p>2.1 下载 <code>voc_label.py</code> 到 <code>build\darknet\x64\data\voc</code>，地址为: <code>http://pjreddie.com/media/files/voc_label.py。</code></p>
</li>
<li><ul>
<li><code>http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar</code>。</li>
<li><code>http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar</code>。</li>
<li><code>http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar</code>。</li>
</ul>
</li>
<li><p>下载并安装python: <code>https://www.python.org/ftp/python/3.5.2/python-3.5.2-amd64.exe</code></p>
</li>
<li><p>运行命令: <code>python build\darknet\x64\data\voc\voc_label.py</code> (来生成文件: 2007_test.txt, 2007_train.txt, 2007_val.txt, 2012_train.txt, 2012_val.txt)。</p>
</li>
<li><p>运行命令: <code>type 2007_train.txt 2007_val.txt 2012_*.txt &gt; train.txt</code>。</p>
</li>
<li><p>在 <code>yolov3-voc.cfg</code>文件中设置 <code>batch=64</code> 和<code>subdivisions=8</code>。</p>
</li>
<li><p>使用 <code>train_voc.cmd</code> 或者使用以下命令开始训练:</p>
<p><code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74</code>。</p>
</li>
</ol>
<p>(<strong>Note:</strong> 如果想要停止loss显示，添加 <code>-dont_show</code>标志. 如果使用CPU运行, 用<code>darknet_no_gpu.exe</code> 代替 <code>darknet.exe</code>。)</p>
<p>如果想要改数据集路径的话，请修改 <code>build\darknet\cfg\voc.data</code>文件。</p>
<p><strong>Note:</strong> 在训练中如果你看到avg为nan，那证明训练出错。但是如果在其他部分出现nan，这属于正常现象，训练过程是正常的。</p>
<h3 id="6-2-如何使用多GPU训练？"><a href="#6-2-如何使用多GPU训练？" class="headerlink" title="6.2 如何使用多GPU训练？"></a>6.2 如何使用多GPU训练？</h3><ol>
<li>首先在一个GPU中训练大概1000个轮次: <code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg darknet53.conv.74</code>。</li>
<li>然后停下来基于这个保存的模型 <code>/backup/yolov3-voc_1000.weights</code> 使用多GPU (最多4个GPU): <code>darknet.exe detector train cfg/voc.data cfg/yolov3-voc.cfg /backup/yolov3-voc_1000.weights -gpus 0,1,2,3</code>。</li>
</ol>
<p>在多GPU训练的时候，<code>learning rate</code>需要进行修改，比如单<code>gpu使用0.001</code>，那么多gpu应该使用0.001/GPUS。然后<code>cfg</code>文件中的<code>burn_in</code>参数和<code>max_batches</code>参数要设置为原来的GPUS倍。</p>
<h3 id="6-3-训练自定义数据集-重点关注"><a href="#6-3-训练自定义数据集-重点关注" class="headerlink" title="6.3 训练自定义数据集(重点关注)"></a>6.3 训练自定义数据集(重点关注)</h3><p>训练较早提出的Yolo系列算法如<code>yolov2-voc.cfg</code>, <code>yolov2-tiny-voc.cfg</code>, <code>yolo-voc.cfg</code>, <code>yolo-voc.2.0.cfg</code>，请看<code>https://github.com/AlexeyAB/darknet/tree/47c7af1cea5bbdedf1184963355e6418cb8b1b4f#how-to-train-pascal-voc-data</code>。</p>
<p>Training Yolo v3:</p>
<ol>
<li>创建与 <code>yolov3.cfg</code>内容相同的 <code>yolo-obj.cfg</code> 或者直接复制然后重命名为<code>yolo-obj.cfg</code> 然后</li>
</ol>
<ul>
<li><p>设置<code>cfg</code>文件中 <code>batch=64</code>。</p>
</li>
<li><p>设置<code>cfg</code>文件中 <code>subdivisions=16</code>。</p>
</li>
<li><p>设置<code>cfg</code>文件中<code>max_batches</code>参数 (一般可以设置为<code>classes*2000</code> 但是不要低于 <code>4000</code>), 比如 如果你有三个类，那么设置<code>max_batches=6000</code>。</p>
</li>
<li><p>设置<code>steps</code>参数，一般为80%和90%的<code>max_batches</code>。比如 <code>steps=4800,5400</code></p>
</li>
<li><p>设置网络输入长宽必须能够整除32，比如 <code>width=416 height=416</code> `</p>
</li>
<li><p>修改yolo层中的 <code>classes=80</code> 改为你的类别的个数，比如<code>classes=3</code>:</p>
</li>
<li><p>修改yolo层前一个卷积层convolutional输出通道数。修改的<code>filter</code>个数有一定要求，按照公式<code>filters=(classes+5)×3</code>来设置。这里的<code>5</code>代表<code>x, y, w, h, conf</code>, 这里的<code>3</code>代表分配<code>3</code>个anchor。</p>
</li>
<li><p>如果使用 <code>[Gaussian_yolo]</code> (Gaussian_yolov3_BDD.cfg)，<code>filters</code>计算方式不太一样，按照 <code>filters=(classes + 9)x3</code>进行计算。</p>
</li>
<li><p>通常来讲，filters的个数计算依赖于类别个数，坐标以及<code>mask</code>的个数（<code>cfg</code>中的<code>mask</code>参数也就是<code>anchors</code>的个数）。</p>
<p>举个例子,对于两个目标,你的 <code>yolo-obj.cfg</code> 和<code>yolov3.cfg</code> 不同的地方应该在每个<code>[yolo]/[region]</code>层的下面几行:</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[convolutional]</span><br><span class="line">filters&#x3D;21</span><br><span class="line"></span><br><span class="line">[region]</span><br><span class="line">classes&#x3D;2</span><br></pre></td></tr></table></figure>
<ol>
<li>在<code>build\darknet\x64\data\</code>创建文件 <code>obj.names</code> , 每行一个类别的名称。</li>
<li>在<code>build\darknet\x64\data\</code> 创建<code>obj.data</code>, 具体内容如下:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">classes&#x3D; 2 # 你的类别的个数</span><br><span class="line">train  &#x3D; data&#x2F;train.txt # 存储用于训练的图片位置</span><br><span class="line">valid  &#x3D; data&#x2F;test.txt # 存储用于测试的图片的位置</span><br><span class="line">names &#x3D; data&#x2F;obj.names # 每行一个类别的名称</span><br><span class="line">backup &#x3D; backup&#x2F;</span><br></pre></td></tr></table></figure>
<ol>
<li>将你的图片放在 <code>build\darknet\x64\data\obj\</code>文件夹下。</li>
<li>你应该标注你的数据集中的每一张图片，使用<code>Yolo_mark</code>这个可视化GUI软件来标注出目标框并且产生标注文件。地址： <code>https://github.com/AlexeyAB/Yolo_mark</code>。</li>
</ol>
<p>软件将会为每一个图像创建一个<code>txt</code>文件，并将其放在同一个文件夹中，命名与原图片的名称相同，唯一不同的就是后缀是txt。txt标注文件中每一个目标独占一行，按照<code>&lt;object-class&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code>的格式排布。</p>
<p>具体参数解释：</p>
<ul>
<li><p><code>&lt;object-class&gt;</code>- 是从 <code>0</code> 到 <code>(classes-1)</code>的整数，代表具体的类别。</p>
</li>
<li><p><code>&lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code> -  是归一化到<code>(0.0 to 1.0]</code>之间的浮点数，都是相对于图片整体的宽和高的一个相对值。</p>
</li>
<li><p>比如: <code>&lt;x&gt; = &lt;absolute_x&gt; / &lt;image_width&gt;</code> 或者 <code>&lt;height&gt; = &lt;absolute_height&gt; / &lt;image_height&gt;</code></p>
</li>
<li><p>需要注意的是: <code>&lt;x_center&gt; &lt;y_center&gt;</code> - 是标注框的中心点，而不是左上角。请注意格式。</p>
<p>举个例子，img1.txt中内容如下，代表有两个类别的三个目标：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1 0.716797 0.395833 0.216406 0.147222</span><br><span class="line">0 0.687109 0.379167 0.255469 0.158333</span><br><span class="line">1 0.420312 0.395833 0.140625 0.166667</span><br></pre></td></tr></table></figure>
<ol>
<li>在<code>build\darknet\x64\data\</code>文件夹中创建train.txt文件，每行包含的是训练集图片的内容。其路径是相对于 <code>darknet.exe</code>的路径或者绝对路径：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data&#x2F;obj&#x2F;img1.jpg</span><br><span class="line">data&#x2F;obj&#x2F;img2.jpg</span><br><span class="line">data&#x2F;obj&#x2F;img3.jpg</span><br></pre></td></tr></table></figure>
<ol>
<li><p>下载预训练权重，并将其放在 <code>build\darknet\x64</code>文件夹中。</p>
<ul>
<li>对于<code>csresnext50-panet-spp.cfg</code> (133 MB)：请查看原工程。</li>
<li>对于<code>yolov3.cfg, yolov3-spp.cfg</code> (154 MB)：请查看原工程。</li>
<li>对于<code>yolov3-tiny-prn.cfg , yolov3-tiny.cfg</code> (6 MB)：请查看原工程。</li>
<li>对于<code>enet-coco.cfg (EfficientNetB0-Yolov3)</code>：请查看原工程。</li>
</ul>
</li>
<li><p>使用以下命令行开始训练: <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74</code>。</p>
<p>对于linux用户使用以下命令开始训练: <code>./darknet detector train data/obj.data yolo-obj.cfg darknet53.conv.74</code> (使用<code>./darknet</code> 而不是 <code>darknet.exe</code>)。</p>
<p>如果想训练的过程中同步显示mAP（每四个epoch进行一次更新），运行命令: <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -map</code>。</p>
<ul>
<li>权重文件 <code>yolo-obj_last.weights</code> 将会保存在 <code>build\darknet\x64\backup\</code> 文件夹中，每100个迭代保存一次。</li>
<li>权重文件<code>yolo-obj_xxxx.weights</code> 将会保存在 <code>build\darknet\x64\backup\</code> 文件夹中，每1000个迭代保存一次。</li>
<li>如果不想在训练的过程中同步展示loss曲线，请执行以下命令 <code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -dont_show</code>。</li>
<li>如果想在训练过程中查看mAP和Loss曲线，可以使用以下命令：<code>darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 -dont_show -mjpeg_port 8090 -map</code> ，然后在浏览器中打开 URL <code>http://ip-address:8090</code> 。</li>
</ul>
</li>
<li><p>训练结束以后，将会在文件夹<code>build\darknet\x64\backup\</code>中得到权重文件 <code>yolo-obj_final.weights</code> 。</p>
</li>
</ol>
<ul>
<li>在100次迭代以后，你可以停下来，然后从这个点加载模型继续训练。比如说, 你在2000次迭代以后停止训练，如果你之后想要恢复训练，只需要运行命令： <code>darknet.exe detector train data/obj.data yolo-obj.cfg backup\yolo-obj_2000.weights</code>，而不需要重头开始训练。</li>
</ul>
<p><strong>注意</strong>：</p>
<ol>
<li>如果在训练的过程中，发现<code>avg</code>指标变为<code>nan</code>，那证明训练过程有误，可能是数据标注越界导致的问题。但是其他指标有<code>nan</code>是正常的。</li>
<li>修改<code>width</code>,<code>height</code>的时候必须要保证两者都能够被32整除。</li>
<li>训练结束后，可以使用以下命令来进行测试：<code>darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights</code></li>
<li>如果出现<code>Ouf of memery</code>问题，那说明显卡的显存不够，你可以通过设置<code>subdivisions</code>参数，将其从原来的<code>16</code>提高为<code>32</code>或者<code>64</code>，这样就能降低使用的显存，保证程序正常运行。</li>
</ol>
<h3 id="6-4-训练tiny-yolo"><a href="#6-4-训练tiny-yolo" class="headerlink" title="6.4 训练tiny-yolo"></a>6.4 训练tiny-yolo</h3><p>训练tiny yolo与以上的训练过程并无明显区别，除了以下几点：</p>
<ul>
<li>下载tiny yolo的预训练权重：<code>https://pjreddie.com/media/files/yolov3-tiny.weights</code></li>
<li>使用以下命令行来获取预训练权重: <code>darknet.exe partial cfg/yolov3-tiny.cfg yolov3-tiny.weights yolov3-tiny.conv.15 15</code>， 这里的15代表前15个层，也就是backbone所在的层。</li>
<li>使用的配置文件应该是 <code>cfg/yolov3-tiny_obj.cfg</code> 而不是 <code>yolov3.cfg</code></li>
<li>使用以下命令开始训练: <code>darknet.exe detector train data/obj.data yolov3-tiny-obj.cfg yolov3-tiny.conv.15</code></li>
</ul>
<p>如果想使用其他backbone进行训练比如 DenseNet201-Yolo或者ResNet50-Yolo, 你可以在以下链接中找到:<code>https://github.com/AlexeyAB/darknet/blob/master/build/darknet/x64/partial.cmd</code></p>
<p>如果你采用的是自己设计的backbone,那就无法进行迁移学习，backbone可以直接进行参数随机初始化。</p>
<h3 id="6-5-什么时候停止训练"><a href="#6-5-什么时候停止训练" class="headerlink" title="6.5 什么时候停止训练"></a>6.5 什么时候停止训练</h3><p>建议为每个类分配至少2000次迭代，但是整体迭代次数不应少于4000次。如果想要更加精准地定义什么时候该停止训练，需要使用以下方法：</p>
<ol>
<li>训练过程中，你将会看到日志中有很多错误的度量指标，你需要在avg指标不再下降的时候停止训练，如下图所示:</li>
</ol>
<blockquote>
<p>Region Avg IOU: 0.798363, Class: 0.893232, Obj: 0.700808, No Obj: 0.004567, Avg Recall: 1.000000,  count: 8 Region Avg IOU: 0.800677, Class: 0.892181, Obj: 0.701590, No Obj: 0.004574, Avg Recall: 1.000000,  count: 8</p>
<p><strong>9002</strong>: 0.211667, <strong>0.60730 avg</strong>, 0.001000 rate, 3.868000 seconds, 576128 images Loaded: 0.000000 seconds</p>
</blockquote>
<ul>
<li><p><strong>9002</strong> - 代表当前的迭代次数。</p>
</li>
<li><p><strong>0.60730 avg</strong> - average loss (error) - <strong>这个指标是平均loss, 其越低越好。</strong></p>
<p>在这个指标不再下降的时候就可以停止训练了。最终的值大概分布在0.05-3.0之间，小而简单的模型通常最终loss比较小，大而复杂的loss可能会比较大。</p>
</li>
</ul>
<p>训练完成后，你就可以从 <code>darknet\build\darknet\x64\backup</code> 文件夹中取出比较靠后的几个<code>weights</code>文件，并对他们进行测试，选择最好的权重文件。</p>
<p>举个例子，你在<code>9000</code>次迭代后停止训练，但最好的权重可能是<code>7000,8000,9000</code>次的值。这种情况的出现是由于<strong>过拟合</strong>导致的。<strong>过拟合</strong>是由于过度学习训练集的分布，而降低了模型在测试集的泛化能力。</p>
<p><strong>Early Stopping Point</strong>示意图:</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/642.webp" alt></p>
<p>为了得到在early stopping point处的权重：</p>
<p>2.1 首先，你的obj.data文件中应该含有valid=valid.txt一项，用于测试在验证集的准确率。如果你没有验证集图片，那就直接复制train.txt重命名为valid.txt。</p>
<p>2.2 假如你选择在<code>9000</code>次迭代后停止，那可以通过以下命令测试<code>7000,8000,9000</code>三个模型的相关指标。选择最高<code>mAP</code>或者最高<code>IoU</code>的模型最为最终模型。</p>
<ul>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_7000.weights</code></li>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_8000.weights</code></li>
<li><code>darknet.exe detector map data/obj.data yolo-obj.cfg backup\yolo-obj_9000.weights</code></li>
</ul>
<p>或者你可以选择使用<code>-map</code>标志符来直接实时测试mAP值：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">darknet.exe detector train data&#x2F;obj.data yolo-obj.cfg darknet53.conv.74 -map</span><br></pre></td></tr></table></figure>
<p>然后你就能得到loss曲线和mAP曲线，mAP每4个epoch对验证集进行一次测试，并将结果显示在图中。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/643.webp" alt></p>
<p>指标解释</p>
<ul>
<li><p><strong>IoU</strong> (intersect over union) - 平均交并比</p>
</li>
<li><p><strong>mAP</strong> (mean average precision) - 每个类的平均精度。</p>
</li>
</ul>
<p><strong>mAP</strong> 是Pascal VOC竞赛的默认指标，与MS COCO竞赛中的AP50指标是一致的。</p>
<p>Precision和Recall参数在Pascal VOC竞赛中略微不同，但 <strong>IoU 的意义都是相同的</strong>。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/644.jpg" alt></p>
<h3 id="6-6-如何在pascal-voc2007数据集上计算mAP指标"><a href="#6-6-如何在pascal-voc2007数据集上计算mAP指标" class="headerlink" title="6.6 如何在pascal voc2007数据集上计算mAP指标"></a>6.6 如何在pascal voc2007数据集上计算mAP指标</h3><ol>
<li>在VOC2007中计算mAP：</li>
</ol>
<ul>
<li>下载VOC数据集，安装python并且下载<code>`2007_test.txt</code>文件，具体可以参考链接：<code>https://github.com/AlexeyAB/darknet#how-to-train-pascal-voc-data</code></li>
<li>下载文件 <code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/scripts/voc_label_difficult.py</code> 到 <code>build\darknet\x64\data\</code> 文件夹，然后运行 <code>voc_label_difficult.py</code> 从而得到 <code>difficult_2007_test.txt</code>。</li>
<li>将下面voc.data文件中的第四行#删除</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">classes&#x3D; 20</span><br><span class="line">train  &#x3D; data&#x2F;train_voc.txt</span><br><span class="line">valid  &#x3D; data&#x2F;2007_test.txt</span><br><span class="line">#difficult &#x3D; data&#x2F;difficult_2007_test.txt</span><br><span class="line">names &#x3D; data&#x2F;voc.names</span><br><span class="line">backup &#x3D; backup&#x2F;</span><br></pre></td></tr></table></figure>
<p>然后就有两个方法来计算得到mAP:</p>
<ol>
<li>使用Darknet + Python: 运行 <code>build/darknet/x64/calc_mAP_voc_py.cmd</code> ，你将得到 <code>yolo-voc.cfg</code> 模型的mAP值, mAP = 75.9%</li>
<li>直接使用命令: 运行文件 <code>build/darknet/x64/calc_mAP.cmd</code> -你将得到 <code>yolo-voc.cfg</code> 模型, 得到mAP = 75.8%</li>
</ol>
<p>YOLOv3的论文：<code>https://arxiv.org/pdf/1612.08242v1.pdf</code>指出对于416x416的YOLOv2，Pascal Voc上的mAP值是76.8%。我们得到的值较低，可能是由于模型在进行检测时的代码略有不同。</p>
<p>如果你想为<code>tiny-yolo-voc</code>计算mAP值，将脚本中<code>tiny-yolo-voc.cfg</code>取消注释，将<code>yolo-voc.cfg</code>注释掉。</p>
<p>如果你是用的是python 2.x 而不是python 3.x, 而且你选择使用Darknet+Python的方式来计算mAP, 那你应该使用 <code>reval_voc.py</code> 和 <code>voc_eval.py</code> 而不是使用 <code>reval_voc_py3.py</code> 和 <code>voc_eval_py3.py</code> 。以上脚本来自以下目录：<code>https://github.com/AlexeyAB/darknet/tree/master/scripts</code>。</p>
<p>目标检测的例子：<code>darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_8000.weights</code></p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/645.webp" alt></p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/ABDarknet/646.webp" alt></p>
<h2 id="7-如何提升目标检测性能？"><a href="#7-如何提升目标检测性能？" class="headerlink" title="7. 如何提升目标检测性能？"></a>7. 如何提升目标检测性能？</h2><ol>
<li><p>训练之前：</p>
<ul>
<li><code>train_network_width * train_obj_width / train_image_width ~= detection_network_width *  detection_obj_width / detection_image_width</code></li>
<li><p><code>train_network_height * train_obj_height / train_image_height ~= detection_network_height *  detection_obj_height / detection_image_height</code></p>
</li>
<li><p>完整模型（5个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3_5l.cfg</code>。</p>
</li>
<li><p>Tiny模型（3个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-tiny_3l.cfg</code>。</p>
</li>
<li><p>带空间金字塔池化的完整模型（3个yolo层）：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov3-spp.cfg</code>。</p>
</li>
<li><p>在<code>cfg</code>文件中将<code>random</code>设为1：这将在Yolo中使用多尺度训练，会提升检测模型准确率。</p>
</li>
<li><p>在<code>cfg</code>文件中把输入分辨率增大(<code>height=608</code>, <code>width=608</code>或者其他任意32的倍数)：这将提升检测模型准确率。</p>
</li>
<li><p>检查你要检测的每个目标在数据集中是否被标记，数据集中任何目标都不应该没有标签。在大多数训练出问题的情况中基本都是有错误的标签（通过使用某些转换脚本，使用第三方工具标注来获得标签），可以通过<code>https://github.com/AlexeyAB/Yolo_mark</code>来检查你的数据集是否全部标注正确。</p>
</li>
<li><p>我的损失函数很高并且mAP很低，训练出错了吗？在训练命令末端使用<code>-show_imgs</code> 标志来运行训练，你是否能看到有正确的边界预测框的目标（在窗口或者<code>aug_...jpg</code>）？如果没有，训练是发生错误了。</p>
</li>
<li><p>对于你要检测的每个目标，训练数据集中必须至少有一个相似的目标，它们具有大致相同的形状，物体侧面姿态，相对大小，旋转角度，倾斜度，照明度等。理想的是，你的训练数据集包括具有不同比例，旋转角度，照明度，物体侧面姿态和处于不同背景的目标图像，你最好拥有2000张不同的图像，并且至少训练<code>2000×classes</code>轮次。</p>
</li>
<li><p>希望你的训练数据集图片包含你不想检测的未标注的目标，也即是无边界框的负样本图片(空的<code>.txt</code>文件)，并且负样本图片的数量和带有目标的正样本图片数量最好一样多。</p>
</li>
<li><p>标注目标的最佳方法是：仅仅标记目标的可见部分或者标记目标的可见和重叠部分，或标记比整个目标多一点(有一点间隙)?根据你希望如何检测目标来进行标记。</p>
</li>
<li><p>为了对图片中包含大量目标的数据进行训练，添加<code>max=200</code>或者更高的值在你<code>cfg</code>文件中<code>yolo</code>层或者<code>region</code>层的最后一行（YOLOv3可以检测到的目标全局最大数量为<code>0,0615234375*(width*height)</code>其中<code>width</code>和<code>height</code>是在<code>cfg</code>文件中的<code>[net]</code>部分指定的）。</p>
</li>
<li><p>对于小目标的训练（把图像resize到416x416大小后小于16x16的目标）：设置<code>layers = -1, 11</code>而不是<code>layers=-1, 36</code>；设置<code>stride=4</code>而不是<code>stride=2</code>。</p>
</li>
<li><p>对于既有大目标又有小目标的训练使用下面的模型：</p>
</li>
<li><p>如果你要训练模型将左右目标分为单独的类别（左/右手，左/右交通标志），那就禁用翻转的数据扩充方式，即在数据输入部分添加<code>flip=0</code>。</p>
</li>
<li><p>一般规则：你的训练数据集应包括一组您想要检测的相对大小的目标，如下：</p>
<p>即，对于测试集中的每个目标，训练集中必须至少有一个同类目标和它具有大约相同的尺寸：</p>
<p><code>object width in percent from Training dataset</code> ~= <code>object width in percent from Test dataset</code></p>
<p>也就是说，如果训练集中仅存在占图像比例80%-90%的目标，则训练后的目标检测网络将无法检测到占图像比例为1-10%的目标。</p>
</li>
<li><p>为了加快训练速度（同时会降低检测精度）使用微调而不是迁移学习，在[net]下面设置<code>stopbackward=1</code>。然后执行下面的命令：<code>./darknet partial cfg/yolov3.cfg yolov3.weights yolov3.conv.81 81</code>这将会创建<code>yolov3.conv.81</code>文件，然后使用<code>yolov3.conv.81</code>文件进行训练而不是<code>darknet53.conv.74</code>。</p>
</li>
<li><p>在观察目标的时候，从不同的方向、不同的照明情况、不同尺度、不同的转角和倾斜角度来看，对神经网络来说，它们都是不同的目标。因此，要检测的目标越多，应使用越复杂的网络模型。</p>
</li>
<li><p>为了让检测框更准，你可以在每个<code>yolo</code>层添加下面三个参数<code>ignore_thresh = .9 iou_normalizer=0.5 iou_loss=giou</code>，这回提高map@0.9，但会降低map@0.5。</p>
</li>
<li><p>当你是神经网络方面的专家时，可以重新计算相对于<code>width</code>和<code>height</code>的<code>anchors</code>：<code>darknet.exe detector calc_anchors data/obj.data -num_of_clusters 9 -width 416 -height 416</code>然后在3个<code>[yolo]</code>层放置这9个<code>anchors</code>。但是你需要修改每个<code>[yolo]</code>层的<code>masks</code>参数，让第一个<code>[yolo]</code>层的<code>anchors</code>尺寸大于60x60，第二个<code>[yolo]</code>层的<code>anchors</code>尺寸大于30x30，剩下就是第三个<code>[yolo]</code>层的<code>mask</code>。宁外，你需要修改每一个<code>[yolo]</code>层前面的<code>filters=(classes + 5)x</code>。如果很多计算的<code>anchors</code>都找不到合适的层，那还是使用Yolo的默认<code>anchors</code>吧。</p>
</li>
</ul>
</li>
<li><p>训练之后：</p>
<ul>
<li>没有必要重新训练模型，直接使用用<code>416x416</code>分辨率训练出来的<code>.weights</code>模型文件。</li>
<li>但是要获得更高的准确率，你应该使用<code>608x608</code>或者<code>832x832</code>来训练，注意如果<code>Out of memory</code>发生了，你应该在<code>.cfg</code>文件中增加<code>subdivisions=16，32，64</code>。</li>
<li>通过在<code>.cfg</code>文件中设置（<code>height=608</code> and <code>width=608</code>）或者（<code>height=832</code> and <code>width=832</code>）或者任何32的倍数，这会提升准确率并使得对小目标的检测更加容易。</li>
</ul>
</li>
</ol>
<h2 id="8-如何标注以及创建标注文件"><a href="#8-如何标注以及创建标注文件" class="headerlink" title="8. 如何标注以及创建标注文件"></a>8. 如何标注以及创建标注文件</h2><p>下面的工程提供了用于标记目标边界框并为YOLO v2&amp;v3 生成标注文件的带图像界面软件，地址为：<code>https://github.com/AlexeyAB/Yolo_mark</code>。</p>
<p>例如对于只有两类目标的数据集标注后有以下文件<code>train.txt</code>,<code>obj.names</code>,<code>obj.data</code>,<code>yolo-obj.cfg</code>,<code>air 1-6.txt</code>,<code>bird 1-4.txt</code>，接着配合<code>train_obj.cmd</code>就可以使用YOLO v2和YOLO v3来训练这个数据集了。</p>
<p>下面提供了5重常见的目标标注工具：</p>
<ul>
<li>C++实现的：<code>https://github.com/AlexeyAB/Yolo_mark</code></li>
<li>Python实现的：<code>https://github.com/tzutalin/labelImg</code></li>
<li>Python实现的：<code>https://github.com/Cartucho/OpenLabeling</code></li>
<li>C++实现的：<code>https://www.ccoderun.ca/darkmark/</code></li>
<li>JavaScript实现的：<code>https://github.com/opencv/cvat</code></li>
</ul>
<h2 id="9-使用YOLO9000"><a href="#9-使用YOLO9000" class="headerlink" title="9. 使用YOLO9000"></a>9. 使用YOLO9000</h2><p>同时检测和分类9000个目标：<code>darknet.exe detector test cfg/combine9k.data cfg/yolo9000.cfg yolo9000.weights data/dog.jpg</code></p>
<ul>
<li><p><code>yolo9000.weights</code>：186Mb的YOLO9000模型需要4G GPU显存，训练好的模型下载地址：<code>http://pjreddie.com/media/files/yolo9000.weights</code>。</p>
</li>
<li><p><code>yolo9000.cfg</code>：YOLO9000的c网络结构文件，同时这里也有<code>9k.tree</code>和<code>coco9k.map</code>文件的路径。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tree&#x3D;data&#x2F;9k.tree</span><br><span class="line">map &#x3D; data&#x2F;coco9k.map</span><br></pre></td></tr></table></figure>
<ul>
<li><code>9k.tree</code>：9418个类别的单词数，每一行的形式为<code>`，如果</code>parent_id==-1<code>那么这个标签没有父类别，地址为：</code><a href="https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.tree`。" target="_blank" rel="noopener">https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.tree`。</a></li>
<li><code>coco9k.map</code>：将MSCOCO的80个目标类别映射到<code>9k.tree</code>的文件，地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/coco9k.map</code>。</li>
</ul>
</li>
<li><p><code>combine9k.data</code>：数据文件，分别是<code>9k.labels</code>。<code>9k.names</code>，<code>inet9k.map</code>的路径（修改<code>combine9k.train.list</code>文件的路径为你自己的）。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/combine9k.data</code>。</p>
</li>
<li><p><code>9k.labels</code>：9418类目标的标签。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.labels</code>。</p>
</li>
<li><p><code>9k.names</code>：9418类目标的名字。地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/9k.names</code>。</p>
</li>
<li><p><code>inet9k.map</code>：将ImageNet的200个目标类别映射到<code>9k.tree</code>的文件，地址为：<code>https://raw.githubusercontent.com/AlexeyAB/darknet/master/build/darknet/x64/data/inet9k.map</code>。</p>
</li>
</ul>
<h2 id="10-如何将YOLO作为DLL和SO库进行使用？"><a href="#10-如何将YOLO作为DLL和SO库进行使用？" class="headerlink" title="10. 如何将YOLO作为DLL和SO库进行使用？"></a>10. 如何将YOLO作为DLL和SO库进行使用？</h2><ul>
<li><p>在Linux上。</p>
<ul>
<li>使用<code>build.sh</code> 或者</li>
<li>使用<code>cmake</code>编译<code>darknet</code> 或者</li>
<li>将<code>Makefile</code>重的<code>LIBSO=0</code>改为<code>LIBSO=1</code>，然后执行<code>make</code>编译<code>darknet</code></li>
</ul>
</li>
<li><p>在Windows上。</p>
<ul>
<li>使用<code>build.ps1</code> 或者</li>
<li>使用<code>cmake</code>编译<code>darknet</code> 或者</li>
<li>使用<code>build\darknet\yolo_cpp_dll.sln</code>或<code>build\darknet\yolo_cpp_dll_no_gpu.sln</code>解决方法编译<code>darknet</code></li>
</ul>
</li>
<li><p>这里有两个API：</p>
<ul>
<li>使用C++ API的C++例子：<code>https://github.com/AlexeyAB/darknet/blob/master/src/yolo_console_dll.cpp</code></li>
<li>使用C API的Python例子：<br><code>https://github.com/AlexeyAB/darknet/blob/master/darknet.py</code><br><code>https://github.com/AlexeyAB/darknet/blob/master/darknet_video.py</code></li>
<li>C API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/darknet.h</code></li>
<li>C++ API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp</code></li>
</ul>
</li>
</ul>
<h2 id="11-附录"><a href="#11-附录" class="headerlink" title="11. 附录"></a>11. 附录</h2><ol>
<li><p>为了将Yolo编译成C++的DLL文件<code>yolo_cpp_dll.dll</code>：打开<code>build\darknet\yolo_cpp_dll.sln</code>解决方案，编译选项选<strong>X64</strong>和<strong>Release</strong>，然后执行Build-&gt;Build yolo_cpp_dll就，编译的一些前置条件为：</p>
<ul>
<li>安装<strong>CUDA 10.0</strong>。</li>
<li>为了使用cuDNN执行以下步骤：点击工程属性-&gt;properties-&gt;C++-&gt;Preprocessor-&gt;Preprocessor Definitions，然后在开头添加一行<code>CUDNN</code>。</li>
</ul>
</li>
<li><p>在自己的C++工程中将Yolo当成DLL文件使用：打开<code>build\darknet\yolo_console_dll.sln</code>解决方案，编译选项选<strong>X64</strong>和<strong>Release</strong>，然后执行Build-&gt;Build yolo_console_dll：</p>
<p><code>yolo_cpp_dll.dll</code>-API：<code>https://github.com/AlexeyAB/darknet/blob/master/include/yolo_v2_class.hpp</code></p>
<ul>
<li>你可以利用Windows资源管理器运行<code>build\darknet\x64\yolo_console_dll.exe</code>可执行程序并<strong>使用下面的命令</strong>:  <code>yolo_console_dll.exe data/coco.names yolov3.cfg yolov3.weights test.mp4</code></li>
<li>启动控制台应用程序并输入图像文件名后，你将看到每个目标的信息：<code> </code></li>
<li>如果要使用OpenCV-GUI你应该将<code>yolo_console_dll.cpp</code>中的<code>//#define OPENCV</code>取消注释。</li>
<li>你可以看到视频检测例子的源代码，地址为yolo_console_dll.cpp的第75行。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">struct bbox_t &#123;</span><br><span class="line">    unsigned int x, y, w, h;    &#x2F;&#x2F; (x,y) - top-left corner, (w, h) - width &amp; height of bounded box</span><br><span class="line">    float prob;                    &#x2F;&#x2F; confidence - probability that the object was found correctly</span><br><span class="line">    unsigned int obj_id;        &#x2F;&#x2F; class of object - from range [0, classes-1]</span><br><span class="line">    unsigned int track_id;        &#x2F;&#x2F; tracking id for video (0 - untracked, 1 - inf - tracked object)</span><br><span class="line">    unsigned int frames_counter;&#x2F;&#x2F; counter of frames on which the object was detected</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class Detector &#123;</span><br><span class="line">public:</span><br><span class="line">        Detector(std::string cfg_filename, std::string weight_filename, int gpu_id &#x3D; 0);</span><br><span class="line">        ~Detector();</span><br><span class="line"></span><br><span class="line">        std::vector&lt;bbox_t&gt; detect(std::string image_filename, float thresh &#x3D; 0.2, bool use_mean &#x3D; false);</span><br><span class="line">        std::vector&lt;bbox_t&gt; detect(image_t img, float thresh &#x3D; 0.2, bool use_mean &#x3D; false);</span><br><span class="line">        static image_t load_image(std::string image_filename);</span><br><span class="line">        static void free_image(image_t m);</span><br><span class="line"></span><br><span class="line">#ifdef OPENCV</span><br><span class="line">        std::vector&lt;bbox_t&gt; detect(cv::Mat mat, float thresh &#x3D; 0.2, bool use_mean &#x3D; false);</span><br><span class="line">	std::shared_ptr&lt;image_t&gt; mat_to_image_resize(cv::Mat mat) const;</span><br><span class="line">#endif</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>

    </div>

    
    
    <div class="post-widgets">
      <div id="needsharebutton-postbottom">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    </div>
	<div>

	  

		<div>

    

        <div >-------------本文结束感谢您的阅读-------------</div>

    

</div>

	  

	</div>
      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag"><i class="fa fa-tag"></i> 目标检测</a>
              <a href="/tags/YOLOv3/" rel="tag"><i class="fa fa-tag"></i> YOLOv3</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/19/ECCV-2018-Convolutional-Block-Attention-Module/" rel="prev" title="ECCV 2018 Convolutional Block Attention Module">
      <i class="fa fa-chevron-left"></i> ECCV 2018 Convolutional Block Attention Module
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/21/AlexeyAB-DarkNet%E6%A1%86%E6%9E%B6%E6%80%BB%E8%A7%88/" rel="next" title="AlexeyAB DarkNet框架总览">
      AlexeyAB DarkNet框架总览 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>



<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-text"> 前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-依赖"><span class="nav-text">1. 依赖</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-环境要求"><span class="nav-text">1.1 环境要求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-数据集获取"><span class="nav-text">1.2 数据集获取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-相比原作者Darknet的改进"><span class="nav-text">2. 相比原作者Darknet的改进</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-命令行使用"><span class="nav-text">3. 命令行使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Linux下如何编译Darknet"><span class="nav-text">4. Linux下如何编译Darknet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-使用CMake编译Darknet"><span class="nav-text">4.1 使用CMake编译Darknet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-使用make编译Darknet"><span class="nav-text">4.2 使用make编译Darknet</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-如何在Window下编译Darknet"><span class="nav-text">5. 如何在Window下编译Darknet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-使用CMake-GUI进行编译"><span class="nav-text">5.1 使用CMake-GUI进行编译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-使用vcpkg进行编译"><span class="nav-text">5.2 使用vcpkg进行编译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-使用legacy-way进行编译"><span class="nav-text">5.3 使用legacy way进行编译</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-如何训练"><span class="nav-text">6. 如何训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-Pascal-VOC-dataset"><span class="nav-text">6.1 Pascal VOC dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-如何使用多GPU训练？"><span class="nav-text">6.2 如何使用多GPU训练？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-训练自定义数据集-重点关注"><span class="nav-text">6.3 训练自定义数据集(重点关注)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-训练tiny-yolo"><span class="nav-text">6.4 训练tiny-yolo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-5-什么时候停止训练"><span class="nav-text">6.5 什么时候停止训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-6-如何在pascal-voc2007数据集上计算mAP指标"><span class="nav-text">6.6 如何在pascal voc2007数据集上计算mAP指标</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-如何提升目标检测性能？"><span class="nav-text">7. 如何提升目标检测性能？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-如何标注以及创建标注文件"><span class="nav-text">8. 如何标注以及创建标注文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-使用YOLO9000"><span class="nav-text">9. 使用YOLO9000</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-如何将YOLO作为DLL和SO库进行使用？"><span class="nav-text">10. 如何将YOLO作为DLL和SO库进行使用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-附录"><span class="nav-text">11. 附录</span></a></li></ol></div>
      </div>
      <!--/noindex-->
	  
     
	  
      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Qiyuan-Z"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Qiyuan-Z</p>
  <div class="site-description" itemprop="description">偉大な魂は目的を持ち、そうでないものは願望を持つ</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">111</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Qiyuan-Z" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Qiyuan-Z" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhengqiyuan@stu.jiangnan.edu.cn" title="E-Mail → mailto:zhengqiyuan@stu.jiangnan.edu.cn" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://project-inkstone.github.io/project-inkstone/?tdsourcetag=s_pctim_aiomsg" title="https:&#x2F;&#x2F;project-inkstone.github.io&#x2F;project-inkstone&#x2F;?tdsourcetag&#x3D;s_pctim_aiomsg" rel="noopener" target="_blank">project-inkstone</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.jngwl.top/" title="https:&#x2F;&#x2F;www.jngwl.top" rel="noopener" target="_blank">清风与归</a>
        </li>
    </ul>
  </div>

      </div>
	  
      <div id="music163player">
		   <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=29784463&auto=1&height=66"></iframe>
		   </iframe>
	  </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qiyuan-Z</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">576k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:43</span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span> 
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("12/01/2019 13:14:21");//此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
setInterval("createtime()",250);
</script>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
	<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
	<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
	<script type="text/javascript">
    		var gitalk = new Gitalk({
		        clientID: '2d10cfb27783db577e70',
		        clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
		        id: md5(location.pathname),
		        repo: 'gitalk',
		        owner: 'Qiyuan-Z',
		        admin: 'Qiyuan-Z',
			distractionFreeMode: '',

		    });
	    gitalk.render('gitalk-container');
	</script>



  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
        pbOptions.boxForm = "horizontal";
        pbOptions.position = "bottomCenter";
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      new needShareButton('#needsharebutton-postbottom', pbOptions);
  </script>
	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
	<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
	<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
	<script type="text/javascript">
    		var gitalk = new Gitalk({
		        clientID: '2d10cfb27783db577e70',
		        clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
		        id: md5(location.pathname),
		        repo: 'gitalk',
		        owner: 'Qiyuan-Z',
		        admin: 'Qiyuan-Z',
			distractionFreeMode: '',

		    });
	    gitalk.render('gitalk-container');
	</script>


  <script type="text/javascript" src="/js/src/clicklove.js"></script>
  <script src="/live2d-widget/autoload.js"></script>
</body>
</html>

