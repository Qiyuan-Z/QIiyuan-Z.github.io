<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>YOLOv2 | Yuan</title><meta name="keywords" content="目标检测"><meta name="author" content="Qiyuan-Z"><meta name="copyright" content="Qiyuan-Z"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="article">
<meta property="og:title" content="YOLOv2">
<meta property="og:url" content="https://qiyuan-z.github.io/2020/02/28/YOLOv2/index.html">
<meta property="og:site_name" content="Yuan">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qiyuan-z.github.io/img/1097380.jpg">
<meta property="article:published_time" content="2020-02-28T05:04:15.279Z">
<meta property="article:modified_time" content="2020-02-28T05:33:30.908Z">
<meta property="article:author" content="Qiyuan-Z">
<meta property="article:tag" content="目标检测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qiyuan-z.github.io/img/1097380.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qiyuan-z.github.io/2020/02/28/YOLOv2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.5/dist/instantsearch.min.js" defer></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"ZQZI62NB22","apiKey":"f208969d7174c4878fcfe069d1a5a6dd","indexName":"blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":200,"languages":{"author":"作者: Qiyuan-Z","link":"链接: ","source":"来源: Yuan","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-right"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-02-28 13:33:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">114</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Yuan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">YOLOv2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-02-28T05:04:15.279Z" title="发表于 2020-02-28 13:04:15">2020-02-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-02-28T05:33:30.908Z" title="更新于 2020-02-28 13:33:30">2020-02-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div><article class="post-content" id="article-container"><h2 id="原理"><a href="#原理" class="headerlink" title=" 原理"></a><span id="more"></span> 原理</h2><p>YOLOv1作为One-Stage目标检测算法的开山之作，速度快是它最大的优势。但我们知道，YOLOv1的定位不够准，并且召回率低。为了提升定位准确度，提高召回率，YOLOv2在YOLOv1的基础上进行了改进。具体的改进方法如图Fig1所示：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/640.webp" alt></p>
<p>可以看到YOLOv2通过增加一些Trick使得v1的map值从63.4提高到了78.6，说明了YOLOv2改进方法的有效性。接下来我们就分析一下这些改进方法。</p>
<h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>这个应该不用多说了，YOLOv2在每个卷积层后面增加了BN层，去掉全连接的dropout。使用BN策略将map值提高了2%。</p>
<h2 id="高分辨率"><a href="#高分辨率" class="headerlink" title="高分辨率"></a>高分辨率</h2><p>当前大多数目标检测网络都喜欢使用主流分类网络如VGG,ResNet来做Backbone，而这些网络大多是在ImageNet上训练的，而分辨率的大小必然会影响到模型在测试集上的表现。所以，YOLOv2将输入的分辨率提升到$448 \times 448$，同时，为了使网络适应高分辨率，YOLOv2先在ImageNet上以$448 \times 448$的分辨率对网络进行10个epoch的微调，让网络适应高分辨率的输入。通过使用高分辨率的输入，YOLOv2将map值提高了约4%。</p>
<h2 id="基于卷积的Anchor机制"><a href="#基于卷积的Anchor机制" class="headerlink" title="基于卷积的Anchor机制"></a>基于卷积的Anchor机制</h2><p>YOLOv1利用全连接层直接对边界框进行预测，导致丢失较多空间信息，定位不准。YOLOv2去掉了YOLOv1中的全连接层，使用Anchor  Boxes预测边界框，同时为了得到更高分辨率的特征图，YOLOv2还去掉了一个池化层。由于图片中的物体都倾向于出现在图片的中心位置，若特征图恰好有一个中心位置，利用这个中心位置预测中心点落入该位置的物体，对这些物体的检测会更容易。所以总希望得到的特征图的宽高都为奇数。YOLOv2通过缩减网络，使用416x416的输入，模型下采样的总步长为32，最后得到13x13的特征图，然后对13x13的特征图的每个cell预测5个anchor boxes，对每个anchor box预测边界框的位置信息、置信度和一套分类概率值。使用anchor boxes之后，YOLOv2可以预测13x13x5=845个边界框，模型的召回率由原来的81%提升到88%，mAP由原来的69.5%降低到69.2%.召回率提升了7%，准确率下降了0.3%。这里我们和SSD以及Faster-RCNN做个对比，Faster  RCNN输入大小为1000*600时的boxes数量大概是6000，在SSD300中boxes数量是8732。显然增加box数量是为了提高object的定位准确率。</p>
<h2 id="维度聚类"><a href="#维度聚类" class="headerlink" title="维度聚类"></a>维度聚类</h2><p>在Faster-RCNN中，Anchor都是手动设定的，YOLOv2使用k-means聚类算法对训练集中的边界框做了聚类分析，尝试找到合适尺寸的Anchor。另外作者发现如果采用标准的k-means聚类，在box的尺寸比较大的时候其误差也更大，而我们希望的是误差和box的尺寸没有太大关系。所以通过IOU定义了如下的距离函数，使得误差和box的大小无关：</p>
<script type="math/tex; mode=display">
d(\text {box }, \text { centroid })=1-I O U(\text { box }, \text { centroid })</script><p>Fig2展示了聚类的簇的个数和IOU之间的关系，两条曲线分别代表了VOC和COCO数据集的测试结果。最后结合不同的K值对召回率的影响，论文选择了K=5，Figure2中右边的示意图是选出来的5个box的大小，这里紫色和黑色也是分别表示两个不同的数据集，可以看出其基本形状是类似的。而且发现聚类的结果和手动设置的anchor box大小差别显著。聚类的结果中多是高瘦的box，而矮胖的box数量较少，这也比较符合数据集中目标的视觉效果。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/641.png" alt></p>
<p>在结果测试时，YOLOv2采用的5种Anchor可以达到的Avg  IOU是61，而Faster-RCNN采用9种Anchor达到的平均IOU是60.9，也即是说本文仅仅选取5种Anchor就可以达到Faster-RCNN中9种Anchor的效果。如Table1所示：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/642.png" alt></p>
<h2 id="新Backbone-Darknet-19"><a href="#新Backbone-Darknet-19" class="headerlink" title="新Backbone:Darknet-19"></a>新Backbone:Darknet-19</h2><p>YOLOv2采用Darknet-19，其网络结构如下图所示，包括19个卷积层和5个max pooling层，主要采用$3 \times 3$卷积和$1 \times 1$卷积，这里$1 \times 1$卷积可以压缩特征图通道数以降低模型计算量和参数，每个卷积层后使用BN层以加快模型收敛同时防止过拟合。最终采用global avg pool 做预测。采用YOLOv2，模型的mAP值没有显著提升，但计算量减少了。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/643.webp" alt></p>
<h2 id="直接位置预测"><a href="#直接位置预测" class="headerlink" title="直接位置预测"></a>直接位置预测</h2><p>YOLOv2在引入Anchor的时候碰到第2个问题：模型不稳定，尤其是训练刚开始阶段。论文任务这种不稳定主要来自box的(x,y)预测值。我们知道在Faster-RCNN中，是通过预测下图中的$t_x$和$t_y$来得到(x,y)值，也就是预测的是offset。另外关于文中的这个公式，这个地方应该把后面的减号改成加号，这样才能符合公式下面的example。这里$\boldsymbol{x}_{\boldsymbol{a}}$和$\boldsymbol{y}_{\boldsymbol{a}}$是anchor的坐标，$\boldsymbol{w}_{\boldsymbol{a}}$和$\boldsymbol{h}_{\boldsymbol{a}}$是anchor的size，$\boldsymbol{x}$和$\boldsymbol{y}$是坐标的预测值，$\boldsymbol{t}_{\boldsymbol{x}}$和$\boldsymbol{t}_{\boldsymbol{y}}$是偏移量。</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/644.png" alt></p>
<p>例子翻译过来是：当预测时$t_{x}=1$，就会把box向右边移动一定距离（具体为anchor box的宽度），预测时$t_{x}=-1$，就会把box向左边移动相同的距离。这个公式没有任何限制，使得无论在什么位置进行预测，任何anchor boxes可以在图像中任意一点结束，模型随机初始化后，需要花很长一段时间才能稳定预测敏感的物体位置。.</p>
<p>注意，高能来了！！！分析了原因之后，YOLOv2没有采用直接预测offset的方法，还是沿用了YOLO算法中直接预测相对于grid  cell的坐标位置的方式。前面提到网络在最后一个卷积层输出13*13大小的特征图，然后每个cell预测5个bounding  box，然后每个bounding box预测5个值：$t_{x}, t_{y}, t_{w}, t_{h}$和$t_o$（这里的$t_{o}$类似YOLOv1中的confidence）。$t_x$和$t_{y}$经过sigmoid函数处理后范围在0到1之间，这样的归一化处理使得模型训练更加稳定。$c_x$和$c_{y}$表示一个cell和图像左上角的横纵距离。$p_w$和$p_h$表示bounding box的宽高，这样$b_x$和$b_y$就是$c_x$和$c_y$这个cell附近的anchor来预测$t_x$和$t<br>_y$得到的结果。如Fig3所示：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/645.webp" alt></p>
<p>其中，$c_x$和$c_{y}$表示grid cell与图像左上角的横纵坐标距离，黑色虚线框是bounding box，蓝色矩形框就是最终预测的结果。注意，上图右边里面的$\delta\left(t_{x}\right)$可以理解为$s t_{x}$，$\delta\left(t_{y}\right)$可以理解为$s t_{y}$。每一个输出的bounding box是针对于一个特定的anchor，anchor其实是bounding box的width及height的一个参考。$p_{w}$和$p_{h}$是某个anchor box的宽和高，一个格子的$c_{x}$和$c_{y}$单位都是1，$\delta\left(t_{x}\right)$，$\delta\left(t_{y}\right)$是相对于某个格子左上角的偏移量。</p>
<h2 id="细粒度特征"><a href="#细粒度特征" class="headerlink" title="细粒度特征"></a>细粒度特征</h2><p>YOLOv2提取Darknet-19最后一个max pool层的输入，得到26x26x512的特征图。经过1x1x64的卷积以降低特征图的维度，得到26x26x64的特征图，然后经过pass  through层的处理变成13x13x256的特征图（抽取原特征图每个2x2的局部区域组成新的channel，即原特征图大小降低4倍，channel增加4倍），再与13x13x1024大小的特征图连接，变成13x13x1280的特征图，最后在这些特征图上做预测。使用Fine-Grained Features，YOLOv2的性能提升了1%。这个过程可以在下面的YOLOv2的结构图中看得很清楚：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/646.webp" alt></p>
<h2 id="多尺度训练"><a href="#多尺度训练" class="headerlink" title="多尺度训练"></a><strong>多尺度训练</strong></h2><p>YOLOv2中使用的Darknet-19网络结构中只有卷积层和池化层，所以其对输入图片的大小没有限制。YOLOv2采用多尺度输入的方式训练，在训练过程中每隔10个batches,重新随机选择输入图片的尺寸，由于Darknet-19下采样总步长为32，输入图片的尺寸一般选择32的倍数{320,352,…,608}。采用Multi-Scale Training,  可以适应不同大小的图片输入，当采用低分辨率的图片输入时，mAP值略有下降，但速度更快，当采用高分辨率的图片输入时，能得到较高mAP值，但速度有所下降。</p>
<p>这种机制使得网络可以更好地预测不同尺寸的图片，意味着同一个网络可以进行不同分辨率的检测任务，在小尺寸图片上YOLOv2运行更快，在速度和精度上达到了平衡。在小尺寸图片检测中，YOLOv2成绩很好，输入为228 x 228的时候，帧率达到90FPS，mAP几乎和Faster  R-CNN的水准相同。使得其在低性能GPU、高帧率视频、多路视频场景中更加适用。在大尺寸图片检测中，YOLOv2达到了SOAT结果，VOC2007 上mAP为78.6%，仍然高于平均水准，下图是YOLOv2和其他网络的精度对比：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/647.jfif" alt></p>
<p>速度对比：</p>
<p><img src="https://blog-1300912400.cos.ap-shanghai.myqcloud.com/YOLOv2/648.webp" alt></p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>YOLOv2的训练主要包括三个阶段。第一阶段：作者使用Darknet-19在标准1000类的ImageNet上训练了160次，用的随机梯度下降法，starting learning rate 为0.1，polynomial rate decay 为4，weight decay为0.0005  ，momentum 为0.9。训练的时候仍然使用了很多常见的数据扩充方法（data augmentation），包括random crops,  rotations, and hue, saturation, and exposure  shifts。（这些训练参数是基于darknet框架，和caffe不尽相同）初始的224 <em> 224训练后，作者把分辨率上调到了448 </em>  448，然后又训练了10次，学习率调整到了0.001。高分辨率下训练的分类网络在top-1准确率76.5%，top-5准确率93.3%。</p>
<p>第二个阶段：分类网络训练完后，就该训练检测网络了，作者去掉了原网络最后一个卷积层，转而增加了三个3 <em> 3 </em> 1024的卷积层（可参考darknet中cfg文件），并且在每一个上述卷积层后面跟一个1 <em>  1的卷积层，输出维度是检测所需的数量。对于VOC数据集，预测5种boxes大小，每个box包含5个坐标值和20个类别，所以总共是5 </em>  （5+20）= 125个输出维度。同时也添加了转移层（passthrough layer ），从最后那个3 <em> 3 </em>  512的卷积层连到倒数第二层，使模型有了细粒度特征。作者的检测模型以0.001的初始学习率训练了160次，在60次和90次的时候，学习率减为原来的十分之一。其他的方面，weight decay为0.0005，momentum为0.9，依然使用了类似于Faster-RCNN和SSD的数据扩充（data  augmentation）策略。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>YOLOv2借鉴了很多其它目标检测方法的一些技巧，如Faster R-CNN的anchor boxes,  SSD中的多尺度检测。除此之外，YOLOv2在网络设计上做了很多tricks,使它能在保证速度的同时提高检测准确率，Multi-Scale  Training更使得同一个模型适应不同大小的输入，从而可以在速度和精度上进行自由权衡。</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></div><div class="post_share"><div class="social-share" data-image="/img/1097380.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/02/29/AlexeyAB-DarkNet%E6%B1%A0%E5%8C%96%E5%B1%82%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(maxpool_layer.c)/"><img class="prev-cover" src="/img/34125236_p0.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">AlexeyAB DarkNet池化层代码详解(maxpool_layer.c)</div></div></a></div><div class="next-post pull-right"><a href="/2020/02/28/YOLOV3%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3(yolo_layer.c)/"><img class="next-cover" src="/img/34125236_p0.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">YOLOV3损失函数代码详解(yolo_layer.c)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/05/09/Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection/" title="Perceptual Generative Adversarial Networks for Small Object Detection"><img class="cover" src="/img/34125236_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-09</div><div class="title">Perceptual Generative Adversarial Networks for Small Object Detection</div></div></a></div><div><a href="/2020/05/08/An-Analysis-of-Scale-Invariance-in-Object-Detection-–-SNIP/" title="An Analysis of Scale Invariance in Object Detection – SNIP"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-08</div><div class="title">An Analysis of Scale Invariance in Object Detection – SNIP</div></div></a></div><div><a href="/2020/05/08/回归损失函数：L1-loss,-L2-loss以及Smooth-L1-Loss的对比/" title="回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比"><img class="cover" src="/img/40356157_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-08</div><div class="title">回归损失函数：L1 loss, L2 loss以及Smooth L1 Loss的对比</div></div></a></div><div><a href="/2020/04/30/两阶段实时检测网络ThunderNet/" title="两阶段实时检测网络ThunderNet"><img class="cover" src="/img/34125236_p0.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-30</div><div class="title">两阶段实时检测网络ThunderNet</div></div></a></div><div><a href="/2020/04/23/SSD代码解析/" title="SSD代码解析"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-23</div><div class="title">SSD代码解析</div></div></a></div><div><a href="/2020/04/20/自适应空间特征融合-(ASFF)/" title="自适应空间特征融合 (ASFF)"><img class="cover" src="/img/1097380.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-20</div><div class="title">自适应空间特征融合 (ASFF)</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text"> 原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">2.</span> <span class="toc-text">批量归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E5%88%86%E8%BE%A8%E7%8E%87"><span class="toc-number">3.</span> <span class="toc-text">高分辨率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84Anchor%E6%9C%BA%E5%88%B6"><span class="toc-number">4.</span> <span class="toc-text">基于卷积的Anchor机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%B4%E5%BA%A6%E8%81%9A%E7%B1%BB"><span class="toc-number">5.</span> <span class="toc-text">维度聚类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B0Backbone-Darknet-19"><span class="toc-number">6.</span> <span class="toc-text">新Backbone:Darknet-19</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B4%E6%8E%A5%E4%BD%8D%E7%BD%AE%E9%A2%84%E6%B5%8B"><span class="toc-number">7.</span> <span class="toc-text">直接位置预测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%86%E7%B2%92%E5%BA%A6%E7%89%B9%E5%BE%81"><span class="toc-number">8.</span> <span class="toc-text">细粒度特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%AE%AD%E7%BB%83"><span class="toc-number">9.</span> <span class="toc-text">多尺度训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">10.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">11.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Qiyuan-Z</div><div class="footer_custom_text">昨日までの私は、もうどこにもいない</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><div class="search-dialog__title" id="algolia-search-title">Algolia</div><div id="algolia-input-panel"><div id="algolia-search-input"></div></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '2d10cfb27783db577e70',
      clientSecret: '154292876bb14966f6ae57304b67859617b08c94',
      repo: 'gitalk',
      owner: 'Qiyuan-Z',
      admin: ['Qiyuan-Z'],
      id: '6c040a5296a1bcdd63690193303b2872',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body></html>